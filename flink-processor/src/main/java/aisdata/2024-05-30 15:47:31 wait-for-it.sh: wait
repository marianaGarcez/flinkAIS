2024-05-30 15:47:37 2024-05-30 13:47:37,901 [main] DEBUG org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator  - CONNECTED: KeyGroupStreamPartitioner - 1 -2024-05-30 15:47:37 2024-05-30 13:47:37,957 [main] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils  - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2024-05-30 15:47:37 2024-05-30 13:47:37,958 [main] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils  - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2024-05-30 15:47:37 2024-05-30 13:47:37,958 [main] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils  - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2024-05-30 15:47:37 2024-05-30 13:47:37,958 [main] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils  - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2024-05-30 15:47:37 2024-05-30 13:47:37,958 [main] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils  - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2024-05-30 15:47:37 2024-05-30 13:47:37,958 [main] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils  - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2024-05-30 15:47:37 2024-05-30 13:47:37,959 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster  - Starting Flink Mini Cluster
2024-05-30 15:47:37 2024-05-30 13:47:37,959 [main] DEBUG org.apache.flink.runtime.minicluster.MiniCluster  - Using configuration MiniClusterConfiguration {singleRpcService=SHARED, numTaskManagers=1, commonBindAddress='null', config={taskmanager.memory.network.min=64 mb, taskmanager.cpu.cores=1000000.0, taskmanager.memory.task.off-heap.size=1099511627776 bytes, taskmanager.memory.jvm-metaspace.size=256 mb, execution.target=local, cluster.io-pool.size=4, taskmanager.network.sort-shuffle.min-buffers=16, taskmanager.memory.jvm-overhead.min=1 gb, rest.bind-port=0, taskmanager.memory.network.max=64 mb, taskmanager.memory.framework.off-heap.size=128 mb, execution.attached=true, taskmanager.memory.managed.size=128 mb, taskmanager.memory.framework.heap.size=128 mb, parallelism.default=8, taskmanager.numberOfTaskSlots=8, taskmanager.memory.task.heap.size=1099511627776 bytes, rest.address=localhost, taskmanager.memory.jvm-overhead.max=1 gb, akka.ask.timeout=PT5M}}
2024-05-30 15:47:37 2024-05-30 13:47:37,961 [main] DEBUG org.apache.flink.runtime.entrypoint.ClusterEntrypointUtils  - Picked /tmp randomly from the configured temporary directories to be used as working directory base.
2024-05-30 15:47:38 2024-05-30 13:47:38,200 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster  - Starting Metrics Registry
2024-05-30 15:47:38 2024-05-30 13:47:38,226 [main] INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl  - No metrics reporter configured, no metrics will be exposed/reported.
2024-05-30 15:47:38 2024-05-30 13:47:38,226 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster  - Starting RPC Service(s)
2024-05-30 15:47:38 2024-05-30 13:47:38,233 [main] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils  - Trying to start local actor system
2024-05-30 15:47:38 2024-05-30 13:47:38,236 [main] DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils  - Using akka configuration
2024-05-30 15:47:38  Config(SimpleConfigObject({"akka":{"actor":{"allow-java-serialization":"on","default-dispatcher":{"executor":"fork-join-executor","fork-join-executor":{"parallelism-factor":1,"parallelism-max":4,"parallelism-min":2},"throughput":15},"guardian-supervisor-strategy":"org.apache.flink.runtime.rpc.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"50s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2024-05-30 15:47:38 2024-05-30 13:47:38,699 [flink-akka.actor.default-dispatcher-7] INFO  akka.event.slf4j.Slf4jLogger  - Slf4jLogger started
2024-05-30 15:47:38 2024-05-30 13:47:38,711 [flink-akka.actor.default-dispatcher-7] DEBUG akka.event.EventStream  - logger log1-Slf4jLogger started
2024-05-30 15:47:38 2024-05-30 13:47:38,712 [flink-akka.actor.default-dispatcher-7] DEBUG akka.event.EventStream  - Default Loggers started
2024-05-30 15:47:38 2024-05-30 13:47:38,802 [main] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils  - Actor system started at akka://flink
2024-05-30 15:47:38 2024-05-30 13:47:38,812 [main] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils  - Trying to start local actor system
2024-05-30 15:47:38 2024-05-30 13:47:38,813 [main] DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils  - Using akka configuration
2024-05-30 15:47:38  Config(SimpleConfigObject({"akka":{"actor":{"allow-java-serialization":"on","default-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"thread-priority":1,"throughput":15,"type":"org.apache.flink.runtime.rpc.akka.PriorityThreadsDispatcher"},"guardian-supervisor-strategy":"org.apache.flink.runtime.rpc.akka.EscalatingSupervisorStrategy","supervisor-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"type":"Dispatcher"},"warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","logger-startup-timeout":"50s","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","serialize-messages":"off","stdout-loglevel":"OFF"}}))
2024-05-30 15:47:38 2024-05-30 13:47:38,827 [flink-metrics-7] INFO  akka.event.slf4j.Slf4jLogger  - Slf4jLogger started
2024-05-30 15:47:38 2024-05-30 13:47:38,829 [flink-metrics-7] DEBUG akka.event.EventStream  - logger log1-Slf4jLogger started
2024-05-30 15:47:38 2024-05-30 13:47:38,829 [flink-metrics-7] DEBUG akka.event.EventStream  - Default Loggers started
2024-05-30 15:47:38 2024-05-30 13:47:38,833 [main] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils  - Actor system started at akka://flink-metrics
2024-05-30 15:47:38 2024-05-30 13:47:38,841 [flink-metrics-akka.actor.supervisor-dispatcher-8] DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor  - Starting AkkaRpcActor with name MetricQueryService.
2024-05-30 15:47:38 2024-05-30 13:47:38,842 [main] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService  - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2024-05-30 15:47:38 2024-05-30 13:47:38,853 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.ClassLoader.ClassesLoaded.
2024-05-30 15:47:38 2024-05-30 13:47:38,854 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.ClassLoader.ClassesUnloaded.
2024-05-30 15:47:38 2024-05-30 13:47:38,855 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.GarbageCollector.PS Scavenge.Count.
2024-05-30 15:47:38 2024-05-30 13:47:38,855 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.GarbageCollector.PS Scavenge.Time.
2024-05-30 15:47:38 2024-05-30 13:47:38,856 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.GarbageCollector.PS MarkSweep.Count.
2024-05-30 15:47:38 2024-05-30 13:47:38,856 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.GarbageCollector.PS MarkSweep.Time.
2024-05-30 15:47:38 2024-05-30 13:47:38,856 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.Memory.Heap.Used.
2024-05-30 15:47:38 2024-05-30 13:47:38,856 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.Memory.Heap.Committed.
2024-05-30 15:47:38 2024-05-30 13:47:38,856 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.Memory.Heap.Max.
2024-05-30 15:47:38 2024-05-30 13:47:38,856 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.Memory.NonHeap.Used.
2024-05-30 15:47:38 2024-05-30 13:47:38,856 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.Memory.NonHeap.Committed.
2024-05-30 15:47:38 2024-05-30 13:47:38,857 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.Memory.NonHeap.Max.
2024-05-30 15:47:38 2024-05-30 13:47:38,857 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.Memory.Metaspace.Used.
2024-05-30 15:47:38 2024-05-30 13:47:38,857 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.Memory.Metaspace.Committed.
2024-05-30 15:47:38 2024-05-30 13:47:38,857 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.Memory.Metaspace.Max.
2024-05-30 15:47:38 2024-05-30 13:47:38,894 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.Memory.Direct.Count.
2024-05-30 15:47:38 2024-05-30 13:47:38,895 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.Memory.Direct.MemoryUsed.
2024-05-30 15:47:38 2024-05-30 13:47:38,895 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.Memory.Direct.TotalCapacity.
2024-05-30 15:47:38 2024-05-30 13:47:38,895 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.Memory.Mapped.Count.
2024-05-30 15:47:38 2024-05-30 13:47:38,895 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.Memory.Mapped.MemoryUsed.
2024-05-30 15:47:38 2024-05-30 13:47:38,895 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.Memory.Mapped.TotalCapacity.
2024-05-30 15:47:38 2024-05-30 13:47:38,896 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.Threads.Count.
2024-05-30 15:47:38 2024-05-30 13:47:38,896 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.CPU.Load.
2024-05-30 15:47:38 2024-05-30 13:47:38,897 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.Status.JVM.CPU.Time.
2024-05-30 15:47:38 2024-05-30 13:47:38,903 [main] INFO  org.apache.flink.runtime.blob.BlobServer  - Created BLOB server storage directory /tmp/minicluster_87d519ae097c9b15471c25350fb7f574/blobStorage
2024-05-30 15:47:38 2024-05-30 13:47:38,905 [main] DEBUG org.apache.flink.util.NetUtils  - Trying to open socket on port 0
2024-05-30 15:47:38 2024-05-30 13:47:38,912 [main] INFO  org.apache.flink.runtime.blob.BlobServer  - Started BLOB server at 0.0.0.0:39925 - max concurrent requests: 50 - max backlog: 1000
2024-05-30 15:47:38 2024-05-30 13:47:38,916 [main] DEBUG org.apache.flink.runtime.hadoop.HadoopDependency  - Checking whether hadoop common dependency in on classpath.
2024-05-30 15:47:38 2024-05-30 13:47:38,918 [main] DEBUG org.apache.flink.runtime.hadoop.HadoopDependency  - Hadoop common dependency cannot be found on classpath.
2024-05-30 15:47:38 2024-05-30 13:47:38,918 [main] INFO  org.apache.flink.runtime.security.token.KerberosDelegationTokenManagerFactory  - Cannot use kerberos delegation token manager because Hadoop cannot be found in the Classpath.
2024-05-30 15:47:38 2024-05-30 13:47:38,920 [main] DEBUG org.apache.flink.runtime.security.token.NoOpDelegationTokenManager  - NoOpDelegationTokenManager
2024-05-30 15:47:38 2024-05-30 13:47:38,922 [main] INFO  org.apache.flink.runtime.blob.PermanentBlobCache  - Created BLOB cache storage directory /tmp/minicluster_87d519ae097c9b15471c25350fb7f574/blobStorage
2024-05-30 15:47:38 2024-05-30 13:47:38,924 [main] INFO  org.apache.flink.runtime.blob.TransientBlobCache  - Created BLOB cache storage directory /tmp/minicluster_87d519ae097c9b15471c25350fb7f574/blobStorage
2024-05-30 15:47:38 2024-05-30 13:47:38,926 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster  - Starting 1 TaskManager(s)
2024-05-30 15:47:38 2024-05-30 13:47:38,929 [main] INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner  - Starting TaskManager with ResourceID: ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff
2024-05-30 15:47:38 2024-05-30 13:47:38,937 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.ClassLoader.ClassesLoaded.
2024-05-30 15:47:38 2024-05-30 13:47:38,937 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.ClassLoader.ClassesUnloaded.
2024-05-30 15:47:38 2024-05-30 13:47:38,937 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.GarbageCollector.PS Scavenge.Count.
2024-05-30 15:47:38 2024-05-30 13:47:38,937 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.GarbageCollector.PS Scavenge.Time.
2024-05-30 15:47:38 2024-05-30 13:47:38,937 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.GarbageCollector.PS MarkSweep.Count.
2024-05-30 15:47:38 2024-05-30 13:47:38,937 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.GarbageCollector.PS MarkSweep.Time.
2024-05-30 15:47:38 2024-05-30 13:47:38,937 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.Memory.Heap.Used.
2024-05-30 15:47:38 2024-05-30 13:47:38,937 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.Memory.Heap.Committed.
2024-05-30 15:47:38 2024-05-30 13:47:38,937 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.Memory.Heap.Max.
2024-05-30 15:47:38 2024-05-30 13:47:38,937 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.Memory.NonHeap.Used.
2024-05-30 15:47:38 2024-05-30 13:47:38,937 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.Memory.NonHeap.Committed.
2024-05-30 15:47:38 2024-05-30 13:47:38,937 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.Memory.NonHeap.Max.
2024-05-30 15:47:38 2024-05-30 13:47:38,938 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.Memory.Metaspace.Used.
2024-05-30 15:47:38 2024-05-30 13:47:38,938 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.Memory.Metaspace.Committed.
2024-05-30 15:47:38 2024-05-30 13:47:38,938 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.Memory.Metaspace.Max.
2024-05-30 15:47:38 2024-05-30 13:47:38,939 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.Memory.Direct.Count.
2024-05-30 15:47:38 2024-05-30 13:47:38,939 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.Memory.Direct.MemoryUsed.
2024-05-30 15:47:38 2024-05-30 13:47:38,939 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.Memory.Direct.TotalCapacity.
2024-05-30 15:47:38 2024-05-30 13:47:38,940 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.Memory.Mapped.Count.
2024-05-30 15:47:38 2024-05-30 13:47:38,941 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.Memory.Mapped.MemoryUsed.
2024-05-30 15:47:38 2024-05-30 13:47:38,941 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.Memory.Mapped.TotalCapacity.
2024-05-30 15:47:38 2024-05-30 13:47:38,941 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.Threads.Count.
2024-05-30 15:47:38 2024-05-30 13:47:38,941 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.CPU.Load.
2024-05-30 15:47:38 2024-05-30 13:47:38,941 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.JVM.CPU.Time.
2024-05-30 15:47:38 2024-05-30 13:47:38,943 [main] INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices  - Temporary file directory '/tmp': total 58 GB, usable 28 GB (48.28% usable)
2024-05-30 15:47:38 2024-05-30 13:47:38,944 [main] DEBUG org.apache.flink.runtime.io.disk.FileChannelManagerImpl  - FileChannelManager uses directory /tmp/flink-io-0726f083-917f-4bf8-a071-30246f00f7b7 for spill files.
2024-05-30 15:47:38 2024-05-30 13:47:38,945 [main] INFO  org.apache.flink.runtime.io.disk.iomanager.IOManager  - Created a new FileChannelManager for spilling of task related data to disk (joins, sorting, ...). Used directories:
2024-05-30 15:47:38     /tmp/flink-io-0726f083-917f-4bf8-a071-30246f00f7b7
2024-05-30 15:47:38 2024-05-30 13:47:38,950 [main] DEBUG org.apache.flink.runtime.io.disk.FileChannelManagerImpl  - FileChannelManager uses directory /tmp/flink-netty-shuffle-cdb9c452-aa5d-4d4d-8f21-8cf6d5e0207b for spill files.
2024-05-30 15:47:38 2024-05-30 13:47:38,951 [main] INFO  org.apache.flink.runtime.io.network.NettyShuffleServiceFactory  - Created a new FileChannelManager for storing result partitions of BLOCKING shuffles. Used directories:
2024-05-30 15:47:38     /tmp/flink-netty-shuffle-cdb9c452-aa5d-4d4d-8f21-8cf6d5e0207b
2024-05-30 15:47:39 2024-05-30 13:47:39,002 [main] INFO  org.apache.flink.runtime.io.network.buffer.NetworkBufferPool  - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2024-05-30 15:47:39 2024-05-30 13:47:39,004 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.Network.TotalMemorySegments.
2024-05-30 15:47:39 2024-05-30 13:47:39,004 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.Network.AvailableMemorySegments.
2024-05-30 15:47:39 2024-05-30 13:47:39,005 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.Shuffle.Netty.TotalMemorySegments.
2024-05-30 15:47:39 2024-05-30 13:47:39,005 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.Shuffle.Netty.TotalMemory.
2024-05-30 15:47:39 2024-05-30 13:47:39,006 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.Shuffle.Netty.AvailableMemorySegments.
2024-05-30 15:47:39 2024-05-30 13:47:39,006 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.Shuffle.Netty.AvailableMemory.
2024-05-30 15:47:39 2024-05-30 13:47:39,006 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.Shuffle.Netty.UsedMemorySegments.
2024-05-30 15:47:39 2024-05-30 13:47:39,007 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.Shuffle.Netty.UsedMemory.
2024-05-30 15:47:39 2024-05-30 13:47:39,007 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.Shuffle.Netty.RequestedMemoryUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,013 [main] INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment  - Starting the network environment and its components.
2024-05-30 15:47:39 2024-05-30 13:47:39,014 [main] DEBUG org.apache.flink.runtime.io.network.NettyShuffleEnvironment  - Starting network connection manager
2024-05-30 15:47:39 2024-05-30 13:47:39,014 [main] INFO  org.apache.flink.runtime.taskexecutor.KvStateService  - Starting the kvState service and its components.
2024-05-30 15:47:39 2024-05-30 13:47:39,018 [main] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Start TaskExecutorLocalStateStoresManager with local state root directories [Ljava.io.File;@841e575.
2024-05-30 15:47:39 2024-05-30 13:47:39,020 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.Flink.Memory.Managed.Used.
2024-05-30 15:47:39 2024-05-30 13:47:39,020 [main] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.Status.Flink.Memory.Managed.Total.
2024-05-30 15:47:39 2024-05-30 13:47:39,021 [main] DEBUG org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration  - Messages have a max timeout of 300000 ms
2024-05-30 15:47:39 2024-05-30 13:47:39,021 [main] INFO  org.apache.flink.configuration.Configuration  - Config uses fallback configuration key 'akka.ask.timeout' instead of key 'taskmanager.slot.timeout'
2024-05-30 15:47:39 2024-05-30 13:47:39,027 [flink-akka.actor.supervisor-dispatcher-8] DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor  - Starting AkkaRpcActor with name taskmanager_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,027 [main] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService  - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2024-05-30 15:47:39 2024-05-30 13:47:39,035 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService  - Start job leader service.
2024-05-30 15:47:39 2024-05-30 13:47:39,036 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.filecache.FileCache  - User file cache uses directory /tmp/flink-dist-cache-3234d74f-944f-4feb-9d62-91e624cf9f91
2024-05-30 15:47:39 2024-05-30 13:47:39,036 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor  - Recovered slot allocation snapshots [].
2024-05-30 15:47:39 2024-05-30 13:47:39,057 [main] INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Upload directory /tmp/flink-web-upload does not exist. 
2024-05-30 15:47:39 2024-05-30 13:47:39,057 [main] INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Created directory /tmp/flink-web-upload for file uploads.
2024-05-30 15:47:39 2024-05-30 13:47:39,059 [main] DEBUG org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory  - Starting Dispatcher REST endpoint.
2024-05-30 15:47:39 2024-05-30 13:47:39,059 [main] INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Starting rest endpoint.
2024-05-30 15:47:39 2024-05-30 13:47:39,060 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Failed to load web based job submission extension.
2024-05-30 15:47:39 2024-05-30 13:47:39,175 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.logging.InternalLoggerFactory  - Using SLF4J as the default logging framework
2024-05-30 15:47:39 2024-05-30 13:47:39,176 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.InternalThreadLocalMap  - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2024-05-30 15:47:39 2024-05-30 13:47:39,176 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.InternalThreadLocalMap  - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2024-05-30 15:47:39 2024-05-30 13:47:39,247 [main] WARN  org.apache.flink.runtime.webmonitor.WebMonitorUtils  - Log file environment variable 'log.file' is not set.
2024-05-30 15:47:39 2024-05-30 13:47:39,247 [main] WARN  org.apache.flink.runtime.webmonitor.WebMonitorUtils  - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
2024-05-30 15:47:39 2024-05-30 13:47:39,261 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0  - -Dio.netty.noUnsafe: false
2024-05-30 15:47:39 2024-05-30 13:47:39,261 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0  - Java version: 8
2024-05-30 15:47:39 2024-05-30 13:47:39,262 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0  - sun.misc.Unsafe.theUnsafe: available
2024-05-30 15:47:39 2024-05-30 13:47:39,262 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0  - sun.misc.Unsafe.copyMemory: available
2024-05-30 15:47:39 2024-05-30 13:47:39,262 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0  - java.nio.Buffer.address: available
2024-05-30 15:47:39 2024-05-30 13:47:39,262 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0  - direct buffer constructor: available
2024-05-30 15:47:39 2024-05-30 13:47:39,262 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0  - java.nio.Bits.unaligned: available, true
2024-05-30 15:47:39 2024-05-30 13:47:39,262 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0  - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2024-05-30 15:47:39 2024-05-30 13:47:39,263 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0  - java.nio.DirectByteBuffer.<init>(long, int): available
2024-05-30 15:47:39 2024-05-30 13:47:39,263 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent  - sun.misc.Unsafe: available
2024-05-30 15:47:39 2024-05-30 13:47:39,263 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent  - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
2024-05-30 15:47:39 2024-05-30 13:47:39,263 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent  - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2024-05-30 15:47:39 2024-05-30 13:47:39,263 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent  - -Dio.netty.maxDirectMemory: 1828716544 bytes
2024-05-30 15:47:39 2024-05-30 13:47:39,263 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent  - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2024-05-30 15:47:39 2024-05-30 13:47:39,263 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.CleanerJava6  - java.nio.ByteBuffer.cleaner(): available
2024-05-30 15:47:39 2024-05-30 13:47:39,264 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent  - -Dio.netty.noPreferDirect: false
2024-05-30 15:47:39 2024-05-30 13:47:39,266 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@5f84abe8 under DELETE@/v1/cluster.
2024-05-30 15:47:39 2024-05-30 13:47:39,266 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@5f84abe8 under DELETE@/cluster.
2024-05-30 15:47:39 2024-05-30 13:47:39,266 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@76954a33 under GET@/v1/config.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@76954a33 under GET@/config.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@24a298a6 under GET@/v1/datasets.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetListHandler@24a298a6 under GET@/datasets.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@982bb90 under GET@/v1/datasets/delete/:triggerid.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteStatusHandler@982bb90 under GET@/datasets/delete/:triggerid.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@27f74733 under DELETE@/v1/datasets/:datasetid.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.dataset.ClusterDataSetDeleteHandlers$ClusterDataSetDeleteTriggerHandler@27f74733 under DELETE@/datasets/:datasetid.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@7bef452c under GET@/v1/jobmanager/config.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@7bef452c under GET@/jobmanager/config.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerEnvironmentHandler@4bb8855f under GET@/v1/jobmanager/environment.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerEnvironmentHandler@4bb8855f under GET@/jobmanager/environment.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@57fae983 under GET@/v1/jobmanager/log.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@57fae983 under GET@/jobmanager/log.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@4a29f290 under GET@/v1/jobmanager/logs.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogListHandler@4a29f290 under GET@/jobmanager/logs.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@4bee18dc under GET@/v1/jobmanager/logs/:filename.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler@4bee18dc under GET@/jobmanager/logs/:filename.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@44f3fe83 under GET@/v1/jobmanager/metrics.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@44f3fe83 under GET@/jobmanager/metrics.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@44c5a16f under GET@/v1/jobmanager/stdout.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerLogFileHandler@44c5a16f under GET@/jobmanager/stdout.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerThreadDumpHandler@417d6615 under GET@/v1/jobmanager/thread-dump.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.JobManagerThreadDumpHandler@417d6615 under GET@/jobmanager/thread-dump.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@7a6ebe1e under GET@/v1/jobs.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@7a6ebe1e under GET@/jobs.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@21325036 under POST@/v1/jobs.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@21325036 under POST@/jobs.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@489543a6 under GET@/v1/jobs/metrics.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@489543a6 under GET@/jobs/metrics.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@6272c96f under GET@/v1/jobs/overview.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@6272c96f under GET@/jobs/overview.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@6de30571 under GET@/v1/jobs/:jobid.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@6de30571 under GET@/jobs/:jobid.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@5ee34b1b under PATCH@/v1/jobs/:jobid.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@5ee34b1b under PATCH@/jobs/:jobid.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@3c89bb12 under GET@/v1/jobs/:jobid/accumulators.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@3c89bb12 under GET@/jobs/:jobid/accumulators.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@48c4245d under GET@/v1/jobs/:jobid/checkpoints.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@48c4245d under GET@/jobs/:jobid/checkpoints.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@3df978b9 under GET@/v1/jobs/:jobid/checkpoints/config.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@3df978b9 under GET@/jobs/:jobid/checkpoints/config.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@7906578e under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@7906578e under GET@/jobs/:jobid/checkpoints/details/:checkpointid.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@8a62297 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@8a62297 under GET@/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@61a91912 under GET@/v1/jobs/:jobid/config.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@61a91912 under GET@/jobs/:jobid/config.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@1763992e under POST@/v1/jobs/:jobid/coordinators/:operatorid.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler@1763992e under POST@/jobs/:jobid/coordinators/:operatorid.
2024-05-30 15:47:39 2024-05-30 13:47:39,267 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@5c92166b under GET@/v1/jobs/:jobid/exceptions.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@5c92166b under GET@/jobs/:jobid/exceptions.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@659925f4 under GET@/v1/jobs/:jobid/execution-result.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@659925f4 under GET@/jobs/:jobid/execution-result.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobManagerJobConfigurationHandler@4cd1c1dc under GET@/v1/jobs/:jobid/jobmanager/config.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobManagerJobConfigurationHandler@4cd1c1dc under GET@/jobs/:jobid/jobmanager/config.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobManagerJobEnvironmentHandler@47f08b81 under GET@/v1/jobs/:jobid/jobmanager/environment.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobManagerJobEnvironmentHandler@47f08b81 under GET@/jobs/:jobid/jobmanager/environment.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.GeneratedLogUrlHandler@b9dfc5a under GET@/v1/jobs/:jobid/jobmanager/log-url.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.GeneratedLogUrlHandler@b9dfc5a under GET@/jobs/:jobid/jobmanager/log-url.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@2787de58 under GET@/v1/jobs/:jobid/metrics.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@2787de58 under GET@/jobs/:jobid/metrics.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@659a2455 under GET@/v1/jobs/:jobid/plan.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@659a2455 under GET@/jobs/:jobid/plan.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@267517e4 under PATCH@/v1/jobs/:jobid/rescaling.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@267517e4 under PATCH@/jobs/:jobid/rescaling.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@426e505c under GET@/v1/jobs/:jobid/rescaling/:triggerid.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@426e505c under GET@/jobs/:jobid/rescaling/:triggerid.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@5b022357 under POST@/v1/jobs/:jobid/savepoints.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@5b022357 under POST@/jobs/:jobid/savepoints.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@6f8e0cee under GET@/v1/jobs/:jobid/savepoints/:triggerid.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@6f8e0cee under GET@/jobs/:jobid/savepoints/:triggerid.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobStatusHandler@614aeccc under GET@/v1/jobs/:jobid/status.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobStatusHandler@614aeccc under GET@/jobs/:jobid/status.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@5116ac09 under POST@/v1/jobs/:jobid/stop.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@5116ac09 under POST@/jobs/:jobid/stop.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.GeneratedLogUrlHandler@1bc425e7 under GET@/v1/jobs/:jobid/taskmanagers/:taskmanagerid/log-url.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.GeneratedLogUrlHandler@1bc425e7 under GET@/jobs/:jobid/taskmanagers/:taskmanagerid/log-url.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@4b2a30d under GET@/v1/jobs/:jobid/vertices/:vertexid.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@4b2a30d under GET@/jobs/:jobid/vertices/:vertexid.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@322803db under GET@/v1/jobs/:jobid/vertices/:vertexid/accumulators.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@322803db under GET@/jobs/:jobid/vertices/:vertexid/accumulators.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@56ba8773 under GET@/v1/jobs/:jobid/vertices/:vertexid/backpressure.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@56ba8773 under GET@/jobs/:jobid/vertices/:vertexid/backpressure.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexFlameGraphHandler$DisabledJobVertexFlameGraphHandler@6ceb7b5e under GET@/v1/jobs/:jobid/vertices/:vertexid/flamegraph.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexFlameGraphHandler$DisabledJobVertexFlameGraphHandler@6ceb7b5e under GET@/jobs/:jobid/vertices/:vertexid/flamegraph.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@7dd00705 under GET@/v1/jobs/:jobid/vertices/:vertexid/metrics.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@7dd00705 under GET@/jobs/:jobid/vertices/:vertexid/metrics.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@f14e5bf under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@f14e5bf under GET@/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@d176a31 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@d176a31 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@3a91d146 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@3a91d146 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@4784013e under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@4784013e under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@6f952d6c under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2024-05-30 15:47:39 2024-05-30 13:47:39,268 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@6f952d6c under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@5965844d under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@5965844d under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@6d4a65c6 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasktimes.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@6d4a65c6 under GET@/jobs/:jobid/vertices/:vertexid/subtasktimes.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@aa004a0 under GET@/v1/jobs/:jobid/vertices/:vertexid/taskmanagers.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@aa004a0 under GET@/jobs/:jobid/vertices/:vertexid/taskmanagers.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@4c98a6d5 under GET@/v1/jobs/:jobid/vertices/:vertexid/watermarks.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@4c98a6d5 under GET@/jobs/:jobid/vertices/:vertexid/watermarks.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@392a04e7 under GET@/v1/jobs/:jobid/yarn-cancel.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@392a04e7 under GET@/jobs/:jobid/yarn-cancel.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@7f02251 under GET@/v1/jobs/:jobid/yarn-stop.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@7f02251 under GET@/jobs/:jobid/yarn-stop.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@dffa30b under GET@/v1/overview.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@dffa30b under GET@/overview.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@4d8126f under POST@/v1/savepoint-disposal.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@4d8126f under POST@/savepoint-disposal.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@6d3c232f under GET@/v1/savepoint-disposal/:triggerid.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@6d3c232f under GET@/savepoint-disposal/:triggerid.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@6b587673 under GET@/v1/taskmanagers.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@6b587673 under GET@/taskmanagers.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@1bcf67e8 under GET@/v1/taskmanagers/metrics.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@1bcf67e8 under GET@/taskmanagers/metrics.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@5f404594 under GET@/v1/taskmanagers/:taskmanagerid.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@5f404594 under GET@/taskmanagers/:taskmanagerid.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@53692008 under GET@/v1/taskmanagers/:taskmanagerid/log.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@53692008 under GET@/taskmanagers/:taskmanagerid/log.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@7b2a3ff8 under GET@/v1/taskmanagers/:taskmanagerid/logs.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogListHandler@7b2a3ff8 under GET@/taskmanagers/:taskmanagerid/logs.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@1bbae752 under GET@/v1/taskmanagers/:taskmanagerid/logs/:filename.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerCustomLogHandler@1bbae752 under GET@/taskmanagers/:taskmanagerid/logs/:filename.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@460b6d54 under GET@/v1/taskmanagers/:taskmanagerid/metrics.
2024-05-30 15:47:39 2024-05-30 13:47:39,269 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@460b6d54 under GET@/taskmanagers/:taskmanagerid/metrics.
2024-05-30 15:47:39 2024-05-30 13:47:39,270 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@5cf87cfd under GET@/v1/taskmanagers/:taskmanagerid/stdout.
2024-05-30 15:47:39 2024-05-30 13:47:39,270 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@5cf87cfd under GET@/taskmanagers/:taskmanagerid/stdout.
2024-05-30 15:47:39 2024-05-30 13:47:39,270 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@76075d65 under GET@/v1/taskmanagers/:taskmanagerid/thread-dump.
2024-05-30 15:47:39 2024-05-30 13:47:39,270 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerThreadDumpHandler@76075d65 under GET@/taskmanagers/:taskmanagerid/thread-dump.
2024-05-30 15:47:39 2024-05-30 13:47:39,273 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.channel.MultithreadEventLoopGroup  - -Dio.netty.eventLoopThreads: 16
2024-05-30 15:47:39 2024-05-30 13:47:39,288 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - -Dio.netty.noKeySetOptimization: false
2024-05-30 15:47:39 2024-05-30 13:47:39,288 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - -Dio.netty.selectorAutoRebuildThreshold: 512
2024-05-30 15:47:39 2024-05-30 13:47:39,292 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent  - org.jctools-core.MpscChunkedArrayQueue: available
2024-05-30 15:47:39 2024-05-30 13:47:39,295 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@c81fd12
2024-05-30 15:47:39 2024-05-30 13:47:39,295 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@47d7bfb3
2024-05-30 15:47:39 2024-05-30 13:47:39,295 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@770b3be0
2024-05-30 15:47:39 2024-05-30 13:47:39,296 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@1eb6e1c
2024-05-30 15:47:39 2024-05-30 13:47:39,296 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@51dbd6e4
2024-05-30 15:47:39 2024-05-30 13:47:39,296 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@2b8bd14b
2024-05-30 15:47:39 2024-05-30 13:47:39,296 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@5f13be1
2024-05-30 15:47:39 2024-05-30 13:47:39,296 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@5f303ecd
2024-05-30 15:47:39 2024-05-30 13:47:39,296 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@50d3bf39
2024-05-30 15:47:39 2024-05-30 13:47:39,296 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@25a73de1
2024-05-30 15:47:39 2024-05-30 13:47:39,296 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@29852487
2024-05-30 15:47:39 2024-05-30 13:47:39,296 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@771db12c
2024-05-30 15:47:39 2024-05-30 13:47:39,296 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@3afae281
2024-05-30 15:47:39 2024-05-30 13:47:39,296 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@26ae880a
2024-05-30 15:47:39 2024-05-30 13:47:39,296 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@260f2144
2024-05-30 15:47:39 2024-05-30 13:47:39,296 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@3c017078
2024-05-30 15:47:39 2024-05-30 13:47:39,296 [main] TRACE org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop  - instrumented a special java.util.Set into: sun.nio.ch.EPollSelectorImpl@51827393
2024-05-30 15:47:39 2024-05-30 13:47:39,308 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.channel.DefaultChannelId  - -Dio.netty.processId: 1 (auto-detected)
2024-05-30 15:47:39 2024-05-30 13:47:39,312 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtilInitializations  - Loopback interface: lo (lo, 127.0.0.1)
2024-05-30 15:47:39 2024-05-30 13:47:39,312 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.NetUtil  - /proc/sys/net/core/somaxconn: 4096
2024-05-30 15:47:39 2024-05-30 13:47:39,313 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.channel.DefaultChannelId  - -Dio.netty.machineId: 02:42:ac:ff:fe:12:00:05 (auto-detected)
2024-05-30 15:47:39 2024-05-30 13:47:39,320 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.ResourceLeakDetector  - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.level: simple
2024-05-30 15:47:39 2024-05-30 13:47:39,320 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.util.ResourceLeakDetector  - -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.targetRecords: 4
2024-05-30 15:47:39 2024-05-30 13:47:39,335 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.numHeapArenas: 16
2024-05-30 15:47:39 2024-05-30 13:47:39,335 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.numDirectArenas: 16
2024-05-30 15:47:39 2024-05-30 13:47:39,335 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.pageSize: 8192
2024-05-30 15:47:39 2024-05-30 13:47:39,335 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.maxOrder: 11
2024-05-30 15:47:39 2024-05-30 13:47:39,335 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.chunkSize: 16777216
2024-05-30 15:47:39 2024-05-30 13:47:39,335 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.smallCacheSize: 256
2024-05-30 15:47:39 2024-05-30 13:47:39,335 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.normalCacheSize: 64
2024-05-30 15:47:39 2024-05-30 13:47:39,335 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2024-05-30 15:47:39 2024-05-30 13:47:39,335 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.cacheTrimInterval: 8192
2024-05-30 15:47:39 2024-05-30 13:47:39,335 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2024-05-30 15:47:39 2024-05-30 13:47:39,335 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.useCacheForAllThreads: true
2024-05-30 15:47:39 2024-05-30 13:47:39,335 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator  - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2024-05-30 15:47:39 2024-05-30 13:47:39,341 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.ByteBufUtil  - -Dio.netty.allocator.type: pooled
2024-05-30 15:47:39 2024-05-30 13:47:39,341 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.ByteBufUtil  - -Dio.netty.threadLocalDirectBufferSize: 0
2024-05-30 15:47:39 2024-05-30 13:47:39,341 [main] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.ByteBufUtil  - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2024-05-30 15:47:39 2024-05-30 13:47:39,348 [main] DEBUG org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Binding rest endpoint to null:0.
2024-05-30 15:47:39 2024-05-30 13:47:39,348 [main] INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - Rest endpoint listening at localhost:34011
2024-05-30 15:47:39 2024-05-30 13:47:39,349 [main] INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService  - Proposing leadership to contender http://localhost:34011
2024-05-30 15:47:39 2024-05-30 13:47:39,351 [mini-cluster-io-thread-1] INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint  - http://localhost:34011 was granted leadership with leaderSessionID=9af869cf-9339-412a-a2d9-f694a2668ac1
2024-05-30 15:47:39 2024-05-30 13:47:39,351 [mini-cluster-io-thread-1] INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService  - Received confirmation of leadership for leader http://localhost:34011 , session=9af869cf-9339-412a-a2d9-f694a2668ac1
2024-05-30 15:47:39 2024-05-30 13:47:39,358 [main] DEBUG org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory  - Starting Dispatcher.
2024-05-30 15:47:39 2024-05-30 13:47:39,359 [main] INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService  - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2024-05-30 15:47:39 2024-05-30 13:47:39,360 [main] DEBUG org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory  - Starting ResourceManagerService.
2024-05-30 15:47:39 2024-05-30 13:47:39,360 [main] INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl  - Starting resource manager service.
2024-05-30 15:47:39 2024-05-30 13:47:39,361 [main] INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService  - Proposing leadership to contender LeaderContender: ResourceManagerServiceImpl
2024-05-30 15:47:39 2024-05-30 13:47:39,361 [mini-cluster-io-thread-2] INFO  org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner  - DefaultDispatcherRunner was granted leadership with leader id c90d1194-e310-40cc-b506-a67381241132. Creating new DispatcherLeaderProcess.
2024-05-30 15:47:39 2024-05-30 13:47:39,363 [pool-2-thread-1] INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl  - Resource manager service is granted leadership with session id 98309392-36c4-4fc2-8cf2-8941f3cfcd91.
2024-05-30 15:47:39 2024-05-30 13:47:39,365 [mini-cluster-io-thread-2] INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess  - Start SessionDispatcherLeaderProcess.
2024-05-30 15:47:39 2024-05-30 13:47:39,366 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster  - Flink Mini Cluster started successfully
2024-05-30 15:47:39 2024-05-30 13:47:39,367 [mini-cluster-io-thread-4] INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess  - Recover all persisted job graphs that are not finished, yet.
2024-05-30 15:47:39 2024-05-30 13:47:39,368 [mini-cluster-io-thread-4] INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess  - Successfully recovered 0 persisted job graphs.
2024-05-30 15:47:39 2024-05-30 13:47:39,374 [flink-akka.actor.supervisor-dispatcher-8] DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor  - Starting FencedAkkaRpcActor with name resourcemanager_1.
2024-05-30 15:47:39 2024-05-30 13:47:39,375 [pool-2-thread-1] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService  - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2024-05-30 15:47:39 2024-05-30 13:47:39,376 [flink-akka.actor.supervisor-dispatcher-8] DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor  - Starting FencedAkkaRpcActor with name dispatcher_2.
2024-05-30 15:47:39 2024-05-30 13:47:39,378 [mini-cluster-io-thread-4] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService  - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
2024-05-30 15:47:39 2024-05-30 13:47:39,391 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.numRunningJobs.
2024-05-30 15:47:39 2024-05-30 13:47:39,391 [mini-cluster-io-thread-4] INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService  - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=c90d1194-e310-40cc-b506-a67381241132
2024-05-30 15:47:39 2024-05-30 13:47:39,392 [mini-cluster-io-thread-2] DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService  - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2024-05-30 15:47:39 2024-05-30 13:47:39,392 [mini-cluster-io-thread-1] DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService  - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/dispatcher_2. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2024-05-30 15:47:39 2024-05-30 13:47:39,399 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Starting the resource manager.
2024-05-30 15:47:39 2024-05-30 13:47:39,399 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.numRegisteredTaskManagers.
2024-05-30 15:47:39 2024-05-30 13:47:39,402 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Starting the slot manager.
2024-05-30 15:47:39 2024-05-30 13:47:39,404 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.taskSlotsAvailable.
2024-05-30 15:47:39 2024-05-30 13:47:39,405 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.taskSlotsTotal.
2024-05-30 15:47:39 2024-05-30 13:47:39,405 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.security.token.NoOpDelegationTokenManager  - start
2024-05-30 15:47:39 2024-05-30 13:47:39,405 [mini-cluster-io-thread-3] INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService  - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=98309392-36c4-4fc2-8cf2-8941f3cfcd91
2024-05-30 15:47:39 2024-05-30 13:47:39,405 [mini-cluster-io-thread-3] DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService  - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2024-05-30 15:47:39 2024-05-30 13:47:39,406 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Trigger heartbeat request.
2024-05-30 15:47:39 2024-05-30 13:47:39,406 [mini-cluster-io-thread-3] DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService  - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2024-05-30 15:47:39 2024-05-30 13:47:39,406 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Trigger heartbeat request.
2024-05-30 15:47:39 2024-05-30 13:47:39,408 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(8cf28941f3cfcd919830939236c44fc2).
2024-05-30 15:47:39 2024-05-30 13:47:39,412 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService  - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2024-05-30 15:47:39 2024-05-30 13:47:39,413 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Resolved ResourceManager address, beginning registration
2024-05-30 15:47:39 2024-05-30 13:47:39,413 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor  - Registration at ResourceManager attempt 1 (timeout=100ms)
2024-05-30 15:47:39 2024-05-30 13:47:39,414 [flink-akka.actor.default-dispatcher-11] DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService  - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2024-05-30 15:47:39 2024-05-30 13:47:39,417 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher  - Received JobGraph submission 'Average Speed by MMSI' (b2acee74555094750d6ee11d259188ed).
2024-05-30 15:47:39 2024-05-30 13:47:39,417 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher  - Submitting job 'Average Speed by MMSI' (b2acee74555094750d6ee11d259188ed).
2024-05-30 15:47:39 2024-05-30 13:47:39,417 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Registering TaskManager with ResourceID ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2024-05-30 15:47:39 2024-05-30 13:47:39,420 [flink-akka.actor.default-dispatcher-11] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor  - Registration with ResourceManager at akka://flink/user/rpc/resourcemanager_1 was successful.
2024-05-30 15:47:39 2024-05-30 13:47:39,420 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id 7f90e2a01ddd0421ecb568d96eaba705.
2024-05-30 15:47:39 2024-05-30 13:47:39,422 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Registering task executor ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff under 7f90e2a01ddd0421ecb568d96eaba705 at the slot manager.
2024-05-30 15:47:39 2024-05-30 13:47:39,428 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner  - Start leadership runner for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,428 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService  - Proposing leadership to contender LeaderContender: JobMasterServiceLeadershipRunner
2024-05-30 15:47:39 2024-05-30 13:47:39,429 [mini-cluster-io-thread-3] DEBUG org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner  - Create new JobMasterServiceProcess because we were granted leadership under 2ec32f4e-9f03-4c3c-91d2-0108919a251a.
2024-05-30 15:47:39 2024-05-30 13:47:39,430 [ForkJoinPool.commonPool-worker-3] DEBUG org.apache.flink.client.ClientUtils  - Wait until job initialization is finished
2024-05-30 15:47:39 2024-05-30 13:47:39,437 [flink-akka.actor.supervisor-dispatcher-8] DEBUG org.apache.flink.runtime.rpc.akka.SupervisorActor  - Starting FencedAkkaRpcActor with name jobmanager_3.
2024-05-30 15:47:39 2024-05-30 13:47:39,437 [jobmanager-io-thread-1] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService  - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2024-05-30 15:47:39 2024-05-30 13:47:39,442 [jobmanager-io-thread-1] INFO  org.apache.flink.runtime.jobmaster.JobMaster  - Initializing job 'Average Speed by MMSI' (b2acee74555094750d6ee11d259188ed).
2024-05-30 15:47:39 2024-05-30 13:47:39,446 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Using the request slot matching strategy: SimpleRequestSlotMatchingStrategy
2024-05-30 15:47:39 2024-05-30 13:47:39,453 [jobmanager-io-thread-1] INFO  org.apache.flink.runtime.jobmaster.JobMaster  - Using restart back off time strategy NoRestartBackoffTimeStrategy for Average Speed by MMSI (b2acee74555094750d6ee11d259188ed).
2024-05-30 15:47:39 2024-05-30 13:47:39,470 [jobmanager-io-thread-1] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Created execution graph b8f610225c2c775ea87fe3766e0e537c for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,480 [jobmanager-io-thread-1] INFO  org.apache.flink.runtime.jobmaster.JobMaster  - Running initialization on master for job Average Speed by MMSI (b2acee74555094750d6ee11d259188ed).
2024-05-30 15:47:39 2024-05-30 13:47:39,480 [jobmanager-io-thread-1] INFO  org.apache.flink.runtime.jobmaster.JobMaster  - Successfully ran initialization on master in 0 ms.
2024-05-30 15:47:39 2024-05-30 13:47:39,480 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Adding 2 vertices from job graph Average Speed by MMSI (b2acee74555094750d6ee11d259188ed).
2024-05-30 15:47:39 2024-05-30 13:47:39,480 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph  - Attaching 2 topologically sorted vertices to existing job graph with 0 vertices and 0 intermediate results.
2024-05-30 15:47:39 2024-05-30 13:47:39,494 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph  - Connecting ExecutionJobVertex e3dfc0d7e9ecd8a43f85f0b68ebf3b80 (Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map)) to 0 predecessors.
2024-05-30 15:47:39 2024-05-30 13:47:39,495 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph  - Connecting ExecutionJobVertex 87aa6a78642c52c526689f50e970e2b8 (TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out) to 1 predecessors.
2024-05-30 15:47:39 2024-05-30 13:47:39,495 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph  - Connecting input 0 of vertex 87aa6a78642c52c526689f50e970e2b8 (TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out) to intermediate result referenced via predecessor e3dfc0d7e9ecd8a43f85f0b68ebf3b80 (Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map)).
2024-05-30 15:47:39 2024-05-30 13:47:39,501 [jobmanager-io-thread-1] INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology  - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2024-05-30 15:47:39 2024-05-30 13:47:39,502 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Successfully created execution graph from job graph Average Speed by MMSI (b2acee74555094750d6ee11d259188ed).
2024-05-30 15:47:39 2024-05-30 13:47:39,505 [jobmanager-io-thread-1] INFO  org.apache.flink.runtime.jobmaster.JobMaster  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@79abbff6
2024-05-30 15:47:39 2024-05-30 13:47:39,505 [jobmanager-io-thread-1] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,506 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,506 [jobmanager-io-thread-1] INFO  org.apache.flink.runtime.jobmaster.JobMaster  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,514 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.totalNumberOfCheckpoints.
2024-05-30 15:47:39 2024-05-30 13:47:39,514 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.numberOfInProgressCheckpoints.
2024-05-30 15:47:39 2024-05-30 13:47:39,514 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.numberOfCompletedCheckpoints.
2024-05-30 15:47:39 2024-05-30 13:47:39,514 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.numberOfFailedCheckpoints.
2024-05-30 15:47:39 2024-05-30 13:47:39,515 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.lastCheckpointRestoreTimestamp.
2024-05-30 15:47:39 2024-05-30 13:47:39,515 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.lastCheckpointSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,515 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.lastCheckpointFullSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,515 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.lastCheckpointDuration.
2024-05-30 15:47:39 2024-05-30 13:47:39,515 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.lastCheckpointProcessedData.
2024-05-30 15:47:39 2024-05-30 13:47:39,516 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.lastCheckpointPersistedData.
2024-05-30 15:47:39 2024-05-30 13:47:39,516 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.lastCheckpointExternalPath.
2024-05-30 15:47:39 2024-05-30 13:47:39,523 [jobmanager-io-thread-1] INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator  - No checkpoint found during restore.
2024-05-30 15:47:39 2024-05-30 13:47:39,523 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.checkpoint.CheckpointCoordinator  - Resetting the master hooks.
2024-05-30 15:47:39 2024-05-30 13:47:39,526 [jobmanager-io-thread-1] INFO  org.apache.flink.runtime.jobmaster.JobMaster  - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@21782f95 for Average Speed by MMSI (b2acee74555094750d6ee11d259188ed).
2024-05-30 15:47:39 2024-05-30 13:47:39,532 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.jobmaster.DefaultJobMasterServiceProcess  - Successfully created the JobMasterService for job b2acee74555094750d6ee11d259188ed under leader id 2ec32f4e-9f03-4c3c-91d2-0108919a251a.
2024-05-30 15:47:39 2024-05-30 13:47:39,532 [jobmanager-io-thread-1] DEBUG org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner  - Confirm leadership 2ec32f4e-9f03-4c3c-91d2-0108919a251a.
2024-05-30 15:47:39 2024-05-30 13:47:39,532 [jobmanager-io-thread-1] INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService  - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=2ec32f4e-9f03-4c3c-91d2-0108919a251a
2024-05-30 15:47:39 2024-05-30 13:47:39,534 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.jobmaster.JobMaster  - Starting execution of job 'Average Speed by MMSI' (b2acee74555094750d6ee11d259188ed) under job master id 91d20108919a251a2ec32f4e9f034c3c.
2024-05-30 15:47:39 2024-05-30 13:47:39,534 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.downtime.
2024-05-30 15:47:39 2024-05-30 13:47:39,534 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.uptime.
2024-05-30 15:47:39 2024-05-30 13:47:39,534 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.numRestarts.
2024-05-30 15:47:39 2024-05-30 13:47:39,535 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.fullRestarts.
2024-05-30 15:47:39 2024-05-30 13:47:39,535 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.initializingTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,535 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.createdTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,535 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.runningTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,535 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.failingTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,535 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.cancellingTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,535 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.restartingTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,535 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric jobmanager.job.deployingTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,535 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator  - Starting split enumerator for source Source: Kafka Source.
2024-05-30 15:47:39 2024-05-30 13:47:39,538 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.jobmaster.JobMaster  - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2024-05-30 15:47:39 2024-05-30 13:47:39,538 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Job Average Speed by MMSI (b2acee74555094750d6ee11d259188ed) switched from state CREATED to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,540 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0) switched from CREATED to SCHEDULED.
2024-05-30 15:47:39 2024-05-30 13:47:39,540 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0) switched from CREATED to SCHEDULED.
2024-05-30 15:47:39 2024-05-30 13:47:39,540 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0) switched from CREATED to SCHEDULED.
2024-05-30 15:47:39 2024-05-30 13:47:39,540 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0) switched from CREATED to SCHEDULED.
2024-05-30 15:47:39 2024-05-30 13:47:39,540 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0) switched from CREATED to SCHEDULED.
2024-05-30 15:47:39 2024-05-30 13:47:39,540 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0) switched from CREATED to SCHEDULED.
2024-05-30 15:47:39 2024-05-30 13:47:39,540 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0) switched from CREATED to SCHEDULED.
2024-05-30 15:47:39 2024-05-30 13:47:39,540 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0) switched from CREATED to SCHEDULED.
2024-05-30 15:47:39 2024-05-30 13:47:39,540 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0) switched from CREATED to SCHEDULED.
2024-05-30 15:47:39 2024-05-30 13:47:39,540 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0) switched from CREATED to SCHEDULED.
2024-05-30 15:47:39 2024-05-30 13:47:39,540 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0) switched from CREATED to SCHEDULED.
2024-05-30 15:47:39 2024-05-30 13:47:39,540 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0) switched from CREATED to SCHEDULED.
2024-05-30 15:47:39 2024-05-30 13:47:39,540 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0) switched from CREATED to SCHEDULED.
2024-05-30 15:47:39 2024-05-30 13:47:39,540 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0) switched from CREATED to SCHEDULED.
2024-05-30 15:47:39 2024-05-30 13:47:39,540 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0) switched from CREATED to SCHEDULED.
2024-05-30 15:47:39 2024-05-30 13:47:39,540 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0) switched from CREATED to SCHEDULED.
2024-05-30 15:47:39 2024-05-30 13:47:39,544 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.PhysicalSlotProviderImpl  - Received slot request [SlotRequestId{f497bd41bbe68fc7eff949fc66856b30}] with resource requirements: ResourceProfile{UNKNOWN}
2024-05-30 15:47:39 2024-05-30 13:47:39,546 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Request new allocated slot with slot request id SlotRequestId{f497bd41bbe68fc7eff949fc66856b30} and resource profile ResourceProfile{UNKNOWN}
2024-05-30 15:47:39 2024-05-30 13:47:39,547 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Declare new resource requirements for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39     required resources: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-05-30 15:47:39     acquired resources: ResourceCounter{resources={}}
2024-05-30 15:47:39 2024-05-30 13:47:39,548 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.PhysicalSlotProviderImpl  - Received slot request [SlotRequestId{23c0657ff49acdd04febbd559dd62198}] with resource requirements: ResourceProfile{UNKNOWN}
2024-05-30 15:47:39 2024-05-30 13:47:39,548 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Request new allocated slot with slot request id SlotRequestId{23c0657ff49acdd04febbd559dd62198} and resource profile ResourceProfile{UNKNOWN}
2024-05-30 15:47:39 2024-05-30 13:47:39,548 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Declare new resource requirements for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39     required resources: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=2}]
2024-05-30 15:47:39     acquired resources: ResourceCounter{resources={}}
2024-05-30 15:47:39 2024-05-30 13:47:39,548 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.PhysicalSlotProviderImpl  - Received slot request [SlotRequestId{a70436baa078ea26d7de28d1b0518817}] with resource requirements: ResourceProfile{UNKNOWN}
2024-05-30 15:47:39 2024-05-30 13:47:39,548 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Request new allocated slot with slot request id SlotRequestId{a70436baa078ea26d7de28d1b0518817} and resource profile ResourceProfile{UNKNOWN}
2024-05-30 15:47:39 2024-05-30 13:47:39,548 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Declare new resource requirements for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39     required resources: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=3}]
2024-05-30 15:47:39     acquired resources: ResourceCounter{resources={}}
2024-05-30 15:47:39 2024-05-30 13:47:39,548 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.PhysicalSlotProviderImpl  - Received slot request [SlotRequestId{059c35af7302614e8b3071092f705708}] with resource requirements: ResourceProfile{UNKNOWN}
2024-05-30 15:47:39 2024-05-30 13:47:39,548 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Request new allocated slot with slot request id SlotRequestId{059c35af7302614e8b3071092f705708} and resource profile ResourceProfile{UNKNOWN}
2024-05-30 15:47:39 2024-05-30 13:47:39,548 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Declare new resource requirements for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39     required resources: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=4}]
2024-05-30 15:47:39     acquired resources: ResourceCounter{resources={}}
2024-05-30 15:47:39 2024-05-30 13:47:39,548 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.PhysicalSlotProviderImpl  - Received slot request [SlotRequestId{5e14a1e0af39d3b52e0954640c821def}] with resource requirements: ResourceProfile{UNKNOWN}
2024-05-30 15:47:39 2024-05-30 13:47:39,548 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Request new allocated slot with slot request id SlotRequestId{5e14a1e0af39d3b52e0954640c821def} and resource profile ResourceProfile{UNKNOWN}
2024-05-30 15:47:39 2024-05-30 13:47:39,548 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Declare new resource requirements for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39     required resources: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=5}]
2024-05-30 15:47:39     acquired resources: ResourceCounter{resources={}}
2024-05-30 15:47:39 2024-05-30 13:47:39,548 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.PhysicalSlotProviderImpl  - Received slot request [SlotRequestId{c02333c264dfd3051a234fe22622c2f1}] with resource requirements: ResourceProfile{UNKNOWN}
2024-05-30 15:47:39 2024-05-30 13:47:39,548 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Request new allocated slot with slot request id SlotRequestId{c02333c264dfd3051a234fe22622c2f1} and resource profile ResourceProfile{UNKNOWN}
2024-05-30 15:47:39 2024-05-30 13:47:39,548 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Declare new resource requirements for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39     required resources: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=6}]
2024-05-30 15:47:39     acquired resources: ResourceCounter{resources={}}
2024-05-30 15:47:39 2024-05-30 13:47:39,548 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.PhysicalSlotProviderImpl  - Received slot request [SlotRequestId{0f20990f681eb0b9d6fc8c171b440585}] with resource requirements: ResourceProfile{UNKNOWN}
2024-05-30 15:47:39 2024-05-30 13:47:39,549 [SourceCoordinator-Source: Kafka Source] INFO  org.apache.kafka.clients.admin.AdminClientConfig  - AdminClientConfig values: 
2024-05-30 15:47:39 2024-05-30 13:47:39,549 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Request new allocated slot with slot request id SlotRequestId{0f20990f681eb0b9d6fc8c171b440585} and resource profile ResourceProfile{UNKNOWN}
2024-05-30 15:47:39 2024-05-30 13:47:39,549 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Declare new resource requirements for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39     required resources: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=7}]
2024-05-30 15:47:39     acquired resources: ResourceCounter{resources={}}
2024-05-30 15:47:39 2024-05-30 13:47:39,549 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.PhysicalSlotProviderImpl  - Received slot request [SlotRequestId{fe72d375d30c21f396aa1676f93ff86c}] with resource requirements: ResourceProfile{UNKNOWN}
2024-05-30 15:47:39 2024-05-30 13:47:39,549 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Request new allocated slot with slot request id SlotRequestId{fe72d375d30c21f396aa1676f93ff86c} and resource profile ResourceProfile{UNKNOWN}
2024-05-30 15:47:39 2024-05-30 13:47:39,549 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Declare new resource requirements for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39     required resources: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=8}]
2024-05-30 15:47:39     acquired resources: ResourceCounter{resources={}}
2024-05-30 15:47:39 2024-05-30 13:47:39,549 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Request a logical slot (SlotRequestId{cdec5d7e6f80cc8c55ceead40844a6de}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4) from the physical slot (SlotRequestId{f497bd41bbe68fc7eff949fc66856b30})
2024-05-30 15:47:39 2024-05-30 13:47:39,550 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Request a logical slot (SlotRequestId{6dfe39a74733116ca63b9123e1b85905}) for execution vertex (id 87aa6a78642c52c526689f50e970e2b8_4) from the physical slot (SlotRequestId{f497bd41bbe68fc7eff949fc66856b30})
2024-05-30 15:47:39 2024-05-30 13:47:39,550 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Request a logical slot (SlotRequestId{d0d94fcff903a81c98c35387d2392bae}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7) from the physical slot (SlotRequestId{23c0657ff49acdd04febbd559dd62198})
2024-05-30 15:47:39 2024-05-30 13:47:39,550 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Request a logical slot (SlotRequestId{387dbcd95a3fdf9988205088f3d1ef3d}) for execution vertex (id 87aa6a78642c52c526689f50e970e2b8_7) from the physical slot (SlotRequestId{23c0657ff49acdd04febbd559dd62198})
2024-05-30 15:47:39 2024-05-30 13:47:39,550 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Request a logical slot (SlotRequestId{007cf8887286986af48feda4482981e2}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5) from the physical slot (SlotRequestId{a70436baa078ea26d7de28d1b0518817})
2024-05-30 15:47:39 2024-05-30 13:47:39,550 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Request a logical slot (SlotRequestId{8f1df5b0763a4bf432656e07b5111909}) for execution vertex (id 87aa6a78642c52c526689f50e970e2b8_5) from the physical slot (SlotRequestId{a70436baa078ea26d7de28d1b0518817})
2024-05-30 15:47:39 2024-05-30 13:47:39,550 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Request a logical slot (SlotRequestId{02e0a08f073bb50d6d68b19d23292e17}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3) from the physical slot (SlotRequestId{059c35af7302614e8b3071092f705708})
2024-05-30 15:47:39 2024-05-30 13:47:39,550 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Request a logical slot (SlotRequestId{b9505f778b4dedcebbb36048159c0252}) for execution vertex (id 87aa6a78642c52c526689f50e970e2b8_3) from the physical slot (SlotRequestId{059c35af7302614e8b3071092f705708})
2024-05-30 15:47:39 2024-05-30 13:47:39,550 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Request a logical slot (SlotRequestId{b8eb79b0bc3e16ad7d1f056d0e67ee20}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2) from the physical slot (SlotRequestId{5e14a1e0af39d3b52e0954640c821def})
2024-05-30 15:47:39 2024-05-30 13:47:39,550 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Request a logical slot (SlotRequestId{43df889df4f5dacaa47adfb493a2ef73}) for execution vertex (id 87aa6a78642c52c526689f50e970e2b8_2) from the physical slot (SlotRequestId{5e14a1e0af39d3b52e0954640c821def})
2024-05-30 15:47:39 2024-05-30 13:47:39,550 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Request a logical slot (SlotRequestId{b2b9571df94165885de8691002c42b83}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1) from the physical slot (SlotRequestId{c02333c264dfd3051a234fe22622c2f1})
2024-05-30 15:47:39 2024-05-30 13:47:39,550 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Request a logical slot (SlotRequestId{1f28d333b1869d5fae29dafcd69757be}) for execution vertex (id 87aa6a78642c52c526689f50e970e2b8_1) from the physical slot (SlotRequestId{c02333c264dfd3051a234fe22622c2f1})
2024-05-30 15:47:39 2024-05-30 13:47:39,550 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Request a logical slot (SlotRequestId{35dff5e94934b7f0819e330816493dfc}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0) from the physical slot (SlotRequestId{0f20990f681eb0b9d6fc8c171b440585})
2024-05-30 15:47:39 2024-05-30 13:47:39,550 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Request a logical slot (SlotRequestId{b59dc5715b907b59535a7b943f3bcff7}) for execution vertex (id 87aa6a78642c52c526689f50e970e2b8_0) from the physical slot (SlotRequestId{0f20990f681eb0b9d6fc8c171b440585})
2024-05-30 15:47:39 2024-05-30 13:47:39,550 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Request a logical slot (SlotRequestId{0ee4d58bfff2c0ca45885cd9c3437dfa}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6) from the physical slot (SlotRequestId{fe72d375d30c21f396aa1676f93ff86c})
2024-05-30 15:47:39 2024-05-30 13:47:39,550 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Request a logical slot (SlotRequestId{45eeea2f09d40c58a02e3a30c0d6c4d7}) for execution vertex (id 87aa6a78642c52c526689f50e970e2b8_6) from the physical slot (SlotRequestId{fe72d375d30c21f396aa1676f93ff86c})
2024-05-30 15:47:39 2024-05-30 13:47:39,553 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Trigger heartbeat request.
2024-05-30 15:47:39 2024-05-30 13:47:39,553 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.jobmaster.JobMaster  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(8cf28941f3cfcd919830939236c44fc2)
2024-05-30 15:47:39 2024-05-30 13:47:39,554 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService  - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/resourcemanager_1. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2024-05-30 15:47:39 2024-05-30 13:47:39,554 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.jobmaster.JobMaster  - Resolved ResourceManager address, beginning registration
2024-05-30 15:47:39 2024-05-30 13:47:39,554 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Registration at ResourceManager attempt 1 (timeout=100ms)
2024-05-30 15:47:39 2024-05-30 13:47:39,555 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.resourcemanager.DefaultJobLeaderIdService  - Add job b2acee74555094750d6ee11d259188ed to job leader id monitoring.
2024-05-30 15:47:39 2024-05-30 13:47:39,555 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Registering job manager 91d20108919a251a2ec32f4e9f034c3c@akka://flink/user/rpc/jobmanager_3 for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,555 [mini-cluster-io-thread-4] DEBUG org.apache.flink.runtime.resourcemanager.DefaultJobLeaderIdService  - Job b2acee74555094750d6ee11d259188ed has a new job leader 2ec32f4e-9f03-4c3c-91d2-0108919a251a@akka://flink/user/rpc/jobmanager_3.
2024-05-30 15:47:39 2024-05-30 13:47:39,555 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService  - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2024-05-30 15:47:39 2024-05-30 13:47:39,559 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Registered job manager 91d20108919a251a2ec32f4e9f034c3c@akka://flink/user/rpc/jobmanager_3 for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,560 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Registration with ResourceManager at akka://flink/user/rpc/resourcemanager_1 was successful.
2024-05-30 15:47:39 2024-05-30 13:47:39,562 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.jobmaster.JobMaster  - JobManager successfully registered at ResourceManager, leader id: 8cf28941f3cfcd919830939236c44fc2.
2024-05-30 15:47:39 2024-05-30 13:47:39,563 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Received resource requirements from job b2acee74555094750d6ee11d259188ed: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=8}]
2024-05-30 15:47:39 2024-05-30 13:47:39,563 [flink-akka.actor.default-dispatcher-10] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultResourceTracker  - Received notification for job b2acee74555094750d6ee11d259188ed having new resource requirements [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=8}].
2024-05-30 15:47:39 2024-05-30 13:47:39,564 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.DefaultResourceTracker  - Initiating tracking of resources for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,564 [flink-akka.actor.default-dispatcher-10] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.JobScopedResourceTracker  - There are 0 excess resources for job b2acee74555094750d6ee11d259188ed before re-assignment.
2024-05-30 15:47:39 2024-05-30 13:47:39,564 [flink-akka.actor.default-dispatcher-10] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.JobScopedResourceTracker  - There are 0 excess resources for job b2acee74555094750d6ee11d259188ed after re-assignment.
2024-05-30 15:47:39 2024-05-30 13:47:39,567 [SourceCoordinator-Source: Kafka Source] DEBUG org.apache.kafka.clients.admin.internals.AdminMetadataManager  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Setting bootstrap cluster metadata Cluster(id = null, nodes = [kafka:9092 (id: -1 rack: null)], partitions = [], controller = null).
2024-05-30 15:47:39 2024-05-30 13:47:39,573 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=count, group=kafka-metrics-count, description=total number of registered metrics, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,579 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-closed:
2024-05-30 15:47:39 2024-05-30 13:47:39,580 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=connection-close-total, group=admin-client-metrics, description=The total number of connections closed, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,580 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=connection-close-rate, group=admin-client-metrics, description=The number of connections closed per second, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,580 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-created:
2024-05-30 15:47:39 2024-05-30 13:47:39,581 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=connection-creation-total, group=admin-client-metrics, description=The total number of new connections established, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,581 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=connection-creation-rate, group=admin-client-metrics, description=The number of new connections established per second, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,581 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication:
2024-05-30 15:47:39 2024-05-30 13:47:39,581 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=successful-authentication-total, group=admin-client-metrics, description=The total number of connections with successful authentication, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,581 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=successful-authentication-rate, group=admin-client-metrics, description=The number of connections with successful authentication per second, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,581 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-reauthentication:
2024-05-30 15:47:39 2024-05-30 13:47:39,581 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=successful-reauthentication-total, group=admin-client-metrics, description=The total number of successful re-authentication of connections, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,582 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=successful-reauthentication-rate, group=admin-client-metrics, description=The number of successful re-authentication of connections per second, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,582 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication-no-reauth:
2024-05-30 15:47:39 2024-05-30 13:47:39,582 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=successful-authentication-no-reauth-total, group=admin-client-metrics, description=The total number of connections with successful authentication where the client does not support re-authentication, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,582 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-authentication:
2024-05-30 15:47:39 2024-05-30 13:47:39,582 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=failed-authentication-total, group=admin-client-metrics, description=The total number of connections with failed authentication, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,582 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=failed-authentication-rate, group=admin-client-metrics, description=The number of connections with failed authentication per second, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,582 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-reauthentication:
2024-05-30 15:47:39 2024-05-30 13:47:39,582 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=failed-reauthentication-total, group=admin-client-metrics, description=The total number of failed re-authentication of connections, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,582 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=failed-reauthentication-rate, group=admin-client-metrics, description=The number of failed re-authentication of connections per second, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,582 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name reauthentication-latency:
2024-05-30 15:47:39 2024-05-30 13:47:39,582 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=reauthentication-latency-max, group=admin-client-metrics, description=The max latency observed due to re-authentication, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,583 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=reauthentication-latency-avg, group=admin-client-metrics, description=The average latency observed due to re-authentication, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,583 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent-received:
2024-05-30 15:47:39 2024-05-30 13:47:39,583 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=network-io-total, group=admin-client-metrics, description=The total number of network operations (reads or writes) on all connections, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,584 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=network-io-rate, group=admin-client-metrics, description=The number of network operations (reads or writes) on all connections per second, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,584 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent:
2024-05-30 15:47:39 2024-05-30 13:47:39,584 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=outgoing-byte-total, group=admin-client-metrics, description=The total number of outgoing bytes sent to all servers, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,584 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=outgoing-byte-rate, group=admin-client-metrics, description=The number of outgoing bytes sent to all servers per second, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,584 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name requests-sent:
2024-05-30 15:47:39 2024-05-30 13:47:39,584 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-total, group=admin-client-metrics, description=The total number of requests sent, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,584 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-rate, group=admin-client-metrics, description=The number of requests sent per second, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,584 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-size-avg, group=admin-client-metrics, description=The average size of requests sent., tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,585 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-size-max, group=admin-client-metrics, description=The maximum size of any request sent., tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,585 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-received:
2024-05-30 15:47:39 2024-05-30 13:47:39,585 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=incoming-byte-total, group=admin-client-metrics, description=The total number of bytes read off all sockets, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,585 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=incoming-byte-rate, group=admin-client-metrics, description=The number of bytes read off all sockets per second, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,585 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name responses-received:
2024-05-30 15:47:39 2024-05-30 13:47:39,585 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=response-total, group=admin-client-metrics, description=The total number of responses received, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,585 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=response-rate, group=admin-client-metrics, description=The number of responses received per second, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,585 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name select-time:
2024-05-30 15:47:39 2024-05-30 13:47:39,585 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=select-total, group=admin-client-metrics, description=The total number of times the I/O layer checked for new I/O to perform, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,585 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=select-rate, group=admin-client-metrics, description=The number of times the I/O layer checked for new I/O to perform per second, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,585 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=io-wait-time-ns-avg, group=admin-client-metrics, description=The average length of time the I/O thread spent waiting for a socket ready for reads or writes in nanoseconds., tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,585 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=io-waittime-total, group=admin-client-metrics, description=*Deprecated* The total time the I/O thread spent waiting, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,585 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=io-wait-ratio, group=admin-client-metrics, description=*Deprecated* The fraction of time the I/O thread spent waiting, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,586 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=io-wait-time-ns-total, group=admin-client-metrics, description=The total time the I/O thread spent waiting, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,586 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name io-time:
2024-05-30 15:47:39 2024-05-30 13:47:39,586 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=io-time-ns-avg, group=admin-client-metrics, description=The average length of time for I/O per select call in nanoseconds., tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,586 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=iotime-total, group=admin-client-metrics, description=*Deprecated* The total time the I/O thread spent doing I/O, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,586 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=io-ratio, group=admin-client-metrics, description=*Deprecated* The fraction of time the I/O thread spent doing I/O, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,586 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=io-time-ns-total, group=admin-client-metrics, description=The total time the I/O thread spent doing I/O, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,587 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.network.Selector  - [AdminClient clientId=flink_consumer-enumerator-admin-client] sslCiphers: created new gauge suite with maxEntries = 100.
2024-05-30 15:47:39 2024-05-30 13:47:39,587 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.network.Selector  - [AdminClient clientId=flink_consumer-enumerator-admin-client] clients: created new gauge suite with maxEntries = 100.
2024-05-30 15:47:39 2024-05-30 13:47:39,588 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=connection-count, group=admin-client-metrics, description=The current number of active connections., tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,594 [SourceCoordinator-Source: Kafka Source] WARN  org.apache.kafka.clients.admin.AdminClientConfig  - The configuration 'key.deserializer' was supplied but isn't a known config.
2024-05-30 15:47:39 2024-05-30 13:47:39,594 [SourceCoordinator-Source: Kafka Source] WARN  org.apache.kafka.clients.admin.AdminClientConfig  - The configuration 'value.deserializer' was supplied but isn't a known config.
2024-05-30 15:47:39 2024-05-30 13:47:39,594 [SourceCoordinator-Source: Kafka Source] WARN  org.apache.kafka.clients.admin.AdminClientConfig  - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2024-05-30 15:47:39 2024-05-30 13:47:39,594 [SourceCoordinator-Source: Kafka Source] WARN  org.apache.kafka.clients.admin.AdminClientConfig  - The configuration 'group.id' was supplied but isn't a known config.
2024-05-30 15:47:39 2024-05-30 13:47:39,594 [SourceCoordinator-Source: Kafka Source] WARN  org.apache.kafka.clients.admin.AdminClientConfig  - The configuration 'client.id.prefix' was supplied but isn't a known config.
2024-05-30 15:47:39 2024-05-30 13:47:39,594 [SourceCoordinator-Source: Kafka Source] WARN  org.apache.kafka.clients.admin.AdminClientConfig  - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2024-05-30 15:47:39 2024-05-30 13:47:39,594 [SourceCoordinator-Source: Kafka Source] WARN  org.apache.kafka.clients.admin.AdminClientConfig  - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2024-05-30 15:47:39 2024-05-30 13:47:39,595 [SourceCoordinator-Source: Kafka Source] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka version: 3.2.3
2024-05-30 15:47:39 2024-05-30 13:47:39,595 [SourceCoordinator-Source: Kafka Source] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka commitId: 50029d3ed8ba576f
2024-05-30 15:47:39 2024-05-30 13:47:39,595 [SourceCoordinator-Source: Kafka Source] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka startTimeMs: 1717076859594
2024-05-30 15:47:39 2024-05-30 13:47:39,596 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=version, group=app-info, description=Metric indicating version, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,596 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=commit-id, group=app-info, description=Metric indicating commit-id, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,596 [SourceCoordinator-Source: Kafka Source] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=start-time-ms, group=app-info, description=Metric indicating start-time-ms, tags={client-id=flink_consumer-enumerator-admin-client}]
2024-05-30 15:47:39 2024-05-30 13:47:39,596 [SourceCoordinator-Source: Kafka Source] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Kafka admin client initialized
2024-05-30 15:47:39 2024-05-30 13:47:39,597 [SourceCoordinator-Source: Kafka Source] INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator  - Starting the KafkaSourceEnumerator for consumer group flink_consumer without periodic partition discovery.
2024-05-30 15:47:39 2024-05-30 13:47:39,597 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Thread starting
2024-05-30 15:47:39 2024-05-30 13:47:39,597 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Trying to choose nodes for [] at 1717076859597
2024-05-30 15:47:39 2024-05-30 13:47:39,598 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Found least loaded node kafka:9092 (id: -1 rack: null) with no active connection
2024-05-30 15:47:39 2024-05-30 13:47:39,598 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Assigned Call(callName=fetchMetadata, deadlineMs=1717076889597, tries=0, nextAllowedTryMs=0) to node kafka:9092 (id: -1 rack: null)
2024-05-30 15:47:39 2024-05-30 13:47:39,598 [SourceCoordinator-Source: Kafka Source-worker-thread-1] DEBUG org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber  - Fetching descriptions for topics: [aisdata]
2024-05-30 15:47:39 2024-05-30 13:47:39,599 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.ClientUtils  - Resolved host kafka as 172.18.0.4
2024-05-30 15:47:39 2024-05-30 13:47:39,599 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Initiating connection to node kafka:9092 (id: -1 rack: null) using address kafka/172.18.0.4
2024-05-30 15:47:39 2024-05-30 13:47:39,600 [SourceCoordinator-Source: Kafka Source-worker-thread-1] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Queueing Call(callName=describeTopics, deadlineMs=1717076919599, tries=0, nextAllowedTryMs=0) with a timeout 30000 ms from now.
2024-05-30 15:47:39 2024-05-30 13:47:39,604 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Client is not ready to send to kafka:9092 (id: -1 rack: null). Must delay 10470 ms
2024-05-30 15:47:39 2024-05-30 13:47:39,604 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Entering KafkaClient#poll(timeout=10470)
2024-05-30 15:47:39 2024-05-30 13:47:39,604 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.requests-sent
2024-05-30 15:47:39 2024-05-30 13:47:39,604 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-total, group=admin-client-node-metrics, description=The total number of requests sent, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node--1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,605 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-rate, group=admin-client-node-metrics, description=The number of requests sent per second, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node--1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,605 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-size-avg, group=admin-client-node-metrics, description=The average size of requests sent., tags={client-id=flink_consumer-enumerator-admin-client, node-id=node--1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,605 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-size-max, group=admin-client-node-metrics, description=The maximum size of any request sent., tags={client-id=flink_consumer-enumerator-admin-client, node-id=node--1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,605 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-sent
2024-05-30 15:47:39 2024-05-30 13:47:39,605 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=outgoing-byte-total, group=admin-client-node-metrics, description=The total number of outgoing bytes, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node--1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,605 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=outgoing-byte-rate, group=admin-client-node-metrics, description=The number of outgoing bytes per second, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node--1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,605 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.responses-received
2024-05-30 15:47:39 2024-05-30 13:47:39,605 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=response-total, group=admin-client-node-metrics, description=The total number of responses received, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node--1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,605 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=response-rate, group=admin-client-node-metrics, description=The number of responses received per second, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node--1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,605 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-received
2024-05-30 15:47:39 2024-05-30 13:47:39,605 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=incoming-byte-total, group=admin-client-node-metrics, description=The total number of incoming bytes, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node--1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,606 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=incoming-byte-rate, group=admin-client-node-metrics, description=The number of incoming bytes per second, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node--1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,606 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.latency
2024-05-30 15:47:39 2024-05-30 13:47:39,606 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-latency-avg, group=admin-client-node-metrics, description=, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node--1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,606 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-latency-max, group=admin-client-node-metrics, description=, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node--1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,606 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.common.network.Selector  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2024-05-30 15:47:39 2024-05-30 13:47:39,634 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Starting allocation of slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_0 for job b2acee74555094750d6ee11d259188ed with resource profile ResourceProfile{UNKNOWN}.
2024-05-30 15:47:39 2024-05-30 13:47:39,634 [flink-akka.actor.default-dispatcher-7] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker  - Slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_0 transitioned from FREE to PENDING for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,635 [flink-akka.actor.default-dispatcher-7] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultResourceTracker  - Received notification for job b2acee74555094750d6ee11d259188ed having acquired resource ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}.
2024-05-30 15:47:39 2024-05-30 13:47:39,636 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Receive slot request 8d65a0633b594e1023055f8eb5d4271d for job b2acee74555094750d6ee11d259188ed from resource manager with leader id 8cf28941f3cfcd919830939236c44fc2.
2024-05-30 15:47:39 2024-05-30 13:47:39,636 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Starting allocation of slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_1 for job b2acee74555094750d6ee11d259188ed with resource profile ResourceProfile{UNKNOWN}.
2024-05-30 15:47:39 2024-05-30 13:47:39,636 [flink-akka.actor.default-dispatcher-7] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker  - Slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_1 transitioned from FREE to PENDING for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,636 [flink-akka.actor.default-dispatcher-7] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultResourceTracker  - Received notification for job b2acee74555094750d6ee11d259188ed having acquired resource ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}.
2024-05-30 15:47:39 2024-05-30 13:47:39,636 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Starting allocation of slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_2 for job b2acee74555094750d6ee11d259188ed with resource profile ResourceProfile{UNKNOWN}.
2024-05-30 15:47:39 2024-05-30 13:47:39,636 [flink-akka.actor.default-dispatcher-7] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker  - Slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_2 transitioned from FREE to PENDING for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,636 [flink-akka.actor.default-dispatcher-7] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultResourceTracker  - Received notification for job b2acee74555094750d6ee11d259188ed having acquired resource ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}.
2024-05-30 15:47:39 2024-05-30 13:47:39,637 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Starting allocation of slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_3 for job b2acee74555094750d6ee11d259188ed with resource profile ResourceProfile{UNKNOWN}.
2024-05-30 15:47:39 2024-05-30 13:47:39,637 [flink-akka.actor.default-dispatcher-7] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker  - Slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_3 transitioned from FREE to PENDING for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,637 [flink-akka.actor.default-dispatcher-7] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultResourceTracker  - Received notification for job b2acee74555094750d6ee11d259188ed having acquired resource ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}.
2024-05-30 15:47:39 2024-05-30 13:47:39,637 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Starting allocation of slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_4 for job b2acee74555094750d6ee11d259188ed with resource profile ResourceProfile{UNKNOWN}.
2024-05-30 15:47:39 2024-05-30 13:47:39,637 [flink-akka.actor.default-dispatcher-7] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker  - Slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_4 transitioned from FREE to PENDING for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,637 [flink-akka.actor.default-dispatcher-7] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultResourceTracker  - Received notification for job b2acee74555094750d6ee11d259188ed having acquired resource ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}.
2024-05-30 15:47:39 2024-05-30 13:47:39,637 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Starting allocation of slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_5 for job b2acee74555094750d6ee11d259188ed with resource profile ResourceProfile{UNKNOWN}.
2024-05-30 15:47:39 2024-05-30 13:47:39,637 [flink-akka.actor.default-dispatcher-7] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker  - Slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_5 transitioned from FREE to PENDING for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,637 [flink-akka.actor.default-dispatcher-7] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultResourceTracker  - Received notification for job b2acee74555094750d6ee11d259188ed having acquired resource ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}.
2024-05-30 15:47:39 2024-05-30 13:47:39,637 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Starting allocation of slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_6 for job b2acee74555094750d6ee11d259188ed with resource profile ResourceProfile{UNKNOWN}.
2024-05-30 15:47:39 2024-05-30 13:47:39,637 [flink-akka.actor.default-dispatcher-7] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker  - Slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_6 transitioned from FREE to PENDING for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,638 [flink-akka.actor.default-dispatcher-7] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultResourceTracker  - Received notification for job b2acee74555094750d6ee11d259188ed having acquired resource ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}.
2024-05-30 15:47:39 2024-05-30 13:47:39,638 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Starting allocation of slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_7 for job b2acee74555094750d6ee11d259188ed with resource profile ResourceProfile{UNKNOWN}.
2024-05-30 15:47:39 2024-05-30 13:47:39,638 [flink-akka.actor.default-dispatcher-7] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker  - Slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_7 transitioned from FREE to PENDING for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,638 [flink-akka.actor.default-dispatcher-7] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultResourceTracker  - Received notification for job b2acee74555094750d6ee11d259188ed having acquired resource ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}.
2024-05-30 15:47:39 2024-05-30 13:47:39,639 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.memory.MemoryManager  - Initialized MemoryManager with total memory size 16777216 and page size 32768.
2024-05-30 15:47:39 2024-05-30 13:47:39,641 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Allocated slot for 8d65a0633b594e1023055f8eb5d4271d.
2024-05-30 15:47:39 2024-05-30 13:47:39,642 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService  - Add job b2acee74555094750d6ee11d259188ed for job leader monitoring.
2024-05-30 15:47:39 2024-05-30 13:47:39,642 [mini-cluster-io-thread-3] DEBUG org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService  - New leader information for job b2acee74555094750d6ee11d259188ed. Address: akka://flink/user/rpc/jobmanager_3, leader id: 91d20108919a251a2ec32f4e9f034c3c.
2024-05-30 15:47:39 2024-05-30 13:47:39,643 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Receive slot request 1682416b57c3204f1e47034ed712058a for job b2acee74555094750d6ee11d259188ed from resource manager with leader id 8cf28941f3cfcd919830939236c44fc2.
2024-05-30 15:47:39 2024-05-30 13:47:39,643 [mini-cluster-io-thread-3] INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService  - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id 2ec32f4e-9f03-4c3c-91d2-0108919a251a.
2024-05-30 15:47:39 2024-05-30 13:47:39,643 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.memory.MemoryManager  - Initialized MemoryManager with total memory size 16777216 and page size 32768.
2024-05-30 15:47:39 2024-05-30 13:47:39,643 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Allocated slot for 1682416b57c3204f1e47034ed712058a.
2024-05-30 15:47:39 2024-05-30 13:47:39,643 [mini-cluster-io-thread-3] DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService  - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2024-05-30 15:47:39 2024-05-30 13:47:39,643 [flink-akka.actor.default-dispatcher-9] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Completed allocation of slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_1 for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,643 [flink-akka.actor.default-dispatcher-9] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker  - Slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_1 transitioned from PENDING to ALLOCATED for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,643 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Receive slot request b8b5242c6762175095a12034622f0abe for job b2acee74555094750d6ee11d259188ed from resource manager with leader id 8cf28941f3cfcd919830939236c44fc2.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-9] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Completed allocation of slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_0 for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-9] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker  - Slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_0 transitioned from PENDING to ALLOCATED for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.memory.MemoryManager  - Initialized MemoryManager with total memory size 16777216 and page size 32768.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Allocated slot for b8b5242c6762175095a12034622f0abe.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-9] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Completed allocation of slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_2 for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-9] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker  - Slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_2 transitioned from PENDING to ALLOCATED for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Receive slot request 6a1740c95dc7f606c4106bac93511e32 for job b2acee74555094750d6ee11d259188ed from resource manager with leader id 8cf28941f3cfcd919830939236c44fc2.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.memory.MemoryManager  - Initialized MemoryManager with total memory size 16777216 and page size 32768.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Allocated slot for 6a1740c95dc7f606c4106bac93511e32.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-9] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Completed allocation of slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_3 for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-9] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker  - Slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_3 transitioned from PENDING to ALLOCATED for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Receive slot request 00eeda8d0616dc2caf6cec5a00ec1267 for job b2acee74555094750d6ee11d259188ed from resource manager with leader id 8cf28941f3cfcd919830939236c44fc2.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.memory.MemoryManager  - Initialized MemoryManager with total memory size 16777216 and page size 32768.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Allocated slot for 00eeda8d0616dc2caf6cec5a00ec1267.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Receive slot request 77ba640e4dccc1995b4af4cd8b888262 for job b2acee74555094750d6ee11d259188ed from resource manager with leader id 8cf28941f3cfcd919830939236c44fc2.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.memory.MemoryManager  - Initialized MemoryManager with total memory size 16777216 and page size 32768.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Allocated slot for 77ba640e4dccc1995b4af4cd8b888262.
2024-05-30 15:47:39 2024-05-30 13:47:39,644 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Receive slot request 6ec3018dfd7ad2d8dcaa869612169256 for job b2acee74555094750d6ee11d259188ed from resource manager with leader id 8cf28941f3cfcd919830939236c44fc2.
2024-05-30 15:47:39 2024-05-30 13:47:39,645 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.memory.MemoryManager  - Initialized MemoryManager with total memory size 16777216 and page size 32768.
2024-05-30 15:47:39 2024-05-30 13:47:39,645 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Allocated slot for 6ec3018dfd7ad2d8dcaa869612169256.
2024-05-30 15:47:39 2024-05-30 13:47:39,645 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Receive slot request 0a6a4da3bdbd82f89f0b6179ebdf87a3 for job b2acee74555094750d6ee11d259188ed from resource manager with leader id 8cf28941f3cfcd919830939236c44fc2.
2024-05-30 15:47:39 2024-05-30 13:47:39,645 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.memory.MemoryManager  - Initialized MemoryManager with total memory size 16777216 and page size 32768.
2024-05-30 15:47:39 2024-05-30 13:47:39,645 [flink-akka.actor.default-dispatcher-9] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Completed allocation of slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_4 for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,645 [flink-akka.actor.default-dispatcher-9] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker  - Slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_4 transitioned from PENDING to ALLOCATED for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,645 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Allocated slot for 0a6a4da3bdbd82f89f0b6179ebdf87a3.
2024-05-30 15:47:39 2024-05-30 13:47:39,645 [flink-akka.actor.default-dispatcher-9] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Completed allocation of slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_5 for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,645 [flink-akka.actor.default-dispatcher-9] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker  - Slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_5 transitioned from PENDING to ALLOCATED for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,645 [flink-akka.actor.default-dispatcher-10] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Completed allocation of slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_7 for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,645 [flink-akka.actor.default-dispatcher-10] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker  - Slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_7 transitioned from PENDING to ALLOCATED for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,645 [flink-akka.actor.default-dispatcher-10] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Completed allocation of slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_6 for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,645 [flink-akka.actor.default-dispatcher-10] TRACE org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotTracker  - Slot ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_6 transitioned from PENDING to ALLOCATED for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,645 [flink-akka.actor.default-dispatcher-11] INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService  - Resolved JobManager address, beginning registration
2024-05-30 15:47:39 2024-05-30 13:47:39,646 [flink-akka.actor.default-dispatcher-11] DEBUG org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService  - Registration at JobManager attempt 1 (timeout=100ms)
2024-05-30 15:47:39 2024-05-30 13:47:39,646 [flink-akka.actor.default-dispatcher-11] DEBUG org.apache.flink.runtime.rpc.akka.AkkaRpcService  - Try to connect to remote RPC endpoint with address akka://flink/user/rpc/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2024-05-30 15:47:39 2024-05-30 13:47:39,648 [flink-akka.actor.default-dispatcher-11] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Register new TaskExecutor ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff.
2024-05-30 15:47:39 2024-05-30 13:47:39,648 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService  - Registration with JobManager at akka://flink/user/rpc/jobmanager_3 was successful.
2024-05-30 15:47:39 2024-05-30 13:47:39,648 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService  - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,649 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Establish JobManager connection for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,650 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Offer reserved slots to the leader of job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,651 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Received [SlotOffer{allocationId=6a1740c95dc7f606c4106bac93511e32, slotIndex=3, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}, SlotOffer{allocationId=6ec3018dfd7ad2d8dcaa869612169256, slotIndex=6, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}, SlotOffer{allocationId=0a6a4da3bdbd82f89f0b6179ebdf87a3, slotIndex=7, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}, SlotOffer{allocationId=1682416b57c3204f1e47034ed712058a, slotIndex=1, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}, SlotOffer{allocationId=00eeda8d0616dc2caf6cec5a00ec1267, slotIndex=4, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}, SlotOffer{allocationId=77ba640e4dccc1995b4af4cd8b888262, slotIndex=5, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}, SlotOffer{allocationId=8d65a0633b594e1023055f8eb5d4271d, slotIndex=0, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}, SlotOffer{allocationId=b8b5242c6762175095a12034622f0abe, slotIndex=2, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}] slot offers from TaskExecutor ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1).
2024-05-30 15:47:39 2024-05-30 13:47:39,651 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Matched slot offer 6a1740c95dc7f606c4106bac93511e32 to requirement ResourceProfile{UNKNOWN}.
2024-05-30 15:47:39 2024-05-30 13:47:39,652 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Matched slot offer 6ec3018dfd7ad2d8dcaa869612169256 to requirement ResourceProfile{UNKNOWN}.
2024-05-30 15:47:39 2024-05-30 13:47:39,652 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Matched slot offer 0a6a4da3bdbd82f89f0b6179ebdf87a3 to requirement ResourceProfile{UNKNOWN}.
2024-05-30 15:47:39 2024-05-30 13:47:39,652 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Matched slot offer 1682416b57c3204f1e47034ed712058a to requirement ResourceProfile{UNKNOWN}.
2024-05-30 15:47:39 2024-05-30 13:47:39,652 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Matched slot offer 00eeda8d0616dc2caf6cec5a00ec1267 to requirement ResourceProfile{UNKNOWN}.
2024-05-30 15:47:39 2024-05-30 13:47:39,652 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Matched slot offer 77ba640e4dccc1995b4af4cd8b888262 to requirement ResourceProfile{UNKNOWN}.
2024-05-30 15:47:39 2024-05-30 13:47:39,652 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Matched slot offer 8d65a0633b594e1023055f8eb5d4271d to requirement ResourceProfile{UNKNOWN}.
2024-05-30 15:47:39 2024-05-30 13:47:39,652 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Matched slot offer b8b5242c6762175095a12034622f0abe to requirement ResourceProfile{UNKNOWN}.
2024-05-30 15:47:39 2024-05-30 13:47:39,652 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool  - Acquired new resources; new total acquired resources: ResourceCounter{resources={ResourceProfile{UNKNOWN}=8}}
2024-05-30 15:47:39 2024-05-30 13:47:39,652 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Matched pending request PendingRequest{slotRequestId=SlotRequestId{f497bd41bbe68fc7eff949fc66856b30}, resourceProfile=ResourceProfile{UNKNOWN}, preferredAllocations=[], isBatchRequest=false, unfulfillableSince=9223372036854775807} with slot AllocatedSlot 6a1740c95dc7f606c4106bac93511e32 @ ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) - 3.
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Reserve slot 6a1740c95dc7f606c4106bac93511e32 for slot request id SlotRequestId{f497bd41bbe68fc7eff949fc66856b30}
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultAllocatedSlotPool  - Reserve free slot with allocation id 6a1740c95dc7f606c4106bac93511e32.
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Matched pending request PendingRequest{slotRequestId=SlotRequestId{23c0657ff49acdd04febbd559dd62198}, resourceProfile=ResourceProfile{UNKNOWN}, preferredAllocations=[], isBatchRequest=false, unfulfillableSince=9223372036854775807} with slot AllocatedSlot 6ec3018dfd7ad2d8dcaa869612169256 @ ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) - 6.
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Reserve slot 6ec3018dfd7ad2d8dcaa869612169256 for slot request id SlotRequestId{23c0657ff49acdd04febbd559dd62198}
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultAllocatedSlotPool  - Reserve free slot with allocation id 6ec3018dfd7ad2d8dcaa869612169256.
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Matched pending request PendingRequest{slotRequestId=SlotRequestId{a70436baa078ea26d7de28d1b0518817}, resourceProfile=ResourceProfile{UNKNOWN}, preferredAllocations=[], isBatchRequest=false, unfulfillableSince=9223372036854775807} with slot AllocatedSlot 0a6a4da3bdbd82f89f0b6179ebdf87a3 @ ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) - 7.
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Reserve slot 0a6a4da3bdbd82f89f0b6179ebdf87a3 for slot request id SlotRequestId{a70436baa078ea26d7de28d1b0518817}
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultAllocatedSlotPool  - Reserve free slot with allocation id 0a6a4da3bdbd82f89f0b6179ebdf87a3.
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Matched pending request PendingRequest{slotRequestId=SlotRequestId{059c35af7302614e8b3071092f705708}, resourceProfile=ResourceProfile{UNKNOWN}, preferredAllocations=[], isBatchRequest=false, unfulfillableSince=9223372036854775807} with slot AllocatedSlot 1682416b57c3204f1e47034ed712058a @ ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) - 1.
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Reserve slot 1682416b57c3204f1e47034ed712058a for slot request id SlotRequestId{059c35af7302614e8b3071092f705708}
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultAllocatedSlotPool  - Reserve free slot with allocation id 1682416b57c3204f1e47034ed712058a.
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Matched pending request PendingRequest{slotRequestId=SlotRequestId{5e14a1e0af39d3b52e0954640c821def}, resourceProfile=ResourceProfile{UNKNOWN}, preferredAllocations=[], isBatchRequest=false, unfulfillableSince=9223372036854775807} with slot AllocatedSlot 00eeda8d0616dc2caf6cec5a00ec1267 @ ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) - 4.
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Reserve slot 00eeda8d0616dc2caf6cec5a00ec1267 for slot request id SlotRequestId{5e14a1e0af39d3b52e0954640c821def}
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultAllocatedSlotPool  - Reserve free slot with allocation id 00eeda8d0616dc2caf6cec5a00ec1267.
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Matched pending request PendingRequest{slotRequestId=SlotRequestId{c02333c264dfd3051a234fe22622c2f1}, resourceProfile=ResourceProfile{UNKNOWN}, preferredAllocations=[], isBatchRequest=false, unfulfillableSince=9223372036854775807} with slot AllocatedSlot 77ba640e4dccc1995b4af4cd8b888262 @ ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) - 5.
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Reserve slot 77ba640e4dccc1995b4af4cd8b888262 for slot request id SlotRequestId{c02333c264dfd3051a234fe22622c2f1}
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultAllocatedSlotPool  - Reserve free slot with allocation id 77ba640e4dccc1995b4af4cd8b888262.
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Matched pending request PendingRequest{slotRequestId=SlotRequestId{0f20990f681eb0b9d6fc8c171b440585}, resourceProfile=ResourceProfile{UNKNOWN}, preferredAllocations=[], isBatchRequest=false, unfulfillableSince=9223372036854775807} with slot AllocatedSlot 8d65a0633b594e1023055f8eb5d4271d @ ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) - 0.
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Reserve slot 8d65a0633b594e1023055f8eb5d4271d for slot request id SlotRequestId{0f20990f681eb0b9d6fc8c171b440585}
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultAllocatedSlotPool  - Reserve free slot with allocation id 8d65a0633b594e1023055f8eb5d4271d.
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Matched pending request PendingRequest{slotRequestId=SlotRequestId{fe72d375d30c21f396aa1676f93ff86c}, resourceProfile=ResourceProfile{UNKNOWN}, preferredAllocations=[], isBatchRequest=false, unfulfillableSince=9223372036854775807} with slot AllocatedSlot b8b5242c6762175095a12034622f0abe @ ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) - 2.
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DeclarativeSlotPoolBridge  - Reserve slot b8b5242c6762175095a12034622f0abe for slot request id SlotRequestId{fe72d375d30c21f396aa1676f93ff86c}
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.slotpool.DefaultAllocatedSlotPool  - Reserve free slot with allocation id b8b5242c6762175095a12034622f0abe.
2024-05-30 15:47:39 2024-05-30 13:47:39,653 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Allocated logical slot (SlotRequestId{cdec5d7e6f80cc8c55ceead40844a6de}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4) from the physical slot (SlotRequestId{f497bd41bbe68fc7eff949fc66856b30})
2024-05-30 15:47:39 2024-05-30 13:47:39,656 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Allocated logical slot (SlotRequestId{6dfe39a74733116ca63b9123e1b85905}) for execution vertex (id 87aa6a78642c52c526689f50e970e2b8_4) from the physical slot (SlotRequestId{f497bd41bbe68fc7eff949fc66856b30})
2024-05-30 15:47:39 2024-05-30 13:47:39,656 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Allocated logical slot (SlotRequestId{d0d94fcff903a81c98c35387d2392bae}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7) from the physical slot (SlotRequestId{23c0657ff49acdd04febbd559dd62198})
2024-05-30 15:47:39 2024-05-30 13:47:39,656 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Allocated logical slot (SlotRequestId{387dbcd95a3fdf9988205088f3d1ef3d}) for execution vertex (id 87aa6a78642c52c526689f50e970e2b8_7) from the physical slot (SlotRequestId{23c0657ff49acdd04febbd559dd62198})
2024-05-30 15:47:39 2024-05-30 13:47:39,656 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Allocated logical slot (SlotRequestId{007cf8887286986af48feda4482981e2}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5) from the physical slot (SlotRequestId{a70436baa078ea26d7de28d1b0518817})
2024-05-30 15:47:39 2024-05-30 13:47:39,656 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Allocated logical slot (SlotRequestId{8f1df5b0763a4bf432656e07b5111909}) for execution vertex (id 87aa6a78642c52c526689f50e970e2b8_5) from the physical slot (SlotRequestId{a70436baa078ea26d7de28d1b0518817})
2024-05-30 15:47:39 2024-05-30 13:47:39,656 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Allocated logical slot (SlotRequestId{02e0a08f073bb50d6d68b19d23292e17}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3) from the physical slot (SlotRequestId{059c35af7302614e8b3071092f705708})
2024-05-30 15:47:39 2024-05-30 13:47:39,656 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Allocated logical slot (SlotRequestId{b9505f778b4dedcebbb36048159c0252}) for execution vertex (id 87aa6a78642c52c526689f50e970e2b8_3) from the physical slot (SlotRequestId{059c35af7302614e8b3071092f705708})
2024-05-30 15:47:39 2024-05-30 13:47:39,656 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Allocated logical slot (SlotRequestId{b8eb79b0bc3e16ad7d1f056d0e67ee20}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2) from the physical slot (SlotRequestId{5e14a1e0af39d3b52e0954640c821def})
2024-05-30 15:47:39 2024-05-30 13:47:39,656 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Allocated logical slot (SlotRequestId{43df889df4f5dacaa47adfb493a2ef73}) for execution vertex (id 87aa6a78642c52c526689f50e970e2b8_2) from the physical slot (SlotRequestId{5e14a1e0af39d3b52e0954640c821def})
2024-05-30 15:47:39 2024-05-30 13:47:39,656 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Allocated logical slot (SlotRequestId{b2b9571df94165885de8691002c42b83}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1) from the physical slot (SlotRequestId{c02333c264dfd3051a234fe22622c2f1})
2024-05-30 15:47:39 2024-05-30 13:47:39,656 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Allocated logical slot (SlotRequestId{1f28d333b1869d5fae29dafcd69757be}) for execution vertex (id 87aa6a78642c52c526689f50e970e2b8_1) from the physical slot (SlotRequestId{c02333c264dfd3051a234fe22622c2f1})
2024-05-30 15:47:39 2024-05-30 13:47:39,656 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Allocated logical slot (SlotRequestId{35dff5e94934b7f0819e330816493dfc}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0) from the physical slot (SlotRequestId{0f20990f681eb0b9d6fc8c171b440585})
2024-05-30 15:47:39 2024-05-30 13:47:39,656 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Allocated logical slot (SlotRequestId{b59dc5715b907b59535a7b943f3bcff7}) for execution vertex (id 87aa6a78642c52c526689f50e970e2b8_0) from the physical slot (SlotRequestId{0f20990f681eb0b9d6fc8c171b440585})
2024-05-30 15:47:39 2024-05-30 13:47:39,656 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Allocated logical slot (SlotRequestId{0ee4d58bfff2c0ca45885cd9c3437dfa}) for execution vertex (id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6) from the physical slot (SlotRequestId{fe72d375d30c21f396aa1676f93ff86c})
2024-05-30 15:47:39 2024-05-30 13:47:39,656 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.scheduler.SharedSlot  - Allocated logical slot (SlotRequestId{45eeea2f09d40c58a02e3a30c0d6c4d7}) for execution vertex (id 87aa6a78642c52c526689f50e970e2b8_6) from the physical slot (SlotRequestId{fe72d375d30c21f396aa1676f93ff86c})
2024-05-30 15:47:39 2024-05-30 13:47:39,657 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0) switched from SCHEDULED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,657 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Deploying Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8) (attempt #0) with attempt id b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0 and vertex id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0 to ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) with allocation id 8d65a0633b594e1023055f8eb5d4271d
2024-05-30 15:47:39 2024-05-30 13:47:39,660 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 8d65a0633b594e1023055f8eb5d4271d.
2024-05-30 15:47:39 2024-05-30 13:47:39,660 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0) switched from SCHEDULED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,660 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Deploying Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8) (attempt #0) with attempt id b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0 and vertex id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1 to ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) with allocation id 77ba640e4dccc1995b4af4cd8b888262
2024-05-30 15:47:39 2024-05-30 13:47:39,662 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0) switched from SCHEDULED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,662 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Deploying Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8) (attempt #0) with attempt id b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0 and vertex id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2 to ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) with allocation id 00eeda8d0616dc2caf6cec5a00ec1267
2024-05-30 15:47:39 2024-05-30 13:47:39,663 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0) switched from SCHEDULED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,663 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Deploying Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8) (attempt #0) with attempt id b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0 and vertex id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3 to ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) with allocation id 1682416b57c3204f1e47034ed712058a
2024-05-30 15:47:39 2024-05-30 13:47:39,665 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0) switched from SCHEDULED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,665 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Deploying Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8) (attempt #0) with attempt id b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0 and vertex id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4 to ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) with allocation id 6a1740c95dc7f606c4106bac93511e32
2024-05-30 15:47:39 2024-05-30 13:47:39,667 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0) switched from SCHEDULED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,667 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Deploying Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8) (attempt #0) with attempt id b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0 and vertex id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5 to ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) with allocation id 0a6a4da3bdbd82f89f0b6179ebdf87a3
2024-05-30 15:47:39 2024-05-30 13:47:39,668 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,668 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,668 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,668 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,668 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0) switched from SCHEDULED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,668 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Deploying Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8) (attempt #0) with attempt id b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0 and vertex id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6 to ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) with allocation id b8b5242c6762175095a12034622f0abe
2024-05-30 15:47:39 2024-05-30 13:47:39,668 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,668 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,668 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,668 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,668 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,668 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,669 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.idleTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,669 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.softBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,669 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.hardBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,669 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.backPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,669 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxSoftBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,669 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0) switched from SCHEDULED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,669 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Deploying Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8) (attempt #0) with attempt id b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0 and vertex id e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7 to ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) with allocation id 6ec3018dfd7ad2d8dcaa869612169256
2024-05-30 15:47:39 2024-05-30 13:47:39,669 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxHardBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,670 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.busyTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,670 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0) switched from SCHEDULED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,670 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Deploying TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8) (attempt #0) with attempt id b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0 and vertex id 87aa6a78642c52c526689f50e970e2b8_0 to ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) with allocation id 8d65a0633b594e1023055f8eb5d4271d
2024-05-30 15:47:39 2024-05-30 13:47:39,672 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBusyTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,672 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBackPressuredTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,672 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateIdleTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,672 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxMailsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,672 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxLatencyMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,672 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,674 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0) switched from SCHEDULED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,674 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Deploying TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8) (attempt #0) with attempt id b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0 and vertex id 87aa6a78642c52c526689f50e970e2b8_1 to ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) with allocation id 77ba640e4dccc1995b4af4cd8b888262
2024-05-30 15:47:39 2024-05-30 13:47:39,674 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0) switched from SCHEDULED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,674 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Deploying TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8) (attempt #0) with attempt id b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0 and vertex id 87aa6a78642c52c526689f50e970e2b8_2 to ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) with allocation id 00eeda8d0616dc2caf6cec5a00ec1267
2024-05-30 15:47:39 2024-05-30 13:47:39,674 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0) switched from SCHEDULED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,674 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Deploying TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8) (attempt #0) with attempt id b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0 and vertex id 87aa6a78642c52c526689f50e970e2b8_3 to ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) with allocation id 1682416b57c3204f1e47034ed712058a
2024-05-30 15:47:39 2024-05-30 13:47:39,674 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0) switched from SCHEDULED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,674 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Deploying TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8) (attempt #0) with attempt id b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0 and vertex id 87aa6a78642c52c526689f50e970e2b8_4 to ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) with allocation id 6a1740c95dc7f606c4106bac93511e32
2024-05-30 15:47:39 2024-05-30 13:47:39,674 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0) switched from SCHEDULED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,675 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Deploying TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8) (attempt #0) with attempt id b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0 and vertex id 87aa6a78642c52c526689f50e970e2b8_5 to ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) with allocation id 0a6a4da3bdbd82f89f0b6179ebdf87a3
2024-05-30 15:47:39 2024-05-30 13:47:39,675 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0) switched from SCHEDULED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,675 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Deploying TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8) (attempt #0) with attempt id b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0 and vertex id 87aa6a78642c52c526689f50e970e2b8_6 to ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) with allocation id b8b5242c6762175095a12034622f0abe
2024-05-30 15:47:39 2024-05-30 13:47:39,675 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0) switched from SCHEDULED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,675 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Deploying TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8) (attempt #0) with attempt id b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0 and vertex id 87aa6a78642c52c526689f50e970e2b8_7 to ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff @ localhost (dataPort=-1) with allocation id 6ec3018dfd7ad2d8dcaa869612169256
2024-05-30 15:47:39 2024-05-30 13:47:39,675 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new allocation id 8d65a0633b594e1023055f8eb5d4271d for local state stores for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,677 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new local state store with configuration LocalRecoveryConfig{localStateDirectories=null} for b2acee74555094750d6ee11d259188ed - e3dfc0d7e9ecd8a43f85f0b68ebf3b80 - 0 under allocation id 8d65a0633b594e1023055f8eb5d4271d.
2024-05-30 15:47:39 2024-05-30 13:47:39,702 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader  - StateChangelogStorageLoader initialized with shortcut names {memory}.
2024-05-30 15:47:39 2024-05-30 13:47:39,702 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader  - Creating a changelog storage with name 'memory'.
2024-05-30 15:47:39 2024-05-30 13:47:39,703 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager  - Registered new state changelog storage for job b2acee74555094750d6ee11d259188ed : org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogStorage@35469a3f.
2024-05-30 15:47:39 2024-05-30 13:47:39,713 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionFactory  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@4a0f62a7
2024-05-30 15:47:39 2024-05-30 13:47:39,713 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,714 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,714 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,715 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,715 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,716 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,716 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,716 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,716 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,716 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,716 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,716 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,716 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,716 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,716 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,716 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,716 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.isBackPressured.
2024-05-30 15:47:39 2024-05-30 13:47:39,717 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0), deploy into slot with allocation id 8d65a0633b594e1023055f8eb5d4271d.
2024-05-30 15:47:39 2024-05-30 13:47:39,718 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0) switched from CREATED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,718 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Creating FileSystem stream leak safety net for task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0) [DEPLOYING]
2024-05-30 15:47:39 2024-05-30 13:47:39,719 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 77ba640e4dccc1995b4af4cd8b888262.
2024-05-30 15:47:39 2024-05-30 13:47:39,721 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.idleTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.softBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.hardBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.backPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxSoftBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxHardBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.busyTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBusyTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBackPressuredTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateIdleTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxMailsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxLatencyMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new allocation id 77ba640e4dccc1995b4af4cd8b888262 for local state stores for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,722 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new local state store with configuration LocalRecoveryConfig{localStateDirectories=null} for b2acee74555094750d6ee11d259188ed - e3dfc0d7e9ecd8a43f85f0b68ebf3b80 - 1 under allocation id 77ba640e4dccc1995b4af4cd8b888262.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager  - Found existing state changelog storage for job b2acee74555094750d6ee11d259188ed: org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogStorage@35469a3f.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionFactory  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@4a0f62a7
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.isBackPressured.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0), deploy into slot with allocation id 77ba640e4dccc1995b4af4cd8b888262.
2024-05-30 15:47:39 2024-05-30 13:47:39,723 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Loading JAR files for task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,724 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Getting user code class loader for task b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0 at library cache manager took 0 milliseconds
2024-05-30 15:47:39 2024-05-30 13:47:39,724 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0) switched from CREATED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,724 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Creating FileSystem stream leak safety net for task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0) [DEPLOYING]
2024-05-30 15:47:39 2024-05-30 13:47:39,724 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Loading JAR files for task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,724 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 00eeda8d0616dc2caf6cec5a00ec1267.
2024-05-30 15:47:39 2024-05-30 13:47:39,725 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Getting user code class loader for task b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0 at library cache manager took 1 milliseconds
2024-05-30 15:47:39 2024-05-30 13:47:39,725 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Registering task at network: Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,725 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Registering task at network: Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,725 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.idleTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.softBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.hardBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.backPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxSoftBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxHardBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.busyTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBusyTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBackPressuredTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateIdleTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxMailsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxLatencyMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new allocation id 00eeda8d0616dc2caf6cec5a00ec1267 for local state stores for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new local state store with configuration LocalRecoveryConfig{localStateDirectories=null} for b2acee74555094750d6ee11d259188ed - e3dfc0d7e9ecd8a43f85f0b68ebf3b80 - 2 under allocation id 00eeda8d0616dc2caf6cec5a00ec1267.
2024-05-30 15:47:39 2024-05-30 13:47:39,726 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager  - Found existing state changelog storage for job b2acee74555094750d6ee11d259188ed: org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogStorage@35469a3f.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionFactory  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@4a0f62a7
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.isBackPressured.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0), deploy into slot with allocation id 00eeda8d0616dc2caf6cec5a00ec1267.
2024-05-30 15:47:39 2024-05-30 13:47:39,727 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.io.network.buffer.LocalBufferPool  - Using a local buffer pool with 9-24 buffers
2024-05-30 15:47:39 2024-05-30 13:47:39,728 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0) switched from CREATED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,728 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Creating FileSystem stream leak safety net for task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0) [DEPLOYING]
2024-05-30 15:47:39 2024-05-30 13:47:39,728 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 1682416b57c3204f1e47034ed712058a.
2024-05-30 15:47:39 2024-05-30 13:47:39,728 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Loading JAR files for task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,728 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Getting user code class loader for task b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0 at library cache manager took 0 milliseconds
2024-05-30 15:47:39 2024-05-30 13:47:39,728 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Registering task at network: Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,729 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.io.network.buffer.LocalBufferPool  - Using a local buffer pool with 9-24 buffers
2024-05-30 15:47:39 2024-05-30 13:47:39,729 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Registered PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,729 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher  - registering c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0
2024-05-30 15:47:39 2024-05-30 13:47:39,729 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Registered PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,729 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,729 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,729 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,729 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,729 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,729 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,729 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,729 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,729 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.idleTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.softBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.hardBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.backPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxSoftBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxHardBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.busyTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBusyTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBackPressuredTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateIdleTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxMailsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxLatencyMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new allocation id 1682416b57c3204f1e47034ed712058a for local state stores for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new local state store with configuration LocalRecoveryConfig{localStateDirectories=null} for b2acee74555094750d6ee11d259188ed - e3dfc0d7e9ecd8a43f85f0b68ebf3b80 - 3 under allocation id 1682416b57c3204f1e47034ed712058a.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager  - Found existing state changelog storage for job b2acee74555094750d6ee11d259188ed: org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogStorage@35469a3f.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionFactory  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@4a0f62a7
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.isBackPressured.
2024-05-30 15:47:39 2024-05-30 13:47:39,730 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0), deploy into slot with allocation id 1682416b57c3204f1e47034ed712058a.
2024-05-30 15:47:39 2024-05-30 13:47:39,731 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 6a1740c95dc7f606c4106bac93511e32.
2024-05-30 15:47:39 2024-05-30 13:47:39,732 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0) switched from CREATED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,732 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.io.network.buffer.LocalBufferPool  - Using a local buffer pool with 9-24 buffers
2024-05-30 15:47:39 2024-05-30 13:47:39,732 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Creating FileSystem stream leak safety net for task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0) [DEPLOYING]
2024-05-30 15:47:39 2024-05-30 13:47:39,732 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Loading JAR files for task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,732 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Registered PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,732 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Getting user code class loader for task b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0 at library cache manager took 0 milliseconds
2024-05-30 15:47:39 2024-05-30 13:47:39,732 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,733 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Registering task at network: Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,733 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.io.network.buffer.LocalBufferPool  - Using a local buffer pool with 9-24 buffers
2024-05-30 15:47:39 2024-05-30 13:47:39,733 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Registered PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,733 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,733 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,733 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,733 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,733 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,733 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,733 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.idleTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.softBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.hardBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.backPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxSoftBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxHardBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.busyTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBusyTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBackPressuredTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateIdleTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxMailsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxLatencyMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new allocation id 6a1740c95dc7f606c4106bac93511e32 for local state stores for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new local state store with configuration LocalRecoveryConfig{localStateDirectories=null} for b2acee74555094750d6ee11d259188ed - e3dfc0d7e9ecd8a43f85f0b68ebf3b80 - 4 under allocation id 6a1740c95dc7f606c4106bac93511e32.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager  - Found existing state changelog storage for job b2acee74555094750d6ee11d259188ed: org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogStorage@35469a3f.
2024-05-30 15:47:39 2024-05-30 13:47:39,734 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionFactory  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@4a0f62a7
2024-05-30 15:47:39 2024-05-30 13:47:39,735 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,735 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,735 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,735 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,735 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,735 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,735 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,735 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,735 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,735 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher  - registering c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0
2024-05-30 15:47:39 2024-05-30 13:47:39,735 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher  - registering c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0
2024-05-30 15:47:39 2024-05-30 13:47:39,735 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,736 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,736 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,736 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,736 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,736 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,736 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,736 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.isBackPressured.
2024-05-30 15:47:39 2024-05-30 13:47:39,736 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0), deploy into slot with allocation id 6a1740c95dc7f606c4106bac93511e32.
2024-05-30 15:47:39 2024-05-30 13:47:39,736 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher  - registering c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0
2024-05-30 15:47:39 2024-05-30 13:47:39,737 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0) switched from CREATED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,737 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Creating FileSystem stream leak safety net for task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0) [DEPLOYING]
2024-05-30 15:47:39 2024-05-30 13:47:39,737 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Loading JAR files for task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,737 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 0a6a4da3bdbd82f89f0b6179ebdf87a3.
2024-05-30 15:47:39 2024-05-30 13:47:39,737 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Getting user code class loader for task b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0 at library cache manager took 0 milliseconds
2024-05-30 15:47:39 2024-05-30 13:47:39,738 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Registering task at network: Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,738 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.io.network.buffer.LocalBufferPool  - Using a local buffer pool with 9-24 buffers
2024-05-30 15:47:39 2024-05-30 13:47:39,738 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Registered PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,738 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher  - registering c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0
2024-05-30 15:47:39 2024-05-30 13:47:39,738 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,738 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,738 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,738 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,739 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,739 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,739 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,739 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,739 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,739 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,739 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.idleTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,739 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.softBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,739 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.hardBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,739 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.backPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,739 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxSoftBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,739 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxHardBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,739 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.busyTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,739 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBusyTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,739 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBackPressuredTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,740 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateIdleTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,740 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxMailsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,740 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxLatencyMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,740 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,740 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new allocation id 0a6a4da3bdbd82f89f0b6179ebdf87a3 for local state stores for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,740 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new local state store with configuration LocalRecoveryConfig{localStateDirectories=null} for b2acee74555094750d6ee11d259188ed - e3dfc0d7e9ecd8a43f85f0b68ebf3b80 - 5 under allocation id 0a6a4da3bdbd82f89f0b6179ebdf87a3.
2024-05-30 15:47:39 2024-05-30 13:47:39,740 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager  - Found existing state changelog storage for job b2acee74555094750d6ee11d259188ed: org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogStorage@35469a3f.
2024-05-30 15:47:39 2024-05-30 13:47:39,740 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionFactory  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@4a0f62a7
2024-05-30 15:47:39 2024-05-30 13:47:39,740 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,740 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,740 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,740 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,740 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,740 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,740 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,740 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,741 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,741 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,741 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,741 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,741 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,741 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,741 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,741 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,741 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.isBackPressured.
2024-05-30 15:47:39 2024-05-30 13:47:39,741 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0), deploy into slot with allocation id 0a6a4da3bdbd82f89f0b6179ebdf87a3.
2024-05-30 15:47:39 2024-05-30 13:47:39,742 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0) switched from CREATED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,742 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Creating FileSystem stream leak safety net for task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0) [DEPLOYING]
2024-05-30 15:47:39 2024-05-30 13:47:39,742 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot b8b5242c6762175095a12034622f0abe.
2024-05-30 15:47:39 2024-05-30 13:47:39,742 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Loading JAR files for task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,742 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Getting user code class loader for task b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0 at library cache manager took 0 milliseconds
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Registering task at network: Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.io.network.buffer.LocalBufferPool  - Using a local buffer pool with 9-24 buffers
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Registered PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher  - registering c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.idleTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.softBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.hardBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.backPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,743 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxSoftBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxHardBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.busyTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBusyTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBackPressuredTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateIdleTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxMailsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxLatencyMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new allocation id b8b5242c6762175095a12034622f0abe for local state stores for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new local state store with configuration LocalRecoveryConfig{localStateDirectories=null} for b2acee74555094750d6ee11d259188ed - e3dfc0d7e9ecd8a43f85f0b68ebf3b80 - 6 under allocation id b8b5242c6762175095a12034622f0abe.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager  - Found existing state changelog storage for job b2acee74555094750d6ee11d259188ed: org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogStorage@35469a3f.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionFactory  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@4a0f62a7
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,744 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,745 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,745 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,745 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.isBackPressured.
2024-05-30 15:47:39 2024-05-30 13:47:39,745 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0), deploy into slot with allocation id b8b5242c6762175095a12034622f0abe.
2024-05-30 15:47:39 2024-05-30 13:47:39,750 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Using partitioner HASH for output 0 of task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,751 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 6ec3018dfd7ad2d8dcaa869612169256.
2024-05-30 15:47:39 2024-05-30 13:47:39,751 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Using partitioner HASH for output 0 of task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,751 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Using partitioner HASH for output 0 of task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,753 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0) switched from CREATED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,753 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Creating FileSystem stream leak safety net for task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0) [DEPLOYING]
2024-05-30 15:47:39 2024-05-30 13:47:39,753 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Loading JAR files for task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,753 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Getting user code class loader for task b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0 at library cache manager took 0 milliseconds
2024-05-30 15:47:39 2024-05-30 13:47:39,753 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,753 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Registering task at network: Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,753 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.io.network.buffer.LocalBufferPool  - Using a local buffer pool with 9-24 buffers
2024-05-30 15:47:39 2024-05-30 13:47:39,753 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Registered PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,753 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.idleTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.softBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.hardBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.backPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxSoftBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxHardBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.busyTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBusyTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBackPressuredTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateIdleTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,754 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxMailsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,755 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxLatencyMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,755 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,755 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new allocation id 6ec3018dfd7ad2d8dcaa869612169256 for local state stores for job b2acee74555094750d6ee11d259188ed.
2024-05-30 15:47:39 2024-05-30 13:47:39,755 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new local state store with configuration LocalRecoveryConfig{localStateDirectories=null} for b2acee74555094750d6ee11d259188ed - e3dfc0d7e9ecd8a43f85f0b68ebf3b80 - 7 under allocation id 6ec3018dfd7ad2d8dcaa869612169256.
2024-05-30 15:47:39 2024-05-30 13:47:39,755 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager  - Found existing state changelog storage for job b2acee74555094750d6ee11d259188ed: org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogStorage@35469a3f.
2024-05-30 15:47:39 2024-05-30 13:47:39,755 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionFactory  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@4a0f62a7
2024-05-30 15:47:39 2024-05-30 13:47:39,755 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,755 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,755 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,755 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,755 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,755 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,755 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,755 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,756 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,756 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,756 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,756 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,756 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,756 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,756 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,756 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,756 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.isBackPressured.
2024-05-30 15:47:39 2024-05-30 13:47:39,753 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher  - registering c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0
2024-05-30 15:47:39 2024-05-30 13:47:39,757 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Using partitioner HASH for output 0 of task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,757 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0), deploy into slot with allocation id 6ec3018dfd7ad2d8dcaa869612169256.
2024-05-30 15:47:39 2024-05-30 13:47:39,757 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Using partitioner HASH for output 0 of task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,758 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 8d65a0633b594e1023055f8eb5d4271d.
2024-05-30 15:47:39 2024-05-30 13:47:39,758 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0) switched from CREATED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,758 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Creating FileSystem stream leak safety net for task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0) [DEPLOYING]
2024-05-30 15:47:39 2024-05-30 13:47:39,758 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Loading JAR files for task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,758 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Getting user code class loader for task b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0 at library cache manager took 0 milliseconds
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Using partitioner HASH for output 0 of task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.idleTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.softBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.hardBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.backPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxSoftBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxHardBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.busyTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBusyTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBackPressuredTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateIdleTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxMailsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxLatencyMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new local state store with configuration LocalRecoveryConfig{localStateDirectories=null} for b2acee74555094750d6ee11d259188ed - 87aa6a78642c52c526689f50e970e2b8 - 0 under allocation id 8d65a0633b594e1023055f8eb5d4271d.
2024-05-30 15:47:39 2024-05-30 13:47:39,759 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager  - Found existing state changelog storage for job b2acee74555094750d6ee11d259188ed: org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogStorage@35469a3f.
2024-05-30 15:47:39 2024-05-30 13:47:39,760 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,760 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,760 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,760 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Using partitioner HASH for output 0 of task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,760 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Registering task at network: Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,760 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.io.network.buffer.LocalBufferPool  - Using a local buffer pool with 9-24 buffers
2024-05-30 15:47:39 2024-05-30 13:47:39,760 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Registered PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,760 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher  - registering c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0
2024-05-30 15:47:39 2024-05-30 13:47:39,761 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Using partitioner HASH for output 0 of task Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,765 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@72a5dc6c
2024-05-30 15:47:39 2024-05-30 13:47:39,765 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@17ad0d2c
2024-05-30 15:47:39 2024-05-30 13:47:39,765 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,765 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,765 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@46a287c8
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,765 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@1ba13fcf
2024-05-30 15:47:39 2024-05-30 13:47:39,765 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@750a8fd1
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,766 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,767 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,767 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,767 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,767 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,767 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,767 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,767 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,767 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,767 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,767 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,768 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,769 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,769 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@2fc1e05b
2024-05-30 15:47:39 2024-05-30 13:47:39,769 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,769 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,769 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,771 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@2c570bac
2024-05-30 15:47:39 2024-05-30 13:47:39,771 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,771 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,771 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,772 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@226a64a3
2024-05-30 15:47:39 2024-05-30 13:47:39,772 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,772 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,772 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,774 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0): Created 8 input channels (local: 8, remote: 0, unknown: 0).
2024-05-30 15:47:39 2024-05-30 13:47:39,775 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,775 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,776 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,776 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,776 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Initializing Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0.
2024-05-30 15:47:39 2024-05-30 13:47:39,776 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Initializing Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0.
2024-05-30 15:47:39 2024-05-30 13:47:39,777 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,777 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Initializing Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0.
2024-05-30 15:47:39 2024-05-30 13:47:39,777 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,777 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Initializing Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0.
2024-05-30 15:47:39 2024-05-30 13:47:39,777 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,777 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Initializing Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0.
2024-05-30 15:47:39 2024-05-30 13:47:39,776 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Initializing Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0.
2024-05-30 15:47:39 2024-05-30 13:47:39,777 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,778 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,779 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,779 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,779 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,779 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,779 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,779 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Initializing Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0.
2024-05-30 15:47:39 2024-05-30 13:47:39,779 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,779 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,779 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,779 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,780 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,779 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,780 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,780 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,779 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Initializing Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0.
2024-05-30 15:47:39 2024-05-30 13:47:39,780 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,780 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.isBackPressured.
2024-05-30 15:47:39 2024-05-30 13:47:39,780 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0), deploy into slot with allocation id 8d65a0633b594e1023055f8eb5d4271d.
2024-05-30 15:47:39 2024-05-30 13:47:39,780 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,781 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,781 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,781 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,782 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,783 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,785 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 6a1740c95dc7f606c4106bac93511e32.
2024-05-30 15:47:39 2024-05-30 13:47:39,786 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 6ec3018dfd7ad2d8dcaa869612169256.
2024-05-30 15:47:39 2024-05-30 13:47:39,786 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 0a6a4da3bdbd82f89f0b6179ebdf87a3.
2024-05-30 15:47:39 2024-05-30 13:47:39,786 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 1682416b57c3204f1e47034ed712058a.
2024-05-30 15:47:39 2024-05-30 13:47:39,786 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 00eeda8d0616dc2caf6cec5a00ec1267.
2024-05-30 15:47:39 2024-05-30 13:47:39,786 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 77ba640e4dccc1995b4af4cd8b888262.
2024-05-30 15:47:39 2024-05-30 13:47:39,786 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 8d65a0633b594e1023055f8eb5d4271d.
2024-05-30 15:47:39 2024-05-30 13:47:39,786 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot b8b5242c6762175095a12034622f0abe.
2024-05-30 15:47:39 2024-05-30 13:47:39,786 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 77ba640e4dccc1995b4af4cd8b888262.
2024-05-30 15:47:39 2024-05-30 13:47:39,785 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0) switched from CREATED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,786 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Creating FileSystem stream leak safety net for task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0) [DEPLOYING]
2024-05-30 15:47:39 2024-05-30 13:47:39,786 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Loading JAR files for task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,787 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Getting user code class loader for task b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0 at library cache manager took 1 milliseconds
2024-05-30 15:47:39 2024-05-30 13:47:39,787 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,788 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,788 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,788 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,788 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,788 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,788 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,788 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,788 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,789 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,789 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.idleTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,789 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.softBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,789 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.hardBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,789 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.backPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,789 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxSoftBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,789 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxHardBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,789 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.busyTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,789 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,790 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,788 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Registering task at network: TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,790 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,790 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,790 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,790 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.buffer.LocalBufferPool  - Using a local buffer pool with 1-8 buffers
2024-05-30 15:47:39 2024-05-30 13:47:39,790 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,790 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,790 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,790 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBusyTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,790 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBackPressuredTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,790 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateIdleTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,790 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxMailsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,791 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxLatencyMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,791 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,791 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new local state store with configuration LocalRecoveryConfig{localStateDirectories=null} for b2acee74555094750d6ee11d259188ed - 87aa6a78642c52c526689f50e970e2b8 - 1 under allocation id 77ba640e4dccc1995b4af4cd8b888262.
2024-05-30 15:47:39 2024-05-30 13:47:39,791 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager  - Found existing state changelog storage for job b2acee74555094750d6ee11d259188ed: org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogStorage@35469a3f.
2024-05-30 15:47:39 2024-05-30 13:47:39,791 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,792 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,792 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,792 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,792 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,792 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,792 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,792 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,792 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@12320c59
2024-05-30 15:47:39 2024-05-30 13:47:39,792 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,792 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,793 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,792 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,793 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,793 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,793 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,793 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,794 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,793 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Initializing TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0.
2024-05-30 15:47:39 2024-05-30 13:47:39,795 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,797 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,798 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,798 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,798 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,798 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,798 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,798 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,798 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,798 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,799 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,799 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,799 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,799 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,799 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,799 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,799 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,800 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,800 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,800 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,800 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,800 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,800 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,800 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,800 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,800 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,800 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,800 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0): Created 8 input channels (local: 8, remote: 0, unknown: 0).
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,801 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,802 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,802 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,803 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,803 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,803 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,803 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,803 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,803 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,803 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,803 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,803 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,803 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,803 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,803 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,804 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,804 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,804 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,804 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,804 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,804 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,804 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,804 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,804 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,804 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,804 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,804 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,804 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,804 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,804 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,804 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,805 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,805 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,805 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,805 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,805 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,805 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,805 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,805 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,806 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,806 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,806 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,806 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,806 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,806 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,806 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,806 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,806 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,806 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,806 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,806 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,807 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,807 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,807 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,807 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,807 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,807 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,807 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,807 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,807 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,807 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,807 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.isBackPressured.
2024-05-30 15:47:39 2024-05-30 13:47:39,807 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0), deploy into slot with allocation id 77ba640e4dccc1995b4af4cd8b888262.
2024-05-30 15:47:39 2024-05-30 13:47:39,807 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,807 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,808 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,808 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,808 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,808 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,808 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,808 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,808 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,808 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,808 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0) switched from CREATED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,809 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Creating FileSystem stream leak safety net for task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0) [DEPLOYING]
2024-05-30 15:47:39 2024-05-30 13:47:39,809 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Loading JAR files for task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,809 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Getting user code class loader for task b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0 at library cache manager took 0 milliseconds
2024-05-30 15:47:39 2024-05-30 13:47:39,808 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,809 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Registering task at network: TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,809 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.buffer.LocalBufferPool  - Using a local buffer pool with 1-8 buffers
2024-05-30 15:47:39 2024-05-30 13:47:39,809 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@129a8e63
2024-05-30 15:47:39 2024-05-30 13:47:39,809 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,809 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,809 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,809 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,811 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,811 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,811 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 00eeda8d0616dc2caf6cec5a00ec1267.
2024-05-30 15:47:39 2024-05-30 13:47:39,812 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,812 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,812 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,813 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,813 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,813 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,813 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,813 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,813 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,813 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,813 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,813 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,813 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,813 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.idleTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.softBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.hardBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.backPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxSoftBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxHardBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.busyTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBusyTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBackPressuredTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateIdleTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxMailsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxLatencyMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,814 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,815 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new local state store with configuration LocalRecoveryConfig{localStateDirectories=null} for b2acee74555094750d6ee11d259188ed - 87aa6a78642c52c526689f50e970e2b8 - 2 under allocation id 00eeda8d0616dc2caf6cec5a00ec1267.
2024-05-30 15:47:39 2024-05-30 13:47:39,815 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager  - Found existing state changelog storage for job b2acee74555094750d6ee11d259188ed: org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogStorage@35469a3f.
2024-05-30 15:47:39 2024-05-30 13:47:39,813 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Initializing TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0.
2024-05-30 15:47:39 2024-05-30 13:47:39,815 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,816 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,817 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,817 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,817 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,817 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,817 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,817 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,817 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,817 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,817 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,817 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,817 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,817 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,817 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,817 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,817 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,817 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,818 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,818 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,818 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,818 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,818 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,818 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,818 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,818 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,818 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,818 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,818 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,818 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,819 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,819 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,819 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,819 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,819 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,819 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,819 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,819 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,819 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,819 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,819 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,821 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,822 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,823 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,823 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,823 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,823 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,823 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,823 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,823 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,823 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,823 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,823 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,823 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,823 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,824 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,824 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,824 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,824 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,824 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Completed connection to node -1. Fetching API versions.
2024-05-30 15:47:39 2024-05-30 13:47:39,824 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,824 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,824 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,824 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,824 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,824 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,824 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Initiating API versions fetch from node -1.
2024-05-30 15:47:39 2024-05-30 13:47:39,824 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,825 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,825 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,825 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,825 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,825 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,825 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,825 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,825 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,826 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInErrors.
2024-05-30 15:47:39 2024-05-30 13:47:39,826 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,826 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,826 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.sourceIdleTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,827 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] No version information found when sending API_VERSIONS with correlation id 0 to node -1. Assuming version 3.
2024-05-30 15:47:39 2024-05-30 13:47:39,827 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,827 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,827 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,827 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentEmitEventTimeLag.
2024-05-30 15:47:39 2024-05-30 13:47:39,827 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,827 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,828 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,829 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,829 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,829 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,829 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,829 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,829 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,829 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,829 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,829 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,830 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,830 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,830 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,830 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,830 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,830 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,830 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,830 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,830 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInErrors.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.sourceIdleTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentEmitEventTimeLag.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.commitsSucceeded.
2024-05-30 15:47:39 2024-05-30 13:47:39,831 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.commitsFailed.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,832 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInErrors.
2024-05-30 15:47:39 2024-05-30 13:47:39,833 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.sourceIdleTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,833 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentEmitEventTimeLag.
2024-05-30 15:47:39 2024-05-30 13:47:39,833 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,833 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.commitsSucceeded.
2024-05-30 15:47:39 2024-05-30 13:47:39,833 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.commitsFailed.
2024-05-30 15:47:39 2024-05-30 13:47:39,834 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,834 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,834 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,834 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,834 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,834 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,834 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,834 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,835 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,835 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInErrors.
2024-05-30 15:47:39 2024-05-30 13:47:39,835 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.sourceIdleTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,835 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentEmitEventTimeLag.
2024-05-30 15:47:39 2024-05-30 13:47:39,835 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,835 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.commitsSucceeded.
2024-05-30 15:47:39 2024-05-30 13:47:39,835 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.commitsFailed.
2024-05-30 15:47:39 2024-05-30 13:47:39,835 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,836 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,836 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,836 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,836 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,836 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,836 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,836 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,836 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,836 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointStartDelayNanos.
2024-05-30 15:47:39 2024-05-30 13:47:39,836 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,836 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Invoking Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,836 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,836 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,837 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,837 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,837 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,837 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointStartDelayNanos.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Invoking Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,838 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointStartDelayNanos.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Invoking Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.commitsSucceeded.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.commitsFailed.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointStartDelayNanos.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Invoking Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInErrors.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,839 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,840 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointAlignmentTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,840 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointStartDelayNanos.
2024-05-30 15:47:39 2024-05-30 13:47:39,840 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,840 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointAlignmentTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,840 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointStartDelayNanos.
2024-05-30 15:47:39 2024-05-30 13:47:39,840 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0): Created 8 input channels (local: 8, remote: 0, unknown: 0).
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,841 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,842 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,842 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,842 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,842 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,842 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,842 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,842 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,842 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,842 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,842 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,842 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,842 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.isBackPressured.
2024-05-30 15:47:39 2024-05-30 13:47:39,842 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0), deploy into slot with allocation id 00eeda8d0616dc2caf6cec5a00ec1267.
2024-05-30 15:47:39 2024-05-30 13:47:39,842 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,843 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,844 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 1682416b57c3204f1e47034ed712058a.
2024-05-30 15:47:39 2024-05-30 13:47:39,843 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0) switched from CREATED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,844 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,844 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,844 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,844 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,844 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,845 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,844 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Creating FileSystem stream leak safety net for task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0) [DEPLOYING]
2024-05-30 15:47:39 2024-05-30 13:47:39,845 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Loading JAR files for task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,845 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Getting user code class loader for task b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0 at library cache manager took 0 milliseconds
2024-05-30 15:47:39 2024-05-30 13:47:39,845 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,845 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,845 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Registering task at network: TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,845 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.buffer.LocalBufferPool  - Using a local buffer pool with 1-8 buffers
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@68a8551
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,845 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.idleTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.softBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.hardBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Initializing TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.backPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxSoftBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxHardBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.busyTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBusyTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBackPressuredTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateIdleTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxMailsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxLatencyMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [flink-akka.actor.default-dispatcher-11] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,846 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new local state store with configuration LocalRecoveryConfig{localStateDirectories=null} for b2acee74555094750d6ee11d259188ed - 87aa6a78642c52c526689f50e970e2b8 - 3 under allocation id 1682416b57c3204f1e47034ed712058a.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager  - Found existing state changelog storage for job b2acee74555094750d6ee11d259188ed: org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogStorage@35469a3f.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInErrors.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.sourceIdleTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.sourceIdleTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentEmitEventTimeLag.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.commitsSucceeded.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.commitsFailed.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointStartDelayNanos.
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Invoking Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,847 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentEmitEventTimeLag.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,848 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,849 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,849 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,849 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,849 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,849 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,849 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,849 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,849 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,849 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,849 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointAlignmentTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,849 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.commitsSucceeded.
2024-05-30 15:47:39 2024-05-30 13:47:39,849 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.commitsFailed.
2024-05-30 15:47:39 2024-05-30 13:47:39,849 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointStartDelayNanos.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInErrors.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.sourceIdleTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentEmitEventTimeLag.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.commitsSucceeded.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.commitsFailed.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointStartDelayNanos.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Invoking Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=flink_consumer-enumerator-admin-client, correlationId=0) and timeout 3600000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.2.3')
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Invoking Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,850 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,851 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,851 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,851 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,851 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,851 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,851 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,851 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInErrors.
2024-05-30 15:47:39 2024-05-30 13:47:39,851 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.sourceIdleTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,851 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentEmitEventTimeLag.
2024-05-30 15:47:39 2024-05-30 13:47:39,851 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,851 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointStartDelayNanos.
2024-05-30 15:47:39 2024-05-30 13:47:39,851 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.commitsSucceeded.
2024-05-30 15:47:39 2024-05-30 13:47:39,851 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.commitsFailed.
2024-05-30 15:47:39 2024-05-30 13:47:39,851 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointStartDelayNanos.
2024-05-30 15:47:39 2024-05-30 13:47:39,851 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Invoking Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] KafkaClient#poll retrieved 0 response(s)
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0): Created 8 input channels (local: 8, remote: 0, unknown: 0).
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Trying to choose nodes for [Call(callName=describeTopics, deadlineMs=1717076919599, tries=0, nextAllowedTryMs=0)] at 1717076859852
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.internals.AdminMetadataManager  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Metadata is not ready: we have not fetched metadata from the bootstrap nodes yet.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Unable to assign Call(callName=describeTopics, deadlineMs=1717076919599, tries=0, nextAllowedTryMs=0) to a node.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.isBackPressured.
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Client is not ready to send to kafka:9092 (id: -1 rack: null). Must delay 9223372036854775807 ms
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Entering KafkaClient#poll(timeout=100)
2024-05-30 15:47:39 2024-05-30 13:47:39,852 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0), deploy into slot with allocation id 1682416b57c3204f1e47034ed712058a.
2024-05-30 15:47:39 2024-05-30 13:47:39,853 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0) switched from CREATED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,853 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Creating FileSystem stream leak safety net for task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0) [DEPLOYING]
2024-05-30 15:47:39 2024-05-30 13:47:39,853 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Loading JAR files for task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,853 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Getting user code class loader for task b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0 at library cache manager took 0 milliseconds
2024-05-30 15:47:39 2024-05-30 13:47:39,853 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 6a1740c95dc7f606c4106bac93511e32.
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Registering task at network: TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.buffer.LocalBufferPool  - Using a local buffer pool with 1-8 buffers
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@18caa33a
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] KafkaClient#poll retrieved 0 response(s)
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Trying to choose nodes for [Call(callName=describeTopics, deadlineMs=1717076919599, tries=0, nextAllowedTryMs=0)] at 1717076859854
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.internals.AdminMetadataManager  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Metadata is not ready: we have not fetched metadata from the bootstrap nodes yet.
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Unable to assign Call(callName=describeTopics, deadlineMs=1717076919599, tries=0, nextAllowedTryMs=0) to a node.
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Client is not ready to send to kafka:9092 (id: -1 rack: null). Must delay 9223372036854775807 ms
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Entering KafkaClient#poll(timeout=100)
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Initializing TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0.
2024-05-30 15:47:39 2024-05-30 13:47:39,858 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,854 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,858 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,859 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,859 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,859 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,859 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,859 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,859 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.idleTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,859 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.softBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,859 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.hardBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,859 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.backPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,859 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxSoftBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,859 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxHardBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,859 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.busyTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,859 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBusyTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,859 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBackPressuredTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,859 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateIdleTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,860 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxMailsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,860 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxLatencyMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,860 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,860 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new local state store with configuration LocalRecoveryConfig{localStateDirectories=null} for b2acee74555094750d6ee11d259188ed - 87aa6a78642c52c526689f50e970e2b8 - 4 under allocation id 6a1740c95dc7f606c4106bac93511e32.
2024-05-30 15:47:39 2024-05-30 13:47:39,860 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager  - Found existing state changelog storage for job b2acee74555094750d6ee11d259188ed: org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogStorage@35469a3f.
2024-05-30 15:47:39 2024-05-30 13:47:39,860 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,860 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,860 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,860 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,860 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0): Created 8 input channels (local: 8, remote: 0, unknown: 0).
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,861 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,862 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.isBackPressured.
2024-05-30 15:47:39 2024-05-30 13:47:39,862 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0), deploy into slot with allocation id 6a1740c95dc7f606c4106bac93511e32.
2024-05-30 15:47:39 2024-05-30 13:47:39,862 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,863 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,863 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot b8b5242c6762175095a12034622f0abe.
2024-05-30 15:47:39 2024-05-30 13:47:39,863 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0) switched from CREATED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,863 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Creating FileSystem stream leak safety net for task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0) [DEPLOYING]
2024-05-30 15:47:39 2024-05-30 13:47:39,863 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Loading JAR files for task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,863 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Getting user code class loader for task b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0 at library cache manager took 0 milliseconds
2024-05-30 15:47:39 2024-05-30 13:47:39,864 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Registering task at network: TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.buffer.LocalBufferPool  - Using a local buffer pool with 1-8 buffers
2024-05-30 15:47:39 2024-05-30 13:47:39,863 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@577bf3e3
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Initializing TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0.
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,865 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,866 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,866 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,866 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,866 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,866 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.idleTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,866 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.softBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,867 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.hardBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,867 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.backPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,867 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxSoftBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,867 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxHardBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,867 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.busyTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,867 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBusyTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,867 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBackPressuredTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,867 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateIdleTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,867 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxMailsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,867 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxLatencyMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,867 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,867 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new local state store with configuration LocalRecoveryConfig{localStateDirectories=null} for b2acee74555094750d6ee11d259188ed - 87aa6a78642c52c526689f50e970e2b8 - 6 under allocation id b8b5242c6762175095a12034622f0abe.
2024-05-30 15:47:39 2024-05-30 13:47:39,867 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager  - Found existing state changelog storage for job b2acee74555094750d6ee11d259188ed: org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogStorage@35469a3f.
2024-05-30 15:47:39 2024-05-30 13:47:39,867 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,867 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,867 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,868 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,868 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,868 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,868 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,868 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,868 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,868 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,868 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,868 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,868 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,868 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,869 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,869 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,869 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,869 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,869 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,869 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0): Created 8 input channels (local: 8, remote: 0, unknown: 0).
2024-05-30 15:47:39 2024-05-30 13:47:39,869 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,869 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,869 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,869 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,869 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,869 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,869 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,870 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,870 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,870 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf  - -Dorg.apache.flink.shaded.netty4.io.netty.buffer.checkAccessible: true
2024-05-30 15:47:39 2024-05-30 13:47:39,870 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf  - -Dorg.apache.flink.shaded.netty4.io.netty.buffer.checkBounds: true
2024-05-30 15:47:39 2024-05-30 13:47:39,870 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,871 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,871 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,871 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,872 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.shaded.netty4.io.netty.util.ResourceLeakDetectorFactory  - Loaded default ResourceLeakDetector: org.apache.flink.shaded.netty4.io.netty.util.ResourceLeakDetector@5d75c711
2024-05-30 15:47:39 2024-05-30 13:47:39,873 [flink-akka.actor.default-dispatcher-10] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.isBackPressured.
2024-05-30 15:47:39 2024-05-30 13:47:39,873 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0), deploy into slot with allocation id b8b5242c6762175095a12034622f0abe.
2024-05-30 15:47:39 2024-05-30 13:47:39,874 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,874 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,874 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,874 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Invoking TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,874 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,874 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,874 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Invoking TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,875 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,875 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,875 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,875 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,875 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,876 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,876 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 0a6a4da3bdbd82f89f0b6179ebdf87a3.
2024-05-30 15:47:39 2024-05-30 13:47:39,877 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,877 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,877 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,877 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,877 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,877 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,877 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,877 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,877 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,877 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,876 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0) switched from CREATED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,877 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Creating FileSystem stream leak safety net for task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0) [DEPLOYING]
2024-05-30 15:47:39 2024-05-30 13:47:39,877 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Loading JAR files for task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,877 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Getting user code class loader for task b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0 at library cache manager took 0 milliseconds
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.idleTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.softBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.hardBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.backPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxSoftBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxHardBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.busyTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBusyTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBackPressuredTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateIdleTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxMailsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxLatencyMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new local state store with configuration LocalRecoveryConfig{localStateDirectories=null} for b2acee74555094750d6ee11d259188ed - 87aa6a78642c52c526689f50e970e2b8 - 5 under allocation id 0a6a4da3bdbd82f89f0b6179ebdf87a3.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager  - Found existing state changelog storage for job b2acee74555094750d6ee11d259188ed: org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogStorage@35469a3f.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Registering task at network: TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.buffer.LocalBufferPool  - Using a local buffer pool with 1-8 buffers
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@61528b05
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Initializing TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0.
2024-05-30 15:47:39 2024-05-30 13:47:39,878 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0): Created 8 input channels (local: 8, remote: 0, unknown: 0).
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.isBackPressured.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0), deploy into slot with allocation id 0a6a4da3bdbd82f89f0b6179ebdf87a3.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,879 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,880 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,880 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,880 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,880 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,880 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,880 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,880 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,880 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,880 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,880 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,880 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,880 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0) switched from CREATED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,880 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl  - Activate slot 6ec3018dfd7ad2d8dcaa869612169256.
2024-05-30 15:47:39 2024-05-30 13:47:39,880 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Creating FileSystem stream leak safety net for task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0) [DEPLOYING]
2024-05-30 15:47:39 2024-05-30 13:47:39,880 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Loading JAR files for task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,881 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Getting user code class loader for task b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0 at library cache manager took 1 milliseconds
2024-05-30 15:47:39 2024-05-30 13:47:39,881 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Invoking TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,881 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Registering task at network: TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,881 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.buffer.LocalBufferPool  - Using a local buffer pool with 1-8 buffers
2024-05-30 15:47:39 2024-05-30 13:47:39,881 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@1b28ca5a
2024-05-30 15:47:39 2024-05-30 13:47:39,881 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,881 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,881 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,881 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,881 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Initializing TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0.
2024-05-30 15:47:39 2024-05-30 13:47:39,882 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,882 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,882 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,882 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,882 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,882 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,882 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,882 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,882 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,882 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,882 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,883 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,883 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,883 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,884 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,883 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Received API_VERSIONS response from node -1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=flink_consumer-enumerator-admin-client, correlationId=0): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=15), ApiVersion(apiKey=2, minVersion=0, maxVersion=8), ApiVersion(apiKey=3, minVersion=0, maxVersion=12), ApiVersion(apiKey=4, minVersion=0, maxVersion=7), ApiVersion(apiKey=5, minVersion=0, maxVersion=4), ApiVersion(apiKey=6, minVersion=0, maxVersion=8), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=8), ApiVersion(apiKey=10, minVersion=0, maxVersion=4), ApiVersion(apiKey=11, minVersion=0, maxVersion=9), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=5), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=4), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=3), ApiVersion(apiKey=30, minVersion=0, maxVersion=3), ApiVersion(apiKey=31, minVersion=0, maxVersion=3), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=4), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=3), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=3), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=3), ApiVersion(apiKey=57, minVersion=0, maxVersion=1), ApiVersion(apiKey=58, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0), ApiVersion(apiKey=65, minVersion=0, maxVersion=0), ApiVersion(apiKey=66, minVersion=0, maxVersion=0), ApiVersion(apiKey=67, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[])
2024-05-30 15:47:39 2024-05-30 13:47:39,884 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,884 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,884 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,884 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,884 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,884 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.idleTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,884 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.softBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,884 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.hardBackPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,884 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.backPressuredTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,885 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxSoftBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,885 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.maxHardBackPressureTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,885 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.busyTimeMsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,885 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBusyTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,885 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateBackPressuredTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,885 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.accumulateIdleTimeMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,885 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxMailsPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,885 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxLatencyMs.
2024-05-30 15:47:39 2024-05-30 13:47:39,885 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.mailboxQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,885 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager  - Registered new local state store with configuration LocalRecoveryConfig{localStateDirectories=null} for b2acee74555094750d6ee11d259188ed - 87aa6a78642c52c526689f50e970e2b8 - 7 under allocation id 6ec3018dfd7ad2d8dcaa869612169256.
2024-05-30 15:47:39 2024-05-30 13:47:39,885 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager  - Found existing state changelog storage for job b2acee74555094750d6ee11d259188ed: org.apache.flink.runtime.state.changelog.inmemory.InMemoryStateChangelogStorage@35469a3f.
2024-05-30 15:47:39 2024-05-30 13:47:39,885 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,886 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,887 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointAlignmentTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,887 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointStartDelayNanos.
2024-05-30 15:47:39 2024-05-30 13:47:39,887 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,887 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,887 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,887 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Output.Buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,887 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,887 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,887 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,887 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,888 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,889 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBytesInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,889 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,889 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBytesInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,889 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,889 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,889 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInLocal.
2024-05-30 15:47:39 2024-05-30 13:47:39,889 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInLocalPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,889 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,889 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.numBuffersInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,889 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInRemote.
2024-05-30 15:47:39 2024-05-30 13:47:39,889 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.numBuffersInRemotePerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,889 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0): Created 8 input channels (local: 8, remote: 0, unknown: 0).
2024-05-30 15:47:39 2024-05-30 13:47:39,890 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,890 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,890 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,890 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,890 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.Shuffle.Netty.Input.Buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,890 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,890 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,890 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.outPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,890 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueLength.
2024-05-30 15:47:39 2024-05-30 13:47:39,890 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputQueueSize.
2024-05-30 15:47:39 2024-05-30 13:47:39,890 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputExclusiveBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,890 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inputFloatingBuffersUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,890 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.buffers.inPoolUsage.
2024-05-30 15:47:39 2024-05-30 13:47:39,891 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.isBackPressured.
2024-05-30 15:47:39 2024-05-30 13:47:39,891 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0), deploy into slot with allocation id 6ec3018dfd7ad2d8dcaa869612169256.
2024-05-30 15:47:39 2024-05-30 13:47:39,891 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_55ed089c8063510c7ff35d8fe8aecfff_(7/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,891 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,892 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,892 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,892 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,892 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,892 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,892 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,892 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,892 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,892 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0) switched from CREATED to DEPLOYING.
2024-05-30 15:47:39 2024-05-30 13:47:39,892 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointAlignmentTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,892 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointStartDelayNanos.
2024-05-30 15:47:39 2024-05-30 13:47:39,893 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Creating FileSystem stream leak safety net for task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0) [DEPLOYING]
2024-05-30 15:47:39 2024-05-30 13:47:39,893 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Loading JAR files for task TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,893 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Getting user code class loader for task b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0 at library cache manager took 0 milliseconds
2024-05-30 15:47:39 2024-05-30 13:47:39,893 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,893 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,893 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Invoking TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,893 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamSink_015b9e3923550d125934f1de5b214fe2_(4/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,893 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,893 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.taskmanager.Task  - Registering task at network: TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0) [DEPLOYING].
2024-05-30 15:47:39 2024-05-30 13:47:39,894 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.buffer.LocalBufferPool  - Using a local buffer pool with 1-8 buffers
2024-05-30 15:47:39 2024-05-30 13:47:39,894 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,894 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@75c176ff
2024-05-30 15:47:39 2024-05-30 13:47:39,894 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,894 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Invoking TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,894 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,894 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,894 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,894 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,894 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,894 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,894 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,894 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,894 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,895 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointAlignmentTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,895 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointStartDelayNanos.
2024-05-30 15:47:39 2024-05-30 13:47:39,895 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,897 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,897 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Invoking TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,897 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamSink_015b9e3923550d125934f1de5b214fe2_(7/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,897 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamSink_015b9e3923550d125934f1de5b214fe2_(5/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,897 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,897 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,898 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] INFO  org.apache.flink.runtime.state.StateBackendLoader  - State backend loader loads the state backend as HashMapStateBackend
2024-05-30 15:47:39 2024-05-30 13:47:39,898 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - The configuration state.checkpoint-storage has not be set in the current sessions flink-conf.yaml. Falling back to a default CheckpointStorage type. Users are strongly encouraged explicitly set this configuration so they understand how their applications are checkpointing snapshots for fault-tolerance.
2024-05-30 15:47:39 2024-05-30 13:47:39,898 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - Checkpoint storage is set to 'jobmanager'
2024-05-30 15:47:39 2024-05-30 13:47:39,898 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,898 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,899 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,899 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Initializing TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0.
2024-05-30 15:47:39 2024-05-30 13:47:39,899 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,899 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,899 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,899 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,899 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,899 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,899 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0) switched from DEPLOYING to INITIALIZING.
2024-05-30 15:47:39 2024-05-30 13:47:39,900 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,900 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,900 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,900 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,900 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,900 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,900 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,900 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,900 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,900 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,900 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointAlignmentTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,900 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointStartDelayNanos.
2024-05-30 15:47:39 2024-05-30 13:47:39,900 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,900 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,900 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Invoking TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,901 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamSink_015b9e3923550d125934f1de5b214fe2_(6/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,901 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,902 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,902 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,902 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,902 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,902 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,902 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,902 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,902 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,902 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_466a800f6d78ae498013491517cb46b8_(6/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,902 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,903 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_466a800f6d78ae498013491517cb46b8_(5/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,903 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,903 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,903 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,903 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,903 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,903 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,903 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,903 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,903 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamSink_015b9e3923550d125934f1de5b214fe2_(2/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_466a800f6d78ae498013491517cb46b8_(7/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_466a800f6d78ae498013491517cb46b8_(2/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating keyed state backend for WindowOperator_87aa6a78642c52c526689f50e970e2b8_(7/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_466a800f6d78ae498013491517cb46b8_(4/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating keyed state backend for WindowOperator_87aa6a78642c52c526689f50e970e2b8_(2/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,905 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating keyed state backend for WindowOperator_87aa6a78642c52c526689f50e970e2b8_(4/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_55ed089c8063510c7ff35d8fe8aecfff_(6/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,905 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_cb5600ceebcdb988bd9e6bec64cb6a90_(7/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,905 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_cb5600ceebcdb988bd9e6bec64cb6a90_(6/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,905 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for TimestampsAndWatermarksOperator_7bc5efc3126096844f12e1c4aac21587_(7/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,905 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for TimestampsAndWatermarksOperator_7bc5efc3126096844f12e1c4aac21587_(6/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating keyed state backend for WindowOperator_87aa6a78642c52c526689f50e970e2b8_(6/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamSink_015b9e3923550d125934f1de5b214fe2_(3/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,905 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_466a800f6d78ae498013491517cb46b8_(3/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,905 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating keyed state backend for WindowOperator_87aa6a78642c52c526689f50e970e2b8_(3/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_55ed089c8063510c7ff35d8fe8aecfff_(4/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,905 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_cb5600ceebcdb988bd9e6bec64cb6a90_(4/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,905 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numRecordsOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,906 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesIn.
2024-05-30 15:47:39 2024-05-30 13:47:39,906 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOut.
2024-05-30 15:47:39 2024-05-30 13:47:39,906 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesInPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,906 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numBytesOutPerSecond.
2024-05-30 15:47:39 2024-05-30 13:47:39,906 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentOutputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,906 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointAlignmentTime.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating keyed state backend for WindowOperator_87aa6a78642c52c526689f50e970e2b8_(5/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_55ed089c8063510c7ff35d8fe8aecfff_(1/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,907 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.checkpointStartDelayNanos.
2024-05-30 15:47:39 2024-05-30 13:47:39,907 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_cb5600ceebcdb988bd9e6bec64cb6a90_(1/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,907 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for TimestampsAndWatermarksOperator_7bc5efc3126096844f12e1c4aac21587_(1/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_55ed089c8063510c7ff35d8fe8aecfff_(3/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,907 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_cb5600ceebcdb988bd9e6bec64cb6a90_(3/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,907 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for TimestampsAndWatermarksOperator_7bc5efc3126096844f12e1c4aac21587_(3/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,908 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_55ed089c8063510c7ff35d8fe8aecfff_(8/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,908 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_cb5600ceebcdb988bd9e6bec64cb6a90_(8/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,908 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for TimestampsAndWatermarksOperator_7bc5efc3126096844f12e1c4aac21587_(8/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,904 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_55ed089c8063510c7ff35d8fe8aecfff_(2/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,908 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_cb5600ceebcdb988bd9e6bec64cb6a90_(2/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,908 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.currentInputWatermark.
2024-05-30 15:47:39 2024-05-30 13:47:39,906 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for TimestampsAndWatermarksOperator_7bc5efc3126096844f12e1c4aac21587_(4/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,908 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for TimestampsAndWatermarksOperator_7bc5efc3126096844f12e1c4aac21587_(2/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,905 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_55ed089c8063510c7ff35d8fe8aecfff_(5/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,910 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_cb5600ceebcdb988bd9e6bec64cb6a90_(5/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,910 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for TimestampsAndWatermarksOperator_7bc5efc3126096844f12e1c4aac21587_(5/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,905 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamSink_015b9e3923550d125934f1de5b214fe2_(1/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,910 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_466a800f6d78ae498013491517cb46b8_(1/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,910 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating keyed state backend for WindowOperator_87aa6a78642c52c526689f50e970e2b8_(1/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,910 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask  - Invoking TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0
2024-05-30 15:47:39 2024-05-30 13:47:39,911 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamSink_015b9e3923550d125934f1de5b214fe2_(8/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,911 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_466a800f6d78ae498013491517cb46b8_(8/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,911 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating keyed state backend for WindowOperator_87aa6a78642c52c526689f50e970e2b8_(8/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,911 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_0e90f93dd6c2bfc9de34a6a7c1979ccc_(4/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,911 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for SourceOperator_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_(4/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,912 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder  - Finished to build heap keyed state-backend.
2024-05-30 15:47:39 2024-05-30 13:47:39,912 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder  - Finished to build heap keyed state-backend.
2024-05-30 15:47:39 2024-05-30 13:47:39,913 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder  - Finished to build heap keyed state-backend.
2024-05-30 15:47:39 2024-05-30 13:47:39,913 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder  - Finished to build heap keyed state-backend.
2024-05-30 15:47:39 2024-05-30 13:47:39,913 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder  - Finished to build heap keyed state-backend.
2024-05-30 15:47:39 2024-05-30 13:47:39,914 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder  - Finished to build heap keyed state-backend.
2024-05-30 15:47:39 2024-05-30 13:47:39,914 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder  - Finished to build heap keyed state-backend.
2024-05-30 15:47:39 2024-05-30 13:47:39,914 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder  - Finished to build heap keyed state-backend.
2024-05-30 15:47:39 2024-05-30 13:47:39,915 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_0e90f93dd6c2bfc9de34a6a7c1979ccc_(2/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,916 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for SourceOperator_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_(2/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,917 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_0e90f93dd6c2bfc9de34a6a7c1979ccc_(5/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,917 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for SourceOperator_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_(5/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,918 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_0e90f93dd6c2bfc9de34a6a7c1979ccc_(6/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,918 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for SourceOperator_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_(6/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,922 [SourceCoordinator-Source: Kafka Source] INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator  - Source Source: Kafka Source registering reader for parallel task 4 (#0) @ 
2024-05-30 15:47:39 2024-05-30 13:47:39,922 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_0e90f93dd6c2bfc9de34a6a7c1979ccc_(3/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,922 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for SourceOperator_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_(3/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,923 [SourceCoordinator-Source: Kafka Source] DEBUG org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator  - Adding reader 4 to KafkaSourceEnumerator for consumer group flink_consumer.
2024-05-30 15:47:39 2024-05-30 13:47:39,923 [SourceCoordinator-Source: Kafka Source] INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator  - Source Source: Kafka Source registering reader for parallel task 1 (#0) @ 
2024-05-30 15:47:39 2024-05-30 13:47:39,923 [SourceCoordinator-Source: Kafka Source] DEBUG org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator  - Adding reader 1 to KafkaSourceEnumerator for consumer group flink_consumer.
2024-05-30 15:47:39 2024-05-30 13:47:39,923 [SourceCoordinator-Source: Kafka Source] INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator  - Source Source: Kafka Source registering reader for parallel task 5 (#0) @ 
2024-05-30 15:47:39 2024-05-30 13:47:39,923 [SourceCoordinator-Source: Kafka Source] DEBUG org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator  - Adding reader 5 to KafkaSourceEnumerator for consumer group flink_consumer.
2024-05-30 15:47:39 2024-05-30 13:47:39,923 [SourceCoordinator-Source: Kafka Source] INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator  - Source Source: Kafka Source registering reader for parallel task 3 (#0) @ 
2024-05-30 15:47:39 2024-05-30 13:47:39,923 [SourceCoordinator-Source: Kafka Source] DEBUG org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator  - Adding reader 3 to KafkaSourceEnumerator for consumer group flink_consumer.
2024-05-30 15:47:39 2024-05-30 13:47:39,923 [SourceCoordinator-Source: Kafka Source] INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator  - Source Source: Kafka Source registering reader for parallel task 2 (#0) @ 
2024-05-30 15:47:39 2024-05-30 13:47:39,923 [SourceCoordinator-Source: Kafka Source] DEBUG org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator  - Adding reader 2 to KafkaSourceEnumerator for consumer group flink_consumer.
2024-05-30 15:47:39 2024-05-30 13:47:39,926 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_0e90f93dd6c2bfc9de34a6a7c1979ccc_(1/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,928 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for SourceOperator_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_(1/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,928 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,931 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,931 [SourceCoordinator-Source: Kafka Source] INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator  - Source Source: Kafka Source registering reader for parallel task 0 (#0) @ 
2024-05-30 15:47:39 2024-05-30 13:47:39,931 [SourceCoordinator-Source: Kafka Source] DEBUG org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator  - Adding reader 0 to KafkaSourceEnumerator for consumer group flink_consumer.
2024-05-30 15:47:39 2024-05-30 13:47:39,932 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,934 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:47:39 2024-05-30 13:47:39,934 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: NOTHING_AVAILABLE
2024-05-30 15:47:39 2024-05-30 13:47:39,936 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_0e90f93dd6c2bfc9de34a6a7c1979ccc_(7/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,936 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for SourceOperator_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_(7/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,936 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Node -1 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 15 [usable: 13], ListOffsets(2): 0 to 8 [usable: 7], Metadata(3): 0 to 12 [usable: 12], LeaderAndIsr(4): 0 to 7 [usable: 6], StopReplica(5): 0 to 4 [usable: 3], UpdateMetadata(6): 0 to 8 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 8 [usable: 8], FindCoordinator(10): 0 to 4 [usable: 4], JoinGroup(11): 0 to 9 [usable: 9], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 5 [usable: 5], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 4 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 3 [usable: 2], CreateAcls(30): 0 to 3 [usable: 2], DeleteAcls(31): 0 to 3 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 4 [usable: 3], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 3 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 3 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterPartition(56): 0 to 3 [usable: 1], UpdateFeatures(57): 0 to 1 [usable: 0], Envelope(58): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): 0 [usable: 0], ListTransactions(66): 0 [usable: 0], AllocateProducerIds(67): 0 [usable: 0]).
2024-05-30 15:47:39 2024-05-30 13:47:39,937 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] KafkaClient#poll retrieved 0 response(s)
2024-05-30 15:47:39 2024-05-30 13:47:39,936 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for StreamMap_0e90f93dd6c2bfc9de34a6a7c1979ccc_(8/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,937 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Trying to choose nodes for [Call(callName=describeTopics, deadlineMs=1717076919599, tries=0, nextAllowedTryMs=0)] at 1717076859937
2024-05-30 15:47:39 2024-05-30 13:47:39,936 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:47:39 2024-05-30 13:47:39,936 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,937 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: NOTHING_AVAILABLE
2024-05-30 15:47:39 2024-05-30 13:47:39,937 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.internals.AdminMetadataManager  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Metadata is not ready: we have not fetched metadata from the bootstrap nodes yet.
2024-05-30 15:47:39 2024-05-30 13:47:39,937 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Unable to assign Call(callName=describeTopics, deadlineMs=1717076919599, tries=0, nextAllowedTryMs=0) to a node.
2024-05-30 15:47:39 2024-05-30 13:47:39,938 [SourceCoordinator-Source: Kafka Source] INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator  - Source Source: Kafka Source registering reader for parallel task 6 (#0) @ 
2024-05-30 15:47:39 2024-05-30 13:47:39,938 [SourceCoordinator-Source: Kafka Source] DEBUG org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator  - Adding reader 6 to KafkaSourceEnumerator for consumer group flink_consumer.
2024-05-30 15:47:39 2024-05-30 13:47:39,938 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for SourceOperator_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_(8/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,938 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to kafka:9092 (id: -1 rack: null). correlationId=1, timeoutMs=29660
2024-05-30 15:47:39 2024-05-30 13:47:39,939 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,939 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:47:39 2024-05-30 13:47:39,939 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: NOTHING_AVAILABLE
2024-05-30 15:47:39 2024-05-30 13:47:39,939 [SourceCoordinator-Source: Kafka Source] INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator  - Source Source: Kafka Source registering reader for parallel task 7 (#0) @ 
2024-05-30 15:47:39 2024-05-30 13:47:39,939 [SourceCoordinator-Source: Kafka Source] DEBUG org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator  - Adding reader 7 to KafkaSourceEnumerator for consumer group flink_consumer.
2024-05-30 15:47:39 2024-05-30 13:47:39,939 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,940 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=12, clientId=flink_consumer-enumerator-admin-client, correlationId=1) and timeout 29660 to node -1: MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2024-05-30 15:47:39 2024-05-30 13:47:39,940 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackend  - Initializing heap keyed state backend with stream factory.
2024-05-30 15:47:39 2024-05-30 13:47:39,940 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for WindowOperator_87aa6a78642c52c526689f50e970e2b8_(1/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,940 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackend  - Initializing heap keyed state backend with stream factory.
2024-05-30 15:47:39 2024-05-30 13:47:39,940 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for WindowOperator_87aa6a78642c52c526689f50e970e2b8_(4/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Entering KafkaClient#poll(timeout=100)
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackend  - Initializing heap keyed state backend with stream factory.
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for WindowOperator_87aa6a78642c52c526689f50e970e2b8_(5/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] KafkaClient#poll retrieved 0 response(s)
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Trying to choose nodes for [Call(callName=describeTopics, deadlineMs=1717076919599, tries=0, nextAllowedTryMs=0)] at 1717076859941
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.internals.AdminMetadataManager  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Metadata is not ready: we have not fetched metadata from the bootstrap nodes yet.
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Unable to assign Call(callName=describeTopics, deadlineMs=1717076919599, tries=0, nextAllowedTryMs=0) to a node.
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Entering KafkaClient#poll(timeout=100)
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackend  - Initializing heap keyed state backend with stream factory.
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for WindowOperator_87aa6a78642c52c526689f50e970e2b8_(2/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackend  - Initializing heap keyed state backend with stream factory.
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for WindowOperator_87aa6a78642c52c526689f50e970e2b8_(8/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackend  - Initializing heap keyed state backend with stream factory.
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackend  - Initializing heap keyed state backend with stream factory.
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: NOTHING_AVAILABLE
2024-05-30 15:47:39 2024-05-30 13:47:39,941 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for WindowOperator_87aa6a78642c52c526689f50e970e2b8_(6/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,942 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,942 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackend  - Initializing heap keyed state backend with stream factory.
2024-05-30 15:47:39 2024-05-30 13:47:39,942 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for WindowOperator_87aa6a78642c52c526689f50e970e2b8_(3/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,943 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:47:39 2024-05-30 13:47:39,943 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: NOTHING_AVAILABLE
2024-05-30 15:47:39 2024-05-30 13:47:39,943 [flink-akka.actor.default-dispatcher-9] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,943 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numLateRecordsDropped.
2024-05-30 15:47:39 2024-05-30 13:47:39,944 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numLateRecordsDropped.
2024-05-30 15:47:39 2024-05-30 13:47:39,944 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numLateRecordsDropped.
2024-05-30 15:47:39 2024-05-30 13:47:39,944 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numLateRecordsDropped.
2024-05-30 15:47:39 2024-05-30 13:47:39,944 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numLateRecordsDropped.
2024-05-30 15:47:39 2024-05-30 13:47:39,945 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,945 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:47:39 2024-05-30 13:47:39,945 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: NOTHING_AVAILABLE
2024-05-30 15:47:39 2024-05-30 13:47:39,945 [flink-akka.actor.default-dispatcher-7] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,944 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,945 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:47:39 2024-05-30 13:47:39,946 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: NOTHING_AVAILABLE
2024-05-30 15:47:39 2024-05-30 13:47:39,945 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numLateRecordsDropped.
2024-05-30 15:47:39 2024-05-30 13:47:39,946 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,946 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:47:39 2024-05-30 13:47:39,946 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: NOTHING_AVAILABLE
2024-05-30 15:47:39 2024-05-30 13:47:39,946 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.streaming.api.operators.BackendRestorerProcedure  - Creating operator state backend for WindowOperator_87aa6a78642c52c526689f50e970e2b8_(7/8) with empty state.
2024-05-30 15:47:39 2024-05-30 13:47:39,946 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numLateRecordsDropped.
2024-05-30 15:47:39 2024-05-30 13:47:39,946 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.numLateRecordsDropped.
2024-05-30 15:47:39 2024-05-30 13:47:39,947 [flink-akka.actor.default-dispatcher-11] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,947 [flink-akka.actor.default-dispatcher-11] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8) (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,950 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Received METADATA response from node -1 for request with header RequestHeader(apiKey=METADATA, apiVersion=12, clientId=flink_consumer-enumerator-admin-client, correlationId=1): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=1, host='kafka', port=9092, rack=null)], clusterId='nzGe6aXUTge_XxOJN9iTig', controllerId=1, topics=[], clusterAuthorizedOperations=-2147483648)
2024-05-30 15:47:39 2024-05-30 13:47:39,950 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] KafkaClient#poll retrieved 1 response(s)
2024-05-30 15:47:39 2024-05-30 13:47:39,951 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.admin.internals.AdminMetadataManager  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Updating cluster metadata to Cluster(id = nzGe6aXUTge_XxOJN9iTig, nodes = [kafka:9092 (id: 1 rack: null)], partitions = [], controller = kafka:9092 (id: 1 rack: null))
2024-05-30 15:47:39 2024-05-30 13:47:39,951 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Call(callName=fetchMetadata, deadlineMs=1717076889597, tries=0, nextAllowedTryMs=0) got response MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=1, host='kafka', port=9092, rack=null)], clusterId='nzGe6aXUTge_XxOJN9iTig', controllerId=1, topics=[], clusterAuthorizedOperations=-2147483648)
2024-05-30 15:47:39 2024-05-30 13:47:39,951 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Trying to choose nodes for [Call(callName=describeTopics, deadlineMs=1717076919599, tries=0, nextAllowedTryMs=0)] at 1717076859950
2024-05-30 15:47:39 2024-05-30 13:47:39,951 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.internals.AdminMetadataManager  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Metadata is ready to use.
2024-05-30 15:47:39 2024-05-30 13:47:39,951 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Found least loaded node kafka:9092 (id: 1 rack: null) with no active connection
2024-05-30 15:47:39 2024-05-30 13:47:39,951 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Assigned Call(callName=describeTopics, deadlineMs=1717076919599, tries=0, nextAllowedTryMs=0) to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:39 2024-05-30 13:47:39,951 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.ClientUtils  - Resolved host kafka as 172.18.0.4
2024-05-30 15:47:39 2024-05-30 13:47:39,951 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Initiating connection to node kafka:9092 (id: 1 rack: null) using address kafka/172.18.0.4
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Client is not ready to send to kafka:9092 (id: 1 rack: null). Must delay 8345 ms
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Entering KafkaClient#poll(timeout=8345)
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.requests-sent
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-total, group=admin-client-node-metrics, description=The total number of requests sent, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node-1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-rate, group=admin-client-node-metrics, description=The number of requests sent per second, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node-1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-size-avg, group=admin-client-node-metrics, description=The average size of requests sent., tags={client-id=flink_consumer-enumerator-admin-client, node-id=node-1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-size-max, group=admin-client-node-metrics, description=The maximum size of any request sent., tags={client-id=flink_consumer-enumerator-admin-client, node-id=node-1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-sent
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=outgoing-byte-total, group=admin-client-node-metrics, description=The total number of outgoing bytes, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node-1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=outgoing-byte-rate, group=admin-client-node-metrics, description=The number of outgoing bytes per second, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node-1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.responses-received
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=response-total, group=admin-client-node-metrics, description=The total number of responses received, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node-1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=response-rate, group=admin-client-node-metrics, description=The number of responses received per second, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node-1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-received
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=incoming-byte-total, group=admin-client-node-metrics, description=The total number of incoming bytes, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node-1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=incoming-byte-rate, group=admin-client-node-metrics, description=The number of incoming bytes per second, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node-1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.latency
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-latency-avg, group=admin-client-node-metrics, description=, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node-1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,952 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-latency-max, group=admin-client-node-metrics, description=, tags={client-id=flink_consumer-enumerator-admin-client, node-id=node-1}]
2024-05-30 15:47:39 2024-05-30 13:47:39,953 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.common.network.Selector  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 1
2024-05-30 15:47:39 2024-05-30 13:47:39,953 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Completed connection to node 1. Fetching API versions.
2024-05-30 15:47:39 2024-05-30 13:47:39,953 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Initiating API versions fetch from node 1.
2024-05-30 15:47:39 2024-05-30 13:47:39,953 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] No version information found when sending API_VERSIONS with correlation id 2 to node 1. Assuming version 3.
2024-05-30 15:47:39 2024-05-30 13:47:39,953 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=flink_consumer-enumerator-admin-client, correlationId=2) and timeout 3600000 to node 1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.2.3')
2024-05-30 15:47:39 2024-05-30 13:47:39,953 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] KafkaClient#poll retrieved 0 response(s)
2024-05-30 15:47:39 2024-05-30 13:47:39,953 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Trying to choose nodes for [] at 1717076859953
2024-05-30 15:47:39 2024-05-30 13:47:39,953 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Client is not ready to send to kafka:9092 (id: 1 rack: null). Must delay 9223372036854775807 ms
2024-05-30 15:47:39 2024-05-30 13:47:39,953 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Entering KafkaClient#poll(timeout=29997)
2024-05-30 15:47:39 2024-05-30 13:47:39,953 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] KafkaClient#poll retrieved 0 response(s)
2024-05-30 15:47:39 2024-05-30 13:47:39,953 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Trying to choose nodes for [] at 1717076859953
2024-05-30 15:47:39 2024-05-30 13:47:39,953 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Client is not ready to send to kafka:9092 (id: 1 rack: null). Must delay 9223372036854775807 ms
2024-05-30 15:47:39 2024-05-30 13:47:39,953 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Entering KafkaClient#poll(timeout=29997)
2024-05-30 15:47:39 2024-05-30 13:47:39,955 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Received API_VERSIONS response from node 1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=flink_consumer-enumerator-admin-client, correlationId=2): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=15), ApiVersion(apiKey=2, minVersion=0, maxVersion=8), ApiVersion(apiKey=3, minVersion=0, maxVersion=12), ApiVersion(apiKey=4, minVersion=0, maxVersion=7), ApiVersion(apiKey=5, minVersion=0, maxVersion=4), ApiVersion(apiKey=6, minVersion=0, maxVersion=8), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=8), ApiVersion(apiKey=10, minVersion=0, maxVersion=4), ApiVersion(apiKey=11, minVersion=0, maxVersion=9), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=5), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=4), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=3), ApiVersion(apiKey=30, minVersion=0, maxVersion=3), ApiVersion(apiKey=31, minVersion=0, maxVersion=3), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=4), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=3), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=3), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=3), ApiVersion(apiKey=57, minVersion=0, maxVersion=1), ApiVersion(apiKey=58, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0), ApiVersion(apiKey=65, minVersion=0, maxVersion=0), ApiVersion(apiKey=66, minVersion=0, maxVersion=0), ApiVersion(apiKey=67, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[])
2024-05-30 15:47:39 2024-05-30 13:47:39,955 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Node 1 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 15 [usable: 13], ListOffsets(2): 0 to 8 [usable: 7], Metadata(3): 0 to 12 [usable: 12], LeaderAndIsr(4): 0 to 7 [usable: 6], StopReplica(5): 0 to 4 [usable: 3], UpdateMetadata(6): 0 to 8 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 8 [usable: 8], FindCoordinator(10): 0 to 4 [usable: 4], JoinGroup(11): 0 to 9 [usable: 9], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 5 [usable: 5], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 4 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 3 [usable: 2], CreateAcls(30): 0 to 3 [usable: 2], DeleteAcls(31): 0 to 3 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 4 [usable: 3], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 3 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 3 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterPartition(56): 0 to 3 [usable: 1], UpdateFeatures(57): 0 to 1 [usable: 0], Envelope(58): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): 0 [usable: 0], ListTransactions(66): 0 [usable: 0], AllocateProducerIds(67): 0 [usable: 0]).
2024-05-30 15:47:39 2024-05-30 13:47:39,955 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] KafkaClient#poll retrieved 0 response(s)
2024-05-30 15:47:39 2024-05-30 13:47:39,955 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Trying to choose nodes for [] at 1717076859955
2024-05-30 15:47:39 2024-05-30 13:47:39,956 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Sending MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='aisdata')], allowAutoTopicCreation=false, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to kafka:9092 (id: 1 rack: null). correlationId=3, timeoutMs=29995
2024-05-30 15:47:39 2024-05-30 13:47:39,956 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=12, clientId=flink_consumer-enumerator-admin-client, correlationId=3) and timeout 29995 to node 1: MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='aisdata')], allowAutoTopicCreation=false, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2024-05-30 15:47:39 2024-05-30 13:47:39,956 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Entering KafkaClient#poll(timeout=59644)
2024-05-30 15:47:39 2024-05-30 13:47:39,956 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] KafkaClient#poll retrieved 0 response(s)
2024-05-30 15:47:39 2024-05-30 13:47:39,956 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Trying to choose nodes for [] at 1717076859956
2024-05-30 15:47:39 2024-05-30 13:47:39,956 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Entering KafkaClient#poll(timeout=59643)
2024-05-30 15:47:39 2024-05-30 13:47:39,958 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] DEBUG org.apache.kafka.clients.NetworkClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=12, clientId=flink_consumer-enumerator-admin-client, correlationId=3): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=1, host='kafka', port=9092, rack=null)], clusterId='nzGe6aXUTge_XxOJN9iTig', controllerId=1, topics=[MetadataResponseTopic(errorCode=0, name='aisdata', topicId=ZiGIwhiYS8-umhWEVwc-NQ, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=1, leaderEpoch=0, replicaNodes=[1], isrNodes=[1], offlineReplicas=[])], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648)
2024-05-30 15:47:39 2024-05-30 13:47:39,958 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] KafkaClient#poll retrieved 1 response(s)
2024-05-30 15:47:39 2024-05-30 13:47:39,961 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Call(callName=describeTopics, deadlineMs=1717076919599, tries=0, nextAllowedTryMs=0) got response MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=1, host='kafka', port=9092, rack=null)], clusterId='nzGe6aXUTge_XxOJN9iTig', controllerId=1, topics=[MetadataResponseTopic(errorCode=0, name='aisdata', topicId=ZiGIwhiYS8-umhWEVwc-NQ, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=1, leaderEpoch=0, replicaNodes=[1], isrNodes=[1], offlineReplicas=[])], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648)
2024-05-30 15:47:39 2024-05-30 13:47:39,961 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Trying to choose nodes for [] at 1717076859958
2024-05-30 15:47:39 2024-05-30 13:47:39,961 [kafka-admin-client-thread | flink_consumer-enumerator-admin-client] TRACE org.apache.kafka.clients.admin.KafkaAdminClient  - [AdminClient clientId=flink_consumer-enumerator-admin-client] Entering KafkaClient#poll(timeout=299992)
2024-05-30 15:47:39 2024-05-30 13:47:39,962 [SourceCoordinator-Source: Kafka Source] INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator  - Discovered new partitions: [aisdata-0]
2024-05-30 15:47:39 2024-05-30 13:47:39,962 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,962 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,962 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,962 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,963 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=1} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=1} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=2} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=3} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=4} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=5} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=6} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=7} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=1} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=2} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=3} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=4} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=5} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=6} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=7} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=1} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=1} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=2} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=3} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=4} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=5} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=6} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=7} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,964 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=2} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=3} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=4} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=5} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=6} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=7} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [SourceCoordinator-Source: Kafka Source] DEBUG org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator  - Partition discovery is disabled.
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,965 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=2} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,966 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,966 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=3} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,966 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,966 [SourceCoordinator-Source: Kafka Source] DEBUG org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator  - Assigned [[Partition: aisdata-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]] to 8 readers of consumer group flink_consumer.
2024-05-30 15:47:39 2024-05-30 13:47:39,966 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=4} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,966 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,966 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=5} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,966 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,966 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,966 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=6} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,966 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,966 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=7} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,966 [flink-akka.actor.default-dispatcher-11] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,967 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate  - Converting recovered input channels (8 channels)
2024-05-30 15:47:39 2024-05-30 13:47:39,967 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,968 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,968 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,968 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,968 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,968 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,968 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,968 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,968 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,968 [SourceCoordinator-Source: Kafka Source] INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator  - Assigning splits to readers {3=[[Partition: aisdata-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
2024-05-30 15:47:39 2024-05-30 13:47:39,968 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,968 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0]: Requesting LOCAL subpartition 5 of partition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,968 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 5 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,970 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0): Creating read view for subpartition 5 of partition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [flink-akka.actor.default-dispatcher-11] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor  - Operator event for b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0 - e3dfc0d7e9ecd8a43f85f0b68ebf3b80
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 5) of ResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0]: Requesting LOCAL subpartition 5 of partition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 5 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0): Creating read view for subpartition 5 of partition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 5) of ResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0]: Requesting LOCAL subpartition 5 of partition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 5 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0): Creating read view for subpartition 5 of partition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 5) of ResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0]: Requesting LOCAL subpartition 5 of partition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 5 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0): Creating read view for subpartition 5 of partition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 5) of ResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0]: Requesting LOCAL subpartition 5 of partition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 5 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,971 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0): Creating read view for subpartition 5 of partition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 5) of ResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0]: Requesting LOCAL subpartition 5 of partition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 5 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0): Creating read view for subpartition 5 of partition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 5) of ResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0]: Requesting LOCAL subpartition 5 of partition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 5 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0): Creating read view for subpartition 5 of partition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 5) of ResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0]: Requesting LOCAL subpartition 5 of partition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 5 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0): Creating read view for subpartition 5 of partition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 5) of ResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate  - Converting recovered input channels (8 channels)
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,973 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,973 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=1} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,973 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,973 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=2} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,973 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,972 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,973 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,973 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,973 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=3} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,973 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0]: Requesting LOCAL subpartition 0 of partition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,973 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,973 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=4} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,973 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,973 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=5} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,973 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 0 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0): Creating read view for subpartition 0 of partition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 0) of ResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0]: Requesting LOCAL subpartition 0 of partition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 0 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0): Creating read view for subpartition 0 of partition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 0) of ResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0]: Requesting LOCAL subpartition 0 of partition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 0 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0): Creating read view for subpartition 0 of partition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 0) of ResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0]: Requesting LOCAL subpartition 0 of partition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 0 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0): Creating read view for subpartition 0 of partition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 0) of ResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0]: Requesting LOCAL subpartition 0 of partition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 0 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0): Creating read view for subpartition 0 of partition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 0) of ResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0]: Requesting LOCAL subpartition 0 of partition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 0 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0): Creating read view for subpartition 0 of partition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 0) of ResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0]: Requesting LOCAL subpartition 0 of partition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 0 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0): Creating read view for subpartition 0 of partition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 0) of ResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0]: Requesting LOCAL subpartition 0 of partition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 0 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0): Creating read view for subpartition 0 of partition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 0) of ResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,973 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=6} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,974 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=7} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,976 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,976 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,977 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,977 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,977 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,977 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,977 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,977 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,977 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,977 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,977 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,977 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,977 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,977 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,977 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,977 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,977 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,977 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate  - Converting recovered input channels (8 channels)
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0]: Requesting LOCAL subpartition 1 of partition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 1 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0): Creating read view for subpartition 1 of partition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 1) of ResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0]: Requesting LOCAL subpartition 1 of partition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 1 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0): Creating read view for subpartition 1 of partition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 1) of ResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0]: Requesting LOCAL subpartition 1 of partition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 1 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0): Creating read view for subpartition 1 of partition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 1) of ResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0]: Requesting LOCAL subpartition 1 of partition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 1 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0): Creating read view for subpartition 1 of partition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 1) of ResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0]: Requesting LOCAL subpartition 1 of partition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 1 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0): Creating read view for subpartition 1 of partition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 1) of ResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0]: Requesting LOCAL subpartition 1 of partition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 1 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0): Creating read view for subpartition 1 of partition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 1) of ResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0]: Requesting LOCAL subpartition 1 of partition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 1 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0): Creating read view for subpartition 1 of partition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 1) of ResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0]: Requesting LOCAL subpartition 1 of partition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 1 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0): Creating read view for subpartition 1 of partition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 1) of ResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,979 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase  - Adding split(s) to reader: [[Partition: aisdata-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,978 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate  - Converting recovered input channels (8 channels)
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,981 [flink-akka.actor.default-dispatcher-11] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,980 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,981 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0]: Requesting LOCAL subpartition 2 of partition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,981 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 2 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,981 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,981 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,982 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=1} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,982 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,982 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=2} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,982 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,982 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,982 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=0} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,982 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0): Creating read view for subpartition 2 of partition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 2) of ResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0]: Requesting LOCAL subpartition 2 of partition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 2 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0): Creating read view for subpartition 2 of partition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 2) of ResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0]: Requesting LOCAL subpartition 2 of partition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 2 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0): Creating read view for subpartition 2 of partition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 2) of ResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate  - Converting recovered input channels (8 channels)
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0]: Requesting LOCAL subpartition 2 of partition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,983 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 2 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0): Creating read view for subpartition 2 of partition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 2) of ResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0]: Requesting LOCAL subpartition 2 of partition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 2 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0): Creating read view for subpartition 2 of partition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 2) of ResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0]: Requesting LOCAL subpartition 2 of partition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 2 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0): Creating read view for subpartition 2 of partition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 2) of ResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0]: Requesting LOCAL subpartition 2 of partition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 2 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0): Creating read view for subpartition 2 of partition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 2) of ResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0]: Requesting LOCAL subpartition 2 of partition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0]: Requesting LOCAL subpartition 4 of partition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=1} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=2} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=3} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=4} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,984 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=5} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=6} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=7} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate  - Converting recovered input channels (8 channels)
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 2 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0): Creating read view for subpartition 2 of partition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate  - Converting recovered input channels (8 channels)
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0]: Requesting LOCAL subpartition 6 of partition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0]: Requesting LOCAL subpartition 7 of partition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 2) of ResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,985 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=3} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 7 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,986 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=4} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0): Creating read view for subpartition 7 of partition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 7) of ResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0]: Requesting LOCAL subpartition 7 of partition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 7 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0): Creating read view for subpartition 7 of partition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 7) of ResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0]: Requesting LOCAL subpartition 7 of partition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 7 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0): Creating read view for subpartition 7 of partition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 7) of ResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0]: Requesting LOCAL subpartition 7 of partition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 7 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0): Creating read view for subpartition 7 of partition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 7) of ResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0]: Requesting LOCAL subpartition 7 of partition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 7 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0): Creating read view for subpartition 7 of partition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 7) of ResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0]: Requesting LOCAL subpartition 7 of partition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 7 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0): Creating read view for subpartition 7 of partition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 7) of ResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0]: Requesting LOCAL subpartition 7 of partition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 7 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0): Creating read view for subpartition 7 of partition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 7) of ResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0]: Requesting LOCAL subpartition 7 of partition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 7 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0): Creating read view for subpartition 7 of partition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 7) of ResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,987 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=5} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=6} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [channel-state-unspilling-thread-1] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] InputChannelRecoveredStateHandler#recover Buffer{cnt=1, size=4, hash=923526} @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 6 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] INFO  org.apache.flink.runtime.taskmanager.Task  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0): Creating read view for subpartition 6 of partition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [flink-akka.actor.default-dispatcher-10] INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8) (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0) switched from INITIALIZING to RUNNING.
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 6) of ResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0
2024-05-30 15:47:39 2024-05-30 13:47:39,988 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate  - Converting recovered input channels (8 channels)
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.ChannelStatePersister  - stopPersisting -1, lastSeenBarrier = -1 (COMPLETED) @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0]: Requesting LOCAL subpartition 3 of partition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 3 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0): Creating read view for subpartition 3 of partition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 3) of ResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0]: Requesting LOCAL subpartition 3 of partition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 3 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0): Creating read view for subpartition 3 of partition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 3) of ResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0]: Requesting LOCAL subpartition 3 of partition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 3 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0): Creating read view for subpartition 3 of partition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 3) of ResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0]: Requesting LOCAL subpartition 3 of partition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0]: Requesting LOCAL subpartition 6 of partition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [channel-state-unspilling-thread-1] DEBUG org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel  - TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)/InputChannelInfo{gateIdx=0, inputChannelIdx=7} finished recovering input.
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 3 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0): Creating read view for subpartition 3 of partition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 3) of ResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0
2024-05-30 15:47:39 2024-05-30 13:47:39,989 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0]: Requesting LOCAL subpartition 3 of partition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 4 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0): Creating read view for subpartition 4 of partition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 4) of ResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 3 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0): Creating read view for subpartition 3 of partition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0]: Requesting LOCAL subpartition 4 of partition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 3) of ResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0]: Requesting LOCAL subpartition 3 of partition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 6 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0): Creating read view for subpartition 6 of partition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 6) of ResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 3 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0): Creating read view for subpartition 3 of partition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 3) of ResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0]: Requesting LOCAL subpartition 6 of partition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 4 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0): Creating read view for subpartition 4 of partition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 4) of ResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0]: Requesting LOCAL subpartition 4 of partition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 4 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0): Creating read view for subpartition 4 of partition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 4) of ResultPartition c03241209d966d8bb09ece01a9db9c83#6@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0]: Requesting LOCAL subpartition 4 of partition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0]: Requesting LOCAL subpartition 3 of partition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 6 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0): Creating read view for subpartition 6 of partition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 6) of ResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 3 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0): Creating read view for subpartition 3 of partition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 3) of ResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0]: Requesting LOCAL subpartition 6 of partition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 4 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0): Creating read view for subpartition 4 of partition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 4) of ResultPartition c03241209d966d8bb09ece01a9db9c83#7@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0]: Requesting LOCAL subpartition 4 of partition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 4 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0): Creating read view for subpartition 4 of partition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 4) of ResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0]: Requesting LOCAL subpartition 4 of partition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 4 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0): Creating read view for subpartition 4 of partition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 4) of ResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0]: Requesting LOCAL subpartition 4 of partition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,990 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0]: Requesting LOCAL subpartition 3 of partition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 6 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0): Creating read view for subpartition 6 of partition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 6) of ResultPartition c03241209d966d8bb09ece01a9db9c83#5@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0]: Requesting LOCAL subpartition 6 of partition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,991 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 6 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0): Creating read view for subpartition 6 of partition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 6) of ResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0]: Requesting LOCAL subpartition 6 of partition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 6 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0): Creating read view for subpartition 6 of partition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 6) of ResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0]: Requesting LOCAL subpartition 6 of partition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 6 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0): Creating read view for subpartition 6 of partition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 6) of ResultPartition c03241209d966d8bb09ece01a9db9c83#0@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0]: Requesting LOCAL subpartition 6 of partition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 4 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0): Creating read view for subpartition 4 of partition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 4) of ResultPartition c03241209d966d8bb09ece01a9db9c83#2@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel  - LocalInputChannel [c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0]: Requesting LOCAL subpartition 4 of partition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0. ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)}
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 4 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0): Creating read view for subpartition 4 of partition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0.
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 4) of ResultPartition c03241209d966d8bb09ece01a9db9c83#3@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,992 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:39 2024-05-30 13:47:39,993 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,993 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:39 2024-05-30 13:47:39,993 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,993 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:39 2024-05-30 13:47:39,993 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,993 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:39 2024-05-30 13:47:39,993 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,993 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:39 2024-05-30 13:47:39,993 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=4}
2024-05-30 15:47:39 2024-05-30 13:47:39,993 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:39 2024-05-30 13:47:39,997 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig  - ConsumerConfig values: 
2024-05-30 15:47:39     allow.auto.create.topics = true
2024-05-30 15:47:39     auto.commit.interval.ms = 5000
2024-05-30 15:47:39     auto.offset.reset = earliest
2024-05-30 15:47:39     bootstrap.servers = [kafka:9092]
2024-05-30 15:47:39     check.crcs = true
2024-05-30 15:47:39     client.dns.lookup = use_all_dns_ips
2024-05-30 15:47:39     client.id = flink_consumer-3
2024-05-30 15:47:39     client.rack = 
2024-05-30 15:47:39     connections.max.idle.ms = 540000
2024-05-30 15:47:39     default.api.timeout.ms = 60000
2024-05-30 15:47:39     enable.auto.commit = false
2024-05-30 15:47:39     exclude.internal.topics = true
2024-05-30 15:47:39     fetch.max.bytes = 52428800
2024-05-30 15:47:39     fetch.max.wait.ms = 500
2024-05-30 15:47:39     fetch.min.bytes = 1
2024-05-30 15:47:39     group.id = flink_consumer
2024-05-30 15:47:39     group.instance.id = null
2024-05-30 15:47:39     heartbeat.interval.ms = 3000
2024-05-30 15:47:39     interceptor.classes = []
2024-05-30 15:47:39     internal.leave.group.on.close = true
2024-05-30 15:47:39     internal.throw.on.fetch.stable.offset.unsupported = false
2024-05-30 15:47:39     isolation.level = read_uncommitted
2024-05-30 15:47:39     key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
2024-05-30 15:47:39     max.partition.fetch.bytes = 1048576
2024-05-30 15:47:39     max.poll.interval.ms = 300000
2024-05-30 15:47:39     max.poll.records = 500
2024-05-30 15:47:39     metadata.max.age.ms = 300000
2024-05-30 15:47:39     metric.reporters = []
2024-05-30 15:47:39     metrics.num.samples = 2
2024-05-30 15:47:39     metrics.recording.level = INFO
2024-05-30 15:47:39     metrics.sample.window.ms = 30000
2024-05-30 15:47:39     partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
2024-05-30 15:47:39     receive.buffer.bytes = 65536
2024-05-30 15:47:39     reconnect.backoff.max.ms = 1000
2024-05-30 15:47:39     reconnect.backoff.ms = 50
2024-05-30 15:47:39     request.timeout.ms = 30000
2024-05-30 15:47:39     retry.backoff.ms = 100
2024-05-30 15:47:39     sasl.client.callback.handler.class = null
2024-05-30 15:47:39     sasl.jaas.config = null
2024-05-30 15:47:39     sasl.kerberos.kinit.cmd = /usr/bin/kinit
2024-05-30 15:47:39     sasl.kerberos.min.time.before.relogin = 60000
2024-05-30 15:47:39     sasl.kerberos.service.name = null
2024-05-30 15:47:39     sasl.kerberos.ticket.renew.jitter = 0.05
2024-05-30 15:47:39     sasl.kerberos.ticket.renew.window.factor = 0.8
2024-05-30 15:47:39     sasl.login.callback.handler.class = null
2024-05-30 15:47:39     sasl.login.class = null
2024-05-30 15:47:39     sasl.login.connect.timeout.ms = null
2024-05-30 15:47:39     sasl.login.read.timeout.ms = null
2024-05-30 15:47:39     sasl.login.refresh.buffer.seconds = 300
2024-05-30 15:47:39     sasl.login.refresh.min.period.seconds = 60
2024-05-30 15:47:39     sasl.login.refresh.window.factor = 0.8
2024-05-30 15:47:39     sasl.login.refresh.window.jitter = 0.05
2024-05-30 15:47:39     sasl.login.retry.backoff.max.ms = 10000
2024-05-30 15:47:39     sasl.login.retry.backoff.ms = 100
2024-05-30 15:47:39     sasl.mechanism = GSSAPI
2024-05-30 15:47:39     sasl.oauthbearer.clock.skew.seconds = 30
2024-05-30 15:47:39     sasl.oauthbearer.expected.audience = null
2024-05-30 15:47:39     sasl.oauthbearer.expected.issuer = null
2024-05-30 15:47:39     sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
2024-05-30 15:47:39     sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
2024-05-30 15:47:39     sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
2024-05-30 15:47:39     sasl.oauthbearer.jwks.endpoint.url = null
2024-05-30 15:47:39     sasl.oauthbearer.scope.claim.name = scope
2024-05-30 15:47:39     sasl.oauthbearer.sub.claim.name = sub
2024-05-30 15:47:39     sasl.oauthbearer.token.endpoint.url = null
2024-05-30 15:47:39     security.protocol = PLAINTEXT
2024-05-30 15:47:39     security.providers = null
2024-05-30 15:47:39     send.buffer.bytes = 131072
2024-05-30 15:47:39     session.timeout.ms = 45000
2024-05-30 15:47:39     socket.connection.setup.timeout.max.ms = 30000
2024-05-30 15:47:39     socket.connection.setup.timeout.ms = 10000
2024-05-30 15:47:39     ssl.cipher.suites = null
2024-05-30 15:47:39     ssl.enabled.protocols = [TLSv1.2]
2024-05-30 15:47:39     ssl.endpoint.identification.algorithm = https
2024-05-30 15:47:39     ssl.engine.factory.class = null
2024-05-30 15:47:39     ssl.key.password = null
2024-05-30 15:47:39     ssl.keymanager.algorithm = SunX509
2024-05-30 15:47:39     ssl.keystore.certificate.chain = null
2024-05-30 15:47:39     ssl.keystore.key = null
2024-05-30 15:47:39     ssl.keystore.location = null
2024-05-30 15:47:39     ssl.keystore.password = null
2024-05-30 15:47:39     ssl.keystore.type = JKS
2024-05-30 15:47:39     ssl.protocol = TLSv1.2
2024-05-30 15:47:39     ssl.provider = null
2024-05-30 15:47:39     ssl.secure.random.implementation = null
2024-05-30 15:47:39     ssl.trustmanager.algorithm = PKIX
2024-05-30 15:47:39     ssl.truststore.certificates = null
2024-05-30 15:47:39     ssl.truststore.location = null
2024-05-30 15:47:39     ssl.truststore.password = null
2024-05-30 15:47:39     ssl.truststore.type = JKS
2024-05-30 15:47:39     value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
2024-05-30 15:47:39 
2024-05-30 15:47:39 2024-05-30 13:47:39,998 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Initializing the Kafka consumer
2024-05-30 15:47:39 2024-05-30 13:47:39,998 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=count, group=kafka-metrics-count, description=total number of registered metrics, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:39 2024-05-30 13:47:39,999 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 6 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:39 2024-05-30 13:47:39,999 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0): Creating read view for subpartition 6 of partition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0.
2024-05-30 15:47:40 2024-05-30 13:47:39,999 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 6) of ResultPartition c03241209d966d8bb09ece01a9db9c83#1@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0
2024-05-30 15:47:40 2024-05-30 13:47:39,999 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=6}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager  - Requesting subpartition 3 of PipelinedResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0 [PIPELINED_BOUNDED, 8 subpartitions, 9 pending consumptions].
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition  - Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0): Creating read view for subpartition 3 of partition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0.
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition  - Created PipelinedSubpartitionView(index: 3) of ResultPartition c03241209d966d8bb09ece01a9db9c83#4@b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=6}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=6}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=6}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_2_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=6}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=2}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=6}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=6}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_1_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=6}
2024-05-30 15:47:40 2024-05-30 13:47:40,000 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=1}
2024-05-30 15:47:40 2024-05-30 13:47:40,001 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_0_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,001 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=0}
2024-05-30 15:47:40 2024-05-30 13:47:40,001 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_7_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,001 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=7}
2024-05-30 15:47:40 2024-05-30 13:47:40,001 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_6_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,001 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=6}
2024-05-30 15:47:40 2024-05-30 13:47:40,001 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_5_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,001 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=5}
2024-05-30 15:47:40 2024-05-30 13:47:40,001 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_4_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=1, size=4, hash=923526} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,001 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] LocalInputChannel#getNextBuffer Buffer{cnt=1, size=4, hash=923526}, seq 0, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=4}
2024-05-30 15:47:40 2024-05-30 13:47:40,009 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name fetch-throttle-time
2024-05-30 15:47:40 2024-05-30 13:47:40,010 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=fetch-throttle-time-avg, group=consumer-fetch-manager-metrics, description=The average throttle time in ms, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,010 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=fetch-throttle-time-max, group=consumer-fetch-manager-metrics, description=The maximum throttle time in ms, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,010 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-closed:
2024-05-30 15:47:40 2024-05-30 13:47:40,011 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=connection-close-total, group=consumer-metrics, description=The total number of connections closed, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,011 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=connection-close-rate, group=consumer-metrics, description=The number of connections closed per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,011 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-created:
2024-05-30 15:47:40 2024-05-30 13:47:40,011 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=connection-creation-total, group=consumer-metrics, description=The total number of new connections established, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,011 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=connection-creation-rate, group=consumer-metrics, description=The number of new connections established per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,011 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication:
2024-05-30 15:47:40 2024-05-30 13:47:40,011 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=successful-authentication-total, group=consumer-metrics, description=The total number of connections with successful authentication, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,011 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=successful-authentication-rate, group=consumer-metrics, description=The number of connections with successful authentication per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,011 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-reauthentication:
2024-05-30 15:47:40 2024-05-30 13:47:40,011 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=successful-reauthentication-total, group=consumer-metrics, description=The total number of successful re-authentication of connections, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,011 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=successful-reauthentication-rate, group=consumer-metrics, description=The number of successful re-authentication of connections per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,011 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication-no-reauth:
2024-05-30 15:47:40 2024-05-30 13:47:40,011 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=successful-authentication-no-reauth-total, group=consumer-metrics, description=The total number of connections with successful authentication where the client does not support re-authentication, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,012 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-authentication:
2024-05-30 15:47:40 2024-05-30 13:47:40,012 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=failed-authentication-total, group=consumer-metrics, description=The total number of connections with failed authentication, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,012 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=failed-authentication-rate, group=consumer-metrics, description=The number of connections with failed authentication per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,012 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-reauthentication:
2024-05-30 15:47:40 2024-05-30 13:47:40,012 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=failed-reauthentication-total, group=consumer-metrics, description=The total number of failed re-authentication of connections, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,012 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=failed-reauthentication-rate, group=consumer-metrics, description=The number of failed re-authentication of connections per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,012 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name reauthentication-latency:
2024-05-30 15:47:40 2024-05-30 13:47:40,012 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=reauthentication-latency-max, group=consumer-metrics, description=The max latency observed due to re-authentication, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,012 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=reauthentication-latency-avg, group=consumer-metrics, description=The average latency observed due to re-authentication, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,012 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent-received:
2024-05-30 15:47:40 2024-05-30 13:47:40,012 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=network-io-total, group=consumer-metrics, description=The total number of network operations (reads or writes) on all connections, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,012 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=network-io-rate, group=consumer-metrics, description=The number of network operations (reads or writes) on all connections per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,012 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent:
2024-05-30 15:47:40 2024-05-30 13:47:40,013 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=outgoing-byte-total, group=consumer-metrics, description=The total number of outgoing bytes sent to all servers, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,013 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=outgoing-byte-rate, group=consumer-metrics, description=The number of outgoing bytes sent to all servers per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,013 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name requests-sent:
2024-05-30 15:47:40 2024-05-30 13:47:40,013 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-total, group=consumer-metrics, description=The total number of requests sent, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,013 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-rate, group=consumer-metrics, description=The number of requests sent per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,013 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-size-avg, group=consumer-metrics, description=The average size of requests sent., tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,013 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-size-max, group=consumer-metrics, description=The maximum size of any request sent., tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,013 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-received:
2024-05-30 15:47:40 2024-05-30 13:47:40,013 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=incoming-byte-total, group=consumer-metrics, description=The total number of bytes read off all sockets, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,013 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=incoming-byte-rate, group=consumer-metrics, description=The number of bytes read off all sockets per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,013 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name responses-received:
2024-05-30 15:47:40 2024-05-30 13:47:40,014 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=response-total, group=consumer-metrics, description=The total number of responses received, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,014 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=response-rate, group=consumer-metrics, description=The number of responses received per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,014 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name select-time:
2024-05-30 15:47:40 2024-05-30 13:47:40,014 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=select-total, group=consumer-metrics, description=The total number of times the I/O layer checked for new I/O to perform, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,014 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=select-rate, group=consumer-metrics, description=The number of times the I/O layer checked for new I/O to perform per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,014 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=io-wait-time-ns-avg, group=consumer-metrics, description=The average length of time the I/O thread spent waiting for a socket ready for reads or writes in nanoseconds., tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,014 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=io-waittime-total, group=consumer-metrics, description=*Deprecated* The total time the I/O thread spent waiting, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,014 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=io-wait-ratio, group=consumer-metrics, description=*Deprecated* The fraction of time the I/O thread spent waiting, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,014 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=io-wait-time-ns-total, group=consumer-metrics, description=The total time the I/O thread spent waiting, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,014 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name io-time:
2024-05-30 15:47:40 2024-05-30 13:47:40,014 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=io-time-ns-avg, group=consumer-metrics, description=The average length of time for I/O per select call in nanoseconds., tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,014 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=iotime-total, group=consumer-metrics, description=*Deprecated* The total time the I/O thread spent doing I/O, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,014 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=io-ratio, group=consumer-metrics, description=*Deprecated* The fraction of time the I/O thread spent doing I/O, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,015 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=io-time-ns-total, group=consumer-metrics, description=The total time the I/O thread spent doing I/O, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,015 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.network.Selector  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] sslCiphers: created new gauge suite with maxEntries = 100.
2024-05-30 15:47:40 2024-05-30 13:47:40,015 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.network.Selector  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] clients: created new gauge suite with maxEntries = 100.
2024-05-30 15:47:40 2024-05-30 13:47:40,015 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=connection-count, group=consumer-metrics, description=The current number of active connections., tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,025 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name heartbeat-latency
2024-05-30 15:47:40 2024-05-30 13:47:40,025 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=heartbeat-response-time-max, group=consumer-coordinator-metrics, description=The max time taken to receive a response to a heartbeat request, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=heartbeat-total, group=consumer-coordinator-metrics, description=The total number of heartbeats, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=heartbeat-rate, group=consumer-coordinator-metrics, description=The number of heartbeats per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name join-latency
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=join-time-avg, group=consumer-coordinator-metrics, description=The average time taken for a group rejoin, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=join-time-max, group=consumer-coordinator-metrics, description=The max time taken for a group rejoin, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=join-total, group=consumer-coordinator-metrics, description=The total number of group joins, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=join-rate, group=consumer-coordinator-metrics, description=The number of group joins per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name sync-latency
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=sync-time-avg, group=consumer-coordinator-metrics, description=The average time taken for a group sync, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=sync-time-max, group=consumer-coordinator-metrics, description=The max time taken for a group sync, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=sync-total, group=consumer-coordinator-metrics, description=The total number of group syncs, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=sync-rate, group=consumer-coordinator-metrics, description=The number of group syncs per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name rebalance-latency
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=rebalance-latency-avg, group=consumer-coordinator-metrics, description=The average time taken for a group to complete a successful rebalance, which may be composed of several failed re-trials until it succeeded, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=rebalance-latency-max, group=consumer-coordinator-metrics, description=The max time taken for a group to complete a successful rebalance, which may be composed of several failed re-trials until it succeeded, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=rebalance-latency-total, group=consumer-coordinator-metrics, description=The total number of milliseconds this consumer has spent in successful rebalances since creation, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=rebalance-total, group=consumer-coordinator-metrics, description=The total number of successful rebalance events, each event is composed of several failed re-trials until it succeeded, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,026 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=rebalance-rate-per-hour, group=consumer-coordinator-metrics, description=The number of successful rebalance events per hour, each event is composed of several failed re-trials until it succeeded, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,027 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-rebalance
2024-05-30 15:47:40 2024-05-30 13:47:40,027 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=failed-rebalance-total, group=consumer-coordinator-metrics, description=The total number of failed rebalance events, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,027 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=failed-rebalance-rate-per-hour, group=consumer-coordinator-metrics, description=The number of failed rebalance events per hour, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,027 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=last-rebalance-seconds-ago, group=consumer-coordinator-metrics, description=The number of seconds since the last successful rebalance event, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,027 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=last-heartbeat-seconds-ago, group=consumer-coordinator-metrics, description=The number of seconds since the last coordinator heartbeat was sent, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,029 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name commit-latency
2024-05-30 15:47:40 2024-05-30 13:47:40,029 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=commit-latency-avg, group=consumer-coordinator-metrics, description=The average time taken for a commit request, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,029 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=commit-latency-max, group=consumer-coordinator-metrics, description=The max time taken for a commit request, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,029 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=commit-total, group=consumer-coordinator-metrics, description=The total number of commit calls, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,029 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=commit-rate, group=consumer-coordinator-metrics, description=The number of commit calls per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,030 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name partition-revoked-latency
2024-05-30 15:47:40 2024-05-30 13:47:40,030 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=partition-revoked-latency-avg, group=consumer-coordinator-metrics, description=The average time taken for a partition-revoked rebalance listener callback, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,030 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=partition-revoked-latency-max, group=consumer-coordinator-metrics, description=The max time taken for a partition-revoked rebalance listener callback, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,030 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name partition-assigned-latency
2024-05-30 15:47:40 2024-05-30 13:47:40,030 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=partition-assigned-latency-avg, group=consumer-coordinator-metrics, description=The average time taken for a partition-assigned rebalance listener callback, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,030 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=partition-assigned-latency-max, group=consumer-coordinator-metrics, description=The max time taken for a partition-assigned rebalance listener callback, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,030 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name partition-lost-latency
2024-05-30 15:47:40 2024-05-30 13:47:40,030 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=partition-lost-latency-avg, group=consumer-coordinator-metrics, description=The average time taken for a partition-lost rebalance listener callback, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,030 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=partition-lost-latency-max, group=consumer-coordinator-metrics, description=The max time taken for a partition-lost rebalance listener callback, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,030 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=assigned-partitions, group=consumer-coordinator-metrics, description=The number of partitions currently assigned to this consumer, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,032 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-fetched
2024-05-30 15:47:40 2024-05-30 13:47:40,032 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=fetch-size-avg, group=consumer-fetch-manager-metrics, description=The average number of bytes fetched per request, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,032 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=fetch-size-max, group=consumer-fetch-manager-metrics, description=The maximum number of bytes fetched per request, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,032 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=bytes-consumed-total, group=consumer-fetch-manager-metrics, description=The total number of bytes consumed, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,032 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=bytes-consumed-rate, group=consumer-fetch-manager-metrics, description=The average number of bytes consumed per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,032 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-fetched
2024-05-30 15:47:40 2024-05-30 13:47:40,032 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=records-per-request-avg, group=consumer-fetch-manager-metrics, description=The average number of records in each request, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,032 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=records-consumed-total, group=consumer-fetch-manager-metrics, description=The total number of records consumed, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,032 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=records-consumed-rate, group=consumer-fetch-manager-metrics, description=The average number of records consumed per second, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,032 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name fetch-latency
2024-05-30 15:47:40 2024-05-30 13:47:40,032 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=fetch-latency-avg, group=consumer-fetch-manager-metrics, description=The average time taken for a fetch request., tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,032 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=fetch-latency-max, group=consumer-fetch-manager-metrics, description=The max time taken for any fetch request., tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,033 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=fetch-total, group=consumer-fetch-manager-metrics, description=The total number of fetch requests., tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,033 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=fetch-rate, group=consumer-fetch-manager-metrics, description=The number of fetch requests per second., tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,033 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-lag
2024-05-30 15:47:40 2024-05-30 13:47:40,033 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=records-lag-max, group=consumer-fetch-manager-metrics, description=The maximum lag in terms of number of records for any partition in this window, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,033 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-lead
2024-05-30 15:47:40 2024-05-30 13:47:40,033 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=records-lead-min, group=consumer-fetch-manager-metrics, description=The minimum lead in terms of number of records for any partition in this window, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=last-poll-seconds-ago, group=consumer-metrics, description=The number of seconds since the last poll() invocation., tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name time-between-poll
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=time-between-poll-avg, group=consumer-metrics, description=The average delay between invocations of poll() in milliseconds., tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=time-between-poll-max, group=consumer-metrics, description=The max delay between invocations of poll() in milliseconds., tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name poll-idle-ratio-avg
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=poll-idle-ratio-avg, group=consumer-metrics, description=The average fraction of time the consumer's poll() is idle as opposed to waiting for the user code to process records., tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name commit-sync-time-ns-total
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=commit-sync-time-ns-total, group=consumer-metrics, description=The total time the consumer has spent in commitSync in nanoseconds, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name committed-time-ns-total
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=committed-time-ns-total, group=consumer-metrics, description=The total time the consumer has spent in committed in nanoseconds, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] WARN  org.apache.kafka.clients.consumer.ConsumerConfig  - The configuration 'client.id.prefix' was supplied but isn't a known config.
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] WARN  org.apache.kafka.clients.consumer.ConsumerConfig  - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka version: 3.2.3
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka commitId: 50029d3ed8ba576f
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka startTimeMs: 1717076860034
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=version, group=app-info, description=Metric indicating version, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=commit-id, group=app-info, description=Metric indicating commit-id, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,034 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=start-time-ms, group=app-info, description=Metric indicating start-time-ms, tags={client-id=flink_consumer-3}]
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Kafka consumer initialized
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.sync-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.reauthentication-latency-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.rebalance-latency-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.fetch-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.start-time-ms.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.outgoing-byte-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.successful-reauthentication-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.heartbeat-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.connection-close-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.connection-creation-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.select-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.response-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.sync-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.partition-revoked-latency-max.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.failed-rebalance-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.join-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.io-time-ns-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.fetch-size-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.connection-creation-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.commit-sync-time-ns-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.failed-rebalance-rate-per-hour.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.network-io-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.sync-time-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.time-between-poll-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.commit-id.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.select-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.records-consumed-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.failed-authentication-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.time-between-poll-max.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.fetch-latency-max.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.network-io-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.commit-latency-max.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.fetch-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.reauthentication-latency-max.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.io-ratio.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.bytes-consumed-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.join-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.request-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.fetch-size-max.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.join-time-max.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.records-per-request-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.rebalance-latency-max.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.commit-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.fetch-throttle-time-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.partition-lost-latency-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.bytes-consumed-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.heartbeat-response-time-max.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.incoming-byte-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.failed-reauthentication-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.records-lead-min.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.io-wait-time-ns-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.request-size-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.successful-reauthentication-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.successful-authentication-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.commit-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.commit-latency-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.partition-assigned-latency-max.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.io-waittime-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.heartbeat-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.successful-authentication-no-reauth-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.fetch-latency-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.last-poll-seconds-ago.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.failed-authentication-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.incoming-byte-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.io-wait-ratio.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.io-wait-time-ns-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.iotime-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,035 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.count.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.records-consumed-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.request-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.io-time-ns-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.fetch-throttle-time-max.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.version.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.connection-count.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.join-time-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.rebalance-rate-per-hour.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.rebalance-latency-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.response-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.poll-idle-ratio-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.successful-authentication-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.request-size-max.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.sync-time-max.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.records-lag-max.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.outgoing-byte-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.last-rebalance-seconds-ago.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.last-heartbeat-seconds-ago.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.partition-lost-latency-max.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.partition-revoked-latency-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.assigned-partitions.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.committed-time-ns-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.failed-reauthentication-rate.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.rebalance-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.connection-close-total.
2024-05-30 15:47:40 2024-05-30 13:47:40,036 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.KafkaConsumer.partition-assigned-latency-avg.
2024-05-30 15:47:40 2024-05-30 13:47:40,039 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Starting split fetcher 0
2024-05-30 15:47:40 2024-05-30 13:47:40,039 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Prepare to run AddSplitsTask: [[[Partition: aisdata-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]]
2024-05-30 15:47:40 2024-05-30 13:47:40,039 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Enqueued task AddSplitsTask: [[[Partition: aisdata-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]]
2024-05-30 15:47:40 2024-05-30 13:47:40,039 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Cleaned wakeup flag.
2024-05-30 15:47:40 2024-05-30 13:47:40,039 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Prepare to run AddSplitsTask: [[[Partition: aisdata-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]]
2024-05-30 15:47:40 2024-05-30 13:47:40,041 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.topic.partition.currentOffset.
2024-05-30 15:47:40 2024-05-30 13:47:40,041 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.KafkaSourceReader.topic.partition.committedOffset.
2024-05-30 15:47:40 2024-05-30 13:47:40,041 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Subscribed to partition(s): aisdata-0
2024-05-30 15:47:40 2024-05-30 13:47:40,043 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader  - Seeking starting offsets to beginning: [aisdata-0]
2024-05-30 15:47:40 2024-05-30 13:47:40,043 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Seeking to EARLIEST offset of partition aisdata-0
2024-05-30 15:47:40 2024-05-30 13:47:40,047 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Leader for partition aisdata-0 is unknown for fetching offset -2
2024-05-30 15:47:40 2024-05-30 13:47:40,047 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Found least loaded node kafka:9092 (id: -1 rack: null) with no active connection
2024-05-30 15:47:40 2024-05-30 13:47:40,047 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Initialize connection to node kafka:9092 (id: -1 rack: null) for sending metadata request
2024-05-30 15:47:40 2024-05-30 13:47:40,047 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.ClientUtils  - Resolved host kafka as 172.18.0.4
2024-05-30 15:47:40 2024-05-30 13:47:40,047 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Initiating connection to node kafka:9092 (id: -1 rack: null) using address kafka/172.18.0.4
2024-05-30 15:47:40 2024-05-30 13:47:40,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.requests-sent
2024-05-30 15:47:40 2024-05-30 13:47:40,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-total, group=consumer-node-metrics, description=The total number of requests sent, tags={client-id=flink_consumer-3, node-id=node--1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-rate, group=consumer-node-metrics, description=The number of requests sent per second, tags={client-id=flink_consumer-3, node-id=node--1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-size-avg, group=consumer-node-metrics, description=The average size of requests sent., tags={client-id=flink_consumer-3, node-id=node--1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-size-max, group=consumer-node-metrics, description=The maximum size of any request sent., tags={client-id=flink_consumer-3, node-id=node--1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-sent
2024-05-30 15:47:40 2024-05-30 13:47:40,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=outgoing-byte-total, group=consumer-node-metrics, description=The total number of outgoing bytes, tags={client-id=flink_consumer-3, node-id=node--1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=outgoing-byte-rate, group=consumer-node-metrics, description=The number of outgoing bytes per second, tags={client-id=flink_consumer-3, node-id=node--1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.responses-received
2024-05-30 15:47:40 2024-05-30 13:47:40,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=response-total, group=consumer-node-metrics, description=The total number of responses received, tags={client-id=flink_consumer-3, node-id=node--1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=response-rate, group=consumer-node-metrics, description=The number of responses received per second, tags={client-id=flink_consumer-3, node-id=node--1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-received
2024-05-30 15:47:40 2024-05-30 13:47:40,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=incoming-byte-total, group=consumer-node-metrics, description=The total number of incoming bytes, tags={client-id=flink_consumer-3, node-id=node--1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=incoming-byte-rate, group=consumer-node-metrics, description=The number of incoming bytes per second, tags={client-id=flink_consumer-3, node-id=node--1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.latency
2024-05-30 15:47:40 2024-05-30 13:47:40,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-latency-avg, group=consumer-node-metrics, description=, tags={client-id=flink_consumer-3, node-id=node--1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,049 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-latency-max, group=consumer-node-metrics, description=, tags={client-id=flink_consumer-3, node-id=node--1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,049 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.common.network.Selector  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2024-05-30 15:47:40 2024-05-30 13:47:40,049 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Completed connection to node -1. Fetching API versions.
2024-05-30 15:47:40 2024-05-30 13:47:40,049 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Initiating API versions fetch from node -1.
2024-05-30 15:47:40 2024-05-30 13:47:40,049 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] No version information found when sending API_VERSIONS with correlation id 0 to node -1. Assuming version 3.
2024-05-30 15:47:40 2024-05-30 13:47:40,049 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=flink_consumer-3, correlationId=0) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.2.3')
2024-05-30 15:47:40 2024-05-30 13:47:40,049 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Leader for partition aisdata-0 is unknown for fetching offset -2
2024-05-30 15:47:40 2024-05-30 13:47:40,049 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Found least loaded connecting node kafka:9092 (id: -1 rack: null)
2024-05-30 15:47:40 2024-05-30 13:47:40,050 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Leader for partition aisdata-0 is unknown for fetching offset -2
2024-05-30 15:47:40 2024-05-30 13:47:40,050 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Found least loaded connecting node kafka:9092 (id: -1 rack: null)
2024-05-30 15:47:40 2024-05-30 13:47:40,051 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received API_VERSIONS response from node -1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=flink_consumer-3, correlationId=0): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=15), ApiVersion(apiKey=2, minVersion=0, maxVersion=8), ApiVersion(apiKey=3, minVersion=0, maxVersion=12), ApiVersion(apiKey=4, minVersion=0, maxVersion=7), ApiVersion(apiKey=5, minVersion=0, maxVersion=4), ApiVersion(apiKey=6, minVersion=0, maxVersion=8), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=8), ApiVersion(apiKey=10, minVersion=0, maxVersion=4), ApiVersion(apiKey=11, minVersion=0, maxVersion=9), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=5), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=4), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=3), ApiVersion(apiKey=30, minVersion=0, maxVersion=3), ApiVersion(apiKey=31, minVersion=0, maxVersion=3), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=4), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=3), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=3), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=3), ApiVersion(apiKey=57, minVersion=0, maxVersion=1), ApiVersion(apiKey=58, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0), ApiVersion(apiKey=65, minVersion=0, maxVersion=0), ApiVersion(apiKey=66, minVersion=0, maxVersion=0), ApiVersion(apiKey=67, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[])
2024-05-30 15:47:40 2024-05-30 13:47:40,051 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node -1 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 15 [usable: 13], ListOffsets(2): 0 to 8 [usable: 7], Metadata(3): 0 to 12 [usable: 12], LeaderAndIsr(4): 0 to 7 [usable: 6], StopReplica(5): 0 to 4 [usable: 3], UpdateMetadata(6): 0 to 8 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 8 [usable: 8], FindCoordinator(10): 0 to 4 [usable: 4], JoinGroup(11): 0 to 9 [usable: 9], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 5 [usable: 5], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 4 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 3 [usable: 2], CreateAcls(30): 0 to 3 [usable: 2], DeleteAcls(31): 0 to 3 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 4 [usable: 3], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 3 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 3 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterPartition(56): 0 to 3 [usable: 1], UpdateFeatures(57): 0 to 1 [usable: 0], Envelope(58): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): 0 [usable: 0], ListTransactions(66): 0 [usable: 0], AllocateProducerIds(67): 0 [usable: 0]).
2024-05-30 15:47:40 2024-05-30 13:47:40,052 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Leader for partition aisdata-0 is unknown for fetching offset -2
2024-05-30 15:47:40 2024-05-30 13:47:40,052 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Found least loaded node kafka:9092 (id: -1 rack: null) connected with no in-flight requests
2024-05-30 15:47:40 2024-05-30 13:47:40,052 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='aisdata')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node kafka:9092 (id: -1 rack: null)
2024-05-30 15:47:40 2024-05-30 13:47:40,052 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=12, clientId=flink_consumer-3, correlationId=1) and timeout 30000 to node -1: MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='aisdata')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2024-05-30 15:47:40 2024-05-30 13:47:40,053 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Leader for partition aisdata-0 is unknown for fetching offset -2
2024-05-30 15:47:40 2024-05-30 13:47:40,054 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received METADATA response from node -1 for request with header RequestHeader(apiKey=METADATA, apiVersion=12, clientId=flink_consumer-3, correlationId=1): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=1, host='kafka', port=9092, rack=null)], clusterId='nzGe6aXUTge_XxOJN9iTig', controllerId=1, topics=[MetadataResponseTopic(errorCode=0, name='aisdata', topicId=ZiGIwhiYS8-umhWEVwc-NQ, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=1, leaderEpoch=0, replicaNodes=[1], isrNodes=[1], offlineReplicas=[])], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648)
2024-05-30 15:47:40 2024-05-30 13:47:40,055 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.kafka.clients.Metadata  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Resetting the last seen epoch of partition aisdata-0 to 0 since the associated topicId changed from null to ZiGIwhiYS8-umhWEVwc-NQ
2024-05-30 15:47:40 2024-05-30 13:47:40,055 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.kafka.clients.Metadata  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Cluster ID: nzGe6aXUTge_XxOJN9iTig
2024-05-30 15:47:40 2024-05-30 13:47:40,055 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Updated cluster metadata updateVersion 2 to MetadataCache{clusterId='nzGe6aXUTge_XxOJN9iTig', nodes={1=kafka:9092 (id: 1 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=aisdata-0, leader=Optional[1], leaderEpoch=Optional[0], replicas=1, isr=1, offlineReplicas=)], controller=kafka:9092 (id: 1 rack: null)}
2024-05-30 15:47:40 2024-05-30 13:47:40,056 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending ListOffsetRequest ListOffsetsRequestData(replicaId=-1, isolationLevel=0, topics=[ListOffsetsTopic(name='aisdata', partitions=[ListOffsetsPartition(partitionIndex=0, currentLeaderEpoch=0, timestamp=-2, maxNumOffsets=1)])]) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:40 2024-05-30 13:47:40,058 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.ClientUtils  - Resolved host kafka as 172.18.0.4
2024-05-30 15:47:40 2024-05-30 13:47:40,058 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Initiating connection to node kafka:9092 (id: 1 rack: null) using address kafka/172.18.0.4
2024-05-30 15:47:40 2024-05-30 13:47:40,058 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.requests-sent
2024-05-30 15:47:40 2024-05-30 13:47:40,058 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-total, group=consumer-node-metrics, description=The total number of requests sent, tags={client-id=flink_consumer-3, node-id=node-1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,058 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-rate, group=consumer-node-metrics, description=The number of requests sent per second, tags={client-id=flink_consumer-3, node-id=node-1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,058 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-size-avg, group=consumer-node-metrics, description=The average size of requests sent., tags={client-id=flink_consumer-3, node-id=node-1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,058 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-size-max, group=consumer-node-metrics, description=The maximum size of any request sent., tags={client-id=flink_consumer-3, node-id=node-1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,058 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-sent
2024-05-30 15:47:40 2024-05-30 13:47:40,058 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=outgoing-byte-total, group=consumer-node-metrics, description=The total number of outgoing bytes, tags={client-id=flink_consumer-3, node-id=node-1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,058 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=outgoing-byte-rate, group=consumer-node-metrics, description=The number of outgoing bytes per second, tags={client-id=flink_consumer-3, node-id=node-1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,058 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.responses-received
2024-05-30 15:47:40 2024-05-30 13:47:40,058 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=response-total, group=consumer-node-metrics, description=The total number of responses received, tags={client-id=flink_consumer-3, node-id=node-1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,058 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=response-rate, group=consumer-node-metrics, description=The number of responses received per second, tags={client-id=flink_consumer-3, node-id=node-1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,058 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-received
2024-05-30 15:47:40 2024-05-30 13:47:40,058 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=incoming-byte-total, group=consumer-node-metrics, description=The total number of incoming bytes, tags={client-id=flink_consumer-3, node-id=node-1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,058 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=incoming-byte-rate, group=consumer-node-metrics, description=The number of incoming bytes per second, tags={client-id=flink_consumer-3, node-id=node-1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,059 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.latency
2024-05-30 15:47:40 2024-05-30 13:47:40,059 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-latency-avg, group=consumer-node-metrics, description=, tags={client-id=flink_consumer-3, node-id=node-1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,059 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=request-latency-max, group=consumer-node-metrics, description=, tags={client-id=flink_consumer-3, node-id=node-1}]
2024-05-30 15:47:40 2024-05-30 13:47:40,059 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.common.network.Selector  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 1
2024-05-30 15:47:40 2024-05-30 13:47:40,059 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Completed connection to node 1. Fetching API versions.
2024-05-30 15:47:40 2024-05-30 13:47:40,059 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Initiating API versions fetch from node 1.
2024-05-30 15:47:40 2024-05-30 13:47:40,059 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] No version information found when sending API_VERSIONS with correlation id 3 to node 1. Assuming version 3.
2024-05-30 15:47:40 2024-05-30 13:47:40,059 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=flink_consumer-3, correlationId=3) and timeout 30000 to node 1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.2.3')
2024-05-30 15:47:40 2024-05-30 13:47:40,060 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received API_VERSIONS response from node 1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=flink_consumer-3, correlationId=3): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=15), ApiVersion(apiKey=2, minVersion=0, maxVersion=8), ApiVersion(apiKey=3, minVersion=0, maxVersion=12), ApiVersion(apiKey=4, minVersion=0, maxVersion=7), ApiVersion(apiKey=5, minVersion=0, maxVersion=4), ApiVersion(apiKey=6, minVersion=0, maxVersion=8), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=8), ApiVersion(apiKey=10, minVersion=0, maxVersion=4), ApiVersion(apiKey=11, minVersion=0, maxVersion=9), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=5), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=4), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=3), ApiVersion(apiKey=30, minVersion=0, maxVersion=3), ApiVersion(apiKey=31, minVersion=0, maxVersion=3), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=4), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=3), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=3), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=3), ApiVersion(apiKey=57, minVersion=0, maxVersion=1), ApiVersion(apiKey=58, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0), ApiVersion(apiKey=65, minVersion=0, maxVersion=0), ApiVersion(apiKey=66, minVersion=0, maxVersion=0), ApiVersion(apiKey=67, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[])
2024-05-30 15:47:40 2024-05-30 13:47:40,061 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 15 [usable: 13], ListOffsets(2): 0 to 8 [usable: 7], Metadata(3): 0 to 12 [usable: 12], LeaderAndIsr(4): 0 to 7 [usable: 6], StopReplica(5): 0 to 4 [usable: 3], UpdateMetadata(6): 0 to 8 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 8 [usable: 8], FindCoordinator(10): 0 to 4 [usable: 4], JoinGroup(11): 0 to 9 [usable: 9], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 5 [usable: 5], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 4 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 3 [usable: 2], CreateAcls(30): 0 to 3 [usable: 2], DeleteAcls(31): 0 to 3 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 4 [usable: 3], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 3 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 3 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterPartition(56): 0 to 3 [usable: 1], UpdateFeatures(57): 0 to 1 [usable: 0], Envelope(58): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): 0 [usable: 0], ListTransactions(66): 0 [usable: 0], AllocateProducerIds(67): 0 [usable: 0]).
2024-05-30 15:47:40 2024-05-30 13:47:40,061 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending LIST_OFFSETS request with header RequestHeader(apiKey=LIST_OFFSETS, apiVersion=7, clientId=flink_consumer-3, correlationId=2) and timeout 30000 to node 1: ListOffsetsRequestData(replicaId=-1, isolationLevel=0, topics=[ListOffsetsTopic(name='aisdata', partitions=[ListOffsetsPartition(partitionIndex=0, currentLeaderEpoch=0, timestamp=-2, maxNumOffsets=1)])])
2024-05-30 15:47:40 2024-05-30 13:47:40,068 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received LIST_OFFSETS response from node 1 for request with header RequestHeader(apiKey=LIST_OFFSETS, apiVersion=7, clientId=flink_consumer-3, correlationId=2): ListOffsetsResponseData(throttleTimeMs=0, topics=[ListOffsetsTopicResponse(name='aisdata', partitions=[ListOffsetsPartitionResponse(partitionIndex=0, errorCode=0, oldStyleOffsets=[], timestamp=-1, offset=0, leaderEpoch=0)])])
2024-05-30 15:47:40 2024-05-30 13:47:40,068 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received ListOffsetResponse ListOffsetsResponseData(throttleTimeMs=0, topics=[ListOffsetsTopicResponse(name='aisdata', partitions=[ListOffsetsPartitionResponse(partitionIndex=0, errorCode=0, oldStyleOffsets=[], timestamp=-1, offset=0, leaderEpoch=0)])]) from broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:40 2024-05-30 13:47:40,069 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Handling ListOffsetResponse response for aisdata-0. Fetched offset 0, timestamp -1
2024-05-30 15:47:40 2024-05-30 13:47:40,069 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.Metadata  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Determining if we should replace existing epoch 0 with new epoch 0 for partition aisdata-0
2024-05-30 15:47:40 2024-05-30 13:47:40,069 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Not replacing existing epoch 0 with new epoch 0 for partition aisdata-0
2024-05-30 15:47:40 2024-05-30 13:47:40,069 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Resetting offset for partition aisdata-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
2024-05-30 15:47:40 2024-05-30 13:47:40,070 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader  - SplitsChange handling result: [aisdata-0, start:0, stop: 9223372036854775807]
2024-05-30 15:47:40 2024-05-30 13:47:40,070 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Finished running task AddSplitsTask: [[[Partition: aisdata-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]]
2024-05-30 15:47:40 2024-05-30 13:47:40,070 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Cleaned wakeup flag.
2024-05-30 15:47:40 2024-05-30 13:47:40,070 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Prepare to run FetchTask
2024-05-30 15:47:40 2024-05-30 13:47:40,071 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=preferred-read-replica, group=consumer-fetch-manager-metrics, description=The current read replica for the partition, or -1 if reading from leader, tags={client-id=flink_consumer-3, topic=aisdata, partition=0}]
2024-05-30 15:47:40 2024-05-30 13:47:40,073 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:40 2024-05-30 13:47:40,073 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 1 with (aisdata-0).
2024-05-30 15:47:40 2024-05-30 13:47:40,073 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED FullFetchRequest(toSend=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:40 2024-05-30 13:47:40,074 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 10000
2024-05-30 15:47:40 2024-05-30 13:47:40,074 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=4) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=0, sessionEpoch=0, topics=[FetchTopic(topic='aisdata', topicId=ZiGIwhiYS8-umhWEVwc-NQ, partitions=[FetchPartition(partition=0, currentLeaderEpoch=0, fetchOffset=0, lastFetchedEpoch=-1, logStartOffset=-1, partitionMaxBytes=1048576)])], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:40 2024-05-30 13:47:40,075 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:40 2024-05-30 13:47:40,075 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9995
2024-05-30 15:47:40 2024-05-30 13:47:40,094 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:40 2024-05-30 13:47:40,094 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9976
2024-05-30 15:47:40 2024-05-30 13:47:40,095 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:40 2024-05-30 13:47:40,095 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9976
2024-05-30 15:47:40 2024-05-30 13:47:40,095 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:40 2024-05-30 13:47:40,095 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9975
2024-05-30 15:47:40 2024-05-30 13:47:40,098 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=4): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[FetchableTopicResponse(topic='', topicId=ZiGIwhiYS8-umhWEVwc-NQ, partitions=[PartitionData(partitionIndex=0, errorCode=0, highWatermark=2000, lastStableOffset=2000, logStartOffset=0, divergingEpoch=EpochEndOffset(epoch=-1, endOffset=-1), currentLeader=LeaderIdAndEpoch(leaderId=-1, leaderEpoch=-1), snapshotId=SnapshotId(endOffset=-1, epoch=-1), abortedTransactions=null, preferredReadReplica=-1, records=MemoryRecords(size=254778, buffer=java.nio.HeapByteBuffer[pos=0 lim=254778 cap=254781]))])])
2024-05-30 15:47:40 2024-05-30 13:47:40,099 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent a full fetch response that created a new incremental fetch session 1036515551 with response=(aisdata-0)
2024-05-30 15:47:40 2024-05-30 13:47:40,099 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Fetch READ_UNCOMMITTED at offset 0 for partition aisdata-0 returned fetch data PartitionData(partitionIndex=0, errorCode=0, highWatermark=2000, lastStableOffset=2000, logStartOffset=0, divergingEpoch=EpochEndOffset(epoch=-1, endOffset=-1), currentLeader=LeaderIdAndEpoch(leaderId=-1, leaderEpoch=-1), snapshotId=SnapshotId(endOffset=-1, epoch=-1), abortedTransactions=null, preferredReadReplica=-1, records=MemoryRecords(size=254778, buffer=java.nio.HeapByteBuffer[pos=0 lim=254778 cap=254781]))
2024-05-30 15:47:40 2024-05-30 13:47:40,100 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Preparing to read 254778 bytes of data for partition aisdata-0 with offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}
2024-05-30 15:47:40 2024-05-30 13:47:40,101 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Updating high watermark for partition aisdata-0 to 2000
2024-05-30 15:47:40 2024-05-30 13:47:40,101 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Updating log start offset for partition aisdata-0 to 0
2024-05-30 15:47:40 2024-05-30 13:47:40,101 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Updating last stable offset for partition aisdata-0 to 2000
2024-05-30 15:47:40 2024-05-30 13:47:40,108 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Returning 500 fetched records at offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} for assigned partition aisdata-0
2024-05-30 15:47:40 2024-05-30 13:47:40,108 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Updating fetch position from FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to FetchPosition{offset=500, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} for partition aisdata-0 and returning 500 records from `poll()`
2024-05-30 15:47:40 2024-05-30 13:47:40,108 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name aisdata-0.records-lag
2024-05-30 15:47:40 2024-05-30 13:47:40,109 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=records-lag, group=consumer-fetch-manager-metrics, description=The latest lag of the partition, tags={client-id=flink_consumer-3, topic=aisdata, partition=0}]
2024-05-30 15:47:40 2024-05-30 13:47:40,109 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=records-lag-max, group=consumer-fetch-manager-metrics, description=The max lag of the partition, tags={client-id=flink_consumer-3, topic=aisdata, partition=0}]
2024-05-30 15:47:40 2024-05-30 13:47:40,109 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=records-lag-avg, group=consumer-fetch-manager-metrics, description=The average lag of the partition, tags={client-id=flink_consumer-3, topic=aisdata, partition=0}]
2024-05-30 15:47:40 2024-05-30 13:47:40,109 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name aisdata-0.records-lead
2024-05-30 15:47:40 2024-05-30 13:47:40,109 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=records-lead, group=consumer-fetch-manager-metrics, description=The latest lead of the partition, tags={client-id=flink_consumer-3, topic=aisdata, partition=0}]
2024-05-30 15:47:40 2024-05-30 13:47:40,109 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=records-lead-min, group=consumer-fetch-manager-metrics, description=The min lead of the partition, tags={client-id=flink_consumer-3, topic=aisdata, partition=0}]
2024-05-30 15:47:40 2024-05-30 13:47:40,109 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=records-lead-avg, group=consumer-fetch-manager-metrics, description=The average lead of the partition, tags={client-id=flink_consumer-3, topic=aisdata, partition=0}]
2024-05-30 15:47:40 2024-05-30 13:47:40,110 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.runtime.metrics.MetricRegistryImpl  - Registering metric taskmanager.job.task.operator.pendingRecords.
2024-05-30 15:47:40 2024-05-30 13:47:40,111 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Finished running task FetchTask
2024-05-30 15:47:40 2024-05-30 13:47:40,111 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:47:40 2024-05-30 13:47:40,111 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Cleaned wakeup flag.
2024-05-30 15:47:40 2024-05-30 13:47:40,111 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Prepare to run FetchTask
2024-05-30 15:47:40 2024-05-30 13:47:40,111 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitting records from fetch for split aisdata-0
2024-05-30 15:47:40 2024-05-30 13:47:40,111 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219000818.0, "lon": 9.889237, "lat": 55.270373, "speed": 0.0, "course": 4.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,112 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219000818.0, "lon": 9.889237, "lat": 55.270373, "speed": 0.0, "course": 4.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,114 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Returning 500 fetched records at offset FetchPosition{offset=500, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} for assigned partition aisdata-0
2024-05-30 15:47:40 2024-05-30 13:47:40,114 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Updating fetch position from FetchPosition{offset=500, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to FetchPosition{offset=1000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} for partition aisdata-0 and returning 500 records from `poll()`
2024-05-30 15:47:40 2024-05-30 13:47:40,114 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Finished running task FetchTask
2024-05-30 15:47:40 2024-05-30 13:47:40,114 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Cleaned wakeup flag.
2024-05-30 15:47:40 2024-05-30 13:47:40,114 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Prepare to run FetchTask
2024-05-30 15:47:40 2024-05-30 13:47:40,117 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Returning 500 fetched records at offset FetchPosition{offset=1000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} for assigned partition aisdata-0
2024-05-30 15:47:40 2024-05-30 13:47:40,117 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Updating fetch position from FetchPosition{offset=1000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to FetchPosition{offset=1500, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} for partition aisdata-0 and returning 500 records from `poll()`
2024-05-30 15:47:40 2024-05-30 13:47:40,117 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Finished running task FetchTask
2024-05-30 15:47:40 2024-05-30 13:47:40,117 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Cleaned wakeup flag.
2024-05-30 15:47:40 2024-05-30 13:47:40,117 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Prepare to run FetchTask
2024-05-30 15:47:40 2024-05-30 13:47:40,119 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Returning 500 fetched records at offset FetchPosition{offset=1500, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} for assigned partition aisdata-0
2024-05-30 15:47:40 2024-05-30 13:47:40,119 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Updating fetch position from FetchPosition{offset=1500, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} for partition aisdata-0 and returning 500 records from `poll()`
2024-05-30 15:47:40 2024-05-30 13:47:40,286 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 0, CreateTime = 1717076858639, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6dc0d194)
2024-05-30 15:47:40 2024-05-30 13:47:40,286 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,286 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 265513470.0, "lon": 12.68785, "lat": 56.044867, "speed": 0.0, "course": 216.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,286 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 265513470.0, "lon": 12.68785, "lat": 56.044867, "speed": 0.0, "course": 216.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,286 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1, CreateTime = 1717076858639, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@64daa257)
2024-05-30 15:47:40 2024-05-30 13:47:40,286 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,286 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 258069000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,286 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 258069000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,286 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 2, CreateTime = 1717076858639, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5f78699a)
2024-05-30 15:47:40 2024-05-30 13:47:40,286 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,286 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 2194006.0, "lon": 5.0334, "lat": 55.538917, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,286 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 2194006.0, "lon": 5.0334, "lat": 55.538917, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,287 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 3, CreateTime = 1717076858639, serialized key size = -1, serialized value size = 109, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d5b6f6)
2024-05-30 15:47:40 2024-05-30 13:47:40,287 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,287 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 211904000.0, "lon": 11.068557, "lat": 56.468103, "speed": 7.5, "course": 169.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,287 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 211904000.0, "lon": 11.068557, "lat": 56.468103, "speed": 7.5, "course": 169.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,287 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 4, CreateTime = 1717076858639, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d729bc9)
2024-05-30 15:47:40 2024-05-30 13:47:40,287 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,287 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 636014191.0, "lon": 14.1158, "lat": 55.096217, "speed": 14.1, "course": 219.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,287 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 636014191.0, "lon": 14.1158, "lat": 55.096217, "speed": 14.1, "course": 219.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,287 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 5, CreateTime = 1717076858639, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5c0b442a)
2024-05-30 15:47:40 2024-05-30 13:47:40,287 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,287 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 220621000.0, "lon": 9.751748, "lat": 55.560007, "speed": 0.0, "course": 39.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,287 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 220621000.0, "lon": 9.751748, "lat": 55.560007, "speed": 0.0, "course": 39.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,287 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 6, CreateTime = 1717076858639, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4023d288)
2024-05-30 15:47:40 2024-05-30 13:47:40,287 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,287 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 352055000.0, "lon": 10.907633, "lat": 57.533617, "speed": 46.9, "course": 46.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,287 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 352055000.0, "lon": 10.907633, "lat": 57.533617, "speed": 46.9, "course": 46.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,288 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 7, CreateTime = 1717076858640, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@123fcc0b)
2024-05-30 15:47:40 2024-05-30 13:47:40,288 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,288 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219005502.0, "lon": 10.586562, "lat": 57.717775, "speed": 0.0, "course": 317.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,288 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219005502.0, "lon": 10.586562, "lat": 57.717775, "speed": 0.0, "course": 317.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,288 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 8, CreateTime = 1717076858640, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1493f072)
2024-05-30 15:47:40 2024-05-30 13:47:40,288 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,288 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 992191016.0, "lon": 11.04671, "lat": 55.324797, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,288 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 992191016.0, "lon": 11.04671, "lat": 55.324797, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,288 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 9, CreateTime = 1717076858640, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4afac7fa)
2024-05-30 15:47:40 2024-05-30 13:47:40,288 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,288 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 265506580.0, "lon": 11.897815, "lat": 57.692128, "speed": 0.0, "course": 329.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,288 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 265506580.0, "lon": 11.897815, "lat": 57.692128, "speed": 0.0, "course": 329.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,288 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 10, CreateTime = 1717076858641, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@745d9997)
2024-05-30 15:47:40 2024-05-30 13:47:40,289 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,289 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 230915000.0, "lon": 7.794633, "lat": 56.47855, "speed": 17.9, "course": 200.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,289 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 230915000.0, "lon": 7.794633, "lat": 56.47855, "speed": 17.9, "course": 200.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,289 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 11, CreateTime = 1717076858641, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@18ee4c83)
2024-05-30 15:47:40 2024-05-30 13:47:40,289 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,289 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 225388000.0, "lon": 12.099532, "lat": 54.447125, "speed": 10.2, "course": 251.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,289 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 225388000.0, "lon": 12.099532, "lat": 54.447125, "speed": 10.2, "course": 251.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,289 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 12, CreateTime = 1717076858641, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@13f53f8c)
2024-05-30 15:47:40 2024-05-30 13:47:40,289 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,289 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 325423000.0, "lon": 10.619855, "lat": 55.060755, "speed": 0.1, "course": 335.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,289 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 325423000.0, "lon": 10.619855, "lat": 55.060755, "speed": 0.1, "course": 335.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,289 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 13, CreateTime = 1717076858641, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@facef1f)
2024-05-30 15:47:40 2024-05-30 13:47:40,289 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,289 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 220492000.0, "lon": 13.113707, "lat": 54.650073, "speed": 6.3, "course": 67.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,289 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 220492000.0, "lon": 13.113707, "lat": 54.650073, "speed": 6.3, "course": 67.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,290 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 14, CreateTime = 1717076858642, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@17254e5c)
2024-05-30 15:47:40 2024-05-30 13:47:40,290 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,290 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 304233000.0, "lon": 13.7635, "lat": 54.137417, "speed": 0.0, "course": 355.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,290 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 304233000.0, "lon": 13.7635, "lat": 54.137417, "speed": 0.0, "course": 355.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,290 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 15, CreateTime = 1717076858642, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7dc5826f)
2024-05-30 15:47:40 2024-05-30 13:47:40,290 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,290 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219000345.0, "lon": 10.824533, "lat": 55.753567, "speed": 16.8, "course": 169.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,290 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219000345.0, "lon": 10.824533, "lat": 55.753567, "speed": 16.8, "course": 169.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,290 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 16, CreateTime = 1717076858642, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4776cb04)
2024-05-30 15:47:40 2024-05-30 13:47:40,290 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,290 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 2194005.0, "lon": 4.272, "lat": 56.344267, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,290 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 2194005.0, "lon": 4.272, "lat": 56.344267, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,290 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 17, CreateTime = 1717076858642, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2f4a00e2)
2024-05-30 15:47:40 2024-05-30 13:47:40,290 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,290 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219001013.0, "lon": 11.082957, "lat": 55.677397, "speed": 0.0, "course": 5.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,290 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219001013.0, "lon": 11.082957, "lat": 55.677397, "speed": 0.0, "course": 5.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,291 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 18, CreateTime = 1717076858643, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@12a0ecf9)
2024-05-30 15:47:40 2024-05-30 13:47:40,291 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,291 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219000431.0, "lon": 11.349992, "lat": 54.65348, "speed": 0.0, "course": 210.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,291 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219000431.0, "lon": 11.349992, "lat": 54.65348, "speed": 0.0, "course": 210.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,291 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 19, CreateTime = 1717076858643, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@43a7c238)
2024-05-30 15:47:40 2024-05-30 13:47:40,291 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,291 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 245461000.0, "lon": 12.938767, "lat": 55.688517, "speed": 0.1, "course": 315.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,291 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 245461000.0, "lon": 12.938767, "lat": 55.688517, "speed": 0.1, "course": 315.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,291 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 20, CreateTime = 1717076858643, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@32781fa3)
2024-05-30 15:47:40 2024-05-30 13:47:40,291 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,291 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219079000.0, "lon": 7.826998, "lat": 55.488803, "speed": 0.1, "course": 203.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,291 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219079000.0, "lon": 7.826998, "lat": 55.488803, "speed": 0.1, "course": 203.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,291 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 21, CreateTime = 1717076858643, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4dca441e)
2024-05-30 15:47:40 2024-05-30 13:47:40,291 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,291 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 230984000.0, "lon": 11.486428, "lat": 57.388193, "speed": 18.1, "course": 338.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,291 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 230984000.0, "lon": 11.486428, "lat": 57.388193, "speed": 18.1, "course": 338.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,292 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 22, CreateTime = 1717076858643, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5818be7a)
2024-05-30 15:47:40 2024-05-30 13:47:40,292 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,292 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 211222680.0, "lon": 10.135463, "lat": 54.315298, "speed": 0.1, "course": 183.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,292 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 211222680.0, "lon": 10.135463, "lat": 54.315298, "speed": 0.1, "course": 183.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,292 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 23, CreateTime = 1717076858643, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@25531143)
2024-05-30 15:47:40 2024-05-30 13:47:40,292 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,292 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 211211200.0, "lon": 10.044788, "lat": 54.771108, "speed": 11.9, "course": 328.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,292 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 211211200.0, "lon": 10.044788, "lat": 54.771108, "speed": 11.9, "course": 328.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,292 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 24, CreateTime = 1717076858644, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5724974d)
2024-05-30 15:47:40 2024-05-30 13:47:40,292 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,292 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219329000.0, "lon": 8.421018, "lat": 55.478222, "speed": 0.0, "course": 353.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,292 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219329000.0, "lon": 8.421018, "lat": 55.478222, "speed": 0.0, "course": 353.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,292 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 25, CreateTime = 1717076858644, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4851d303)
2024-05-30 15:47:40 2024-05-30 13:47:40,292 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,292 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 305203000.0, "lon": 14.610305, "lat": 55.380512, "speed": 9.5, "course": 23.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,292 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 305203000.0, "lon": 14.610305, "lat": 55.380512, "speed": 9.5, "course": 23.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 26, CreateTime = 1717076858644, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@55a75f1d)
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 2190066.0, "lon": 8.16694, "lat": 56.530085, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 2190066.0, "lon": 8.16694, "lat": 56.530085, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 27, CreateTime = 1717076858645, serialized key size = -1, serialized value size = 110, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@68c385e3)
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219008746.0, "lon": 10.302162, "lat": 56.60731, "speed": 0.1, "course": 136.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219008746.0, "lon": 10.302162, "lat": 56.60731, "speed": 0.1, "course": 136.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 28, CreateTime = 1717076858645, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1baef949)
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 2655146.0, "lon": 12.937938, "lat": 56.790038, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 2655146.0, "lon": 12.937938, "lat": 56.790038, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 29, CreateTime = 1717076858645, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5da1f8f4)
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219000961.0, "lon": 10.833655, "lat": 54.93389, "speed": 0.0, "course": 335.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219000961.0, "lon": 10.833655, "lat": 54.93389, "speed": 0.0, "course": 335.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 30, CreateTime = 1717076858645, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@32910bea)
2024-05-30 15:47:40 2024-05-30 13:47:40,293 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 240198000.0, "lon": 11.13595, "lat": 57.630067, "speed": 14.7, "course": 313.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 240198000.0, "lon": 11.13595, "lat": 57.630067, "speed": 14.7, "course": 313.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 31, CreateTime = 1717076858645, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@46896cc6)
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219001459.0, "lon": 11.3487, "lat": 54.656803, "speed": 0.0, "course": 320.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219001459.0, "lon": 11.3487, "lat": 54.656803, "speed": 0.0, "course": 320.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 32, CreateTime = 1717076858645, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2a81b1ef)
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 220205000.0, "lon": 12.466702, "lat": 54.95202, "speed": 0.0, "course": 311.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 220205000.0, "lon": 12.466702, "lat": 54.95202, "speed": 0.0, "course": 311.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 33, CreateTime = 1717076858645, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@78358a13)
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219001362.0, "lon": 10.616185, "lat": 55.061993, "speed": 0.0, "course": 349.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219001362.0, "lon": 10.616185, "lat": 55.061993, "speed": 0.0, "course": 349.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 34, CreateTime = 1717076858645, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@42c100a4)
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 211343680.0, "lon": 11.766605, "lat": 54.275342, "speed": 13.1, "course": 59.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 211343680.0, "lon": 11.766605, "lat": 54.275342, "speed": 13.1, "course": 59.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 35, CreateTime = 1717076858645, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4f23ab66)
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 265610900.0, "lon": 12.903563, "lat": 55.756648, "speed": 0.0, "course": 321.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,294 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 265610900.0, "lon": 12.903563, "lat": 55.756648, "speed": 0.0, "course": 321.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 36, CreateTime = 1717076858646, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@680a75a4)
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 319562000.0, "lon": 14.710783, "lat": 55.320767, "speed": 13.1, "course": 230.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 319562000.0, "lon": 14.710783, "lat": 55.320767, "speed": 13.1, "course": 230.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 37, CreateTime = 1717076858646, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3c3b1fa4)
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219000484.0, "lon": 9.7557, "lat": 55.559083, "speed": 0.0, "course": 120.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219000484.0, "lon": 9.7557, "lat": 55.559083, "speed": 0.0, "course": 120.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 38, CreateTime = 1717076858646, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7635eca7)
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 244620052.0, "lon": 8.44983, "lat": 55.458763, "speed": 0.0, "course": 187.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 244620052.0, "lon": 8.44983, "lat": 55.458763, "speed": 0.0, "course": 187.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 39, CreateTime = 1717076858646, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@249f019c)
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 265874000.0, "lon": 12.246847, "lat": 54.516813, "speed": 12.9, "course": 19.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 265874000.0, "lon": 12.246847, "lat": 54.516813, "speed": 12.9, "course": 19.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 40, CreateTime = 1717076858646, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1f83e7fe)
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 236189000.0, "lon": 10.221, "lat": 56.1445, "speed": 0.0, "course": 223.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 236189000.0, "lon": 10.221, "lat": 56.1445, "speed": 0.0, "course": 223.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 41, CreateTime = 1717076858646, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7b211d95)
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 220043000.0, "lon": 14.0155, "lat": 54.935967, "speed": 0.6, "course": 270.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,295 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 220043000.0, "lon": 14.0155, "lat": 54.935967, "speed": 0.6, "course": 270.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 42, CreateTime = 1717076858646, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@22a89682)
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219294000.0, "lon": 8.59845, "lat": 57.121717, "speed": 0.0, "course": 27.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219294000.0, "lon": 8.59845, "lat": 57.121717, "speed": 0.0, "course": 27.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 43, CreateTime = 1717076858646, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7e67f0aa)
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 2190071.0, "lon": 8.648263, "lat": 57.110037, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 2190071.0, "lon": 8.648263, "lat": 57.110037, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 44, CreateTime = 1717076858646, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7edb448f)
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 265513640.0, "lon": 10.004458, "lat": 57.966235, "speed": 0.1, "course": 101.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 265513640.0, "lon": 10.004458, "lat": 57.966235, "speed": 0.1, "course": 101.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 45, CreateTime = 1717076858646, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@d652374)
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 245180000.0, "lon": 14.543242, "lat": 55.316253, "speed": 11.1, "course": 49.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 245180000.0, "lon": 14.543242, "lat": 55.316253, "speed": 11.1, "course": 49.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 46, CreateTime = 1717076858646, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6b9fa8dc)
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 215140000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 215140000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 47, CreateTime = 1717076858646, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2abce7a5)
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 304822000.0, "lon": 9.436688, "lat": 54.798183, "speed": 0.0, "course": 357.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 304822000.0, "lon": 9.436688, "lat": 54.798183, "speed": 0.0, "course": 357.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 48, CreateTime = 1717076858646, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@e673141)
2024-05-30 15:47:40 2024-05-30 13:47:40,296 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219338000.0, "lon": 8.415328, "lat": 55.475345, "speed": 0.0, "course": 11.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219338000.0, "lon": 8.415328, "lat": 55.475345, "speed": 0.0, "course": 11.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 49, CreateTime = 1717076858646, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2abddd7a)
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 211216490.0, "lon": 12.166667, "lat": 54.2915, "speed": 5.6, "course": 39.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 211216490.0, "lon": 12.166667, "lat": 54.2915, "speed": 5.6, "course": 39.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 50, CreateTime = 1717076858647, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3cf249b9)
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219005059.0, "lon": 11.927987, "lat": 54.572718, "speed": 0.0, "course": 256.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219005059.0, "lon": 11.927987, "lat": 54.572718, "speed": 0.0, "course": 256.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 51, CreateTime = 1717076858647, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@713e104d)
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219000643.0, "lon": 9.7303, "lat": 55.26023, "speed": 0.0, "course": 94.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219000643.0, "lon": 9.7303, "lat": 55.26023, "speed": 0.0, "course": 94.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 52, CreateTime = 1717076858647, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4664da12)
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 2190068.0, "lon": 10.94586, "lat": 56.447263, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 2190068.0, "lon": 10.94586, "lat": 56.447263, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 53, CreateTime = 1717076858647, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2f689a9)
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 2614800.0, "lon": 14.580335, "lat": 53.981453, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 2614800.0, "lon": 14.580335, "lat": 53.981453, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 54, CreateTime = 1717076858647, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2c67a7cf)
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219002416.0, "lon": 10.216207, "lat": 56.15289, "speed": 0.0, "course": 109.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,297 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219002416.0, "lon": 10.216207, "lat": 56.15289, "speed": 0.0, "course": 109.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 55, CreateTime = 1717076858647, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2dda7676)
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219001789.0, "lon": 11.082625, "lat": 55.67753, "speed": 0.0, "course": 3.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219001789.0, "lon": 11.082625, "lat": 55.67753, "speed": 0.0, "course": 3.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 56, CreateTime = 1717076858647, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4d0e9d95)
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 235004750.0, "lon": 10.583507, "lat": 57.715117, "speed": 0.0, "course": 3.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 235004750.0, "lon": 10.583507, "lat": 57.715117, "speed": 0.0, "course": 3.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 57, CreateTime = 1717076858647, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7b83fe5c)
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219000647.0, "lon": 8.424285, "lat": 55.471788, "speed": 0.1, "course": 73.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219000647.0, "lon": 8.424285, "lat": 55.471788, "speed": 0.1, "course": 73.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 58, CreateTime = 1717076858647, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6a4b673c)
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 992111840.0, "lon": 12.629975, "lat": 54.612927, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 992111840.0, "lon": 12.629975, "lat": 54.612927, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 59, CreateTime = 1717076858647, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@145cc5c5)
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 211377940.0, "lon": 12.08724, "lat": 54.18181, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 211377940.0, "lon": 12.08724, "lat": 54.18181, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 60, CreateTime = 1717076858648, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2d0710ee)
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 304010455.0, "lon": 12.805048, "lat": 54.756097, "speed": 7.5, "course": 72.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,298 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 304010455.0, "lon": 12.805048, "lat": 54.756097, "speed": 7.5, "course": 72.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,299 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 61, CreateTime = 1717076858648, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@49926a0c)
2024-05-30 15:47:40 2024-05-30 13:47:40,299 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,299 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 370614000.0, "lon": 11.533133, "lat": 57.26635, "speed": 14.2, "course": 162.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,299 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 370614000.0, "lon": 11.533133, "lat": 57.26635, "speed": 14.2, "course": 162.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,299 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 62, CreateTime = 1717076858648, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@78d19685)
2024-05-30 15:47:40 2024-05-30 13:47:40,299 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,299 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 2655140.0, "lon": 12.708198, "lat": 56.053338, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,299 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 2655140.0, "lon": 12.708198, "lat": 56.053338, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 63, CreateTime = 1717076858648, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@a5106b7)
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 220256000.0, "lon": 9.963062, "lat": 57.592937, "speed": 0.0, "course": 325.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 220256000.0, "lon": 9.963062, "lat": 57.592937, "speed": 0.0, "course": 325.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 64, CreateTime = 1717076858648, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1f44f773)
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219005786.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219005786.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 65, CreateTime = 1717076858648, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@455c3c9d)
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 231059000.0, "lon": 10.523427, "lat": 54.85301, "speed": 0.0, "course": 295.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 231059000.0, "lon": 10.523427, "lat": 54.85301, "speed": 0.0, "course": 295.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 66, CreateTime = 1717076858648, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@31cdff0d)
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219525000.0, "lon": 10.536958, "lat": 57.433462, "speed": 0.0, "course": 127.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219525000.0, "lon": 10.536958, "lat": 57.433462, "speed": 0.0, "course": 127.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 67, CreateTime = 1717076858648, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@33ab233d)
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 992111841.0, "lon": 12.63, "lat": 54.583967, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,301 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 992111841.0, "lon": 12.63, "lat": 54.583967, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 68, CreateTime = 1717076858648, serialized key size = -1, serialized value size = 110, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@b6cb554)
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 245253000.0, "lon": 7.806375, "lat": 55.276408, "speed": 4.3, "course": 327.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 245253000.0, "lon": 7.806375, "lat": 55.276408, "speed": 4.3, "course": 327.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 69, CreateTime = 1717076858648, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2ff0d870)
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 304010514.0, "lon": 10.835405, "lat": 54.568118, "speed": 11.9, "course": 83.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 304010514.0, "lon": 10.835405, "lat": 54.568118, "speed": 11.9, "course": 83.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 70, CreateTime = 1717076858649, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@719b7f14)
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 230217000.0, "lon": 6.975123, "lat": 56.438672, "speed": 14.4, "course": 165.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 230217000.0, "lon": 6.975123, "lat": 56.438672, "speed": 14.4, "course": 165.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 71, CreateTime = 1717076858649, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1b4308d1)
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 992191017.0, "lon": 11.020218, "lat": 56.067345, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 992191017.0, "lon": 11.020218, "lat": 56.067345, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 72, CreateTime = 1717076858649, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@75ebd8f8)
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219000181.0, "lon": 10.257507, "lat": 54.942053, "speed": 0.0, "course": 205.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,302 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219000181.0, "lon": 10.257507, "lat": 54.942053, "speed": 0.0, "course": 205.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 73, CreateTime = 1717076858649, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5c71bd6d)
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 249622000.0, "lon": 11.661742, "lat": 54.208872, "speed": 9.8, "course": 69.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 249622000.0, "lon": 11.661742, "lat": 54.208872, "speed": 9.8, "course": 69.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 74, CreateTime = 1717076858649, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@76b81a28)
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 218159000.0, "lon": 10.34585, "lat": 56.970337, "speed": 7.7, "course": 305.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 218159000.0, "lon": 10.34585, "lat": 56.970337, "speed": 7.7, "course": 305.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 75, CreateTime = 1717076858649, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@75be91ae)
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219000407.0, "lon": 10.921417, "lat": 57.296683, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219000407.0, "lon": 10.921417, "lat": 57.296683, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 76, CreateTime = 1717076858649, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5eb9abf9)
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 636012690.0, "lon": 10.806017, "lat": 55.7892, "speed": 12.2, "course": 176.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 636012690.0, "lon": 10.806017, "lat": 55.7892, "speed": 12.2, "course": 176.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 77, CreateTime = 1717076858649, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@f72ef96)
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 245914000.0, "lon": 7.984033, "lat": 55.128283, "speed": 3.0, "course": 128.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 245914000.0, "lon": 7.984033, "lat": 55.128283, "speed": 3.0, "course": 128.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 78, CreateTime = 1717076858649, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@39addd0a)
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 992111840.0, "lon": 12.629948, "lat": 54.612952, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 992111840.0, "lon": 12.629948, "lat": 54.612952, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 79, CreateTime = 1717076858649, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@381f1870)
2024-05-30 15:47:40 2024-05-30 13:47:40,303 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219015583.0, "lon": 8.307367, "lat": 56.551548, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219015583.0, "lon": 8.307367, "lat": 56.551548, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 80, CreateTime = 1717076858649, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2b6a9ae9)
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219004838.0, "lon": 11.928708, "lat": 54.572008, "speed": 0.0, "course": 17.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219004838.0, "lon": 11.928708, "lat": 54.572008, "speed": 0.0, "course": 17.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 81, CreateTime = 1717076858650, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@33fcde4d)
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 265186000.0, "lon": 13.568943, "lat": 54.775812, "speed": 15.2, "course": 156.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 265186000.0, "lon": 13.568943, "lat": 54.775812, "speed": 15.2, "course": 156.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 82, CreateTime = 1717076858650, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@646e10b5)
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219801000.0, "lon": 9.964817, "lat": 57.592883, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219801000.0, "lon": 9.964817, "lat": 57.592883, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 83, CreateTime = 1717076858650, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@247248d0)
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 256587000.0, "lon": 8.9302, "lat": 57.416375, "speed": 14.1, "course": 51.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 256587000.0, "lon": 8.9302, "lat": 57.416375, "speed": 14.1, "course": 51.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 84, CreateTime = 1717076858650, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5b302365)
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 219007333.0, "lon": 14.93125, "lat": 54.700317, "speed": 0.1, "course": 335.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 219007333.0, "lon": 14.93125, "lat": 54.700317, "speed": 0.1, "course": 335.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 85, CreateTime = 1717076858650, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@eeb80f8)
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 231201000.0, "lon": 10.060023, "lat": 57.764525, "speed": 15.7, "course": 13.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,304 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 231201000.0, "lon": 10.060023, "lat": 57.764525, "speed": 15.7, "course": 13.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 86, CreateTime = 1717076858650, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1a94d228)
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 258606000.0, "lon": 10.727282, "lat": 57.367525, "speed": 14.2, "course": 5.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 258606000.0, "lon": 10.727282, "lat": 57.367525, "speed": 14.2, "course": 5.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 87, CreateTime = 1717076858650, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2c163d62)
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 2573115.0, "lon": 9.7, "lat": 59.233333, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 2573115.0, "lon": 9.7, "lat": 59.233333, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 88, CreateTime = 1717076858650, serialized key size = -1, serialized value size = 106, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7667188e)
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:00", "mmsi": 2655185.0, "lon": 14.775318, "lat": 56.22696, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:00", "mmsi": 2655185.0, "lon": 14.775318, "lat": 56.22696, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 89, CreateTime = 1717076858650, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@24d9bafa)
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 211410690.0, "lon": 11.491625, "lat": 57.168453, "speed": 9.5, "course": 150.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 211410690.0, "lon": 11.491625, "lat": 57.168453, "speed": 9.5, "course": 150.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 90, CreateTime = 1717076858650, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@18e029db)
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219002827.0, "lon": 10.587308, "lat": 57.717488, "speed": 0.0, "course": 336.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219002827.0, "lon": 10.587308, "lat": 57.717488, "speed": 0.0, "course": 336.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 91, CreateTime = 1717076858650, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@580fa88)
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 215729000.0, "lon": 12.629912, "lat": 54.627027, "speed": 1.0, "course": 56.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,305 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 215729000.0, "lon": 12.629912, "lat": 54.627027, "speed": 1.0, "course": 56.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 92, CreateTime = 1717076858650, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4b6d21de)
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219159000.0, "lon": 11.086, "lat": 55.677333, "speed": 0.0, "course": 305.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219159000.0, "lon": 11.086, "lat": 55.677333, "speed": 0.0, "course": 305.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 93, CreateTime = 1717076858650, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@228a5c23)
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219679000.0, "lon": 11.096798, "lat": 55.6746, "speed": 6.8, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219679000.0, "lon": 11.096798, "lat": 55.6746, "speed": 6.8, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 94, CreateTime = 1717076858650, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3b3d0758)
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 236561000.0, "lon": 12.996733, "lat": 55.24179, "speed": 11.0, "course": 98.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 236561000.0, "lon": 12.996733, "lat": 55.24179, "speed": 11.0, "course": 98.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 95, CreateTime = 1717076858651, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@39ebee0d)
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219008474.0, "lon": 9.954283, "lat": 57.591617, "speed": 0.0, "course": 359.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219008474.0, "lon": 9.954283, "lat": 57.591617, "speed": 0.0, "course": 359.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,306 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 96, CreateTime = 1717076858651, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1b2a4b3f)
2024-05-30 15:47:40 2024-05-30 13:47:40,307 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,307 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219001751.0, "lon": 8.598033, "lat": 57.1227, "speed": 0.0, "course": 198.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,307 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219001751.0, "lon": 8.598033, "lat": 57.1227, "speed": 0.0, "course": 198.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,307 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 97, CreateTime = 1717076858651, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6b31673d)
2024-05-30 15:47:40 2024-05-30 13:47:40,307 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,307 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 265663280.0, "lon": 11.898288, "lat": 57.692295, "speed": 0.0, "course": 333.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,307 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 265663280.0, "lon": 11.898288, "lat": 57.692295, "speed": 0.0, "course": 333.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,307 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 98, CreateTime = 1717076858651, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@38e5aac4)
2024-05-30 15:47:40 2024-05-30 13:47:40,307 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,307 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219440000.0, "lon": 4.228393, "lat": 56.078402, "speed": 0.0, "course": 278.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,307 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219440000.0, "lon": 4.228393, "lat": 56.078402, "speed": 0.0, "course": 278.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,307 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 99, CreateTime = 1717076858651, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5e98a053)
2024-05-30 15:47:40 2024-05-30 13:47:40,307 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,307 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 273356200.0, "lon": 10.3037, "lat": 57.780945, "speed": 8.6, "course": 263.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,307 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 273356200.0, "lon": 10.3037, "lat": 57.780945, "speed": 8.6, "course": 263.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,308 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 100, CreateTime = 1717076858651, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@17a26b0c)
2024-05-30 15:47:40 2024-05-30 13:47:40,308 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,308 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 261006470.0, "lon": 14.373063, "lat": 54.019658, "speed": 8.2, "course": 33.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,308 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 261006470.0, "lon": 14.373063, "lat": 54.019658, "speed": 8.2, "course": 33.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,308 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 101, CreateTime = 1717076858651, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@774aee4a)
2024-05-30 15:47:40 2024-05-30 13:47:40,308 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,308 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 220046000.0, "lon": 9.96141, "lat": 57.593755, "speed": 0.0, "course": 20.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,308 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 220046000.0, "lon": 9.96141, "lat": 57.593755, "speed": 0.0, "course": 20.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,308 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 102, CreateTime = 1717076858651, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@626cc9ed)
2024-05-30 15:47:40 2024-05-30 13:47:40,308 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,308 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 211910000.0, "lon": 8.245333, "lat": 57.05405, "speed": 23.2, "course": 40.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,308 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 211910000.0, "lon": 8.245333, "lat": 57.05405, "speed": 23.2, "course": 40.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,309 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 103, CreateTime = 1717076858651, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@796d67cb)
2024-05-30 15:47:40 2024-05-30 13:47:40,309 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,309 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 220378000.0, "lon": 12.318, "lat": 55.4345, "speed": 16.0, "course": 131.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,309 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 220378000.0, "lon": 12.318, "lat": 55.4345, "speed": 16.0, "course": 131.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,309 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 104, CreateTime = 1717076858651, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7d9389e1)
2024-05-30 15:47:40 2024-05-30 13:47:40,309 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,309 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 304010928.0, "lon": 10.90415, "lat": 57.703767, "speed": 10.9, "course": 138.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,309 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 304010928.0, "lon": 10.90415, "lat": 57.703767, "speed": 10.9, "course": 138.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,309 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 105, CreateTime = 1717076858651, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5d0b10a7)
2024-05-30 15:47:40 2024-05-30 13:47:40,309 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,309 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 277339000.0, "lon": 15.611372, "lat": 54.97645, "speed": 20.5, "course": 75.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,309 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 277339000.0, "lon": 15.611372, "lat": 54.97645, "speed": 20.5, "course": 75.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,309 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 106, CreateTime = 1717076858651, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@592c994a)
2024-05-30 15:47:40 2024-05-30 13:47:40,309 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,309 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 311411000.0, "lon": 13.016225, "lat": 55.180037, "speed": 13.4, "course": 321.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,309 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 311411000.0, "lon": 13.016225, "lat": 55.180037, "speed": 13.4, "course": 321.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 107, CreateTime = 1717076858652, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4bedfe9b)
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219886000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219886000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 108, CreateTime = 1717076858652, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2a50ba86)
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 265410000.0, "lon": 11.606113, "lat": 57.608057, "speed": 17.2, "course": 253.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 265410000.0, "lon": 11.606113, "lat": 57.608057, "speed": 17.2, "course": 253.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 109, CreateTime = 1717076858652, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2fdb0943)
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 211215340.0, "lon": 11.636305, "lat": 54.387007, "speed": 10.4, "course": 130.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 211215340.0, "lon": 11.636305, "lat": 54.387007, "speed": 10.4, "course": 130.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 110, CreateTime = 1717076858652, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1200333b)
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 211327150.0, "lon": 9.579002, "lat": 54.21115, "speed": 7.2, "course": 53.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 211327150.0, "lon": 9.579002, "lat": 54.21115, "speed": 7.2, "course": 53.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 111, CreateTime = 1717076858652, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@36bd1ec6)
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 265527470.0, "lon": 12.546045, "lat": 56.199238, "speed": 0.0, "course": 7.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 265527470.0, "lon": 12.546045, "lat": 56.199238, "speed": 0.0, "course": 7.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 112, CreateTime = 1717076858652, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1916161d)
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 2190047.0, "lon": 12.613717, "lat": 55.69725, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,310 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 2190047.0, "lon": 12.613717, "lat": 55.69725, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,311 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 113, CreateTime = 1717076858652, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6ef0956d)
2024-05-30 15:47:40 2024-05-30 13:47:40,311 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,311 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 565589000.0, "lon": 10.88985, "lat": 57.715933, "speed": 12.6, "course": 136.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,311 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 565589000.0, "lon": 10.88985, "lat": 57.715933, "speed": 12.6, "course": 136.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,311 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 114, CreateTime = 1717076858652, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7dfaea63)
2024-05-30 15:47:40 2024-05-30 13:47:40,311 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,311 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219000733.0, "lon": 10.259517, "lat": 54.941767, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,311 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219000733.0, "lon": 10.259517, "lat": 54.941767, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,311 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 115, CreateTime = 1717076858652, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@236f9034)
2024-05-30 15:47:40 2024-05-30 13:47:40,311 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,311 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 205586000.0, "lon": 12.830452, "lat": 55.855852, "speed": 0.0, "course": 154.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,311 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 205586000.0, "lon": 12.830452, "lat": 55.855852, "speed": 0.0, "course": 154.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,311 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 116, CreateTime = 1717076858652, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@a60ccba)
2024-05-30 15:47:40 2024-05-30 13:47:40,311 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,311 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 377664000.0, "lon": 12.422755, "lat": 55.477638, "speed": 0.0, "course": 342.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,311 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 377664000.0, "lon": 12.422755, "lat": 55.477638, "speed": 0.0, "course": 342.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 117, CreateTime = 1717076858652, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@60d17b66)
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 357562000.0, "lon": 8.285133, "lat": 57.254717, "speed": 16.2, "course": 58.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 357562000.0, "lon": 8.285133, "lat": 57.254717, "speed": 16.2, "course": 58.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 118, CreateTime = 1717076858652, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4a522ced)
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219008996.0, "lon": 12.611983, "lat": 55.695532, "speed": 0.0, "course": 66.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219008996.0, "lon": 12.611983, "lat": 55.695532, "speed": 0.0, "course": 66.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 119, CreateTime = 1717076858652, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@15e3fba3)
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 265260000.0, "lon": 10.865583, "lat": 54.741467, "speed": 11.0, "course": 174.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 265260000.0, "lon": 10.865583, "lat": 54.741467, "speed": 11.0, "course": 174.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 120, CreateTime = 1717076858653, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@196ae0b9)
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 266039000.0, "lon": 11.137507, "lat": 56.099747, "speed": 17.6, "course": 208.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 266039000.0, "lon": 11.137507, "lat": 56.099747, "speed": 17.6, "course": 208.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 121, CreateTime = 1717076858653, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@728bb2b9)
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219012685.0, "lon": 12.68294, "lat": 54.829758, "speed": 9.3, "course": 52.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,312 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219012685.0, "lon": 12.68294, "lat": 54.829758, "speed": 9.3, "course": 52.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,313 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 122, CreateTime = 1717076858653, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2965cd41)
2024-05-30 15:47:40 2024-05-30 13:47:40,313 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,313 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 305601000.0, "lon": 15.702617, "lat": 54.828517, "speed": 15.0, "course": 97.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,313 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 305601000.0, "lon": 15.702617, "lat": 54.828517, "speed": 15.0, "course": 97.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,313 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 123, CreateTime = 1717076858653, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2351052d)
2024-05-30 15:47:40 2024-05-30 13:47:40,313 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,313 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 273416080.0, "lon": 11.273378, "lat": 57.523577, "speed": 9.1, "course": 296.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,313 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 273416080.0, "lon": 11.273378, "lat": 57.523577, "speed": 9.1, "course": 296.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,313 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 124, CreateTime = 1717076858653, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6df056d6)
2024-05-30 15:47:40 2024-05-30 13:47:40,313 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,313 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 211231520.0, "lon": 10.162833, "lat": 54.3425, "speed": 6.6, "course": 180.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,313 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 211231520.0, "lon": 10.162833, "lat": 54.3425, "speed": 6.6, "course": 180.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,314 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 125, CreateTime = 1717076858653, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@42c13fab)
2024-05-30 15:47:40 2024-05-30 13:47:40,314 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,314 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 2190065.0, "lon": 8.115165, "lat": 55.560718, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,314 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 2190065.0, "lon": 8.115165, "lat": 55.560718, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,314 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 126, CreateTime = 1717076858653, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4549fd77)
2024-05-30 15:47:40 2024-05-30 13:47:40,314 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,314 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 265007000.0, "lon": 8.496152, "lat": 57.292723, "speed": 14.6, "course": 51.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,314 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 265007000.0, "lon": 8.496152, "lat": 57.292723, "speed": 14.6, "course": 51.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 127, CreateTime = 1717076858653, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6e1af09e)
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 266041000.0, "lon": 11.606333, "lat": 54.252333, "speed": 18.5, "course": 61.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 266041000.0, "lon": 11.606333, "lat": 54.252333, "speed": 18.5, "course": 61.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 128, CreateTime = 1717076858653, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1b34d6d)
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 311969000.0, "lon": 9.201333, "lat": 57.8325, "speed": 12.1, "course": 33.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 311969000.0, "lon": 9.201333, "lat": 57.8325, "speed": 12.1, "course": 33.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 129, CreateTime = 1717076858653, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4ac41697)
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 220338000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 220338000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 130, CreateTime = 1717076858653, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@40ecf8fd)
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219009273.0, "lon": 8.598367, "lat": 57.122517, "speed": 1.4, "course": 5.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219009273.0, "lon": 8.598367, "lat": 57.122517, "speed": 1.4, "course": 5.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 131, CreateTime = 1717076858653, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@794b7e7e)
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 265610950.0, "lon": 12.997305, "lat": 55.613713, "speed": 0.0, "course": 129.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 265610950.0, "lon": 12.997305, "lat": 55.613713, "speed": 0.0, "course": 129.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 132, CreateTime = 1717076858653, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@62089c1f)
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 257307000.0, "lon": 10.06147, "lat": 57.04981, "speed": 0.0, "course": 230.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 257307000.0, "lon": 10.06147, "lat": 57.04981, "speed": 0.0, "course": 230.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 133, CreateTime = 1717076858653, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@8124e67)
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 992191024.0, "lon": 10.843057, "lat": 54.919928, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,315 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 992191024.0, "lon": 10.843057, "lat": 54.919928, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 134, CreateTime = 1717076858653, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2f9e7488)
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 232003651.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 232003651.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 135, CreateTime = 1717076858654, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@d84578b)
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 2655130.0, "lon": 14.158068, "lat": 55.668103, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 2655130.0, "lon": 14.158068, "lat": 55.668103, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 136, CreateTime = 1717076858654, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2b4ada40)
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 215140000.0, "lon": 15.207512, "lat": 55.567152, "speed": 12.6, "course": 59.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 215140000.0, "lon": 15.207512, "lat": 55.567152, "speed": 12.6, "course": 59.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 137, CreateTime = 1717076858654, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@31b1c838)
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219230000.0, "lon": 12.691138, "lat": 56.043238, "speed": 0.0, "course": 30.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219230000.0, "lon": 12.691138, "lat": 56.043238, "speed": 0.0, "course": 30.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 138, CreateTime = 1717076858654, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6dd7d0b2)
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 220453000.0, "lon": 9.972843, "lat": 57.593463, "speed": 0.0, "course": 9.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 220453000.0, "lon": 9.972843, "lat": 57.593463, "speed": 0.0, "course": 9.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 139, CreateTime = 1717076858654, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@42c0fa8c)
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219537000.0, "lon": 10.908378, "lat": 55.885675, "speed": 14.3, "course": 40.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219537000.0, "lon": 10.908378, "lat": 55.885675, "speed": 14.3, "course": 40.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 140, CreateTime = 1717076858654, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3f25a04e)
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 249127000.0, "lon": 7.83302, "lat": 56.931635, "speed": 9.4, "course": 239.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 249127000.0, "lon": 7.83302, "lat": 56.931635, "speed": 9.4, "course": 239.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 141, CreateTime = 1717076858654, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@ea4f9a)
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219002317.0, "lon": 12.694453, "lat": 55.53699, "speed": 10.0, "course": 356.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,316 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219002317.0, "lon": 12.694453, "lat": 55.53699, "speed": 10.0, "course": 356.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,317 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 142, CreateTime = 1717076858654, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@53eb4d75)
2024-05-30 15:47:40 2024-05-30 13:47:40,317 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,317 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219171000.0, "lon": 8.443975, "lat": 55.464157, "speed": 0.0, "course": 303.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,317 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219171000.0, "lon": 8.443975, "lat": 55.464157, "speed": 0.0, "course": 303.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,317 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 143, CreateTime = 1717076858654, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@163ad91e)
2024-05-30 15:47:40 2024-05-30 13:47:40,317 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,317 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219004266.0, "lon": 8.22256, "lat": 56.705323, "speed": 0.1, "course": 10.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,317 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219004266.0, "lon": 8.22256, "lat": 56.705323, "speed": 0.1, "course": 10.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,317 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 144, CreateTime = 1717076858654, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@48f2c47)
2024-05-30 15:47:40 2024-05-30 13:47:40,317 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,317 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 212097000.0, "lon": 10.89772, "lat": 54.909207, "speed": 11.1, "course": 15.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,317 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 212097000.0, "lon": 10.89772, "lat": 54.909207, "speed": 11.1, "course": 15.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,317 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 145, CreateTime = 1717076858654, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@56cb35d3)
2024-05-30 15:47:40 2024-05-30 13:47:40,317 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,317 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 211397660.0, "lon": 11.639527, "lat": 57.104635, "speed": 13.0, "course": 160.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 211397660.0, "lon": 11.639527, "lat": 57.104635, "speed": 13.0, "course": 160.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 146, CreateTime = 1717076858654, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5fc25a9a)
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219004242.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219004242.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 147, CreateTime = 1717076858654, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1ff09a55)
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219262000.0, "lon": 11.131723, "lat": 55.334242, "speed": 0.0, "course": 99.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219262000.0, "lon": 11.131723, "lat": 55.334242, "speed": 0.0, "course": 99.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 148, CreateTime = 1717076858654, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@62e060f8)
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 311814000.0, "lon": 8.507418, "lat": 57.774297, "speed": 14.0, "course": 268.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 311814000.0, "lon": 8.507418, "lat": 57.774297, "speed": 14.0, "course": 268.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 149, CreateTime = 1717076858655, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d8ab4da)
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 265349000.0, "lon": 8.534267, "lat": 57.685908, "speed": 1.8, "course": 65.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,318 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 265349000.0, "lon": 8.534267, "lat": 57.685908, "speed": 1.8, "course": 65.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 150, CreateTime = 1717076858655, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2051357b)
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 209642000.0, "lon": 10.721147, "lat": 57.417682, "speed": 11.0, "course": 4.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 209642000.0, "lon": 10.721147, "lat": 57.417682, "speed": 11.0, "course": 4.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 151, CreateTime = 1717076858655, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3be82116)
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219014374.0, "lon": 11.101207, "lat": 55.676113, "speed": 0.1, "course": 350.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219014374.0, "lon": 11.101207, "lat": 55.676113, "speed": 0.1, "course": 350.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 152, CreateTime = 1717076858655, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5aee7133)
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 248811000.0, "lon": 10.80084, "lat": 55.729822, "speed": 16.3, "course": 10.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 248811000.0, "lon": 10.80084, "lat": 55.729822, "speed": 16.3, "course": 10.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 153, CreateTime = 1717076858655, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@627a32d0)
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219000463.0, "lon": 10.56993, "lat": 55.516175, "speed": 0.1, "course": 273.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219000463.0, "lon": 10.56993, "lat": 55.516175, "speed": 0.1, "course": 273.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=413, hash=-2052108070} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=1}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=463, hash=-1628549819} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=0}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=413, hash=-2052108070}, seq 1, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=438, hash=759023609} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=6}
2024-05-30 15:47:40 2024-05-30 13:47:40,320 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=438, hash=759023609}, seq 1, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,320 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=463, hash=1281369217} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=5}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=513, hash=849532951} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=2}
2024-05-30 15:47:40 2024-05-30 13:47:40,320 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=463, hash=1281369217}, seq 1, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,320 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=513, hash=849532951}, seq 1, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=513, hash=-1306244461} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=7}
2024-05-30 15:47:40 2024-05-30 13:47:40,320 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=513, hash=-1306244461}, seq 1, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=638, hash=1191767604} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,320 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=638, hash=1191767604}, seq 1, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 154, CreateTime = 1717076858655, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4b293909)
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=513, hash=-1932315446} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=4}
2024-05-30 15:47:40 2024-05-30 13:47:40,321 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=513, hash=-1932315446}, seq 1, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,319 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=463, hash=-1628549819}, seq 1, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219043000.0, "lon": 4.211962, "lat": 56.369802, "speed": 0.4, "course": 141.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219043000.0, "lon": 4.211962, "lat": 56.369802, "speed": 0.4, "course": 141.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 155, CreateTime = 1717076858656, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@313341eb)
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 220000054.0, "lon": 9.175067, "lat": 56.709, "speed": 0.0, "course": 31.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 220000054.0, "lon": 9.175067, "lat": 56.709, "speed": 0.0, "course": 31.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 156, CreateTime = 1717076858656, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@187dd917)
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 266203000.0, "lon": 10.66301, "lat": 57.67751, "speed": 0.1, "course": 318.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 266203000.0, "lon": 10.66301, "lat": 57.67751, "speed": 0.1, "course": 318.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 157, CreateTime = 1717076858656, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2ba2947a)
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 992191508.0, "lon": 4.758667, "lat": 55.579667, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 992191508.0, "lon": 4.758667, "lat": 55.579667, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 158, CreateTime = 1717076858656, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@29411176)
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 992191529.0, "lon": 4.56165, "lat": 55.834082, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 992191529.0, "lon": 4.56165, "lat": 55.834082, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 159, CreateTime = 1717076858656, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@25621ac)
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 2190076.0, "lon": 9.502143, "lat": 55.674673, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 2190076.0, "lon": 9.502143, "lat": 55.674673, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 160, CreateTime = 1717076858657, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7495e590)
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219011248.0, "lon": 10.355727, "lat": 56.96762, "speed": 1.6, "course": 163.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,323 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219011248.0, "lon": 10.355727, "lat": 56.96762, "speed": 1.6, "course": 163.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 161, CreateTime = 1717076858657, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4b2bbe3c)
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 636011573.0, "lon": 12.2181, "lat": 54.545967, "speed": 11.5, "course": 198.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 636011573.0, "lon": 12.2181, "lat": 54.545967, "speed": 11.5, "course": 198.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 162, CreateTime = 1717076858657, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6a40dc8e)
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 304010714.0, "lon": 13.279933, "lat": 54.70965, "speed": 11.8, "course": 265.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 304010714.0, "lon": 13.279933, "lat": 54.70965, "speed": 11.8, "course": 265.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 163, CreateTime = 1717076858658, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5928db2b)
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 265217000.0, "lon": 12.128768, "lat": 54.156722, "speed": 0.0, "course": 308.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 265217000.0, "lon": 12.128768, "lat": 54.156722, "speed": 0.0, "course": 308.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 164, CreateTime = 1717076858658, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2ca1cfb)
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 304010723.0, "lon": 9.507028, "lat": 57.547263, "speed": 10.1, "course": 243.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 304010723.0, "lon": 9.507028, "lat": 57.547263, "speed": 10.1, "course": 243.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 165, CreateTime = 1717076858658, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@140688c0)
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 211824000.0, "lon": 10.985338, "lat": 54.373253, "speed": 0.1, "course": 354.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 211824000.0, "lon": 10.985338, "lat": 54.373253, "speed": 0.1, "course": 354.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 166, CreateTime = 1717076858658, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@784e9262)
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 211230400.0, "lon": 11.264667, "lat": 54.580833, "speed": 10.1, "course": 292.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 211230400.0, "lon": 11.264667, "lat": 54.580833, "speed": 10.1, "course": 292.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 167, CreateTime = 1717076858659, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6720efc3)
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 2190069.0, "lon": 9.824128, "lat": 57.003823, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 2190069.0, "lon": 9.824128, "lat": 57.003823, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 168, CreateTime = 1717076858659, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@35df1a18)
2024-05-30 15:47:40 2024-05-30 13:47:40,324 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 265246000.0, "lon": 10.780248, "lat": 57.674308, "speed": 0.1, "course": 45.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 265246000.0, "lon": 10.780248, "lat": 57.674308, "speed": 0.1, "course": 45.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 169, CreateTime = 1717076858659, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@153fd4eb)
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 211225390.0, "lon": 11.191223, "lat": 54.419848, "speed": 0.0, "course": 326.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 211225390.0, "lon": 11.191223, "lat": 54.419848, "speed": 0.0, "course": 326.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 170, CreateTime = 1717076858659, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@19ee99ac)
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 236407000.0, "lon": 9.638112, "lat": 57.763747, "speed": 13.0, "course": 73.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 236407000.0, "lon": 9.638112, "lat": 57.763747, "speed": 13.0, "course": 73.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 171, CreateTime = 1717076858659, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@795023a5)
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219002682.0, "lon": 12.614572, "lat": 56.042887, "speed": 0.0, "course": 319.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219002682.0, "lon": 12.614572, "lat": 56.042887, "speed": 0.0, "course": 319.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 172, CreateTime = 1717076858659, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3492f94d)
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 220464000.0, "lon": 9.905997, "lat": 57.711198, "speed": 20.0, "course": 257.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 220464000.0, "lon": 9.905997, "lat": 57.711198, "speed": 20.0, "course": 257.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 173, CreateTime = 1717076858660, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5f61fbb8)
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 304936000.0, "lon": 12.644462, "lat": 55.899863, "speed": 11.3, "course": 160.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 304936000.0, "lon": 12.644462, "lat": 55.899863, "speed": 11.3, "course": 160.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 174, CreateTime = 1717076858660, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@32af3a01)
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 311026000.0, "lon": 6.850897, "lat": 55.541995, "speed": 9.8, "course": 161.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 311026000.0, "lon": 6.850897, "lat": 55.541995, "speed": 9.8, "course": 161.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 175, CreateTime = 1717076858660, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4a1a7afa)
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219006113.0, "lon": 11.128115, "lat": 57.321287, "speed": 0.0, "course": 331.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,325 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219006113.0, "lon": 11.128115, "lat": 57.321287, "speed": 0.0, "course": 331.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 176, CreateTime = 1717076858660, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6961aa65)
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 266331000.0, "lon": 10.785608, "lat": 55.65712, "speed": 18.0, "course": 6.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 266331000.0, "lon": 10.785608, "lat": 55.65712, "speed": 18.0, "course": 6.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 177, CreateTime = 1717076858660, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@390d30ca)
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 273334800.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 273334800.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 178, CreateTime = 1717076858661, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@72397ad8)
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219001522.0, "lon": 10.585437, "lat": 57.717618, "speed": 0.0, "course": 325.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219001522.0, "lon": 10.585437, "lat": 57.717618, "speed": 0.0, "course": 325.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 179, CreateTime = 1717076858661, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6bed13cf)
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219002159.0, "lon": 10.59278, "lat": 57.71825, "speed": 0.0, "course": 150.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219002159.0, "lon": 10.59278, "lat": 57.71825, "speed": 0.0, "course": 150.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 180, CreateTime = 1717076858661, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@f3bae55)
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 992191027.0, "lon": 10.861665, "lat": 55.902018, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 992191027.0, "lon": 10.861665, "lat": 55.902018, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 181, CreateTime = 1717076858661, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5fe05418)
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 2655135.0, "lon": 13.270358, "lat": 55.478315, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 2655135.0, "lon": 13.270358, "lat": 55.478315, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 182, CreateTime = 1717076858661, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@66b61a86)
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 211247340.0, "lon": 9.71535, "lat": 54.318483, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 211247340.0, "lon": 9.71535, "lat": 54.318483, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 183, CreateTime = 1717076858661, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@65c60ef4)
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219005465.0, "lon": 10.670572, "lat": 54.751292, "speed": 0.0, "course": 329.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,326 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219005465.0, "lon": 10.670572, "lat": 54.751292, "speed": 0.0, "course": 329.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 184, CreateTime = 1717076858662, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@37dd4d1f)
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 219002732.0, "lon": 10.549643, "lat": 57.439347, "speed": 0.0, "course": 156.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 219002732.0, "lon": 10.549643, "lat": 57.439347, "speed": 0.0, "course": 156.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 185, CreateTime = 1717076858662, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6a409f68)
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 211518140.0, "lon": 7.468017, "lat": 55.391333, "speed": 3.3, "course": 89.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 211518140.0, "lon": 7.468017, "lat": 55.391333, "speed": 3.3, "course": 89.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 186, CreateTime = 1717076858662, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3cf4ca8c)
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:01", "mmsi": 211800000.0, "lon": 11.424488, "lat": 57.220383, "speed": 9.4, "course": 159.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:01", "mmsi": 211800000.0, "lon": 11.424488, "lat": 57.220383, "speed": 9.4, "course": 159.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 187, CreateTime = 1717076858662, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6910d248)
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 2190077.0, "lon": 14.879105, "lat": 55.149087, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 2190077.0, "lon": 14.879105, "lat": 55.149087, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 188, CreateTime = 1717076858662, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3478dfc0)
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219461000.0, "lon": 12.042342, "lat": 54.89227, "speed": 0.0, "course": 323.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219461000.0, "lon": 12.042342, "lat": 54.89227, "speed": 0.0, "course": 323.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 189, CreateTime = 1717076858663, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5a2dadf8)
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 265228000.0, "lon": 12.72413, "lat": 54.665863, "speed": 11.6, "course": 66.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 265228000.0, "lon": 12.72413, "lat": 54.665863, "speed": 11.6, "course": 66.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 190, CreateTime = 1717076858663, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4017ac9b)
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 211629000.0, "lon": 10.513552, "lat": 55.5775, "speed": 9.6, "course": 147.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,327 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 211629000.0, "lon": 10.513552, "lat": 55.5775, "speed": 9.6, "course": 147.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 191, CreateTime = 1717076858663, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2f7aa443)
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 2190067.0, "lon": 9.55263, "lat": 54.966167, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 2190067.0, "lon": 9.55263, "lat": 54.966167, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 192, CreateTime = 1717076858663, serialized key size = -1, serialized value size = 110, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5d8ef8b3)
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 273133200.0, "lon": 10.927352, "lat": 54.689237, "speed": 11.9, "course": 299.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 273133200.0, "lon": 10.927352, "lat": 54.689237, "speed": 11.9, "course": 299.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 193, CreateTime = 1717076858663, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6afbdc97)
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 233150000.0, "lon": 15.698433, "lat": 55.7276, "speed": 14.4, "course": 62.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 233150000.0, "lon": 15.698433, "lat": 55.7276, "speed": 14.4, "course": 62.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 194, CreateTime = 1717076858663, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@17f5d627)
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 258808000.0, "lon": 12.696867, "lat": 55.630283, "speed": 12.4, "course": 359.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 258808000.0, "lon": 12.696867, "lat": 55.630283, "speed": 12.4, "course": 359.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 195, CreateTime = 1717076858663, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d573026)
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 244759000.0, "lon": 8.041135, "lat": 55.093387, "speed": 9.0, "course": 272.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 244759000.0, "lon": 8.041135, "lat": 55.093387, "speed": 9.0, "course": 272.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 196, CreateTime = 1717076858664, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4736065f)
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219338000.0, "lon": 8.415328, "lat": 55.475345, "speed": 0.0, "course": 11.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219338000.0, "lon": 8.415328, "lat": 55.475345, "speed": 0.0, "course": 11.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 197, CreateTime = 1717076858664, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@739d654a)
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 211211250.0, "lon": 10.04641, "lat": 54.767687, "speed": 11.7, "course": 328.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 211211250.0, "lon": 10.04641, "lat": 54.767687, "speed": 11.7, "course": 328.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 198, CreateTime = 1717076858664, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4a60c1f0)
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219005901.0, "lon": 8.599698, "lat": 57.122575, "speed": 0.0, "course": 297.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,328 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219005901.0, "lon": 8.599698, "lat": 57.122575, "speed": 0.0, "course": 297.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 199, CreateTime = 1717076858664, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1ee20e9a)
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 376474000.0, "lon": 12.675892, "lat": 55.76533, "speed": 8.8, "course": 180.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 376474000.0, "lon": 12.675892, "lat": 55.76533, "speed": 8.8, "course": 180.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 200, CreateTime = 1717076858664, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6991e7e7)
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 377801000.0, "lon": 12.470775, "lat": 54.833697, "speed": 8.9, "course": 212.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 377801000.0, "lon": 12.470775, "lat": 54.833697, "speed": 8.9, "course": 212.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 201, CreateTime = 1717076858665, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@71be78aa)
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 305117000.0, "lon": 15.472333, "lat": 55.649, "speed": 13.7, "course": 65.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 305117000.0, "lon": 15.472333, "lat": 55.649, "speed": 13.7, "course": 65.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 202, CreateTime = 1717076858665, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3d1d582c)
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219000546.0, "lon": 9.423862, "lat": 55.040555, "speed": 0.0, "course": 295.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219000546.0, "lon": 9.423862, "lat": 55.040555, "speed": 0.0, "course": 295.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 203, CreateTime = 1717076858665, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@330507cb)
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 211430000.0, "lon": 11.19089, "lat": 54.421617, "speed": 0.0, "course": 176.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 211430000.0, "lon": 11.19089, "lat": 54.421617, "speed": 0.0, "course": 176.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 204, CreateTime = 1717076858665, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@55cd7093)
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 215681000.0, "lon": 12.754742, "lat": 55.271573, "speed": 14.0, "course": 111.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 215681000.0, "lon": 12.754742, "lat": 55.271573, "speed": 14.0, "course": 111.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 205, CreateTime = 1717076858665, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@573429a8)
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 220352000.0, "lon": 12.467128, "lat": 54.95253, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 220352000.0, "lon": 12.467128, "lat": 54.95253, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 206, CreateTime = 1717076858666, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@bfd75a)
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 305654000.0, "lon": 9.57221, "lat": 54.207903, "speed": 5.9, "course": 50.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 305654000.0, "lon": 9.57221, "lat": 54.207903, "speed": 5.9, "course": 50.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 207, CreateTime = 1717076858666, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1b9fa3d9)
2024-05-30 15:47:40 2024-05-30 13:47:40,329 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219000547.0, "lon": 10.308212, "lat": 56.990218, "speed": 0.0, "course": 278.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219000547.0, "lon": 10.308212, "lat": 56.990218, "speed": 0.0, "course": 278.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 208, CreateTime = 1717076858666, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@25e811d1)
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219000961.0, "lon": 10.833655, "lat": 54.93389, "speed": 0.0, "course": 335.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219000961.0, "lon": 10.833655, "lat": 54.93389, "speed": 0.0, "course": 335.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 209, CreateTime = 1717076858666, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@53e715ad)
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219009267.0, "lon": 11.125878, "lat": 55.332253, "speed": 0.0, "course": 272.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219009267.0, "lon": 11.125878, "lat": 55.332253, "speed": 0.0, "course": 272.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 210, CreateTime = 1717076858669, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2d9c0d8c)
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 992191020.0, "lon": 11.097095, "lat": 55.254717, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 992191020.0, "lon": 11.097095, "lat": 55.254717, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 211, CreateTime = 1717076858670, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4b7bf28d)
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 220174000.0, "lon": 9.6989, "lat": 57.559662, "speed": 16.4, "course": 59.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 220174000.0, "lon": 9.6989, "lat": 57.559662, "speed": 16.4, "course": 59.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 212, CreateTime = 1717076858670, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2ef814aa)
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 220334000.0, "lon": 10.587983, "lat": 57.717933, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 220334000.0, "lon": 10.587983, "lat": 57.717933, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 213, CreateTime = 1717076858670, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@455926a5)
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219087000.0, "lon": 8.224763, "lat": 56.702978, "speed": 0.0, "course": 359.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,330 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219087000.0, "lon": 8.224763, "lat": 56.702978, "speed": 0.0, "course": 359.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 214, CreateTime = 1717076858670, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@8e4a3ef)
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 246384000.0, "lon": 12.093017, "lat": 54.156033, "speed": 0.1, "course": 53.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 246384000.0, "lon": 12.093017, "lat": 54.156033, "speed": 0.1, "course": 53.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 215, CreateTime = 1717076858670, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1c1fc7e4)
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 255801540.0, "lon": 11.865333, "lat": 56.741333, "speed": 18.2, "course": 168.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 255801540.0, "lon": 11.865333, "lat": 56.741333, "speed": 18.2, "course": 168.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 216, CreateTime = 1717076858670, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@72accd89)
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 257689000.0, "lon": 12.236018, "lat": 54.456677, "speed": 14.8, "course": 29.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 257689000.0, "lon": 12.236018, "lat": 54.456677, "speed": 14.8, "course": 29.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 217, CreateTime = 1717076858670, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7ecca177)
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219689000.0, "lon": 8.2225, "lat": 56.6983, "speed": 0.0, "course": 306.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219689000.0, "lon": 8.2225, "lat": 56.6983, "speed": 0.0, "course": 306.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 218, CreateTime = 1717076858670, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@539a8e9a)
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 245882000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 245882000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 219, CreateTime = 1717076858670, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@31d853ea)
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 2190052.0, "lon": 11.196913, "lat": 54.872387, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 2190052.0, "lon": 11.196913, "lat": 54.872387, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 220, CreateTime = 1717076858670, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@250c00dd)
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 211215210.0, "lon": 12.091602, "lat": 54.17976, "speed": 0.1, "course": 296.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 211215210.0, "lon": 12.091602, "lat": 54.17976, "speed": 0.1, "course": 296.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 221, CreateTime = 1717076858670, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3ed0ca12)
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 311995000.0, "lon": 10.264855, "lat": 57.791432, "speed": 18.9, "course": 76.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,331 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 311995000.0, "lon": 10.264855, "lat": 57.791432, "speed": 18.9, "course": 76.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 222, CreateTime = 1717076858670, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@39396d0c)
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219000417.0, "lon": 10.923035, "lat": 56.41269, "speed": 0.0, "course": 278.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219000417.0, "lon": 10.923035, "lat": 56.41269, "speed": 0.0, "course": 278.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 223, CreateTime = 1717076858670, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4a0d3ec2)
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219000062.0, "lon": 12.04125, "lat": 54.892385, "speed": 0.0, "course": 354.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219000062.0, "lon": 12.04125, "lat": 54.892385, "speed": 0.0, "course": 354.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 224, CreateTime = 1717076858673, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@fc2c5b6)
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 2655150.0, "lon": 12.058618, "lat": 57.694, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 2655150.0, "lon": 12.058618, "lat": 57.694, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 225, CreateTime = 1717076858673, serialized key size = -1, serialized value size = 109, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@377a1e06)
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219015579.0, "lon": 7.998963, "lat": 55.502742, "speed": 10.8, "course": 290.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219015579.0, "lon": 7.998963, "lat": 55.502742, "speed": 10.8, "course": 290.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 226, CreateTime = 1717076858673, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@455944e8)
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 377411000.0, "lon": 14.376333, "lat": 55.270498, "speed": 11.0, "course": 219.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 377411000.0, "lon": 14.376333, "lat": 55.270498, "speed": 11.0, "course": 219.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 227, CreateTime = 1717076858673, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@660199af)
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219138000.0, "lon": 8.218667, "lat": 56.696533, "speed": 0.1, "course": 9.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219138000.0, "lon": 8.218667, "lat": 56.696533, "speed": 0.1, "course": 9.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 228, CreateTime = 1717076858673, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7ff71fac)
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219002418.0, "lon": 14.972017, "lat": 55.212365, "speed": 0.0, "course": 173.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219002418.0, "lon": 14.972017, "lat": 55.212365, "speed": 0.0, "course": 173.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 229, CreateTime = 1717076858674, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@189aa47a)
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 265177000.0, "lon": 11.690783, "lat": 57.630527, "speed": 17.0, "course": 26.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 265177000.0, "lon": 11.690783, "lat": 57.630527, "speed": 17.0, "course": 26.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 230, CreateTime = 1717076858674, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@176bdd85)
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219004144.0, "lon": 14.797867, "lat": 54.719287, "speed": 0.7, "course": 74.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,332 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219004144.0, "lon": 14.797867, "lat": 54.719287, "speed": 0.7, "course": 74.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 231, CreateTime = 1717076858674, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7d4de226)
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 244967000.0, "lon": 12.434192, "lat": 54.572185, "speed": 9.8, "course": 59.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 244967000.0, "lon": 12.434192, "lat": 54.572185, "speed": 9.8, "course": 59.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 232, CreateTime = 1717076858674, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3a00985c)
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 564698000.0, "lon": 9.547487, "lat": 57.723218, "speed": 11.7, "course": 256.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 564698000.0, "lon": 9.547487, "lat": 57.723218, "speed": 11.7, "course": 256.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 233, CreateTime = 1717076858674, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@77745212)
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 259222000.0, "lon": 11.619618, "lat": 56.519588, "speed": 19.2, "course": 210.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 259222000.0, "lon": 11.619618, "lat": 56.519588, "speed": 19.2, "course": 210.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 234, CreateTime = 1717076858674, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3e3a3e8c)
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 231730000.0, "lon": 10.588872, "lat": 57.71719, "speed": 0.0, "course": 2.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 231730000.0, "lon": 10.588872, "lat": 57.71719, "speed": 0.0, "course": 2.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 235, CreateTime = 1717076858674, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2c74b7bf)
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 992191516.0, "lon": 5.07835, "lat": 55.402067, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 992191516.0, "lon": 5.07835, "lat": 55.402067, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 236, CreateTime = 1717076858674, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@12880815)
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 992191509.0, "lon": 4.759832, "lat": 55.580767, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 992191509.0, "lon": 4.759832, "lat": 55.580767, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 237, CreateTime = 1717076858674, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@47392c94)
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219000479.0, "lon": 11.962683, "lat": 54.471733, "speed": 15.4, "course": 346.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219000479.0, "lon": 11.962683, "lat": 54.471733, "speed": 15.4, "course": 346.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 238, CreateTime = 1717076858674, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2818b4a1)
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 244806000.0, "lon": 7.284662, "lat": 55.591417, "speed": 5.0, "course": 309.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 244806000.0, "lon": 7.284662, "lat": 55.591417, "speed": 5.0, "course": 309.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 239, CreateTime = 1717076858674, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@21582752)
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 259898000.0, "lon": 11.430333, "lat": 56.529833, "speed": 14.6, "course": 50.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,333 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 259898000.0, "lon": 11.430333, "lat": 56.529833, "speed": 14.6, "course": 50.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 240, CreateTime = 1717076858674, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@73c24bcc)
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219007844.0, "lon": 10.67058, "lat": 54.750893, "speed": 0.0, "course": 351.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219007844.0, "lon": 10.67058, "lat": 54.750893, "speed": 0.0, "course": 351.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 241, CreateTime = 1717076858674, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7d1194ac)
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 245882000.0, "lon": 10.037583, "lat": 56.68245, "speed": 0.0, "course": 2.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 245882000.0, "lon": 10.037583, "lat": 56.68245, "speed": 0.0, "course": 2.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 242, CreateTime = 1717076858675, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@10c18a13)
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 259448000.0, "lon": 9.956957, "lat": 57.592568, "speed": 0.0, "course": 60.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 259448000.0, "lon": 9.956957, "lat": 57.592568, "speed": 0.0, "course": 60.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 243, CreateTime = 1717076858675, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@70434dee)
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 220343000.0, "lon": 10.585662, "lat": 57.71772, "speed": 0.0, "course": 168.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 220343000.0, "lon": 10.585662, "lat": 57.71772, "speed": 0.0, "course": 168.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 244, CreateTime = 1717076858675, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@11bef401)
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 211316340.0, "lon": 13.405433, "lat": 54.865683, "speed": 5.3, "course": 0.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 211316340.0, "lon": 13.405433, "lat": 54.865683, "speed": 5.3, "course": 0.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 245, CreateTime = 1717076858675, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@607bb66e)
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 246162000.0, "lon": 12.842172, "lat": 56.652033, "speed": 5.1, "course": 79.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 246162000.0, "lon": 12.842172, "lat": 56.652033, "speed": 5.1, "course": 79.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 246, CreateTime = 1717076858675, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7c763960)
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 211211290.0, "lon": 10.036257, "lat": 54.777967, "speed": 11.6, "course": 329.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 211211290.0, "lon": 10.036257, "lat": 54.777967, "speed": 11.6, "course": 329.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 247, CreateTime = 1717076858675, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1630373d)
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219001261.0, "lon": 9.633717, "lat": 56.988383, "speed": 0.0, "course": 6.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219001261.0, "lon": 9.633717, "lat": 56.988383, "speed": 0.0, "course": 6.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 248, CreateTime = 1717076858675, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@70c8c706)
2024-05-30 15:47:40 2024-05-30 13:47:40,334 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 261201000.0, "lon": 11.540817, "lat": 54.174825, "speed": 8.6, "course": 23.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 261201000.0, "lon": 11.540817, "lat": 54.174825, "speed": 8.6, "course": 23.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 249, CreateTime = 1717076858675, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4dbdc7b7)
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219226000.0, "lon": 8.127833, "lat": 55.4265, "speed": 14.5, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219226000.0, "lon": 8.127833, "lat": 55.4265, "speed": 14.5, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 250, CreateTime = 1717076858675, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4d5a59)
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 2190074.0, "lon": 10.574652, "lat": 57.738675, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 2190074.0, "lon": 10.574652, "lat": 57.738675, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 251, CreateTime = 1717076858675, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@17d31cb2)
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219796000.0, "lon": 15.135618, "lat": 55.059095, "speed": 0.0, "course": 318.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219796000.0, "lon": 15.135618, "lat": 55.059095, "speed": 0.0, "course": 318.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 252, CreateTime = 1717076858675, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@211509b9)
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 235007859.0, "lon": 10.618662, "lat": 57.441565, "speed": 0.0, "course": 3.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 235007859.0, "lon": 10.618662, "lat": 57.441565, "speed": 0.0, "course": 3.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 253, CreateTime = 1717076858675, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2b6e253)
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219000589.0, "lon": 13.855808, "lat": 54.896222, "speed": 9.7, "course": 118.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,335 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219000589.0, "lon": 13.855808, "lat": 54.896222, "speed": 9.7, "course": 118.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,337 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 254, CreateTime = 1717076858675, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@68c3ffce)
2024-05-30 15:47:40 2024-05-30 13:47:40,337 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,337 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 209696000.0, "lon": 11.376, "lat": 54.545113, "speed": 15.4, "course": 295.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,337 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 209696000.0, "lon": 11.376, "lat": 54.545113, "speed": 15.4, "course": 295.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,337 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 255, CreateTime = 1717076858675, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@67fa48e8)
2024-05-30 15:47:40 2024-05-30 13:47:40,337 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219002416.0, "lon": 10.216207, "lat": 56.15289, "speed": 0.0, "course": 109.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219002416.0, "lon": 10.216207, "lat": 56.15289, "speed": 0.0, "course": 109.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 256, CreateTime = 1717076858676, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6eabdd6f)
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 211304040.0, "lon": 7.158412, "lat": 55.195018, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 211304040.0, "lon": 7.158412, "lat": 55.195018, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 257, CreateTime = 1717076858676, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5b3a0e93)
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 211188000.0, "lon": 11.241317, "lat": 54.517377, "speed": 14.8, "course": 24.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 211188000.0, "lon": 11.241317, "lat": 54.517377, "speed": 14.8, "course": 24.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 258, CreateTime = 1717076858676, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2c70b7b5)
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219002767.0, "lon": 11.510513, "lat": 56.716042, "speed": 0.0, "course": 12.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219002767.0, "lon": 11.510513, "lat": 56.716042, "speed": 0.0, "course": 12.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 259, CreateTime = 1717076858676, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@197807db)
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219000543.0, "lon": 10.505283, "lat": 57.492042, "speed": 0.0, "course": 291.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219000543.0, "lon": 10.505283, "lat": 57.492042, "speed": 0.0, "course": 291.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 260, CreateTime = 1717076858676, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2908f13e)
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 257049000.0, "lon": 3.39297, "lat": 56.278232, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 257049000.0, "lon": 3.39297, "lat": 56.278232, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 261, CreateTime = 1717076858676, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@22cd3c1a)
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219001461.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,338 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219001461.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 262, CreateTime = 1717076858676, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@ba9eae9)
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 3638.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 3638.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 263, CreateTime = 1717076858676, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@52b66298)
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 245529000.0, "lon": 14.249683, "lat": 53.978483, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 245529000.0, "lon": 14.249683, "lat": 53.978483, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 264, CreateTime = 1717076858676, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3cd9f8f1)
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 265518160.0, "lon": 12.687683, "lat": 56.044737, "speed": 0.1, "course": 88.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 265518160.0, "lon": 12.687683, "lat": 56.044737, "speed": 0.1, "course": 88.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 265, CreateTime = 1717076858676, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@77bf3e9c)
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 256072000.0, "lon": 6.013792, "lat": 55.42952, "speed": 13.2, "course": 215.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 256072000.0, "lon": 6.013792, "lat": 55.42952, "speed": 13.2, "course": 215.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 266, CreateTime = 1717076858676, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@33856c20)
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 218759000.0, "lon": 11.578197, "lat": 56.121005, "speed": 8.2, "course": 84.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 218759000.0, "lon": 11.578197, "lat": 56.121005, "speed": 8.2, "course": 84.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 267, CreateTime = 1717076858676, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@52467a6a)
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 246262000.0, "lon": 12.705183, "lat": 55.519167, "speed": 12.5, "course": 355.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 246262000.0, "lon": 12.705183, "lat": 55.519167, "speed": 12.5, "course": 355.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 268, CreateTime = 1717076858676, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@21ab0ea3)
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219004263.0, "lon": 10.913015, "lat": 55.710747, "speed": 9.2, "course": 290.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219004263.0, "lon": 10.913015, "lat": 55.710747, "speed": 9.2, "course": 290.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 269, CreateTime = 1717076858676, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2f6e9fd4)
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 220275000.0, "lon": 8.42217, "lat": 55.475463, "speed": 0.0, "course": 325.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 220275000.0, "lon": 8.42217, "lat": 55.475463, "speed": 0.0, "course": 325.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 270, CreateTime = 1717076858676, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@37120275)
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219295000.0, "lon": 8.224393, "lat": 56.703437, "speed": 0.0, "course": 209.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,339 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219295000.0, "lon": 8.224393, "lat": 56.703437, "speed": 0.0, "course": 209.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 271, CreateTime = 1717076858677, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5666bbd7)
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 211196300.0, "lon": 9.93391, "lat": 54.650868, "speed": 0.0, "course": 317.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 211196300.0, "lon": 9.93391, "lat": 54.650868, "speed": 0.0, "course": 317.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 272, CreateTime = 1717076858677, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2fc169ae)
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 211369090.0, "lon": 13.154188, "lat": 55.007065, "speed": 0.0, "course": 317.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 211369090.0, "lon": 13.154188, "lat": 55.007065, "speed": 0.0, "course": 317.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 273, CreateTime = 1717076858677, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@748ad3bd)
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 309272000.0, "lon": 13.88963, "lat": 55.006712, "speed": 12.4, "course": 170.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 309272000.0, "lon": 13.88963, "lat": 55.006712, "speed": 12.4, "course": 170.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 274, CreateTime = 1717076858677, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@532c76f3)
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 220083000.0, "lon": 8.1228, "lat": 56.004757, "speed": 0.0, "course": 156.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 220083000.0, "lon": 8.1228, "lat": 56.004757, "speed": 0.0, "course": 156.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 275, CreateTime = 1717076858677, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3077d742)
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 220247000.0, "lon": 8.417217, "lat": 55.476812, "speed": 0.0, "course": 15.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 220247000.0, "lon": 8.417217, "lat": 55.476812, "speed": 0.0, "course": 15.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 276, CreateTime = 1717076858677, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@145f44fb)
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 2655148.0, "lon": 12.390502, "lat": 57.108777, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 2655148.0, "lon": 12.390502, "lat": 57.108777, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 277, CreateTime = 1717076858677, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@366a7af6)
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 220018000.0, "lon": 11.664817, "lat": 54.4755, "speed": 10.5, "course": 285.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 220018000.0, "lon": 11.664817, "lat": 54.4755, "speed": 10.5, "course": 285.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 278, CreateTime = 1717076858677, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6411926)
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 265457000.0, "lon": 11.0251, "lat": 56.492233, "speed": 12.6, "course": 6.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 265457000.0, "lon": 11.0251, "lat": 56.492233, "speed": 12.6, "course": 6.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 279, CreateTime = 1717076858677, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@802136b)
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 2190048.0, "lon": 12.12953, "lat": 56.079123, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 2190048.0, "lon": 12.12953, "lat": 56.079123, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 280, CreateTime = 1717076858677, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6614e60c)
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 992191023.0, "lon": 10.98809, "lat": 55.045063, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,340 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 992191023.0, "lon": 10.98809, "lat": 55.045063, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 281, CreateTime = 1717076858677, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@34c8df2)
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 256587000.0, "lon": 8.9302, "lat": 57.416375, "speed": 14.1, "course": 51.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 256587000.0, "lon": 8.9302, "lat": 57.416375, "speed": 14.1, "course": 51.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 282, CreateTime = 1717076858677, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@dca2c94)
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 240244000.0, "lon": 12.664333, "lat": 55.418583, "speed": 12.6, "course": 195.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 240244000.0, "lon": 12.664333, "lat": 55.418583, "speed": 12.6, "course": 195.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 283, CreateTime = 1717076858677, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@15cbff0d)
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 219000762.0, "lon": 10.259028, "lat": 55.911898, "speed": 0.0, "course": 14.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 219000762.0, "lon": 10.259028, "lat": 55.911898, "speed": 0.0, "course": 14.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 284, CreateTime = 1717076858677, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@54ae4f3e)
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 221219001.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 221219001.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 285, CreateTime = 1717076858677, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@33ea6b44)
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 248085000.0, "lon": 12.709003, "lat": 56.006655, "speed": 0.1, "course": 348.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 248085000.0, "lon": 12.709003, "lat": 56.006655, "speed": 0.1, "course": 348.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 286, CreateTime = 1717076858678, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6f185f21)
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:02", "mmsi": 319161000.0, "lon": 11.456133, "lat": 56.345867, "speed": 14.4, "course": 28.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:02", "mmsi": 319161000.0, "lon": 11.456133, "lat": 56.345867, "speed": 14.4, "course": 28.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 287, CreateTime = 1717076858678, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@25e1e658)
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 230204000.0, "lon": 12.830738, "lat": 54.712585, "speed": 15.1, "course": 59.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,341 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 230204000.0, "lon": 12.830738, "lat": 54.712585, "speed": 15.1, "course": 59.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 288, CreateTime = 1717076858678, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3908a65)
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 258237000.0, "lon": 10.962115, "lat": 56.67148, "speed": 10.4, "course": 350.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 258237000.0, "lon": 10.962115, "lat": 56.67148, "speed": 10.4, "course": 350.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 289, CreateTime = 1717076858678, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@63c06118)
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219385000.0, "lon": 12.592997, "lat": 55.67928, "speed": 0.1, "course": 284.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219385000.0, "lon": 12.592997, "lat": 55.67928, "speed": 0.1, "course": 284.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 290, CreateTime = 1717076858678, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4e0cdb16)
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 220223000.0, "lon": 9.317672, "lat": 57.45326, "speed": 17.5, "course": 55.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 220223000.0, "lon": 9.317672, "lat": 57.45326, "speed": 17.5, "course": 55.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 291, CreateTime = 1717076858678, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@64f527a9)
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 257307000.0, "lon": 10.06147, "lat": 57.04981, "speed": 0.0, "course": 230.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 257307000.0, "lon": 10.06147, "lat": 57.04981, "speed": 0.0, "course": 230.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 292, CreateTime = 1717076858678, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@63314af0)
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 215013000.0, "lon": 15.013102, "lat": 55.570297, "speed": 17.1, "course": 238.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 215013000.0, "lon": 15.013102, "lat": 55.570297, "speed": 17.1, "course": 238.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 293, CreateTime = 1717076858678, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3992f2f)
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 304201000.0, "lon": 10.262985, "lat": 54.485883, "speed": 10.8, "course": 207.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 304201000.0, "lon": 10.262985, "lat": 54.485883, "speed": 10.8, "course": 207.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 294, CreateTime = 1717076858678, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2b659021)
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219014049.0, "lon": 14.881917, "lat": 54.7003, "speed": 0.2, "course": 27.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219014049.0, "lon": 14.881917, "lat": 54.7003, "speed": 0.2, "course": 27.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 295, CreateTime = 1717076858678, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6660328b)
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,342 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 992190004.0, "lon": 10.925078, "lat": 56.410887, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 992190004.0, "lon": 10.925078, "lat": 56.410887, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 296, CreateTime = 1717076858678, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@fef827d)
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 211910000.0, "lon": 8.245583, "lat": 57.054217, "speed": 23.3, "course": 40.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 211910000.0, "lon": 8.245583, "lat": 57.054217, "speed": 23.3, "course": 40.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 297, CreateTime = 1717076858678, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@45c534f8)
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 233234000.0, "lon": 7.320553, "lat": 56.393075, "speed": 15.4, "course": 213.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 233234000.0, "lon": 7.320553, "lat": 56.393075, "speed": 15.4, "course": 213.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 298, CreateTime = 1717076858678, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@422650f9)
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 245726000.0, "lon": 10.612158, "lat": 56.692958, "speed": 11.2, "course": 37.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 245726000.0, "lon": 10.612158, "lat": 56.692958, "speed": 11.2, "course": 37.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 299, CreateTime = 1717076858678, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2535d65c)
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219007457.0, "lon": 8.601098, "lat": 57.121018, "speed": 0.0, "course": 283.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219007457.0, "lon": 8.601098, "lat": 57.121018, "speed": 0.0, "course": 283.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 300, CreateTime = 1717076858678, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@56ba44ed)
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 992191026.0, "lon": 10.83737, "lat": 55.798355, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 992191026.0, "lon": 10.83737, "lat": 55.798355, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 301, CreateTime = 1717076858679, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3a34d836)
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 265610040.0, "lon": 9.426123, "lat": 57.535572, "speed": 9.2, "course": 240.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 265610040.0, "lon": 9.426123, "lat": 57.535572, "speed": 9.2, "course": 240.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 302, CreateTime = 1717076858679, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4a65f611)
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 253056000.0, "lon": 11.303187, "lat": 54.545327, "speed": 11.5, "course": 110.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,343 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 253056000.0, "lon": 11.303187, "lat": 54.545327, "speed": 11.5, "course": 110.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,344 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 303, CreateTime = 1717076858679, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@41694e37)
2024-05-30 15:47:40 2024-05-30 13:47:40,344 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,344 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 211298240.0, "lon": 12.087193, "lat": 54.109935, "speed": 0.0, "course": 313.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,344 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 211298240.0, "lon": 12.087193, "lat": 54.109935, "speed": 0.0, "course": 313.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,344 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 304, CreateTime = 1717076858679, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4570e7db)
2024-05-30 15:47:40 2024-05-30 13:47:40,344 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,344 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 210888000.0, "lon": 14.248212, "lat": 53.964367, "speed": 0.0, "course": 0.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,344 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 210888000.0, "lon": 14.248212, "lat": 53.964367, "speed": 0.0, "course": 0.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,344 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 305, CreateTime = 1717076858679, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5999722b)
2024-05-30 15:47:40 2024-05-30 13:47:40,344 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,344 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 245253000.0, "lon": 7.80634, "lat": 55.27644, "speed": 4.2, "course": 327.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,344 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 245253000.0, "lon": 7.80634, "lat": 55.27644, "speed": 4.2, "course": 327.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,344 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 306, CreateTime = 1717076858679, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3c29d277)
2024-05-30 15:47:40 2024-05-30 13:47:40,344 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,344 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 210008000.0, "lon": 10.942513, "lat": 57.68109, "speed": 17.2, "course": 132.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,344 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 210008000.0, "lon": 10.942513, "lat": 57.68109, "speed": 17.2, "course": 132.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 307, CreateTime = 1717076858679, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@37ba3b33)
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 230315000.0, "lon": 10.943167, "lat": 55.907667, "speed": 15.1, "course": 38.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 230315000.0, "lon": 10.943167, "lat": 55.907667, "speed": 15.1, "course": 38.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 308, CreateTime = 1717076858679, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@75365c20)
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 220341000.0, "lon": 9.962795, "lat": 57.593115, "speed": 0.0, "course": 157.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 220341000.0, "lon": 9.962795, "lat": 57.593115, "speed": 0.0, "course": 157.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 309, CreateTime = 1717076858680, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@67ac7087)
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219328000.0, "lon": 14.273452, "lat": 54.899943, "speed": 3.9, "course": 35.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219328000.0, "lon": 14.273452, "lat": 54.899943, "speed": 3.9, "course": 35.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 310, CreateTime = 1717076858680, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1564bc6f)
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219948000.0, "lon": 7.899167, "lat": 57.438795, "speed": 2.8, "course": 32.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219948000.0, "lon": 7.899167, "lat": 57.438795, "speed": 2.8, "course": 32.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 311, CreateTime = 1717076858680, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@73616e53)
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 265150000.0, "lon": 12.30012, "lat": 54.562092, "speed": 16.3, "course": 33.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 265150000.0, "lon": 12.30012, "lat": 54.562092, "speed": 16.3, "course": 33.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 312, CreateTime = 1717076858680, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3471fb43)
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 2190073.0, "lon": 11.052713, "lat": 57.268853, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 2190073.0, "lon": 11.052713, "lat": 57.268853, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 313, CreateTime = 1717076858680, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@30dd9d02)
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 244446000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,345 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 244446000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 314, CreateTime = 1717076858680, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@eac8b2)
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 235073852.0, "lon": 11.351125, "lat": 54.656642, "speed": 0.0, "course": 137.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 235073852.0, "lon": 11.351125, "lat": 54.656642, "speed": 0.0, "course": 137.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 315, CreateTime = 1717076858680, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@78012d0a)
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 245820000.0, "lon": 11.9672, "lat": 54.18965, "speed": 10.4, "course": 77.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 245820000.0, "lon": 11.9672, "lat": 54.18965, "speed": 10.4, "course": 77.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 316, CreateTime = 1717076858680, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@43117aaa)
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219009537.0, "lon": 8.22476, "lat": 56.702657, "speed": 0.0, "course": 332.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219009537.0, "lon": 8.22476, "lat": 56.702657, "speed": 0.0, "course": 332.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 317, CreateTime = 1717076858680, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1f78ca47)
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 265276000.0, "lon": 14.853455, "lat": 54.483773, "speed": 10.7, "course": 303.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 265276000.0, "lon": 14.853455, "lat": 54.483773, "speed": 10.7, "course": 303.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 318, CreateTime = 1717076858680, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@49813e42)
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219188000.0, "lon": 8.628523, "lat": 57.535777, "speed": 2.8, "course": 263.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219188000.0, "lon": 8.628523, "lat": 57.535777, "speed": 2.8, "course": 263.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 319, CreateTime = 1717076858680, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@38192305)
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 992191521.0, "lon": 4.179298, "lat": 56.1784, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 992191521.0, "lon": 4.179298, "lat": 56.1784, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 320, CreateTime = 1717076858680, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7015da86)
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 257438000.0, "lon": 4.749515, "lat": 55.717038, "speed": 0.2, "course": 13.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 257438000.0, "lon": 4.749515, "lat": 55.717038, "speed": 0.2, "course": 13.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 321, CreateTime = 1717076858680, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@29e60c31)
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 992191022.0, "lon": 10.998067, "lat": 55.129242, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 992191022.0, "lon": 10.998067, "lat": 55.129242, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 322, CreateTime = 1717076858680, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@69d54461)
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 220323000.0, "lon": 10.585282, "lat": 57.717315, "speed": 0.0, "course": 353.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,346 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 220323000.0, "lon": 10.585282, "lat": 57.717315, "speed": 0.0, "course": 353.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 323, CreateTime = 1717076858681, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@18a55355)
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 209392000.0, "lon": 8.570862, "lat": 55.086308, "speed": 0.1, "course": 302.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 209392000.0, "lon": 8.570862, "lat": 55.086308, "speed": 0.1, "course": 302.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 324, CreateTime = 1717076858681, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@46ba6b2d)
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 266039000.0, "lon": 11.137372, "lat": 56.099603, "speed": 17.6, "course": 208.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 266039000.0, "lon": 11.137372, "lat": 56.099603, "speed": 17.6, "course": 208.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 325, CreateTime = 1717076858681, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5fa4604f)
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 375752000.0, "lon": 14.806607, "lat": 55.443812, "speed": 7.9, "course": 261.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 375752000.0, "lon": 14.806607, "lat": 55.443812, "speed": 7.9, "course": 261.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 326, CreateTime = 1717076858681, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1c11c196)
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 265410000.0, "lon": 11.605827, "lat": 57.608012, "speed": 17.2, "course": 253.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 265410000.0, "lon": 11.605827, "lat": 57.608012, "speed": 17.2, "course": 253.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 327, CreateTime = 1717076858681, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2e9c16ba)
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 538002019.0, "lon": 11.787498, "lat": 56.415115, "speed": 11.0, "course": 127.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 538002019.0, "lon": 11.787498, "lat": 56.415115, "speed": 11.0, "course": 127.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 328, CreateTime = 1717076858681, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3beaf347)
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219000603.0, "lon": 8.439717, "lat": 55.460783, "speed": 0.0, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219000603.0, "lon": 8.439717, "lat": 55.460783, "speed": 0.0, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 329, CreateTime = 1717076858681, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@47b05a6d)
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219006301.0, "lon": 10.58638, "lat": 57.718063, "speed": 0.0, "course": 320.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219006301.0, "lon": 10.58638, "lat": 57.718063, "speed": 0.0, "course": 320.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 330, CreateTime = 1717076858681, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@55bf3e7c)
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 220272000.0, "lon": 9.755762, "lat": 55.559417, "speed": 0.0, "course": 311.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 220272000.0, "lon": 9.755762, "lat": 55.559417, "speed": 0.0, "course": 311.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 331, CreateTime = 1717076858681, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1b58dbb7)
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 218465000.0, "lon": 8.575257, "lat": 54.693272, "speed": 0.0, "course": 0.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,347 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 218465000.0, "lon": 8.575257, "lat": 54.693272, "speed": 0.0, "course": 0.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 332, CreateTime = 1717076858681, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@77c47350)
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 257462000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 257462000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 333, CreateTime = 1717076858681, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@32622cf7)
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 992111842.0, "lon": 12.691883, "lat": 54.630667, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 992111842.0, "lon": 12.691883, "lat": 54.630667, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 334, CreateTime = 1717076858681, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1e82a819)
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 220345000.0, "lon": 10.024768, "lat": 58.08622, "speed": 2.6, "course": 245.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 220345000.0, "lon": 10.024768, "lat": 58.08622, "speed": 2.6, "course": 245.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 335, CreateTime = 1717076858681, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@435a4d1d)
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219007698.0, "lon": 10.924117, "lat": 56.409607, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219007698.0, "lon": 10.924117, "lat": 56.409607, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 336, CreateTime = 1717076858681, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1750e8d5)
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 235076416.0, "lon": 10.530387, "lat": 55.467868, "speed": 0.0, "course": 38.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 235076416.0, "lon": 10.530387, "lat": 55.467868, "speed": 0.0, "course": 38.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 337, CreateTime = 1717076858681, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@34f67b5c)
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 331102000.0, "lon": 10.546823, "lat": 57.441573, "speed": 0.0, "course": 285.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 331102000.0, "lon": 10.546823, "lat": 57.441573, "speed": 0.0, "course": 285.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 338, CreateTime = 1717076858682, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3f3fcfbb)
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 211298120.0, "lon": 8.576597, "lat": 54.692823, "speed": 0.0, "course": 294.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 211298120.0, "lon": 8.576597, "lat": 54.692823, "speed": 0.0, "course": 294.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 339, CreateTime = 1717076858682, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2e9c4fe4)
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219000852.0, "lon": 14.687862, "lat": 55.098913, "speed": 0.1, "course": 291.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,348 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219000852.0, "lon": 14.687862, "lat": 55.098913, "speed": 0.1, "course": 291.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 340, CreateTime = 1717076858682, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3e1a1ca2)
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219592000.0, "lon": 11.381655, "lat": 57.752155, "speed": 16.9, "course": 342.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219592000.0, "lon": 11.381655, "lat": 57.752155, "speed": 16.9, "course": 342.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 341, CreateTime = 1717076858682, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3931bca6)
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 238199000.0, "lon": 10.8885, "lat": 54.636833, "speed": 12.2, "course": 298.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 238199000.0, "lon": 10.8885, "lat": 54.636833, "speed": 12.2, "course": 298.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 342, CreateTime = 1717076858682, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7832fe2c)
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 309985000.0, "lon": 9.451003, "lat": 58.135607, "speed": 9.4, "course": 213.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 309985000.0, "lon": 9.451003, "lat": 58.135607, "speed": 9.4, "course": 213.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 343, CreateTime = 1717076858682, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@341d6da1)
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 992191503.0, "lon": 5.107282, "lat": 55.478917, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 992191503.0, "lon": 5.107282, "lat": 55.478917, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 344, CreateTime = 1717076858682, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5a8c988c)
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 244073000.0, "lon": 12.042353, "lat": 54.410753, "speed": 11.8, "course": 89.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 244073000.0, "lon": 12.042353, "lat": 54.410753, "speed": 11.8, "course": 89.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 345, CreateTime = 1717076858682, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6e6ccbf7)
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219005954.0, "lon": 10.5867, "lat": 57.718233, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219005954.0, "lon": 10.5867, "lat": 57.718233, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 346, CreateTime = 1717076858682, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1c09b88)
2024-05-30 15:47:40 2024-05-30 13:47:40,349 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 308739000.0, "lon": 12.284417, "lat": 54.541383, "speed": 11.4, "course": 13.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 308739000.0, "lon": 12.284417, "lat": 54.541383, "speed": 11.4, "course": 13.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 347, CreateTime = 1717076858682, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5e6f8e74)
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 304010515.0, "lon": 10.580168, "lat": 54.570007, "speed": 14.7, "course": 246.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 304010515.0, "lon": 10.580168, "lat": 54.570007, "speed": 14.7, "course": 246.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 348, CreateTime = 1717076858682, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@601925cd)
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219012073.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219012073.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 349, CreateTime = 1717076858682, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6822794a)
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219000892.0, "lon": 11.3596, "lat": 54.915767, "speed": 0.2, "course": 320.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219000892.0, "lon": 11.3596, "lat": 54.915767, "speed": 0.2, "course": 320.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 350, CreateTime = 1717076858682, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d3ba31d)
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 259769000.0, "lon": 13.057022, "lat": 54.819612, "speed": 14.0, "course": 70.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 259769000.0, "lon": 13.057022, "lat": 54.819612, "speed": 14.0, "course": 70.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 351, CreateTime = 1717076858682, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4f858ce0)
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 231695000.0, "lon": 4.4335, "lat": 56.1015, "speed": 12.2, "course": 59.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 231695000.0, "lon": 4.4335, "lat": 56.1015, "speed": 12.2, "course": 59.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 352, CreateTime = 1717076858682, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@669bff90)
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,350 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 220356000.0, "lon": 10.663632, "lat": 55.449328, "speed": 0.0, "course": 170.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 220356000.0, "lon": 10.663632, "lat": 55.449328, "speed": 0.0, "course": 170.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 353, CreateTime = 1717076858683, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1d883220)
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 257689000.0, "lon": 12.236075, "lat": 54.456735, "speed": 14.8, "course": 29.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 257689000.0, "lon": 12.236075, "lat": 54.456735, "speed": 14.8, "course": 29.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 354, CreateTime = 1717076858683, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2d9b49c7)
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 211226860.0, "lon": 7.386342, "lat": 55.260368, "speed": 15.6, "course": 248.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 211226860.0, "lon": 7.386342, "lat": 55.260368, "speed": 15.6, "course": 248.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 355, CreateTime = 1717076858683, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4e1a3218)
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 245739000.0, "lon": 10.229813, "lat": 54.446093, "speed": 12.1, "course": 207.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 245739000.0, "lon": 10.229813, "lat": 54.446093, "speed": 12.1, "course": 207.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 356, CreateTime = 1717076858683, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@77c43334)
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 265615860.0, "lon": 13.058615, "lat": 55.675683, "speed": 0.0, "course": 329.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 265615860.0, "lon": 13.058615, "lat": 55.675683, "speed": 0.0, "course": 329.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 357, CreateTime = 1717076858683, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2b0116de)
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219000613.0, "lon": 11.134575, "lat": 55.333315, "speed": 0.1, "course": 299.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219000613.0, "lon": 11.134575, "lat": 55.333315, "speed": 0.1, "course": 299.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 358, CreateTime = 1717076858683, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5ca3a708)
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219012671.0, "lon": 15.135433, "lat": 55.060233, "speed": 0.0, "course": 331.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219012671.0, "lon": 15.135433, "lat": 55.060233, "speed": 0.0, "course": 331.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 359, CreateTime = 1717076858683, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4336c476)
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 265463000.0, "lon": 12.263947, "lat": 54.53951, "speed": 11.9, "course": 21.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,351 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 265463000.0, "lon": 12.263947, "lat": 54.53951, "speed": 11.9, "course": 21.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 360, CreateTime = 1717076858683, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@153d12b7)
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219014012.0, "lon": 8.422017, "lat": 55.472597, "speed": 0.0, "course": 194.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219014012.0, "lon": 8.422017, "lat": 55.472597, "speed": 0.0, "course": 194.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 361, CreateTime = 1717076858683, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@36295128)
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219014161.0, "lon": 8.123553, "lat": 56.004128, "speed": 0.0, "course": 278.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219014161.0, "lon": 8.123553, "lat": 56.004128, "speed": 0.0, "course": 278.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 362, CreateTime = 1717076858683, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@77732b02)
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 209273000.0, "lon": 7.756283, "lat": 56.621802, "speed": 11.0, "course": 34.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 209273000.0, "lon": 7.756283, "lat": 56.621802, "speed": 11.0, "course": 34.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 363, CreateTime = 1717076858683, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@21354ee)
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 277382000.0, "lon": 9.449, "lat": 57.471667, "speed": 10.1, "course": 237.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 277382000.0, "lon": 9.449, "lat": 57.471667, "speed": 10.1, "course": 237.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 364, CreateTime = 1717076858683, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7fc646b1)
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 218176000.0, "lon": 7.3666, "lat": 55.544567, "speed": 8.1, "course": 204.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 218176000.0, "lon": 7.3666, "lat": 55.544567, "speed": 8.1, "course": 204.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 365, CreateTime = 1717076858683, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@31ae870)
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 235075191.0, "lon": 13.1827, "lat": 54.7901, "speed": 13.2, "course": 270.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 235075191.0, "lon": 13.1827, "lat": 54.7901, "speed": 13.2, "course": 270.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 366, CreateTime = 1717076858684, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d5fe82a)
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 259769000.0, "lon": 13.057022, "lat": 54.819612, "speed": 14.0, "course": 70.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 259769000.0, "lon": 13.057022, "lat": 54.819612, "speed": 14.0, "course": 70.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 367, CreateTime = 1717076858684, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@75f3654b)
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 231565000.0, "lon": 10.55335, "lat": 57.438028, "speed": 0.1, "course": 192.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 231565000.0, "lon": 10.55335, "lat": 57.438028, "speed": 0.1, "course": 192.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 368, CreateTime = 1717076858684, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@38cd468a)
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 221219001.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,352 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 221219001.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 369, CreateTime = 1717076858684, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6cc0708b)
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 265548360.0, "lon": 12.785567, "lat": 55.799448, "speed": 11.8, "course": 329.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 265548360.0, "lon": 12.785567, "lat": 55.799448, "speed": 11.8, "course": 329.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 370, CreateTime = 1717076858684, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7eccdb81)
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219001149.0, "lon": 12.308883, "lat": 56.127612, "speed": 0.0, "course": 308.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219001149.0, "lon": 12.308883, "lat": 56.127612, "speed": 0.0, "course": 308.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 371, CreateTime = 1717076858684, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@107b302e)
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219000674.0, "lon": 10.521748, "lat": 54.856665, "speed": 0.0, "course": 150.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219000674.0, "lon": 10.521748, "lat": 54.856665, "speed": 0.0, "course": 150.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 372, CreateTime = 1717076858684, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@42d0ddbd)
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 211190000.0, "lon": 11.279955, "lat": 54.587152, "speed": 14.8, "course": 203.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 211190000.0, "lon": 11.279955, "lat": 54.587152, "speed": 14.8, "course": 203.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 373, CreateTime = 1717076858684, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2dfbb944)
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 311007200.0, "lon": 14.135123, "lat": 54.344428, "speed": 15.4, "course": 339.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 311007200.0, "lon": 14.135123, "lat": 54.344428, "speed": 15.4, "course": 339.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 374, CreateTime = 1717076858684, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@35f37fa9)
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219001299.0, "lon": 8.421517, "lat": 55.473133, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,353 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219001299.0, "lon": 8.421517, "lat": 55.473133, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 375, CreateTime = 1717076858684, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7cc0c379)
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219197000.0, "lon": 7.72705, "lat": 55.051467, "speed": 7.2, "course": 35.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219197000.0, "lon": 7.72705, "lat": 55.051467, "speed": 7.2, "course": 35.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 376, CreateTime = 1717076858684, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3839d469)
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219007333.0, "lon": 14.93125, "lat": 54.700317, "speed": 0.5, "course": 333.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219007333.0, "lon": 14.93125, "lat": 54.700317, "speed": 0.5, "course": 333.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 377, CreateTime = 1717076858685, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@48f87bb3)
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219000872.0, "lon": 10.304615, "lat": 56.990923, "speed": 0.1, "course": 289.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219000872.0, "lon": 10.304615, "lat": 56.990923, "speed": 0.1, "course": 289.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 378, CreateTime = 1717076858685, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@66585b32)
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 376532000.0, "lon": 10.044353, "lat": 57.057105, "speed": 0.0, "course": 287.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 376532000.0, "lon": 10.044353, "lat": 57.057105, "speed": 0.0, "course": 287.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 379, CreateTime = 1717076858685, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1c79878b)
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 992191019.0, "lon": 11.022513, "lat": 55.363552, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 992191019.0, "lon": 11.022513, "lat": 55.363552, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 380, CreateTime = 1717076858685, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6a1592f1)
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219762000.0, "lon": 7.652717, "lat": 57.542983, "speed": 2.1, "course": 75.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219762000.0, "lon": 7.652717, "lat": 57.542983, "speed": 2.1, "course": 75.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 381, CreateTime = 1717076858685, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@613b59e3)
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219001647.0, "lon": 10.053292, "lat": 55.822213, "speed": 0.0, "course": 337.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219001647.0, "lon": 10.053292, "lat": 55.822213, "speed": 0.0, "course": 337.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 382, CreateTime = 1717076858685, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@451e1f3d)
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219005867.0, "lon": 10.588148, "lat": 57.717862, "speed": 0.0, "course": 298.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,354 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219005867.0, "lon": 10.588148, "lat": 57.717862, "speed": 0.0, "course": 298.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 383, CreateTime = 1717076858685, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@150b9dca)
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 261002420.0, "lon": 15.55297, "lat": 54.999353, "speed": 9.5, "course": 355.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 261002420.0, "lon": 15.55297, "lat": 54.999353, "speed": 9.5, "course": 355.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 384, CreateTime = 1717076858685, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@534f1780)
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 244323000.0, "lon": 7.641723, "lat": 55.326655, "speed": 3.3, "course": 308.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 244323000.0, "lon": 7.641723, "lat": 55.326655, "speed": 3.3, "course": 308.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 385, CreateTime = 1717076858685, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6800a84b)
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219125000.0, "lon": 8.21977, "lat": 56.693078, "speed": 0.0, "course": 336.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219125000.0, "lon": 8.21977, "lat": 56.693078, "speed": 0.0, "course": 336.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 386, CreateTime = 1717076858689, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5dd2a581)
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 992191028.0, "lon": 10.820028, "lat": 55.558697, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 992191028.0, "lon": 10.820028, "lat": 55.558697, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 387, CreateTime = 1717076858689, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@14fe963c)
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:03", "mmsi": 219014974.0, "lon": 12.69095, "lat": 56.045267, "speed": 0.1, "course": 358.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,355 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:03", "mmsi": 219014974.0, "lon": 12.69095, "lat": 56.045267, "speed": 0.1, "course": 358.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 388, CreateTime = 1717076858689, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3f267034)
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 636014186.0, "lon": 11.101932, "lat": 56.027597, "speed": 9.4, "course": 24.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 636014186.0, "lon": 11.101932, "lat": 56.027597, "speed": 9.4, "course": 24.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 389, CreateTime = 1717076858690, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5289c56b)
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 246542000.0, "lon": 10.840732, "lat": 54.542857, "speed": 10.4, "course": 73.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 246542000.0, "lon": 10.840732, "lat": 54.542857, "speed": 10.4, "course": 73.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 390, CreateTime = 1717076858690, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1a3f8c16)
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 992191016.0, "lon": 11.046717, "lat": 55.324795, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 992191016.0, "lon": 11.046717, "lat": 55.324795, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 391, CreateTime = 1717076858690, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7a90a61b)
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 211298130.0, "lon": 8.690022, "lat": 54.73038, "speed": 0.0, "course": 105.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 211298130.0, "lon": 8.690022, "lat": 54.73038, "speed": 0.0, "course": 105.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 392, CreateTime = 1717076858690, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@763bdead)
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 245749000.0, "lon": 11.2185, "lat": 57.715167, "speed": 19.2, "course": 290.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 245749000.0, "lon": 11.2185, "lat": 57.715167, "speed": 19.2, "course": 290.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 393, CreateTime = 1717076858691, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6a05ef9c)
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 352678000.0, "lon": 10.256442, "lat": 54.943517, "speed": 0.1, "course": 190.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 352678000.0, "lon": 10.256442, "lat": 54.943517, "speed": 0.1, "course": 190.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 394, CreateTime = 1717076858691, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@c3c91f6)
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 233068000.0, "lon": 9.811302, "lat": 54.363595, "speed": 5.9, "course": 268.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 233068000.0, "lon": 9.811302, "lat": 54.363595, "speed": 5.9, "course": 268.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 395, CreateTime = 1717076858691, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@73635e14)
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 304634000.0, "lon": 10.220333, "lat": 54.433167, "speed": 12.9, "course": 206.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 304634000.0, "lon": 10.220333, "lat": 54.433167, "speed": 12.9, "course": 206.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 396, CreateTime = 1717076858691, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5b052863)
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 245958000.0, "lon": 10.041475, "lat": 57.758177, "speed": 11.2, "course": 59.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,356 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 245958000.0, "lon": 10.041475, "lat": 57.758177, "speed": 11.2, "course": 59.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 397, CreateTime = 1717076858691, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1eb94590)
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 311007200.0, "lon": 14.135123, "lat": 54.344428, "speed": 15.4, "course": 339.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 311007200.0, "lon": 14.135123, "lat": 54.344428, "speed": 15.4, "course": 339.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 398, CreateTime = 1717076858691, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7662d490)
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 259372000.0, "lon": 12.695818, "lat": 55.613987, "speed": 6.3, "course": 175.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 259372000.0, "lon": 12.695818, "lat": 55.613987, "speed": 6.3, "course": 175.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 399, CreateTime = 1717076858691, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1f98b7b6)
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219002881.0, "lon": 8.598895, "lat": 57.121878, "speed": 0.0, "course": 167.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219002881.0, "lon": 8.598895, "lat": 57.121878, "speed": 0.0, "course": 167.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 400, CreateTime = 1717076858691, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d2cc216)
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 477748300.0, "lon": 8.838833, "lat": 57.6025, "speed": 14.9, "course": 61.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 477748300.0, "lon": 8.838833, "lat": 57.6025, "speed": 14.9, "course": 61.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 401, CreateTime = 1717076858691, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@396d8fe6)
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219072000.0, "lon": 12.596217, "lat": 55.708923, "speed": 0.0, "course": 288.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219072000.0, "lon": 12.596217, "lat": 55.708923, "speed": 0.0, "course": 288.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 402, CreateTime = 1717076858691, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@59cb1a0f)
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219250000.0, "lon": 4.736828, "lat": 55.579607, "speed": 0.5, "course": 185.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219250000.0, "lon": 4.736828, "lat": 55.579607, "speed": 0.5, "course": 185.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 403, CreateTime = 1717076858691, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3343387)
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 992191515.0, "lon": 4.271982, "lat": 56.3447, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 992191515.0, "lon": 4.271982, "lat": 56.3447, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 404, CreateTime = 1717076858691, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@8836d85)
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 992191527.0, "lon": 4.7485, "lat": 55.715667, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 992191527.0, "lon": 4.7485, "lat": 55.715667, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 405, CreateTime = 1717076858692, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5dc4c1cc)
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219000551.0, "lon": 12.187268, "lat": 55.454503, "speed": 0.0, "course": 207.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219000551.0, "lon": 12.187268, "lat": 55.454503, "speed": 0.0, "course": 207.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 406, CreateTime = 1717076858692, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5cdeb319)
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 236196000.0, "lon": 12.2613, "lat": 56.19485, "speed": 10.9, "course": 78.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 236196000.0, "lon": 12.2613, "lat": 56.19485, "speed": 10.9, "course": 78.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,357 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 407, CreateTime = 1717076858692, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7e541b0e)
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 248980000.0, "lon": 12.096353, "lat": 54.435967, "speed": 17.5, "course": 263.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 248980000.0, "lon": 12.096353, "lat": 54.435967, "speed": 17.5, "course": 263.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 408, CreateTime = 1717076858692, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6da8be04)
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 311037700.0, "lon": 11.716847, "lat": 56.9953, "speed": 12.1, "course": 161.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 311037700.0, "lon": 11.716847, "lat": 56.9953, "speed": 12.1, "course": 161.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 409, CreateTime = 1717076858692, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1619d8dc)
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 311852000.0, "lon": 14.18426, "lat": 54.345993, "speed": 13.0, "course": 350.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 311852000.0, "lon": 14.18426, "lat": 54.345993, "speed": 13.0, "course": 350.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 410, CreateTime = 1717076858692, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3ff6e77d)
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219014875.0, "lon": 11.508002, "lat": 57.79193, "speed": 11.6, "course": 169.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219014875.0, "lon": 11.508002, "lat": 57.79193, "speed": 11.6, "course": 169.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 411, CreateTime = 1717076858692, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@61a417e6)
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 249622000.0, "lon": 11.661962, "lat": 54.208917, "speed": 9.9, "course": 71.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 249622000.0, "lon": 11.661962, "lat": 54.208917, "speed": 9.9, "course": 71.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 412, CreateTime = 1717076858692, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@49d4dd48)
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219009273.0, "lon": 8.598367, "lat": 57.122533, "speed": 1.6, "course": 4.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219009273.0, "lon": 8.598367, "lat": 57.122533, "speed": 1.6, "course": 4.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 413, CreateTime = 1717076858692, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@11d33396)
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 211224970.0, "lon": 10.98277, "lat": 54.373853, "speed": 0.0, "course": 297.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 211224970.0, "lon": 10.98277, "lat": 54.373853, "speed": 0.0, "course": 297.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 414, CreateTime = 1717076858692, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1916e3de)
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 244613000.0, "lon": 12.071553, "lat": 54.48119, "speed": 10.4, "course": 277.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 244613000.0, "lon": 12.071553, "lat": 54.48119, "speed": 10.4, "course": 277.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 415, CreateTime = 1717076858692, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@584ccc3d)
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 235398000.0, "lon": 10.584498, "lat": 57.716033, "speed": 0.0, "course": 274.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 235398000.0, "lon": 10.584498, "lat": 57.716033, "speed": 0.0, "course": 274.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 416, CreateTime = 1717076858692, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@379d74e1)
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 220338000.0, "lon": 15.135435, "lat": 55.062043, "speed": 0.0, "course": 341.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 220338000.0, "lon": 15.135435, "lat": 55.062043, "speed": 0.0, "course": 341.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 417, CreateTime = 1717076858692, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3fdabe07)
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219467000.0, "lon": 13.230523, "lat": 55.264228, "speed": 10.3, "course": 273.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219467000.0, "lon": 13.230523, "lat": 55.264228, "speed": 10.3, "course": 273.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 418, CreateTime = 1717076858692, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@11fca231)
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219005906.0, "lon": 11.166803, "lat": 56.002422, "speed": 7.5, "course": 233.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,358 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219005906.0, "lon": 11.166803, "lat": 56.002422, "speed": 7.5, "course": 233.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 419, CreateTime = 1717076858693, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2f6fa917)
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 220249000.0, "lon": 8.055862, "lat": 56.315677, "speed": 9.4, "course": 175.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 220249000.0, "lon": 8.055862, "lat": 56.315677, "speed": 9.4, "course": 175.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 420, CreateTime = 1717076858693, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7389fa67)
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 277093000.0, "lon": 15.613333, "lat": 54.686667, "speed": 16.7, "course": 79.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 277093000.0, "lon": 15.613333, "lat": 54.686667, "speed": 16.7, "course": 79.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 421, CreateTime = 1717076858693, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@19495897)
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219000605.0, "lon": 8.440422, "lat": 55.460733, "speed": 0.0, "course": 279.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219000605.0, "lon": 8.440422, "lat": 55.460733, "speed": 0.0, "course": 279.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 422, CreateTime = 1717076858693, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d508ca5)
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219005513.0, "lon": 8.60116, "lat": 57.121858, "speed": 0.0, "course": 339.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219005513.0, "lon": 8.60116, "lat": 57.121858, "speed": 0.0, "course": 339.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 423, CreateTime = 1717076858693, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3fa5b709)
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219000352.0, "lon": 10.2241, "lat": 56.160467, "speed": 0.0, "course": 346.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219000352.0, "lon": 10.2241, "lat": 56.160467, "speed": 0.0, "course": 346.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 424, CreateTime = 1717076858693, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3c33858)
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219904000.0, "lon": 9.665093, "lat": 57.908465, "speed": 0.5, "course": 72.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219904000.0, "lon": 9.665093, "lat": 57.908465, "speed": 0.5, "course": 72.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 425, CreateTime = 1717076858693, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@509d4557)
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219011321.0, "lon": 8.96567, "lat": 57.715822, "speed": 0.5, "course": 69.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219011321.0, "lon": 8.96567, "lat": 57.715822, "speed": 0.5, "course": 69.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 426, CreateTime = 1717076858693, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3941de45)
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219140000.0, "lon": 8.593227, "lat": 57.119278, "speed": 0.0, "course": 357.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219140000.0, "lon": 8.593227, "lat": 57.119278, "speed": 0.0, "course": 357.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 427, CreateTime = 1717076858696, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2bce2b9b)
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 266262000.0, "lon": 12.6316, "lat": 55.042647, "speed": 17.6, "course": 178.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 266262000.0, "lon": 12.6316, "lat": 55.042647, "speed": 17.6, "course": 178.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 428, CreateTime = 1717076858697, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3155d742)
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219622000.0, "lon": 10.539443, "lat": 55.470505, "speed": 0.0, "course": 89.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219622000.0, "lon": 10.539443, "lat": 55.470505, "speed": 0.0, "course": 89.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 429, CreateTime = 1717076858698, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@b588bc2)
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 304669000.0, "lon": 12.081648, "lat": 54.442643, "speed": 9.4, "course": 268.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 304669000.0, "lon": 12.081648, "lat": 54.442643, "speed": 9.4, "course": 268.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 430, CreateTime = 1717076858698, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3c5ccf1a)
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 220359000.0, "lon": 9.963172, "lat": 57.592882, "speed": 0.0, "course": 336.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,359 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 220359000.0, "lon": 9.963172, "lat": 57.592882, "speed": 0.0, "course": 336.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 431, CreateTime = 1717076858698, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6694b9f9)
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 304080890.0, "lon": 14.504167, "lat": 55.284167, "speed": 21.6, "course": 36.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 304080890.0, "lon": 14.504167, "lat": 55.284167, "speed": 21.6, "course": 36.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 432, CreateTime = 1717076858698, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@79648dae)
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 247221100.0, "lon": 8.835182, "lat": 57.64975, "speed": 10.4, "course": 72.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 247221100.0, "lon": 8.835182, "lat": 57.64975, "speed": 10.4, "course": 72.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 433, CreateTime = 1717076858698, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@36ad0fdb)
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 235011250.0, "lon": 12.885993, "lat": 54.797847, "speed": 17.5, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 235011250.0, "lon": 12.885993, "lat": 54.797847, "speed": 17.5, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 434, CreateTime = 1717076858698, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6cd3320b)
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 257494000.0, "lon": 13.298965, "lat": 55.19693, "speed": 6.3, "course": 284.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 257494000.0, "lon": 13.298965, "lat": 55.19693, "speed": 6.3, "course": 284.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 435, CreateTime = 1717076858699, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2fcb1519)
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 205365000.0, "lon": 11.800388, "lat": 54.420837, "speed": 15.9, "course": 316.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 205365000.0, "lon": 11.800388, "lat": 54.420837, "speed": 15.9, "course": 316.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 436, CreateTime = 1717076858699, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@721fe4b3)
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 220278000.0, "lon": 9.664213, "lat": 57.901912, "speed": 0.4, "course": 94.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 220278000.0, "lon": 9.664213, "lat": 57.901912, "speed": 0.4, "course": 94.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 437, CreateTime = 1717076858699, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2c92fefc)
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 265579090.0, "lon": 11.660655, "lat": 57.707522, "speed": 0.0, "course": 350.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 265579090.0, "lon": 11.660655, "lat": 57.707522, "speed": 0.0, "course": 350.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 438, CreateTime = 1717076858699, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5924c20f)
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 257019640.0, "lon": 10.550667, "lat": 57.4425, "speed": 0.0, "course": 148.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 257019640.0, "lon": 10.550667, "lat": 57.4425, "speed": 0.0, "course": 148.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 439, CreateTime = 1717076858699, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2e3077ef)
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 265514800.0, "lon": 12.997438, "lat": 55.613557, "speed": 0.0, "course": 119.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 265514800.0, "lon": 12.997438, "lat": 55.613557, "speed": 0.0, "course": 119.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 440, CreateTime = 1717076858699, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@230734e6)
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219000125.0, "lon": 10.588117, "lat": 57.716833, "speed": 0.6, "course": 273.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219000125.0, "lon": 10.588117, "lat": 57.716833, "speed": 0.6, "course": 273.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 441, CreateTime = 1717076858699, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@18594b64)
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 259894000.0, "lon": 15.218463, "lat": 55.639357, "speed": 14.4, "course": 241.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 259894000.0, "lon": 15.218463, "lat": 55.639357, "speed": 14.4, "course": 241.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 442, CreateTime = 1717076858699, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6712c6da)
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219342000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219342000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,360 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 443, CreateTime = 1717076858699, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4a304ad8)
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 257182000.0, "lon": 11.53189, "lat": 57.358263, "speed": 15.8, "course": 335.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 257182000.0, "lon": 11.53189, "lat": 57.358263, "speed": 15.8, "course": 335.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 444, CreateTime = 1717076858700, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@508af77c)
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 265225000.0, "lon": 14.24289, "lat": 53.985217, "speed": 0.2, "course": 50.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 265225000.0, "lon": 14.24289, "lat": 53.985217, "speed": 0.2, "course": 50.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 445, CreateTime = 1717076858701, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@25a8462)
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 265522600.0, "lon": 11.796225, "lat": 57.605663, "speed": 0.1, "course": 183.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 265522600.0, "lon": 11.796225, "lat": 57.605663, "speed": 0.1, "course": 183.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 446, CreateTime = 1717076858702, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@738fb6e5)
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219923000.0, "lon": 12.27424, "lat": 54.294003, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219923000.0, "lon": 12.27424, "lat": 54.294003, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 447, CreateTime = 1717076858703, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3ba144c6)
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 246061000.0, "lon": 12.834982, "lat": 55.859782, "speed": 0.0, "course": 62.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 246061000.0, "lon": 12.834982, "lat": 55.859782, "speed": 0.0, "course": 62.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 448, CreateTime = 1717076858703, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3c1775d9)
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 220378000.0, "lon": 12.318333, "lat": 55.434167, "speed": 15.9, "course": 130.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 220378000.0, "lon": 12.318333, "lat": 55.434167, "speed": 15.9, "course": 130.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 449, CreateTime = 1717076858703, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6ab89fad)
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 265360000.0, "lon": 11.95846, "lat": 57.706428, "speed": 0.0, "course": 358.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 265360000.0, "lon": 11.95846, "lat": 57.706428, "speed": 0.0, "course": 358.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 450, CreateTime = 1717076858703, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@640e2481)
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 247072400.0, "lon": 15.694167, "lat": 55.434167, "speed": 13.3, "course": 92.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 247072400.0, "lon": 15.694167, "lat": 55.434167, "speed": 13.3, "course": 92.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 451, CreateTime = 1717076858703, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5538dbb2)
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 244965000.0, "lon": 7.708312, "lat": 55.25024, "speed": 3.5, "course": 275.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 244965000.0, "lon": 7.708312, "lat": 55.25024, "speed": 3.5, "course": 275.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 452, CreateTime = 1717076858703, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5206c571)
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 235034149.0, "lon": 12.141198, "lat": 54.433428, "speed": 14.7, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 235034149.0, "lon": 12.141198, "lat": 54.433428, "speed": 14.7, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 453, CreateTime = 1717076858703, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7c6d7d6b)
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219002493.0, "lon": 10.447083, "lat": 55.599215, "speed": 0.1, "course": 159.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219002493.0, "lon": 10.447083, "lat": 55.599215, "speed": 0.1, "course": 159.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 454, CreateTime = 1717076858703, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6952744b)
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219002769.0, "lon": 10.925477, "lat": 56.409287, "speed": 0.0, "course": 335.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,361 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219002769.0, "lon": 10.925477, "lat": 56.409287, "speed": 0.0, "course": 335.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 455, CreateTime = 1717076858704, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7aa4d798)
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 220461000.0, "lon": 10.58486, "lat": 57.716868, "speed": 0.0, "course": 0.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 220461000.0, "lon": 10.58486, "lat": 57.716868, "speed": 0.0, "course": 0.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 456, CreateTime = 1717076858704, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1eedb8f0)
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219001262.0, "lon": 11.929867, "lat": 54.572167, "speed": 0.0, "course": 216.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219001262.0, "lon": 11.929867, "lat": 54.572167, "speed": 0.0, "course": 216.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 457, CreateTime = 1717076858704, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@97c1863)
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219001673.0, "lon": 9.891583, "lat": 58.077733, "speed": 2.4, "course": 54.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219001673.0, "lon": 9.891583, "lat": 58.077733, "speed": 2.4, "course": 54.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 458, CreateTime = 1717076858704, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7376c52b)
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 246252000.0, "lon": 12.057485, "lat": 54.464785, "speed": 10.4, "course": 269.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 246252000.0, "lon": 12.057485, "lat": 54.464785, "speed": 10.4, "course": 269.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 459, CreateTime = 1717076858704, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2f32d4ca)
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219477000.0, "lon": 15.136518, "lat": 55.063688, "speed": 0.6, "course": 288.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219477000.0, "lon": 15.136518, "lat": 55.063688, "speed": 0.6, "course": 288.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 460, CreateTime = 1717076858704, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5c6bd3e4)
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 212130000.0, "lon": 11.784947, "lat": 56.924888, "speed": 14.3, "course": 341.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 212130000.0, "lon": 11.784947, "lat": 56.924888, "speed": 14.3, "course": 341.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 461, CreateTime = 1717076858705, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@353d770a)
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219014427.0, "lon": 12.087863, "lat": 54.181932, "speed": 0.0, "course": 340.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219014427.0, "lon": 12.087863, "lat": 54.181932, "speed": 0.0, "course": 340.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 462, CreateTime = 1717076858706, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7027b31b)
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219043000.0, "lon": 4.211968, "lat": 56.369797, "speed": 0.4, "course": 141.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219043000.0, "lon": 4.211968, "lat": 56.369797, "speed": 0.4, "course": 141.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 463, CreateTime = 1717076858706, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@498aad51)
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 265200000.0, "lon": 11.241383, "lat": 56.16005, "speed": 20.0, "course": 227.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 265200000.0, "lon": 11.241383, "lat": 56.16005, "speed": 20.0, "course": 227.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 464, CreateTime = 1717076858706, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4bfca377)
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219007589.0, "lon": 10.785743, "lat": 55.139387, "speed": 0.0, "course": 350.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219007589.0, "lon": 10.785743, "lat": 55.139387, "speed": 0.0, "course": 350.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 465, CreateTime = 1717076858706, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@15a71825)
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 211404810.0, "lon": 13.16167, "lat": 54.688207, "speed": 4.6, "course": 260.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 211404810.0, "lon": 13.16167, "lat": 54.688207, "speed": 4.6, "course": 260.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 466, CreateTime = 1717076858706, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5855cee1)
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 212675000.0, "lon": 11.433083, "lat": 57.45755, "speed": 16.3, "course": 339.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,362 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 212675000.0, "lon": 11.433083, "lat": 57.45755, "speed": 16.3, "course": 339.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 467, CreateTime = 1717076858706, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@44a9009f)
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 258514000.0, "lon": 12.60016, "lat": 55.689902, "speed": 0.0, "course": 263.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 258514000.0, "lon": 12.60016, "lat": 55.689902, "speed": 0.0, "course": 263.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 468, CreateTime = 1717076858707, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6a60f466)
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 992191500.0, "lon": 4.618232, "lat": 55.576482, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 992191500.0, "lon": 4.618232, "lat": 55.576482, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 469, CreateTime = 1717076858707, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@472baf3f)
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 992191506.0, "lon": 5.107417, "lat": 55.4773, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 992191506.0, "lon": 5.107417, "lat": 55.4773, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 470, CreateTime = 1717076858707, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@31ff43fd)
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 209078000.0, "lon": 11.7675, "lat": 56.923167, "speed": 12.8, "course": 159.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 209078000.0, "lon": 11.7675, "lat": 56.923167, "speed": 12.8, "course": 159.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 471, CreateTime = 1717076858708, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3d5e00a5)
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 220232000.0, "lon": 8.426817, "lat": 55.473017, "speed": 0.0, "course": 50.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 220232000.0, "lon": 8.426817, "lat": 55.473017, "speed": 0.0, "course": 50.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 472, CreateTime = 1717076858708, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@50f010ac)
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219005502.0, "lon": 10.586562, "lat": 57.717775, "speed": 0.0, "course": 317.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219005502.0, "lon": 10.586562, "lat": 57.717775, "speed": 0.0, "course": 317.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 473, CreateTime = 1717076858709, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4ab80fda)
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 211317180.0, "lon": 8.455725, "lat": 57.172523, "speed": 13.2, "course": 221.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 211317180.0, "lon": 8.455725, "lat": 57.172523, "speed": 13.2, "course": 221.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 474, CreateTime = 1717076858710, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1135ddb)
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219439000.0, "lon": 9.647498, "lat": 57.914453, "speed": 0.5, "course": 81.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219439000.0, "lon": 9.647498, "lat": 57.914453, "speed": 0.5, "course": 81.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 475, CreateTime = 1717076858710, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4c053e74)
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219000368.0, "lon": 12.61669, "lat": 56.034042, "speed": 0.1, "course": 195.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219000368.0, "lon": 12.61669, "lat": 56.034042, "speed": 0.1, "course": 195.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 476, CreateTime = 1717076858710, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1c202228)
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219108000.0, "lon": 15.09935, "lat": 55.3029, "speed": 9.3, "course": 95.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219108000.0, "lon": 15.09935, "lat": 55.3029, "speed": 9.3, "course": 95.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 477, CreateTime = 1717076858710, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@16ec28a9)
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:04", "mmsi": 219009704.0, "lon": 12.385638, "lat": 55.611592, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:04", "mmsi": 219009704.0, "lon": 12.385638, "lat": 55.611592, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 478, CreateTime = 1717076858710, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@d0a422a)
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219000809.0, "lon": 11.514508, "lat": 54.97197, "speed": 0.0, "course": 165.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,363 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219000809.0, "lon": 11.514508, "lat": 54.97197, "speed": 0.0, "course": 165.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 479, CreateTime = 1717076858710, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@68193b61)
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 2190049.0, "lon": 10.918783, "lat": 55.735817, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 2190049.0, "lon": 10.918783, "lat": 55.735817, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 480, CreateTime = 1717076858711, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@75b56528)
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219002358.0, "lon": 11.347955, "lat": 54.656347, "speed": 0.0, "course": 143.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219002358.0, "lon": 11.347955, "lat": 54.656347, "speed": 0.0, "course": 143.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 481, CreateTime = 1717076858711, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2ebb257)
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 250002012.0, "lon": 11.89835, "lat": 56.799095, "speed": 14.7, "course": 340.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 250002012.0, "lon": 11.89835, "lat": 56.799095, "speed": 14.7, "course": 340.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 482, CreateTime = 1717076858711, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5d2fbb32)
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 265410000.0, "lon": 11.605542, "lat": 57.607967, "speed": 17.2, "course": 253.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 265410000.0, "lon": 11.605542, "lat": 57.607967, "speed": 17.2, "course": 253.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 483, CreateTime = 1717076858712, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7c4c51c5)
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219001343.0, "lon": 11.958083, "lat": 56.228067, "speed": 0.0, "course": 250.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219001343.0, "lon": 11.958083, "lat": 56.228067, "speed": 0.0, "course": 250.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 484, CreateTime = 1717076858713, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@228ee741)
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219002761.0, "lon": 15.135647, "lat": 55.062232, "speed": 0.0, "course": 216.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219002761.0, "lon": 15.135647, "lat": 55.062232, "speed": 0.0, "course": 216.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 485, CreateTime = 1717076858713, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7da8904d)
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219654000.0, "lon": 12.597247, "lat": 55.708817, "speed": 0.0, "course": 305.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219654000.0, "lon": 12.597247, "lat": 55.708817, "speed": 0.0, "course": 305.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 486, CreateTime = 1717076858713, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5dfe42e1)
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219838000.0, "lon": 10.583835, "lat": 57.71596, "speed": 0.0, "course": 18.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219838000.0, "lon": 10.583835, "lat": 57.71596, "speed": 0.0, "course": 18.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 487, CreateTime = 1717076858713, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4322e2e2)
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 211910000.0, "lon": 8.245867, "lat": 57.054383, "speed": 23.3, "course": 40.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 211910000.0, "lon": 8.245867, "lat": 57.054383, "speed": 23.3, "course": 40.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 488, CreateTime = 1717076858713, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@16c3a128)
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 235035113.0, "lon": 12.610405, "lat": 55.200037, "speed": 14.9, "course": 175.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 235035113.0, "lon": 12.610405, "lat": 55.200037, "speed": 14.9, "course": 175.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 489, CreateTime = 1717076858714, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2fd06145)
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219868000.0, "lon": 9.95819, "lat": 57.59237, "speed": 0.0, "course": 64.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219868000.0, "lon": 9.95819, "lat": 57.59237, "speed": 0.0, "course": 64.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,364 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 490, CreateTime = 1717076858714, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@16d714)
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 211493380.0, "lon": 8.395958, "lat": 54.629192, "speed": 0.0, "course": 103.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 211493380.0, "lon": 8.395958, "lat": 54.629192, "speed": 0.0, "course": 103.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 491, CreateTime = 1717076858714, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@54f70006)
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219000028.0, "lon": 12.68982, "lat": 56.040003, "speed": 0.0, "course": 237.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219000028.0, "lon": 12.68982, "lat": 56.040003, "speed": 0.0, "course": 237.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 492, CreateTime = 1717076858714, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5fb62151)
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219004263.0, "lon": 10.912875, "lat": 55.710777, "speed": 9.2, "course": 290.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219004263.0, "lon": 10.912875, "lat": 55.710777, "speed": 9.2, "course": 290.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 493, CreateTime = 1717076858714, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7340a9ab)
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219012638.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219012638.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 494, CreateTime = 1717076858714, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@45d86ea0)
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 212644000.0, "lon": 11.624283, "lat": 57.602983, "speed": 16.3, "course": 97.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 212644000.0, "lon": 11.624283, "lat": 57.602983, "speed": 16.3, "course": 97.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 495, CreateTime = 1717076858715, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@29c3b12d)
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 265651100.0, "lon": 12.745007, "lat": 55.992565, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 265651100.0, "lon": 12.745007, "lat": 55.992565, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 496, CreateTime = 1717076858715, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4711a1ed)
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219000175.0, "lon": 10.21529, "lat": 56.152397, "speed": 0.0, "course": 317.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219000175.0, "lon": 10.21529, "lat": 56.152397, "speed": 0.0, "course": 317.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 497, CreateTime = 1717076858715, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@31ea5555)
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 259579000.0, "lon": 3.3615, "lat": 56.277833, "speed": 1.2, "course": 46.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 259579000.0, "lon": 3.3615, "lat": 56.277833, "speed": 1.2, "course": 46.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 498, CreateTime = 1717076858715, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@374180a6)
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 265511440.0, "lon": 11.666273, "lat": 57.621607, "speed": 17.9, "course": 70.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 265511440.0, "lon": 11.666273, "lat": 57.621607, "speed": 17.9, "course": 70.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 499, CreateTime = 1717076858715, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@33f05ba)
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Current fetch is finished.
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitting records from fetch for split aisdata-0
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Finished running task FetchTask
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Cleaned wakeup flag.
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 212636000.0, "lon": 11.9695, "lat": 54.4365, "speed": 14.2, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Prepare to run FetchTask
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 212636000.0, "lon": 11.9695, "lat": 54.4365, "speed": 14.2, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 500, CreateTime = 1717076858715, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@49ebc2f9)
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 2655153.0, "lon": 11.821313, "lat": 58.374063, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,365 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 2655153.0, "lon": 11.821313, "lat": 58.374063, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 501, CreateTime = 1717076858715, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2a48766c)
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 265483000.0, "lon": 10.599167, "lat": 57.718167, "speed": 0.0, "course": 148.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 265483000.0, "lon": 10.599167, "lat": 57.718167, "speed": 0.0, "course": 148.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 502, CreateTime = 1717076858715, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@11b79733)
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.aisdata.bytes-fetched
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 266039000.0, "lon": 11.137237, "lat": 56.09946, "speed": 17.5, "course": 207.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 266039000.0, "lon": 11.137237, "lat": 56.09946, "speed": 17.5, "course": 207.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 503, CreateTime = 1717076858715, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6ade526a)
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219014162.0, "lon": 8.600537, "lat": 57.12244, "speed": 0.0, "course": 177.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219014162.0, "lon": 8.600537, "lat": 57.12244, "speed": 0.0, "course": 177.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=fetch-size-avg, group=consumer-fetch-manager-metrics, description=The average number of bytes fetched per request for a topic, tags={client-id=flink_consumer-3, topic=aisdata}]
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=fetch-size-max, group=consumer-fetch-manager-metrics, description=The maximum number of bytes fetched per request for a topic, tags={client-id=flink_consumer-3, topic=aisdata}]
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 504, CreateTime = 1717076858715, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7d35a9c2)
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219012302.0, "lon": 12.466667, "lat": 54.9525, "speed": 0.0, "course": 2.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219012302.0, "lon": 12.466667, "lat": 54.9525, "speed": 0.0, "course": 2.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=bytes-consumed-total, group=consumer-fetch-manager-metrics, description=The total number of bytes consumed for a topic, tags={client-id=flink_consumer-3, topic=aisdata}]
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=bytes-consumed-rate, group=consumer-fetch-manager-metrics, description=The average number of bytes consumed per second for a topic, tags={client-id=flink_consumer-3, topic=aisdata}]
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.aisdata.records-fetched
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 505, CreateTime = 1717076858716, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@14274b1e)
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 265073000.0, "lon": 14.870933, "lat": 54.7083, "speed": 6.9, "course": 242.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 265073000.0, "lon": 14.870933, "lat": 54.7083, "speed": 6.9, "course": 242.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=records-per-request-avg, group=consumer-fetch-manager-metrics, description=The average number of records in each request for a topic, tags={client-id=flink_consumer-3, topic=aisdata}]
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=records-consumed-total, group=consumer-fetch-manager-metrics, description=The total number of records consumed for a topic, tags={client-id=flink_consumer-3, topic=aisdata}]
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 506, CreateTime = 1717076858716, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@398458a6)
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.common.metrics.Metrics  - Registered metric named MetricName [name=records-consumed-rate, group=consumer-fetch-manager-metrics, description=The average number of records consumed per second for a topic, tags={client-id=flink_consumer-3, topic=aisdata}]
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 257983000.0, "lon": 7.44979, "lat": 57.184357, "speed": 14.5, "course": 245.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 257983000.0, "lon": 7.44979, "lat": 57.184357, "speed": 14.5, "course": 245.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 507, CreateTime = 1717076858716, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@215110fe)
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219000429.0, "lon": 11.344493, "lat": 54.649965, "speed": 9.4, "course": 45.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219000429.0, "lon": 11.344493, "lat": 54.649965, "speed": 9.4, "course": 45.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 508, CreateTime = 1717076858716, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@71fac6af)
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 253062000.0, "lon": 14.339912, "lat": 55.281363, "speed": 12.8, "course": 218.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,366 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 253062000.0, "lon": 14.339912, "lat": 55.281363, "speed": 12.8, "course": 218.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,367 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Returning 0 fetched records at offset FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} for assigned partition aisdata-0
2024-05-30 15:47:40 2024-05-30 13:47:40,367 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:40 2024-05-30 13:47:40,367 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 509, CreateTime = 1717076858716, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5f2b0c35)
2024-05-30 15:47:40 2024-05-30 13:47:40,367 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,367 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219002731.0, "lon": 11.511367, "lat": 56.71586, "speed": 0.0, "course": 164.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,367 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219002731.0, "lon": 11.511367, "lat": 56.71586, "speed": 0.0, "course": 164.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,367 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=1) for node 1. Added (), altered (ZiGIwhiYS8-umhWEVwc-NQ:aisdata-0), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:40 2024-05-30 13:47:40,367 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 510, CreateTime = 1717076858716, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@44713e1e)
2024-05-30 15:47:40 2024-05-30 13:47:40,367 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,367 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(aisdata-0), toForget=(), toReplace=(), implied=(), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:40 2024-05-30 13:47:40,367 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 10000
2024-05-30 15:47:40 2024-05-30 13:47:40,367 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 265285000.0, "lon": 10.851297, "lat": 57.46816, "speed": 16.5, "course": 248.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,367 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 265285000.0, "lon": 10.851297, "lat": 57.46816, "speed": 16.5, "course": 248.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,367 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=5) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=1, topics=[FetchTopic(topic='aisdata', topicId=ZiGIwhiYS8-umhWEVwc-NQ, partitions=[FetchPartition(partition=0, currentLeaderEpoch=0, fetchOffset=2000, lastFetchedEpoch=-1, logStartOffset=-1, partitionMaxBytes=1048576)])], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9998
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 511, CreateTime = 1717076858716, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d8e108e)
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 211211290.0, "lon": 10.036162, "lat": 54.778062, "speed": 11.6, "course": 329.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 211211290.0, "lon": 10.036162, "lat": 54.778062, "speed": 11.6, "course": 329.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 512, CreateTime = 1717076858716, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4ae67c2e)
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219167000.0, "lon": 5.053453, "lat": 55.398928, "speed": 0.4, "course": 353.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219167000.0, "lon": 5.053453, "lat": 55.398928, "speed": 0.4, "course": 353.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 513, CreateTime = 1717076858716, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4d2b9be3)
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 266239000.0, "lon": 12.012423, "lat": 54.366862, "speed": 13.6, "course": 51.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 266239000.0, "lon": 12.012423, "lat": 54.366862, "speed": 13.6, "course": 51.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 514, CreateTime = 1717076858716, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@e7cd96)
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 2190051.0, "lon": 11.98851, "lat": 55.05217, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,368 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 2190051.0, "lon": 11.98851, "lat": 55.05217, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 515, CreateTime = 1717076858716, serialized key size = -1, serialized value size = 110, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1d70b764)
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 233199000.0, "lon": 10.992513, "lat": 54.970017, "speed": 11.1, "course": 44.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 233199000.0, "lon": 10.992513, "lat": 54.970017, "speed": 11.1, "course": 44.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 516, CreateTime = 1717076858717, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@640ebfe8)
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219000373.0, "lon": 10.537667, "lat": 56.077533, "speed": 17.1, "course": 315.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219000373.0, "lon": 10.537667, "lat": 56.077533, "speed": 17.1, "course": 315.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 517, CreateTime = 1717076858717, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@756bc409)
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219001872.0, "lon": 10.590473, "lat": 57.718585, "speed": 0.0, "course": 325.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219001872.0, "lon": 10.590473, "lat": 57.718585, "speed": 0.0, "course": 325.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 518, CreateTime = 1717076858717, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4b5e2c4f)
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 258407000.0, "lon": 12.688642, "lat": 55.703185, "speed": 10.4, "course": 359.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 258407000.0, "lon": 12.688642, "lat": 55.703185, "speed": 10.4, "course": 359.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 519, CreateTime = 1717076858717, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@530d79d7)
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 377262000.0, "lon": 11.406165, "lat": 54.086833, "speed": 9.5, "course": 2.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 377262000.0, "lon": 11.406165, "lat": 54.086833, "speed": 9.5, "course": 2.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 520, CreateTime = 1717076858721, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@42ed6da1)
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 220273000.0, "lon": 10.925038, "lat": 56.409202, "speed": 0.0, "course": 356.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 220273000.0, "lon": 10.925038, "lat": 56.409202, "speed": 0.0, "course": 356.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 521, CreateTime = 1717076858721, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@690db279)
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 213720000.0, "lon": 14.241933, "lat": 55.166383, "speed": 8.0, "course": 92.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 213720000.0, "lon": 14.241933, "lat": 55.166383, "speed": 8.0, "course": 92.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 522, CreateTime = 1717076858721, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@538bd743)
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 265504570.0, "lon": 11.871233, "lat": 57.683158, "speed": 0.0, "course": 279.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 265504570.0, "lon": 11.871233, "lat": 57.683158, "speed": 0.0, "course": 279.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 523, CreateTime = 1717076858721, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6bf0cf24)
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 265550210.0, "lon": 11.76243, "lat": 57.61833, "speed": 0.0, "course": 170.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 265550210.0, "lon": 11.76243, "lat": 57.61833, "speed": 0.0, "course": 170.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 524, CreateTime = 1717076858721, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@42d9279e)
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 261449000.0, "lon": 13.991017, "lat": 54.808083, "speed": 10.5, "course": 351.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 261449000.0, "lon": 13.991017, "lat": 54.808083, "speed": 10.5, "course": 351.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 525, CreateTime = 1717076858721, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4643dbc6)
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 211462760.0, "lon": 9.819418, "lat": 54.36269, "speed": 0.1, "course": 198.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 211462760.0, "lon": 9.819418, "lat": 54.36269, "speed": 0.1, "course": 198.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 526, CreateTime = 1717076858722, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4bff3d82)
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219203000.0, "lon": 8.443833, "lat": 55.464, "speed": 0.0, "course": 323.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219203000.0, "lon": 8.443833, "lat": 55.464, "speed": 0.0, "course": 323.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 527, CreateTime = 1717076858722, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@269b5236)
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 246043000.0, "lon": 11.909933, "lat": 56.709733, "speed": 14.6, "course": 168.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 246043000.0, "lon": 11.909933, "lat": 56.709733, "speed": 14.6, "course": 168.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 528, CreateTime = 1717076858724, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2d7574ac)
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 211291160.0, "lon": 8.80775, "lat": 54.497317, "speed": 0.0, "course": 173.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 211291160.0, "lon": 8.80775, "lat": 54.497317, "speed": 0.0, "course": 173.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 529, CreateTime = 1717076858724, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7530172f)
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219014146.0, "lon": 11.258932, "lat": 54.560372, "speed": 7.1, "course": 116.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219014146.0, "lon": 11.258932, "lat": 54.560372, "speed": 7.1, "course": 116.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 530, CreateTime = 1717076858725, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@47912726)
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219438000.0, "lon": 4.910442, "lat": 56.482188, "speed": 0.1, "course": 326.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219438000.0, "lon": 4.910442, "lat": 56.482188, "speed": 0.1, "course": 326.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 531, CreateTime = 1717076858725, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3be7d700)
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 2190075.0, "lon": 10.614558, "lat": 55.02709, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 2190075.0, "lon": 10.614558, "lat": 55.02709, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 532, CreateTime = 1717076858725, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3d3104c4)
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 266321000.0, "lon": 11.899092, "lat": 57.691707, "speed": 0.1, "course": 273.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 266321000.0, "lon": 11.899092, "lat": 57.691707, "speed": 0.1, "course": 273.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 533, CreateTime = 1717076858726, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@484df522)
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 265276000.0, "lon": 14.853243, "lat": 54.483853, "speed": 10.6, "course": 303.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 265276000.0, "lon": 14.853243, "lat": 54.483853, "speed": 10.6, "course": 303.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 534, CreateTime = 1717076858726, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6ab431a)
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 220451000.0, "lon": 14.83712, "lat": 55.248087, "speed": 0.1, "course": 272.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 220451000.0, "lon": 14.83712, "lat": 55.248087, "speed": 0.1, "course": 272.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 535, CreateTime = 1717076858726, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@371cb18)
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 258714000.0, "lon": 12.027933, "lat": 54.432447, "speed": 10.6, "course": 271.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 258714000.0, "lon": 12.027933, "lat": 54.432447, "speed": 10.6, "course": 271.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 536, CreateTime = 1717076858726, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3653e896)
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 376481000.0, "lon": 15.520773, "lat": 55.665355, "speed": 7.5, "course": 56.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 376481000.0, "lon": 15.520773, "lat": 55.665355, "speed": 7.5, "course": 56.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 537, CreateTime = 1717076858726, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1190ff9b)
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 249327000.0, "lon": 13.663657, "lat": 54.838772, "speed": 10.7, "course": 77.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 249327000.0, "lon": 13.663657, "lat": 54.838772, "speed": 10.7, "course": 77.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 538, CreateTime = 1717076858727, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4d7fcd20)
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219003141.0, "lon": 11.799492, "lat": 55.755018, "speed": 0.1, "course": 12.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219003141.0, "lon": 11.799492, "lat": 55.755018, "speed": 0.1, "course": 12.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 539, CreateTime = 1717076858727, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@405bf69c)
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 265609960.0, "lon": 11.796252, "lat": 57.60562, "speed": 0.0, "course": 332.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 265609960.0, "lon": 11.796252, "lat": 57.60562, "speed": 0.0, "course": 332.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 540, CreateTime = 1717076858727, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6965a159)
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219106000.0, "lon": 10.507092, "lat": 57.49234, "speed": 0.0, "course": 351.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219106000.0, "lon": 10.507092, "lat": 57.49234, "speed": 0.0, "course": 351.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 541, CreateTime = 1717076858727, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7f1ff7c9)
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219002826.0, "lon": 11.928753, "lat": 54.571808, "speed": 0.0, "course": 278.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219002826.0, "lon": 11.928753, "lat": 54.571808, "speed": 0.0, "course": 278.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 542, CreateTime = 1717076858728, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4c3a33c7)
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 257723000.0, "lon": 7.109252, "lat": 55.510013, "speed": 13.9, "course": 281.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 257723000.0, "lon": 7.109252, "lat": 55.510013, "speed": 13.9, "course": 281.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 543, CreateTime = 1717076858728, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@53cad3ca)
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219001359.0, "lon": 10.671017, "lat": 56.14896, "speed": 0.1, "course": 182.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219001359.0, "lon": 10.671017, "lat": 56.14896, "speed": 0.1, "course": 182.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 544, CreateTime = 1717076858728, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1761cf83)
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219777000.0, "lon": 10.522413, "lat": 54.851957, "speed": 0.0, "course": 15.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219777000.0, "lon": 10.522413, "lat": 54.851957, "speed": 0.0, "course": 15.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 545, CreateTime = 1717076858728, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@17c0d319)
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219011248.0, "lon": 10.355742, "lat": 56.967592, "speed": 1.6, "course": 164.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219011248.0, "lon": 10.355742, "lat": 56.967592, "speed": 1.6, "course": 164.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 546, CreateTime = 1717076858728, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@a797e2d)
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 257689000.0, "lon": 12.236188, "lat": 54.456857, "speed": 14.8, "course": 29.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 257689000.0, "lon": 12.236188, "lat": 54.456857, "speed": 14.8, "course": 29.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 547, CreateTime = 1717076858729, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@fa8a82b)
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 210100000.0, "lon": 4.4162, "lat": 56.197248, "speed": 9.1, "course": 3.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 210100000.0, "lon": 4.4162, "lat": 56.197248, "speed": 9.1, "course": 3.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 548, CreateTime = 1717076858729, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@16ac738a)
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219001619.0, "lon": 9.543142, "lat": 55.706565, "speed": 0.0, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219001619.0, "lon": 9.543142, "lat": 55.706565, "speed": 0.0, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 549, CreateTime = 1717076858730, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7e5225d)
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 992191504.0, "lon": 5.105748, "lat": 55.478232, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 992191504.0, "lon": 5.105748, "lat": 55.478232, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 550, CreateTime = 1717076858730, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@46acac9a)
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219001543.0, "lon": 10.215802, "lat": 56.152643, "speed": 0.0, "course": 113.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219001543.0, "lon": 10.215802, "lat": 56.152643, "speed": 0.0, "course": 113.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 551, CreateTime = 1717076858730, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@c8fbd94)
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219157000.0, "lon": 15.115067, "lat": 55.679767, "speed": 11.4, "course": 57.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219157000.0, "lon": 15.115067, "lat": 55.679767, "speed": 11.4, "course": 57.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 552, CreateTime = 1717076858730, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@794abfac)
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 265527020.0, "lon": 12.722267, "lat": 55.903445, "speed": 0.0, "course": 321.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 265527020.0, "lon": 12.722267, "lat": 55.903445, "speed": 0.0, "course": 321.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 553, CreateTime = 1717076858730, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@57138d12)
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 265594380.0, "lon": 12.707102, "lat": 55.406967, "speed": 6.3, "course": 8.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 265594380.0, "lon": 12.707102, "lat": 55.406967, "speed": 6.3, "course": 8.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 554, CreateTime = 1717076858730, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@74f82316)
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219678000.0, "lon": 8.445875, "lat": 55.463177, "speed": 0.0, "course": 292.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219678000.0, "lon": 8.445875, "lat": 55.463177, "speed": 0.0, "course": 292.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 555, CreateTime = 1717076858730, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@56a4300)
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 220329000.0, "lon": 10.58285, "lat": 57.715267, "speed": 0.0, "course": 333.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 220329000.0, "lon": 10.58285, "lat": 57.715267, "speed": 0.0, "course": 333.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 556, CreateTime = 1717076858730, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@29f12bde)
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 310602000.0, "lon": 11.627618, "lat": 57.550335, "speed": 0.0, "course": 157.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 310602000.0, "lon": 11.627618, "lat": 57.550335, "speed": 0.0, "course": 157.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 557, CreateTime = 1717076858731, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@62c148ef)
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 259269000.0, "lon": 8.596622, "lat": 57.12208, "speed": 0.1, "course": 164.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 259269000.0, "lon": 8.596622, "lat": 57.12208, "speed": 0.1, "course": 164.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 558, CreateTime = 1717076858732, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@57143732)
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 265846000.0, "lon": 10.59827, "lat": 57.71797, "speed": 0.0, "course": 2.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 265846000.0, "lon": 10.59827, "lat": 57.71797, "speed": 0.0, "course": 2.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 559, CreateTime = 1717076858732, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@310c93)
2024-05-30 15:47:40 2024-05-30 13:47:40,373 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 248743000.0, "lon": 11.879868, "lat": 54.372725, "speed": 9.0, "course": 335.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 248743000.0, "lon": 11.879868, "lat": 54.372725, "speed": 9.0, "course": 335.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 560, CreateTime = 1717076858732, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@203e7890)
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219079000.0, "lon": 7.826998, "lat": 55.488803, "speed": 0.1, "course": 203.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219079000.0, "lon": 7.826998, "lat": 55.488803, "speed": 0.1, "course": 203.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 561, CreateTime = 1717076858732, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@48d0da48)
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219945000.0, "lon": 11.314502, "lat": 57.711672, "speed": 17.2, "course": 155.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219945000.0, "lon": 11.314502, "lat": 57.711672, "speed": 17.2, "course": 155.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 562, CreateTime = 1717076858732, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3e8bc9c7)
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 265581970.0, "lon": 10.780103, "lat": 57.674297, "speed": 0.0, "course": 117.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 265581970.0, "lon": 10.780103, "lat": 57.674297, "speed": 0.0, "course": 117.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 563, CreateTime = 1717076858732, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@36560f11)
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219000141.0, "lon": 12.427318, "lat": 55.097643, "speed": 0.6, "course": 322.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219000141.0, "lon": 12.427318, "lat": 55.097643, "speed": 0.6, "course": 322.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 564, CreateTime = 1717076858733, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@65ff1bb3)
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 212360000.0, "lon": 15.525433, "lat": 55.75405, "speed": 10.9, "course": 238.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 212360000.0, "lon": 15.525433, "lat": 55.75405, "speed": 10.9, "course": 238.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 565, CreateTime = 1717076858733, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2bb39fde)
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219702000.0, "lon": 10.666972, "lat": 56.155213, "speed": 0.1, "course": 182.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219702000.0, "lon": 10.666972, "lat": 56.155213, "speed": 0.1, "course": 182.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 566, CreateTime = 1717076858733, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4b16be9e)
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219321000.0, "lon": 4.898767, "lat": 56.467333, "speed": 0.6, "course": 48.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219321000.0, "lon": 4.898767, "lat": 56.467333, "speed": 0.6, "course": 48.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 567, CreateTime = 1717076858733, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4d3e0e6a)
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 2190072.0, "lon": 9.963737, "lat": 57.523683, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 2190072.0, "lon": 9.963737, "lat": 57.523683, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 568, CreateTime = 1717076858733, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5001b6fd)
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 277334000.0, "lon": 13.975108, "lat": 54.668552, "speed": 13.3, "course": 278.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 277334000.0, "lon": 13.975108, "lat": 54.668552, "speed": 13.3, "course": 278.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 569, CreateTime = 1717076858733, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@677b8e4c)
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 215822000.0, "lon": 8.069165, "lat": 55.427408, "speed": 11.7, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 215822000.0, "lon": 8.069165, "lat": 55.427408, "speed": 11.7, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 570, CreateTime = 1717076858733, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@19e73e73)
2024-05-30 15:47:40 2024-05-30 13:47:40,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:05", "mmsi": 219001749.0, "lon": 11.34817, "lat": 54.656495, "speed": 0.0, "course": 107.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:05", "mmsi": 219001749.0, "lon": 11.34817, "lat": 54.656495, "speed": 0.0, "course": 107.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 571, CreateTime = 1717076858734, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@24973e7b)
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219001111.0, "lon": 10.59248, "lat": 57.718672, "speed": 0.0, "course": 86.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219001111.0, "lon": 10.59248, "lat": 57.718672, "speed": 0.0, "course": 86.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 572, CreateTime = 1717076858735, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@79fcc24a)
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219653000.0, "lon": 14.693713, "lat": 55.098532, "speed": 0.0, "course": 260.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219653000.0, "lon": 14.693713, "lat": 55.098532, "speed": 0.0, "course": 260.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 573, CreateTime = 1717076858735, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@42ce2ad7)
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 236451000.0, "lon": 15.170333, "lat": 55.636667, "speed": 12.7, "course": 240.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 236451000.0, "lon": 15.170333, "lat": 55.636667, "speed": 12.7, "course": 240.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 574, CreateTime = 1717076858735, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@627a905b)
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 230964000.0, "lon": 15.791357, "lat": 55.734298, "speed": 14.0, "course": 62.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 230964000.0, "lon": 15.791357, "lat": 55.734298, "speed": 14.0, "course": 62.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 575, CreateTime = 1717076858735, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7f030e89)
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219001849.0, "lon": 10.593853, "lat": 57.719835, "speed": 0.0, "course": 162.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219001849.0, "lon": 10.593853, "lat": 57.719835, "speed": 0.0, "course": 162.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 576, CreateTime = 1717076858735, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@60726db1)
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 265513230.0, "lon": 12.489082, "lat": 56.891918, "speed": 0.0, "course": 80.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 265513230.0, "lon": 12.489082, "lat": 56.891918, "speed": 0.0, "course": 80.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 577, CreateTime = 1717076858735, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@53d96bfa)
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 992191016.0, "lon": 11.046728, "lat": 55.324792, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 992191016.0, "lon": 11.046728, "lat": 55.324792, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 578, CreateTime = 1717076858735, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6517d192)
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 245921000.0, "lon": 11.78334, "lat": 57.277662, "speed": 11.9, "course": 313.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 245921000.0, "lon": 11.78334, "lat": 57.277662, "speed": 11.9, "course": 313.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 579, CreateTime = 1717076858736, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@287ecff)
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 231812000.0, "lon": 10.6012, "lat": 57.719533, "speed": 0.1, "course": 303.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 231812000.0, "lon": 10.6012, "lat": 57.719533, "speed": 0.1, "course": 303.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 580, CreateTime = 1717076858736, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@716b06fb)
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219001514.0, "lon": 11.861947, "lat": 54.770127, "speed": 0.0, "course": 327.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219001514.0, "lon": 11.861947, "lat": 54.770127, "speed": 0.0, "course": 327.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 581, CreateTime = 1717076858736, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@69753597)
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 220253000.0, "lon": 11.346373, "lat": 57.670033, "speed": 20.7, "course": 292.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 220253000.0, "lon": 11.346373, "lat": 57.670033, "speed": 20.7, "course": 292.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 582, CreateTime = 1717076858736, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3235f26a)
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 636091854.0, "lon": 12.309668, "lat": 54.647355, "speed": 16.8, "course": 225.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 636091854.0, "lon": 12.309668, "lat": 54.647355, "speed": 16.8, "course": 225.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 583, CreateTime = 1717076858736, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@f6800c7)
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 211188000.0, "lon": 11.241517, "lat": 54.517627, "speed": 14.6, "course": 24.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 211188000.0, "lon": 11.241517, "lat": 54.517627, "speed": 14.6, "course": 24.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 584, CreateTime = 1717076858736, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@261d930f)
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 265548670.0, "lon": 11.796293, "lat": 57.605707, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 265548670.0, "lon": 11.796293, "lat": 57.605707, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 585, CreateTime = 1717076858736, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6684d3d6)
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 261201000.0, "lon": 11.540917, "lat": 54.174973, "speed": 8.6, "course": 21.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 261201000.0, "lon": 11.540917, "lat": 54.174973, "speed": 8.6, "course": 21.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 586, CreateTime = 1717076858736, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7bbfcbce)
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 273313900.0, "lon": 12.350517, "lat": 54.654462, "speed": 8.6, "course": 237.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 273313900.0, "lon": 12.350517, "lat": 54.654462, "speed": 8.6, "course": 237.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 587, CreateTime = 1717076858737, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@341e9246)
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 258606000.0, "lon": 10.72734, "lat": 57.36785, "speed": 14.1, "course": 5.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 258606000.0, "lon": 10.72734, "lat": 57.36785, "speed": 14.1, "course": 5.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 588, CreateTime = 1717076858737, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7ed1ea21)
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 636014191.0, "lon": 14.115367, "lat": 55.095917, "speed": 14.1, "course": 219.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 636014191.0, "lon": 14.115367, "lat": 55.095917, "speed": 14.1, "course": 219.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 589, CreateTime = 1717076858737, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3e0b8c4e)
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 244806000.0, "lon": 7.284342, "lat": 55.591578, "speed": 4.3, "course": 312.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 244806000.0, "lon": 7.284342, "lat": 55.591578, "speed": 4.3, "course": 312.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 590, CreateTime = 1717076858737, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3b6fd1fa)
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 207083000.0, "lon": 15.343085, "lat": 55.689082, "speed": 12.5, "course": 244.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 207083000.0, "lon": 15.343085, "lat": 55.689082, "speed": 12.5, "course": 244.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 591, CreateTime = 1717076858737, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7ba3e873)
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 220432000.0, "lon": 11.13, "lat": 55.331177, "speed": 0.0, "course": 70.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 220432000.0, "lon": 11.13, "lat": 55.331177, "speed": 0.0, "course": 70.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 592, CreateTime = 1717076858737, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@a5295c4)
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 249605000.0, "lon": 10.85416, "lat": 54.73713, "speed": 13.9, "course": 179.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 249605000.0, "lon": 10.85416, "lat": 54.73713, "speed": 13.9, "course": 179.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 593, CreateTime = 1717076858737, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6859113c)
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 538090391.0, "lon": 12.248638, "lat": 54.565358, "speed": 13.2, "course": 198.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 538090391.0, "lon": 12.248638, "lat": 54.565358, "speed": 13.2, "course": 198.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 594, CreateTime = 1717076858737, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2d7cedcc)
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 277334000.0, "lon": 13.975108, "lat": 54.668552, "speed": 13.3, "course": 278.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 277334000.0, "lon": 13.975108, "lat": 54.668552, "speed": 13.3, "course": 278.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 595, CreateTime = 1717076858737, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@49787860)
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219380002.0, "lon": 9.89552, "lat": 57.024898, "speed": 0.0, "course": 330.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219380002.0, "lon": 9.89552, "lat": 57.024898, "speed": 0.0, "course": 330.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 596, CreateTime = 1717076858737, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@579a283e)
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 211265530.0, "lon": 14.959167, "lat": 55.474, "speed": 15.0, "course": 59.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 211265530.0, "lon": 14.959167, "lat": 55.474, "speed": 15.0, "course": 59.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 597, CreateTime = 1717076858737, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@776a1300)
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 218413000.0, "lon": 12.091215, "lat": 54.17099, "speed": 0.0, "course": 287.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 218413000.0, "lon": 12.091215, "lat": 54.17099, "speed": 0.0, "course": 287.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 598, CreateTime = 1717076858737, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3db292ac)
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219012073.0, "lon": 9.8659, "lat": 55.858002, "speed": 0.0, "course": 336.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219012073.0, "lon": 9.8659, "lat": 55.858002, "speed": 0.0, "course": 336.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 599, CreateTime = 1717076858737, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@37035602)
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 211209290.0, "lon": 9.933, "lat": 54.629048, "speed": 0.1, "course": 303.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 211209290.0, "lon": 9.933, "lat": 54.629048, "speed": 0.1, "course": 303.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 600, CreateTime = 1717076858737, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@31de5304)
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219005878.0, "lon": 10.585748, "lat": 57.715897, "speed": 0.1, "course": 335.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219005878.0, "lon": 10.585748, "lat": 57.715897, "speed": 0.1, "course": 335.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 601, CreateTime = 1717076858737, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@168bb42c)
2024-05-30 15:47:40 2024-05-30 13:47:40,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 636014480.0, "lon": 11.009567, "lat": 55.966133, "speed": 12.9, "course": 214.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 636014480.0, "lon": 11.009567, "lat": 55.966133, "speed": 12.9, "course": 214.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 602, CreateTime = 1717076858737, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3f0573a3)
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 236501000.0, "lon": 14.339452, "lat": 55.156097, "speed": 13.2, "course": 38.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 236501000.0, "lon": 14.339452, "lat": 55.156097, "speed": 13.2, "course": 38.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 603, CreateTime = 1717076858738, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@129b8107)
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219007225.0, "lon": 10.308492, "lat": 56.990233, "speed": 0.0, "course": 341.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219007225.0, "lon": 10.308492, "lat": 56.990233, "speed": 0.0, "course": 341.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 604, CreateTime = 1717076858738, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@511eb623)
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 377411000.0, "lon": 14.376167, "lat": 55.270333, "speed": 11.0, "course": 218.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 377411000.0, "lon": 14.376167, "lat": 55.270333, "speed": 11.0, "course": 218.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 605, CreateTime = 1717076858738, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1aff52f8)
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219015063.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219015063.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 606, CreateTime = 1717076858738, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@e73a26f)
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219023000.0, "lon": 10.910715, "lat": 54.9208, "speed": 10.3, "course": 40.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219023000.0, "lon": 10.910715, "lat": 54.9208, "speed": 10.3, "course": 40.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 607, CreateTime = 1717076858738, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@402e891f)
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 246667000.0, "lon": 13.333863, "lat": 55.012145, "speed": 7.1, "course": 258.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 246667000.0, "lon": 13.333863, "lat": 55.012145, "speed": 7.1, "course": 258.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 608, CreateTime = 1717076858738, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@64a59097)
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 220476000.0, "lon": 10.546715, "lat": 57.441058, "speed": 0.0, "course": 327.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 220476000.0, "lon": 10.546715, "lat": 57.441058, "speed": 0.0, "course": 327.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 609, CreateTime = 1717076858738, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@42d7669)
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219799000.0, "lon": 12.309987, "lat": 56.127705, "speed": 0.0, "course": 338.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219799000.0, "lon": 12.309987, "lat": 56.127705, "speed": 0.0, "course": 338.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 610, CreateTime = 1717076858738, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@17decc59)
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219002415.0, "lon": 8.22216, "lat": 56.704695, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219002415.0, "lon": 8.22216, "lat": 56.704695, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 611, CreateTime = 1717076858738, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@230cc9cc)
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 331209000.0, "lon": 9.887463, "lat": 55.270017, "speed": 0.0, "course": 331.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,378 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 331209000.0, "lon": 9.887463, "lat": 55.270017, "speed": 0.0, "course": 331.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 612, CreateTime = 1717076858738, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6be5c412)
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 265610940.0, "lon": 12.687892, "lat": 56.0448, "speed": 0.0, "course": 8.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 265610940.0, "lon": 12.687892, "lat": 56.0448, "speed": 0.0, "course": 8.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 613, CreateTime = 1717076858738, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4147939)
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219001549.0, "lon": 10.587087, "lat": 57.718277, "speed": 0.0, "course": 3.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219001549.0, "lon": 10.587087, "lat": 57.718277, "speed": 0.0, "course": 3.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 614, CreateTime = 1717076858738, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@65c9d1e6)
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 256189000.0, "lon": 10.389907, "lat": 57.794495, "speed": 10.0, "course": 247.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 256189000.0, "lon": 10.389907, "lat": 57.794495, "speed": 10.0, "course": 247.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 615, CreateTime = 1717076858738, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@20ce263a)
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 231201000.0, "lon": 10.060215, "lat": 57.764947, "speed": 15.7, "course": 13.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 231201000.0, "lon": 10.060215, "lat": 57.764947, "speed": 15.7, "course": 13.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 616, CreateTime = 1717076858738, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@65cea365)
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 308874000.0, "lon": 12.466765, "lat": 54.705658, "speed": 9.9, "course": 236.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 308874000.0, "lon": 12.466765, "lat": 54.705658, "speed": 9.9, "course": 236.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 617, CreateTime = 1717076858738, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4234c354)
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 266041000.0, "lon": 11.607, "lat": 54.252667, "speed": 18.5, "course": 61.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 266041000.0, "lon": 11.607, "lat": 54.252667, "speed": 18.5, "course": 61.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 618, CreateTime = 1717076858739, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@69d96c15)
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219000321.0, "lon": 12.347562, "lat": 54.760937, "speed": 8.8, "course": 219.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219000321.0, "lon": 12.347562, "lat": 54.760937, "speed": 8.8, "course": 219.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 619, CreateTime = 1717076858739, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@38f778e2)
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 265276000.0, "lon": 14.853243, "lat": 54.483853, "speed": 10.6, "course": 303.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 265276000.0, "lon": 14.853243, "lat": 54.483853, "speed": 10.6, "course": 303.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 620, CreateTime = 1717076858739, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@28322112)
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 304010160.0, "lon": 12.009283, "lat": 55.958883, "speed": 2.3, "course": 38.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 304010160.0, "lon": 12.009283, "lat": 55.958883, "speed": 2.3, "course": 38.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 621, CreateTime = 1717076858739, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4cf86923)
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219013968.0, "lon": 11.35215, "lat": 54.651667, "speed": 0.0, "course": 134.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219013968.0, "lon": 11.35215, "lat": 54.651667, "speed": 0.0, "course": 134.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 622, CreateTime = 1717076858739, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6e630d6d)
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 265561990.0, "lon": 13.03454, "lat": 55.624623, "speed": 0.0, "course": 337.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,379 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 265561990.0, "lon": 13.03454, "lat": 55.624623, "speed": 0.0, "course": 337.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 623, CreateTime = 1717076858739, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6dd0482b)
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 311020200.0, "lon": 6.424013, "lat": 55.545498, "speed": 12.0, "course": 171.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 311020200.0, "lon": 6.424013, "lat": 55.545498, "speed": 12.0, "course": 171.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 624, CreateTime = 1717076858739, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5453ce32)
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 255803201.0, "lon": 12.69635, "lat": 56.025833, "speed": 0.0, "course": 164.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 255803201.0, "lon": 12.69635, "lat": 56.025833, "speed": 0.0, "course": 164.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 625, CreateTime = 1717076858739, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5bed14ea)
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 211215630.0, "lon": 12.12956, "lat": 54.156082, "speed": 0.0, "course": 148.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 211215630.0, "lon": 12.12956, "lat": 54.156082, "speed": 0.0, "course": 148.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 626, CreateTime = 1717076858739, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2d13629f)
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 220619000.0, "lon": 10.549023, "lat": 55.864673, "speed": 0.0, "course": 51.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 220619000.0, "lon": 10.549023, "lat": 55.864673, "speed": 0.0, "course": 51.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 627, CreateTime = 1717076858739, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@426de606)
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 212172000.0, "lon": 7.0429, "lat": 56.422817, "speed": 15.0, "course": 36.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 212172000.0, "lon": 7.0429, "lat": 56.422817, "speed": 15.0, "course": 36.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 628, CreateTime = 1717076858739, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@8058227)
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219001842.0, "lon": 8.222173, "lat": 56.701778, "speed": 0.0, "course": 243.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219001842.0, "lon": 8.222173, "lat": 56.701778, "speed": 0.0, "course": 243.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 629, CreateTime = 1717076858739, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3bfc9d89)
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219011922.0, "lon": 13.251597, "lat": 54.764758, "speed": 10.4, "course": 90.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219011922.0, "lon": 13.251597, "lat": 54.764758, "speed": 10.4, "course": 90.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 630, CreateTime = 1717076858739, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@d4d07f3)
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 249434000.0, "lon": 13.24195, "lat": 54.902683, "speed": 13.5, "course": 247.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 249434000.0, "lon": 13.24195, "lat": 54.902683, "speed": 13.5, "course": 247.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 631, CreateTime = 1717076858739, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@20bd9d8a)
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 240198000.0, "lon": 11.135583, "lat": 57.63025, "speed": 14.7, "course": 313.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 240198000.0, "lon": 11.135583, "lat": 57.63025, "speed": 14.7, "course": 313.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 632, CreateTime = 1717076858739, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@40d3700)
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219014579.0, "lon": 8.61421, "lat": 56.517163, "speed": 0.0, "course": 298.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219014579.0, "lon": 8.61421, "lat": 56.517163, "speed": 0.0, "course": 298.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 633, CreateTime = 1717076858739, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5bc2e2dd)
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 257462000.0, "lon": 10.028252, "lat": 57.681982, "speed": 12.9, "course": 245.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 257462000.0, "lon": 10.028252, "lat": 57.681982, "speed": 12.9, "course": 245.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 634, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3e5504c9)
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219014165.0, "lon": 10.540688, "lat": 57.437962, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,380 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219014165.0, "lon": 10.540688, "lat": 57.437962, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 635, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@72c88f44)
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219000577.0, "lon": 10.52888, "lat": 55.796272, "speed": 0.0, "course": 145.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219000577.0, "lon": 10.52888, "lat": 55.796272, "speed": 0.0, "course": 145.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 636, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1f90032a)
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219000604.0, "lon": 8.44195, "lat": 55.4616, "speed": 0.0, "course": 193.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219000604.0, "lon": 8.44195, "lat": 55.4616, "speed": 0.0, "course": 193.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 637, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5308ce0f)
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219001461.0, "lon": 13.024667, "lat": 55.636967, "speed": 0.0, "course": 356.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219001461.0, "lon": 13.024667, "lat": 55.636967, "speed": 0.0, "course": 356.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 638, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@456debeb)
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219007333.0, "lon": 14.93125, "lat": 54.700317, "speed": 0.9, "course": 287.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219007333.0, "lon": 14.93125, "lat": 54.700317, "speed": 0.9, "course": 287.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 639, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@73e9eead)
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 265859000.0, "lon": 10.92761, "lat": 56.409172, "speed": 0.0, "course": 200.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 265859000.0, "lon": 10.92761, "lat": 56.409172, "speed": 0.0, "course": 200.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 640, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6c7f2aa9)
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 992191522.0, "lon": 4.80165, "lat": 55.721317, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 992191522.0, "lon": 4.80165, "lat": 55.721317, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 641, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7992f99f)
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 992191525.0, "lon": 4.882617, "lat": 55.639632, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 992191525.0, "lon": 4.882617, "lat": 55.639632, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 642, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@530a77f5)
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 236203000.0, "lon": 13.026222, "lat": 55.262232, "speed": 10.3, "course": 273.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 236203000.0, "lon": 13.026222, "lat": 55.262232, "speed": 10.3, "course": 273.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 643, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6f2a77bf)
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 230984000.0, "lon": 11.486087, "lat": 57.388667, "speed": 18.1, "course": 338.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 230984000.0, "lon": 11.486087, "lat": 57.388667, "speed": 18.1, "course": 338.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 644, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7a153291)
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 222222222.0, "lon": 9.893773, "lat": 57.024472, "speed": 0.1, "course": 258.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 222222222.0, "lon": 9.893773, "lat": 57.024472, "speed": 0.1, "course": 258.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 645, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@14a5624d)
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 265627630.0, "lon": 11.777997, "lat": 57.574383, "speed": 0.1, "course": 325.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,381 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 265627630.0, "lon": 11.777997, "lat": 57.574383, "speed": 0.1, "course": 325.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 646, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@14901af3)
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219001232.0, "lon": 11.924897, "lat": 54.573415, "speed": 0.0, "course": 135.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219001232.0, "lon": 11.924897, "lat": 54.573415, "speed": 0.0, "course": 135.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 647, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@283b0051)
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219011553.0, "lon": 9.753593, "lat": 55.559905, "speed": 0.0, "course": 4.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219011553.0, "lon": 9.753593, "lat": 55.559905, "speed": 0.0, "course": 4.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 648, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7b693e7d)
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 220339000.0, "lon": 15.135718, "lat": 55.061367, "speed": 0.0, "course": 185.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 220339000.0, "lon": 15.135718, "lat": 55.061367, "speed": 0.0, "course": 185.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 649, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@44619c57)
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 211106000.0, "lon": 8.601303, "lat": 57.123112, "speed": 0.0, "course": 311.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 211106000.0, "lon": 8.601303, "lat": 57.123112, "speed": 0.0, "course": 311.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 650, CreateTime = 1717076858740, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@50b251aa)
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219024000.0, "lon": 9.773933, "lat": 57.945485, "speed": 0.7, "course": 87.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219024000.0, "lon": 9.773933, "lat": 57.945485, "speed": 0.7, "course": 87.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 651, CreateTime = 1717076858741, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@207bfa65)
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219000751.0, "lon": 14.35506, "lat": 55.55774, "speed": 0.0, "course": 277.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219000751.0, "lon": 14.35506, "lat": 55.55774, "speed": 0.0, "course": 277.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 652, CreateTime = 1717076858741, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1253b2c1)
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 257496000.0, "lon": 9.210317, "lat": 57.860967, "speed": 14.0, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 257496000.0, "lon": 9.210317, "lat": 57.860967, "speed": 14.0, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 653, CreateTime = 1717076858741, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5a9807f8)
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 211462760.0, "lon": 9.819418, "lat": 54.36269, "speed": 0.1, "course": 189.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 211462760.0, "lon": 9.819418, "lat": 54.36269, "speed": 0.1, "course": 189.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 654, CreateTime = 1717076858741, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@18e52200)
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 230915000.0, "lon": 7.794267, "lat": 56.478017, "speed": 18.0, "course": 200.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,382 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 230915000.0, "lon": 7.794267, "lat": 56.478017, "speed": 18.0, "course": 200.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 655, CreateTime = 1717076858741, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@67b24bab)
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219002687.0, "lon": 11.928832, "lat": 54.571745, "speed": 0.0, "course": 182.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219002687.0, "lon": 11.928832, "lat": 54.571745, "speed": 0.0, "course": 182.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 656, CreateTime = 1717076858741, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@68783826)
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 265509710.0, "lon": 11.641258, "lat": 57.744065, "speed": 0.1, "course": 211.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 265509710.0, "lon": 11.641258, "lat": 57.744065, "speed": 0.1, "course": 211.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 657, CreateTime = 1717076858741, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@72c55516)
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219005496.0, "lon": 9.956562, "lat": 57.593435, "speed": 0.0, "course": 10.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219005496.0, "lon": 9.956562, "lat": 57.593435, "speed": 0.0, "course": 10.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 658, CreateTime = 1717076858741, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@43818c6c)
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219000345.0, "lon": 10.8247, "lat": 55.753017, "speed": 16.8, "course": 170.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219000345.0, "lon": 10.8247, "lat": 55.753017, "speed": 16.8, "course": 170.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 659, CreateTime = 1717076858741, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@369b68a4)
2024-05-30 15:47:40 2024-05-30 13:47:40,383 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 3638.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 3638.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 660, CreateTime = 1717076858741, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1f8bdf59)
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219000775.0, "lon": 8.220943, "lat": 56.701587, "speed": 0.0, "course": 141.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219000775.0, "lon": 8.220943, "lat": 56.701587, "speed": 0.0, "course": 141.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 661, CreateTime = 1717076858741, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@47be445b)
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219001976.0, "lon": 9.962463, "lat": 57.593252, "speed": 0.0, "course": 333.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219001976.0, "lon": 9.962463, "lat": 57.593252, "speed": 0.0, "course": 333.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 662, CreateTime = 1717076858741, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@893522c)
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219000896.0, "lon": 14.692272, "lat": 55.094207, "speed": 0.0, "course": 327.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219000896.0, "lon": 14.692272, "lat": 55.094207, "speed": 0.0, "course": 327.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 663, CreateTime = 1717076858741, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@65a0c5d2)
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 211202710.0, "lon": 11.077523, "lat": 54.354103, "speed": 0.1, "course": 188.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 211202710.0, "lon": 11.077523, "lat": 54.354103, "speed": 0.1, "course": 188.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 664, CreateTime = 1717076858741, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2410bf28)
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 219009135.0, "lon": 8.59915, "lat": 57.121663, "speed": 0.1, "course": 43.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 219009135.0, "lon": 8.59915, "lat": 57.121663, "speed": 0.1, "course": 43.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 665, CreateTime = 1717076858742, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@11b9bb6d)
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 265660390.0, "lon": 12.70787, "lat": 55.409022, "speed": 6.4, "course": 8.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 265660390.0, "lon": 12.70787, "lat": 55.409022, "speed": 6.4, "course": 8.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 666, CreateTime = 1717076858742, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3298944)
2024-05-30 15:47:40 2024-05-30 13:47:40,384 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,385 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 218083000.0, "lon": 9.43329, "lat": 54.795075, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,385 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 218083000.0, "lon": 9.43329, "lat": 54.795075, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,385 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 667, CreateTime = 1717076858742, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@604442a6)
2024-05-30 15:47:40 2024-05-30 13:47:40,385 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,385 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:06", "mmsi": 235059487.0, "lon": 11.058472, "lat": 56.008837, "speed": 12.6, "course": 214.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,385 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:06", "mmsi": 235059487.0, "lon": 11.058472, "lat": 56.008837, "speed": 12.6, "course": 214.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,385 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 668, CreateTime = 1717076858742, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@410c5879)
2024-05-30 15:47:40 2024-05-30 13:47:40,385 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,385 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 306013000.0, "lon": 8.479993, "lat": 57.648418, "speed": 3.9, "course": 24.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,385 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 306013000.0, "lon": 8.479993, "lat": 57.648418, "speed": 3.9, "course": 24.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 669, CreateTime = 1717076858742, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1db2f1e6)
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 256016000.0, "lon": 10.292133, "lat": 56.146117, "speed": 7.7, "course": 302.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 256016000.0, "lon": 10.292133, "lat": 56.146117, "speed": 7.7, "course": 302.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 670, CreateTime = 1717076858742, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@521e38bd)
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 230217000.0, "lon": 6.975323, "lat": 56.438287, "speed": 14.5, "course": 162.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 230217000.0, "lon": 6.975323, "lat": 56.438287, "speed": 14.5, "course": 162.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 671, CreateTime = 1717076858742, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@100d012a)
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219099000.0, "lon": 4.544328, "lat": 55.805213, "speed": 1.3, "course": 57.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219099000.0, "lon": 4.544328, "lat": 55.805213, "speed": 1.3, "course": 57.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 672, CreateTime = 1717076858742, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@33614cc2)
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219601000.0, "lon": 10.53781, "lat": 55.469842, "speed": 0.0, "course": 310.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219601000.0, "lon": 10.53781, "lat": 55.469842, "speed": 0.0, "course": 310.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 673, CreateTime = 1717076858742, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@39d6b689)
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 211225380.0, "lon": 11.190172, "lat": 54.42166, "speed": 0.1, "course": 269.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 211225380.0, "lon": 11.190172, "lat": 54.42166, "speed": 0.1, "course": 269.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 674, CreateTime = 1717076858742, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1a2eaade)
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 211910000.0, "lon": 8.2461, "lat": 57.05455, "speed": 23.3, "course": 40.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 211910000.0, "lon": 8.2461, "lat": 57.05455, "speed": 23.3, "course": 40.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 675, CreateTime = 1717076858742, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@62d2ece0)
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219005567.0, "lon": 10.302577, "lat": 56.60731, "speed": 0.0, "course": 55.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219005567.0, "lon": 10.302577, "lat": 56.60731, "speed": 0.0, "course": 55.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 676, CreateTime = 1717076858742, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5becbb24)
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 220042000.0, "lon": 8.593113, "lat": 57.119633, "speed": 0.0, "course": 19.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 220042000.0, "lon": 8.593113, "lat": 57.119633, "speed": 0.0, "course": 19.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 677, CreateTime = 1717076858742, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@57822c2e)
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 304588000.0, "lon": 12.700167, "lat": 55.971167, "speed": 13.3, "course": 336.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 304588000.0, "lon": 12.700167, "lat": 55.971167, "speed": 13.3, "course": 336.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 678, CreateTime = 1717076858742, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3815045a)
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 258069000.0, "lon": 4.23488, "lat": 56.41562, "speed": 11.8, "course": 196.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 258069000.0, "lon": 4.23488, "lat": 56.41562, "speed": 11.8, "course": 196.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 679, CreateTime = 1717076858742, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4d554a54)
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219743000.0, "lon": 9.668887, "lat": 57.836592, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219743000.0, "lon": 9.668887, "lat": 57.836592, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 680, CreateTime = 1717076858743, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@735eed41)
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219244000.0, "lon": 7.49918, "lat": 56.820092, "speed": 0.5, "course": 36.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219244000.0, "lon": 7.49918, "lat": 56.820092, "speed": 0.5, "course": 36.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 681, CreateTime = 1717076858743, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@35fb5c58)
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219006022.0, "lon": 9.177117, "lat": 57.738617, "speed": 0.2, "course": 9.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,386 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219006022.0, "lon": 9.177117, "lat": 57.738617, "speed": 0.2, "course": 9.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 682, CreateTime = 1717076858743, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@25dcb969)
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 211898000.0, "lon": 10.907002, "lat": 54.753118, "speed": 8.2, "course": 349.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 211898000.0, "lon": 10.907002, "lat": 54.753118, "speed": 8.2, "course": 349.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 683, CreateTime = 1717076858743, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@423c506c)
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 220315000.0, "lon": 8.123095, "lat": 56.004815, "speed": 0.1, "course": 326.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 220315000.0, "lon": 8.123095, "lat": 56.004815, "speed": 0.1, "course": 326.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 684, CreateTime = 1717076858743, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@468c998f)
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219000501.0, "lon": 10.082083, "lat": 55.104783, "speed": 0.0, "course": 9.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219000501.0, "lon": 10.082083, "lat": 55.104783, "speed": 0.0, "course": 9.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 685, CreateTime = 1717076858743, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@297a149a)
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 211202730.0, "lon": 10.217205, "lat": 54.403445, "speed": 0.1, "course": 186.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 211202730.0, "lon": 10.217205, "lat": 54.403445, "speed": 0.1, "course": 186.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 686, CreateTime = 1717076858743, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@69ade72d)
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219000771.0, "lon": 8.350013, "lat": 55.475232, "speed": 10.7, "course": 48.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219000771.0, "lon": 8.350013, "lat": 55.475232, "speed": 10.7, "course": 48.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 687, CreateTime = 1717076858743, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@49326544)
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 220378000.0, "lon": 12.3185, "lat": 55.434167, "speed": 15.9, "course": 130.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 220378000.0, "lon": 12.3185, "lat": 55.434167, "speed": 15.9, "course": 130.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 688, CreateTime = 1717076858743, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6b50cd0c)
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 236150000.0, "lon": 11.502357, "lat": 54.519332, "speed": 11.1, "course": 294.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 236150000.0, "lon": 11.502357, "lat": 54.519332, "speed": 11.1, "course": 294.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 689, CreateTime = 1717076858743, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@12f7da38)
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 999999999.0, "lon": 12.119143, "lat": 54.157427, "speed": 0.0, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 999999999.0, "lon": 12.119143, "lat": 54.157427, "speed": 0.0, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 690, CreateTime = 1717076858743, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1465c3c4)
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219000548.0, "lon": 9.33395, "lat": 57.839517, "speed": 6.1, "course": 89.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219000548.0, "lon": 9.33395, "lat": 57.839517, "speed": 6.1, "course": 89.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 691, CreateTime = 1717076858743, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4ea79c49)
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 265548350.0, "lon": 12.798833, "lat": 55.7991, "speed": 12.3, "course": 330.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 265548350.0, "lon": 12.798833, "lat": 55.7991, "speed": 12.3, "course": 330.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 692, CreateTime = 1717076858743, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2372103c)
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 220135000.0, "lon": 9.624255, "lat": 57.910393, "speed": 0.5, "course": 63.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 220135000.0, "lon": 9.624255, "lat": 57.910393, "speed": 0.5, "course": 63.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 693, CreateTime = 1717076858744, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@ff82870)
2024-05-30 15:47:40 2024-05-30 13:47:40,387 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219004128.0, "lon": 10.586217, "lat": 57.717625, "speed": 0.0, "course": 323.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219004128.0, "lon": 10.586217, "lat": 57.717625, "speed": 0.0, "course": 323.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 694, CreateTime = 1717076858744, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@35b9a1a8)
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219003452.0, "lon": 12.680212, "lat": 55.593135, "speed": 0.0, "course": 330.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219003452.0, "lon": 12.680212, "lat": 55.593135, "speed": 0.0, "course": 330.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 695, CreateTime = 1717076858744, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@470e2682)
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219002176.0, "lon": 9.753783, "lat": 55.560252, "speed": 0.0, "course": 9.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219002176.0, "lon": 9.753783, "lat": 55.560252, "speed": 0.0, "course": 9.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 696, CreateTime = 1717076858744, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@744e2daf)
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 370614000.0, "lon": 11.53335, "lat": 57.265967, "speed": 14.2, "course": 162.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 370614000.0, "lon": 11.53335, "lat": 57.265967, "speed": 14.2, "course": 162.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 697, CreateTime = 1717076858744, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3abb20fe)
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219005969.0, "lon": 10.589655, "lat": 57.718372, "speed": 0.0, "course": 328.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219005969.0, "lon": 10.589655, "lat": 57.718372, "speed": 0.0, "course": 328.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 698, CreateTime = 1717076858744, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@427762e0)
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 265410000.0, "lon": 11.605117, "lat": 57.607895, "speed": 17.3, "course": 252.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 265410000.0, "lon": 11.605117, "lat": 57.607895, "speed": 17.3, "course": 252.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 699, CreateTime = 1717076858744, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@747b761a)
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 211211200.0, "lon": 10.044488, "lat": 54.77139, "speed": 11.9, "course": 328.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 211211200.0, "lon": 10.044488, "lat": 54.77139, "speed": 11.9, "course": 328.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 700, CreateTime = 1717076858744, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@71dd1e6f)
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219011768.0, "lon": 7.348263, "lat": 55.252905, "speed": 10.2, "course": 251.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219011768.0, "lon": 7.348263, "lat": 55.252905, "speed": 10.2, "course": 251.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 701, CreateTime = 1717076858744, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@12027c7a)
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 211226940.0, "lon": 10.98469, "lat": 54.373398, "speed": 0.0, "course": 143.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 211226940.0, "lon": 10.98469, "lat": 54.373398, "speed": 0.0, "course": 143.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 702, CreateTime = 1717076858745, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6b1b7cb8)
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 312412000.0, "lon": 11.09868, "lat": 55.182378, "speed": 8.5, "course": 7.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 312412000.0, "lon": 11.09868, "lat": 55.182378, "speed": 8.5, "course": 7.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 703, CreateTime = 1717076858745, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@44ff1c67)
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 220193000.0, "lon": 12.595565, "lat": 55.706465, "speed": 0.0, "course": 331.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 220193000.0, "lon": 12.595565, "lat": 55.706465, "speed": 0.0, "course": 331.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 704, CreateTime = 1717076858745, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5d485cf1)
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219003966.0, "lon": 10.594147, "lat": 57.71992, "speed": 0.0, "course": 276.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219003966.0, "lon": 10.594147, "lat": 57.71992, "speed": 0.0, "course": 276.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 705, CreateTime = 1717076858745, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5ca80a8e)
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 265457000.0, "lon": 11.0251, "lat": 56.492233, "speed": 12.6, "course": 6.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 265457000.0, "lon": 11.0251, "lat": 56.492233, "speed": 12.6, "course": 6.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 706, CreateTime = 1717076858745, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6ce6531f)
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219124000.0, "lon": 6.917348, "lat": 56.473762, "speed": 13.3, "course": 214.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219124000.0, "lon": 6.917348, "lat": 56.473762, "speed": 13.3, "course": 214.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 707, CreateTime = 1717076858745, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@504666c0)
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 256587000.0, "lon": 8.930768, "lat": 57.416625, "speed": 14.2, "course": 51.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,388 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 256587000.0, "lon": 8.930768, "lat": 57.416625, "speed": 14.2, "course": 51.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 708, CreateTime = 1717076858745, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4f7607ed)
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 265186000.0, "lon": 13.569285, "lat": 54.775363, "speed": 15.2, "course": 156.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 265186000.0, "lon": 13.569285, "lat": 54.775363, "speed": 15.2, "course": 156.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 709, CreateTime = 1717076858745, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@531688f7)
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 257207000.0, "lon": 10.5525, "lat": 56.02225, "speed": 10.4, "course": 35.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 257207000.0, "lon": 10.5525, "lat": 56.02225, "speed": 10.4, "course": 35.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 710, CreateTime = 1717076858745, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@d364721)
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 218459000.0, "lon": 14.692542, "lat": 55.093412, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 218459000.0, "lon": 14.692542, "lat": 55.093412, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 711, CreateTime = 1717076858749, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6ea54021)
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 257689000.0, "lon": 12.2363, "lat": 54.456977, "speed": 14.8, "course": 28.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 257689000.0, "lon": 12.2363, "lat": 54.456977, "speed": 14.8, "course": 28.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 712, CreateTime = 1717076858749, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@11136b77)
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219002774.0, "lon": 9.959108, "lat": 57.594272, "speed": 0.0, "course": 323.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219002774.0, "lon": 9.959108, "lat": 57.594272, "speed": 0.0, "course": 323.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 713, CreateTime = 1717076858749, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@76251892)
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 211405020.0, "lon": 13.907792, "lat": 54.241385, "speed": 0.0, "course": 306.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 211405020.0, "lon": 13.907792, "lat": 54.241385, "speed": 0.0, "course": 306.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 714, CreateTime = 1717076858749, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@49154638)
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 992191514.0, "lon": 5.134467, "lat": 55.557232, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 992191514.0, "lon": 5.134467, "lat": 55.557232, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 715, CreateTime = 1717076858749, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@df5b373)
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 211263800.0, "lon": 12.08095, "lat": 54.171745, "speed": 0.6, "course": 188.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 211263800.0, "lon": 12.08095, "lat": 54.171745, "speed": 0.6, "course": 188.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 716, CreateTime = 1717076858749, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7b73969)
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219002317.0, "lon": 12.694427, "lat": 55.53726, "speed": 10.0, "course": 356.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219002317.0, "lon": 12.694427, "lat": 55.53726, "speed": 10.0, "course": 356.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 717, CreateTime = 1717076858750, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@59884085)
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219043000.0, "lon": 4.211982, "lat": 56.36979, "speed": 0.5, "course": 136.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219043000.0, "lon": 4.211982, "lat": 56.36979, "speed": 0.5, "course": 136.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 718, CreateTime = 1717076858750, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3acfe90a)
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 357562000.0, "lon": 8.28585, "lat": 57.25495, "speed": 16.3, "course": 58.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 357562000.0, "lon": 8.28585, "lat": 57.25495, "speed": 16.3, "course": 58.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 719, CreateTime = 1717076858750, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1a81ab0b)
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 220464000.0, "lon": 9.905145, "lat": 57.711083, "speed": 20.0, "course": 257.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 220464000.0, "lon": 9.905145, "lat": 57.711083, "speed": 20.0, "course": 257.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 720, CreateTime = 1717076858750, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@24c3a543)
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 477688000.0, "lon": 15.520185, "lat": 55.735532, "speed": 12.2, "course": 242.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 477688000.0, "lon": 15.520185, "lat": 55.735532, "speed": 12.2, "course": 242.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 721, CreateTime = 1717076858750, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3f544536)
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219000479.0, "lon": 11.962533, "lat": 54.472083, "speed": 15.2, "course": 346.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219000479.0, "lon": 11.962533, "lat": 54.472083, "speed": 15.2, "course": 346.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 722, CreateTime = 1717076858750, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7a967c6f)
2024-05-30 15:47:40 2024-05-30 13:47:40,389 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 311814000.0, "lon": 8.50682, "lat": 57.774287, "speed": 14.0, "course": 268.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 311814000.0, "lon": 8.50682, "lat": 57.774287, "speed": 14.0, "course": 268.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 723, CreateTime = 1717076858750, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d5859c5)
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 248811000.0, "lon": 10.800955, "lat": 55.730193, "speed": 16.3, "course": 9.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 248811000.0, "lon": 10.800955, "lat": 55.730193, "speed": 16.3, "course": 9.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 724, CreateTime = 1717076858750, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@54880090)
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 211245200.0, "lon": 12.744705, "lat": 55.013128, "speed": 12.1, "course": 215.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 211245200.0, "lon": 12.744705, "lat": 55.013128, "speed": 12.1, "course": 215.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 725, CreateTime = 1717076858750, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@496882c2)
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 266304000.0, "lon": 10.597188, "lat": 57.718652, "speed": 0.0, "course": 27.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 266304000.0, "lon": 10.597188, "lat": 57.718652, "speed": 0.0, "course": 27.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 726, CreateTime = 1717076858751, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@d4ea84)
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 265501910.0, "lon": 11.913333, "lat": 57.693527, "speed": 0.0, "course": 337.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 265501910.0, "lon": 11.913333, "lat": 57.693527, "speed": 0.0, "course": 337.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 727, CreateTime = 1717076858751, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2fed0d2a)
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 249622000.0, "lon": 11.66226, "lat": 54.208975, "speed": 9.8, "course": 72.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 249622000.0, "lon": 11.66226, "lat": 54.208975, "speed": 9.8, "course": 72.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 728, CreateTime = 1717076858751, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3b7514c7)
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219014012.0, "lon": 8.422017, "lat": 55.472597, "speed": 0.0, "course": 194.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219014012.0, "lon": 8.422017, "lat": 55.472597, "speed": 0.0, "course": 194.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 729, CreateTime = 1717076858751, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3686eff9)
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 258401000.0, "lon": 4.538005, "lat": 55.76335, "speed": 1.0, "course": 55.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 258401000.0, "lon": 4.538005, "lat": 55.76335, "speed": 1.0, "course": 55.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 730, CreateTime = 1717076858751, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@11a1a367)
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 257273000.0, "lon": 8.20596, "lat": 55.405543, "speed": 10.1, "course": 207.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 257273000.0, "lon": 8.20596, "lat": 55.405543, "speed": 10.1, "course": 207.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 731, CreateTime = 1717076858751, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@56e26824)
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 212390000.0, "lon": 13.02218, "lat": 55.62025, "speed": 0.0, "course": 353.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 212390000.0, "lon": 13.02218, "lat": 55.62025, "speed": 0.0, "course": 353.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 732, CreateTime = 1717076858751, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@45229d13)
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219014124.0, "lon": 9.690283, "lat": 55.675463, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219014124.0, "lon": 9.690283, "lat": 55.675463, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 733, CreateTime = 1717076858751, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@44da4b69)
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 259486000.0, "lon": 10.540867, "lat": 57.437083, "speed": 0.0, "course": 354.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 259486000.0, "lon": 10.540867, "lat": 57.437083, "speed": 0.0, "course": 354.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 734, CreateTime = 1717076858751, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@58fc620e)
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219013192.0, "lon": 11.016757, "lat": 54.817525, "speed": 0.0, "course": 331.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219013192.0, "lon": 11.016757, "lat": 54.817525, "speed": 0.0, "course": 331.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 735, CreateTime = 1717076858751, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1d1a927d)
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 314216000.0, "lon": 12.7707, "lat": 55.784683, "speed": 12.8, "course": 142.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 314216000.0, "lon": 12.7707, "lat": 55.784683, "speed": 12.8, "course": 142.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 736, CreateTime = 1717076858751, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4c814ec8)
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219004616.0, "lon": 11.124195, "lat": 57.3202, "speed": 0.0, "course": 321.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219004616.0, "lon": 11.124195, "lat": 57.3202, "speed": 0.0, "course": 321.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 737, CreateTime = 1717076858751, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5a96d532)
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 215681000.0, "lon": 12.75538, "lat": 55.27143, "speed": 14.0, "course": 111.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,390 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 215681000.0, "lon": 12.75538, "lat": 55.27143, "speed": 14.0, "course": 111.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 738, CreateTime = 1717076858751, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6141207c)
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 220067000.0, "lon": 10.67267, "lat": 54.752348, "speed": 0.1, "course": 321.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 220067000.0, "lon": 10.67267, "lat": 54.752348, "speed": 0.1, "course": 321.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 739, CreateTime = 1717076858752, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2881df53)
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 220550000.0, "lon": 11.79365, "lat": 56.127517, "speed": 8.9, "course": 83.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 220550000.0, "lon": 11.79365, "lat": 56.127517, "speed": 8.9, "course": 83.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 740, CreateTime = 1717076858752, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6eb02385)
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 273327100.0, "lon": 9.492333, "lat": 55.491733, "speed": 0.0, "course": 19.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 273327100.0, "lon": 9.492333, "lat": 55.491733, "speed": 0.0, "course": 19.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 741, CreateTime = 1717076858752, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2634424)
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 220333000.0, "lon": 10.586373, "lat": 57.717935, "speed": 0.0, "course": 265.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 220333000.0, "lon": 10.586373, "lat": 57.717935, "speed": 0.0, "course": 265.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 742, CreateTime = 1717076858752, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6a49c6d4)
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219537000.0, "lon": 10.908888, "lat": 55.885895, "speed": 14.3, "course": 40.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219537000.0, "lon": 10.908888, "lat": 55.885895, "speed": 14.3, "course": 40.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 743, CreateTime = 1717076858752, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4c14f789)
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219011196.0, "lon": 11.100302, "lat": 55.675227, "speed": 0.1, "course": 38.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219011196.0, "lon": 11.100302, "lat": 55.675227, "speed": 0.1, "course": 38.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 744, CreateTime = 1717076858752, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@23d75985)
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 273438290.0, "lon": 11.09861, "lat": 57.633637, "speed": 5.5, "course": 282.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 273438290.0, "lon": 11.09861, "lat": 57.633637, "speed": 5.5, "course": 282.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 745, CreateTime = 1717076858752, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3b8d7bbf)
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 258897000.0, "lon": 12.524458, "lat": 56.113427, "speed": 9.8, "course": 130.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 258897000.0, "lon": 12.524458, "lat": 56.113427, "speed": 9.8, "course": 130.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 746, CreateTime = 1717076858752, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1fd6657c)
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 636091254.0, "lon": 9.36895, "lat": 58.023383, "speed": 16.8, "course": 43.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 636091254.0, "lon": 9.36895, "lat": 58.023383, "speed": 16.8, "course": 43.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 747, CreateTime = 1717076858752, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@749571b0)
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 235070529.0, "lon": 10.92845, "lat": 54.92695, "speed": 7.1, "course": 49.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 235070529.0, "lon": 10.92845, "lat": 54.92695, "speed": 7.1, "course": 49.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 748, CreateTime = 1717076858752, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d1705d6)
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219001959.0, "lon": 8.423773, "lat": 55.4718, "speed": 0.0, "course": 321.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219001959.0, "lon": 8.423773, "lat": 55.4718, "speed": 0.0, "course": 321.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 749, CreateTime = 1717076858752, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3d17db48)
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219010764.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219010764.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 750, CreateTime = 1717076858752, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1146a413)
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 212341000.0, "lon": 7.504802, "lat": 57.42656, "speed": 0.5, "course": 140.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 212341000.0, "lon": 7.504802, "lat": 57.42656, "speed": 0.5, "course": 140.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 751, CreateTime = 1717076858752, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4e015f7a)
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 636091871.0, "lon": 3.994833, "lat": 56.462833, "speed": 13.0, "course": 178.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 636091871.0, "lon": 3.994833, "lat": 56.462833, "speed": 13.0, "course": 178.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 752, CreateTime = 1717076858753, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1bedcad9)
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 246238000.0, "lon": 7.74447, "lat": 55.261308, "speed": 2.9, "course": 343.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 246238000.0, "lon": 7.74447, "lat": 55.261308, "speed": 2.9, "course": 343.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 753, CreateTime = 1717076858753, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@18a39f77)
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:07", "mmsi": 219009338.0, "lon": 11.928353, "lat": 54.572417, "speed": 0.0, "course": 167.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,391 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:07", "mmsi": 219009338.0, "lon": 11.928353, "lat": 54.572417, "speed": 0.0, "course": 167.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 754, CreateTime = 1717076858755, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3c61d64c)
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219005932.0, "lon": 15.136642, "lat": 55.057533, "speed": 0.0, "course": 344.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219005932.0, "lon": 15.136642, "lat": 55.057533, "speed": 0.0, "course": 344.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 755, CreateTime = 1717076858755, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@785fa435)
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 220295000.0, "lon": 10.586478, "lat": 57.717545, "speed": 0.0, "course": 332.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 220295000.0, "lon": 10.586478, "lat": 57.717545, "speed": 0.0, "course": 332.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 756, CreateTime = 1717076858755, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@d9102e5)
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219132000.0, "lon": 9.643533, "lat": 57.831717, "speed": 13.4, "course": 275.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219132000.0, "lon": 9.643533, "lat": 57.831717, "speed": 13.4, "course": 275.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 757, CreateTime = 1717076858755, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@94d6c07)
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 265507770.0, "lon": 11.793212, "lat": 57.600353, "speed": 0.1, "course": 194.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 265507770.0, "lon": 11.793212, "lat": 57.600353, "speed": 0.1, "course": 194.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 758, CreateTime = 1717076858757, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3bac08d4)
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 992191016.0, "lon": 11.04673, "lat": 55.32479, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 992191016.0, "lon": 11.04673, "lat": 55.32479, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 759, CreateTime = 1717076858758, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3ed77d98)
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 233150000.0, "lon": 15.699133, "lat": 55.727817, "speed": 14.4, "course": 62.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 233150000.0, "lon": 15.699133, "lat": 55.727817, "speed": 14.4, "course": 62.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 760, CreateTime = 1717076858758, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3b54d68d)
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 220174000.0, "lon": 9.699623, "lat": 57.55987, "speed": 16.0, "course": 59.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 220174000.0, "lon": 9.699623, "lat": 57.55987, "speed": 16.0, "course": 59.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 761, CreateTime = 1717076858758, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@591ba8b4)
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219010982.0, "lon": 8.422612, "lat": 55.475593, "speed": 0.1, "course": 320.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219010982.0, "lon": 8.422612, "lat": 55.475593, "speed": 0.1, "course": 320.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 762, CreateTime = 1717076858759, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2aae1eb)
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 258517000.0, "lon": 9.958975, "lat": 57.593623, "speed": 0.0, "course": 323.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 258517000.0, "lon": 9.958975, "lat": 57.593623, "speed": 0.0, "course": 323.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 763, CreateTime = 1717076858759, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@714679b)
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219009273.0, "lon": 8.598383, "lat": 57.122567, "speed": 1.6, "course": 3.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219009273.0, "lon": 8.598383, "lat": 57.122567, "speed": 1.6, "course": 3.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 764, CreateTime = 1717076858759, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1a69294a)
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 265177000.0, "lon": 11.691098, "lat": 57.630882, "speed": 16.9, "course": 25.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 265177000.0, "lon": 11.691098, "lat": 57.630882, "speed": 16.9, "course": 25.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 765, CreateTime = 1717076858759, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1eb37cbb)
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 211514540.0, "lon": 10.269458, "lat": 54.496357, "speed": 0.8, "course": 38.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 211514540.0, "lon": 10.269458, "lat": 54.496357, "speed": 0.8, "course": 38.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 766, CreateTime = 1717076858760, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4b43733f)
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 211211810.0, "lon": 10.040992, "lat": 54.773582, "speed": 11.6, "course": 327.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 211211810.0, "lon": 10.040992, "lat": 54.773582, "speed": 11.6, "course": 327.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 767, CreateTime = 1717076858760, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6f4ffd73)
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 220088000.0, "lon": 9.15042, "lat": 57.882592, "speed": 2.7, "course": 191.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,392 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 220088000.0, "lon": 9.15042, "lat": 57.882592, "speed": 2.7, "course": 191.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 768, CreateTime = 1717076858760, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3c3fbaa9)
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 247072400.0, "lon": 15.694167, "lat": 55.434167, "speed": 13.3, "course": 92.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 247072400.0, "lon": 15.694167, "lat": 55.434167, "speed": 13.3, "course": 92.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 769, CreateTime = 1717076858761, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@396c5f31)
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 255801540.0, "lon": 11.8655, "lat": 56.740833, "speed": 18.2, "course": 168.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 255801540.0, "lon": 11.8655, "lat": 56.740833, "speed": 18.2, "course": 168.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 770, CreateTime = 1717076858762, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@696619a8)
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219226000.0, "lon": 8.127, "lat": 55.4265, "speed": 14.5, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219226000.0, "lon": 8.127, "lat": 55.4265, "speed": 14.5, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 771, CreateTime = 1717076858762, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7952d592)
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219000873.0, "lon": 10.30825, "lat": 56.99095, "speed": 0.0, "course": 340.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219000873.0, "lon": 10.30825, "lat": 56.99095, "speed": 0.0, "course": 340.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 772, CreateTime = 1717076858762, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@38f9d2e3)
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219000737.0, "lon": 11.352375, "lat": 54.65325, "speed": 0.1, "course": 174.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219000737.0, "lon": 11.352375, "lat": 54.65325, "speed": 0.1, "course": 174.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 773, CreateTime = 1717076858762, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@63b7871a)
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219007679.0, "lon": 10.588425, "lat": 57.716952, "speed": 0.0, "course": 138.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219007679.0, "lon": 10.588425, "lat": 57.716952, "speed": 0.0, "course": 138.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 774, CreateTime = 1717076858762, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3a45799d)
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219000141.0, "lon": 12.42731, "lat": 55.09765, "speed": 0.7, "course": 327.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219000141.0, "lon": 12.42731, "lat": 55.09765, "speed": 0.7, "course": 327.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 775, CreateTime = 1717076858762, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@55d4c502)
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 207088000.0, "lon": 10.802053, "lat": 57.786205, "speed": 10.9, "course": 322.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 207088000.0, "lon": 10.802053, "lat": 57.786205, "speed": 10.9, "course": 322.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 776, CreateTime = 1717076858762, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@23cc6b91)
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 304010870.0, "lon": 9.92609, "lat": 57.055307, "speed": 0.1, "course": 295.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 304010870.0, "lon": 9.92609, "lat": 57.055307, "speed": 0.1, "course": 295.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 777, CreateTime = 1717076858762, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7c9cb7a5)
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 259222000.0, "lon": 11.619115, "lat": 56.519128, "speed": 19.2, "course": 210.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 259222000.0, "lon": 11.619115, "lat": 56.519128, "speed": 19.2, "course": 210.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 778, CreateTime = 1717076858762, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d04b03a)
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 230315000.0, "lon": 10.9435, "lat": 55.908, "speed": 15.1, "course": 38.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 230315000.0, "lon": 10.9435, "lat": 55.908, "speed": 15.1, "course": 38.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 779, CreateTime = 1717076858763, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1e0b844d)
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 992191513.0, "lon": 5.033267, "lat": 55.5387, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 992191513.0, "lon": 5.033267, "lat": 55.5387, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 780, CreateTime = 1717076858763, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5edbf4fe)
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 992191519.0, "lon": 4.49135, "lat": 55.606082, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 992191519.0, "lon": 4.49135, "lat": 55.606082, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 781, CreateTime = 1717076858763, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@47e3411f)
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 265426000.0, "lon": 14.235267, "lat": 55.229033, "speed": 13.0, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,393 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 265426000.0, "lon": 14.235267, "lat": 55.229033, "speed": 13.0, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 782, CreateTime = 1717076858763, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@faeacb9)
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 305601000.0, "lon": 15.703383, "lat": 54.82845, "speed": 15.0, "course": 98.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 305601000.0, "lon": 15.703383, "lat": 54.82845, "speed": 15.0, "course": 98.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 783, CreateTime = 1717076858763, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4dc578ed)
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 220303000.0, "lon": 10.586945, "lat": 57.717605, "speed": 0.0, "course": 153.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 220303000.0, "lon": 10.586945, "lat": 57.717605, "speed": 0.0, "course": 153.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 784, CreateTime = 1717076858763, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4c3819af)
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219004896.0, "lon": 10.621102, "lat": 55.058433, "speed": 0.0, "course": 24.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219004896.0, "lon": 10.621102, "lat": 55.058433, "speed": 0.0, "course": 24.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 785, CreateTime = 1717076858763, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@118e428e)
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219000811.0, "lon": 11.48291, "lat": 54.88397, "speed": 0.0, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219000811.0, "lon": 11.48291, "lat": 54.88397, "speed": 0.0, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 786, CreateTime = 1717076858763, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6bbfef62)
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 220223000.0, "lon": 9.318323, "lat": 57.45351, "speed": 17.5, "course": 54.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 220223000.0, "lon": 9.318323, "lat": 57.45351, "speed": 17.5, "course": 54.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 787, CreateTime = 1717076858763, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@d5be0e8)
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219010743.0, "lon": 11.79391, "lat": 57.598953, "speed": 0.0, "course": 7.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219010743.0, "lon": 11.79391, "lat": 57.598953, "speed": 0.0, "course": 7.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 788, CreateTime = 1717076858763, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@122758d)
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219001214.0, "lon": 12.613505, "lat": 56.042672, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219001214.0, "lon": 12.613505, "lat": 56.042672, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 789, CreateTime = 1717076858763, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@62dbcd15)
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219040000.0, "lon": 11.368308, "lat": 55.97284, "speed": 0.0, "course": 330.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219040000.0, "lon": 11.368308, "lat": 55.97284, "speed": 0.0, "course": 330.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 790, CreateTime = 1717076858763, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@760bead3)
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219963000.0, "lon": 11.245233, "lat": 57.366567, "speed": 1.7, "course": 12.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219963000.0, "lon": 11.245233, "lat": 57.366567, "speed": 1.7, "course": 12.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 791, CreateTime = 1717076858763, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2485085a)
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219014851.0, "lon": 8.59736, "lat": 57.1227, "speed": 0.0, "course": 106.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219014851.0, "lon": 8.59736, "lat": 57.1227, "speed": 0.0, "course": 106.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 792, CreateTime = 1717076858763, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@36999f5a)
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 231201000.0, "lon": 10.060215, "lat": 57.764947, "speed": 15.7, "course": 13.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 231201000.0, "lon": 10.060215, "lat": 57.764947, "speed": 15.7, "course": 13.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 793, CreateTime = 1717076858764, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@a165ff9)
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 220378000.0, "lon": 12.318833, "lat": 55.434, "speed": 15.9, "course": 130.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 220378000.0, "lon": 12.318833, "lat": 55.434, "speed": 15.9, "course": 130.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 794, CreateTime = 1717076858764, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@23e2611a)
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 257478000.0, "lon": 12.885197, "lat": 55.614157, "speed": 10.5, "course": 40.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 257478000.0, "lon": 12.885197, "lat": 55.614157, "speed": 10.5, "course": 40.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 795, CreateTime = 1717076858764, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2f297ae4)
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219002467.0, "lon": 8.427218, "lat": 55.479067, "speed": 0.1, "course": 342.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,394 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219002467.0, "lon": 8.427218, "lat": 55.479067, "speed": 0.1, "course": 342.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 796, CreateTime = 1717076858764, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@55305314)
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219000769.0, "lon": 12.615857, "lat": 56.042847, "speed": 0.0, "course": 330.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219000769.0, "lon": 12.615857, "lat": 56.042847, "speed": 0.0, "course": 330.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 797, CreateTime = 1717076858764, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6de127dc)
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 261449000.0, "lon": 13.991017, "lat": 54.808083, "speed": 10.5, "course": 351.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 261449000.0, "lon": 13.991017, "lat": 54.808083, "speed": 10.5, "course": 351.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 798, CreateTime = 1717076858764, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5d3b71cb)
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 220333000.0, "lon": 10.586373, "lat": 57.717935, "speed": 0.0, "course": 265.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 220333000.0, "lon": 10.586373, "lat": 57.717935, "speed": 0.0, "course": 265.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 799, CreateTime = 1717076858764, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@39a1ded2)
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 209696000.0, "lon": 11.375343, "lat": 54.545288, "speed": 15.4, "course": 294.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 209696000.0, "lon": 11.375343, "lat": 54.545288, "speed": 15.4, "course": 294.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 800, CreateTime = 1717076858764, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6ede8201)
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 265608060.0, "lon": 12.857128, "lat": 56.662653, "speed": 0.0, "course": 39.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 265608060.0, "lon": 12.857128, "lat": 56.662653, "speed": 0.0, "course": 39.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 801, CreateTime = 1717076858764, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@a6587c1)
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 231048000.0, "lon": 10.57341, "lat": 54.79816, "speed": 0.0, "course": 179.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 231048000.0, "lon": 10.57341, "lat": 54.79816, "speed": 0.0, "course": 179.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 802, CreateTime = 1717076858764, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@c560a6f)
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 220177000.0, "lon": 4.539333, "lat": 55.468667, "speed": 1.6, "course": 21.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 220177000.0, "lon": 4.539333, "lat": 55.468667, "speed": 1.6, "course": 21.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 803, CreateTime = 1717076858764, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3b361279)
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219959000.0, "lon": 8.446752, "lat": 57.51923, "speed": 2.7, "course": 255.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219959000.0, "lon": 8.446752, "lat": 57.51923, "speed": 2.7, "course": 255.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 804, CreateTime = 1717076858764, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@21e25194)
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 231754000.0, "lon": 7.919765, "lat": 56.708722, "speed": 13.5, "course": 27.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 231754000.0, "lon": 7.919765, "lat": 56.708722, "speed": 13.5, "course": 27.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 805, CreateTime = 1717076858764, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@71f81e6)
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 211223400.0, "lon": 12.093805, "lat": 54.154122, "speed": 0.0, "course": 107.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 211223400.0, "lon": 12.093805, "lat": 54.154122, "speed": 0.0, "course": 107.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 806, CreateTime = 1717076858764, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3ba6e618)
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 273324000.0, "lon": 12.993813, "lat": 55.161263, "speed": 7.4, "course": 129.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 273324000.0, "lon": 12.993813, "lat": 55.161263, "speed": 7.4, "course": 129.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 807, CreateTime = 1717076858765, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@30889ecf)
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 265866000.0, "lon": 12.513528, "lat": 54.826517, "speed": 13.6, "course": 216.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 265866000.0, "lon": 12.513528, "lat": 54.826517, "speed": 13.6, "course": 216.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 808, CreateTime = 1717076858765, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3d517bb)
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 261201000.0, "lon": 11.540965, "lat": 54.175047, "speed": 8.6, "course": 20.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 261201000.0, "lon": 11.540965, "lat": 54.175047, "speed": 8.6, "course": 20.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 809, CreateTime = 1717076858765, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@78bea696)
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219004263.0, "lon": 10.912592, "lat": 55.710835, "speed": 9.2, "course": 290.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219004263.0, "lon": 10.912592, "lat": 55.710835, "speed": 9.2, "course": 290.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 810, CreateTime = 1717076858765, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@742409bf)
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 2190062.0, "lon": 8.12934, "lat": 56.000308, "speed": 0.0, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,395 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 2190062.0, "lon": 8.12934, "lat": 56.000308, "speed": 0.0, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 811, CreateTime = 1717076858765, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@ae8f12)
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219002783.0, "lon": 8.12004, "lat": 56.37151, "speed": 0.1, "course": 302.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219002783.0, "lon": 8.12004, "lat": 56.37151, "speed": 0.1, "course": 302.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 812, CreateTime = 1717076858765, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2bed2873)
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 309359000.0, "lon": 10.229667, "lat": 56.9835, "speed": 8.1, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 309359000.0, "lon": 10.229667, "lat": 56.9835, "speed": 8.1, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 813, CreateTime = 1717076858765, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@266ab18e)
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 266331000.0, "lon": 10.785732, "lat": 55.6577, "speed": 18.0, "course": 6.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 266331000.0, "lon": 10.785732, "lat": 55.6577, "speed": 18.0, "course": 6.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 814, CreateTime = 1717076858765, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@72d72d0d)
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 309519000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 309519000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 815, CreateTime = 1717076858765, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@675fa5a)
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 211211290.0, "lon": 10.035962, "lat": 54.778245, "speed": 11.7, "course": 326.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 211211290.0, "lon": 10.035962, "lat": 54.778245, "speed": 11.7, "course": 326.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 816, CreateTime = 1717076858765, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4499f457)
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 311995000.0, "lon": 10.265803, "lat": 57.791568, "speed": 18.9, "course": 75.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 311995000.0, "lon": 10.265803, "lat": 57.791568, "speed": 18.9, "course": 75.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 817, CreateTime = 1717076858765, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@370ccb8b)
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 314208000.0, "lon": 7.8397, "lat": 57.424783, "speed": 12.4, "course": 206.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 314208000.0, "lon": 7.8397, "lat": 57.424783, "speed": 12.4, "course": 206.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 818, CreateTime = 1717076858765, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7cf82722)
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 273333020.0, "lon": 11.716933, "lat": 54.204233, "speed": 9.1, "course": 49.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 273333020.0, "lon": 11.716933, "lat": 54.204233, "speed": 9.1, "course": 49.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 819, CreateTime = 1717076858765, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5576b5cd)
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 211211250.0, "lon": 10.046058, "lat": 54.768007, "speed": 11.7, "course": 327.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 211211250.0, "lon": 10.046058, "lat": 54.768007, "speed": 11.7, "course": 327.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 820, CreateTime = 1717076858766, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5e46d878)
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 255803370.0, "lon": 9.031748, "lat": 57.497938, "speed": 10.3, "course": 240.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 255803370.0, "lon": 9.031748, "lat": 57.497938, "speed": 10.3, "course": 240.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 821, CreateTime = 1717076858766, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@fc700a8)
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 265858000.0, "lon": 12.884123, "lat": 55.251123, "speed": 10.8, "course": 95.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 265858000.0, "lon": 12.884123, "lat": 55.251123, "speed": 10.8, "course": 95.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 822, CreateTime = 1717076858766, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@323bf745)
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 215013000.0, "lon": 15.012382, "lat": 55.570053, "speed": 17.1, "course": 239.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 215013000.0, "lon": 15.012382, "lat": 55.570053, "speed": 17.1, "course": 239.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 823, CreateTime = 1717076858766, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5283f412)
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219921000.0, "lon": 15.13528, "lat": 55.064073, "speed": 0.0, "course": 315.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219921000.0, "lon": 15.13528, "lat": 55.064073, "speed": 0.0, "course": 315.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 824, CreateTime = 1717076858766, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3aee6322)
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219005068.0, "lon": 11.160372, "lat": 55.171403, "speed": 0.1, "course": 189.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219005068.0, "lon": 11.160372, "lat": 55.171403, "speed": 0.1, "course": 189.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 825, CreateTime = 1717076858766, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@d1bf697)
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 259196000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,396 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 259196000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 826, CreateTime = 1717076858766, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6077b9ae)
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219001819.0, "lon": 12.981895, "lat": 55.22782, "speed": 10.2, "course": 105.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219001819.0, "lon": 12.981895, "lat": 55.22782, "speed": 10.2, "course": 105.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 827, CreateTime = 1717076858766, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2d19f2d6)
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219007572.0, "lon": 9.897353, "lat": 57.05738, "speed": 0.0, "course": 145.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219007572.0, "lon": 9.897353, "lat": 57.05738, "speed": 0.0, "course": 145.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 828, CreateTime = 1717076858766, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@64277324)
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 265007000.0, "lon": 8.496945, "lat": 57.29305, "speed": 14.5, "course": 53.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 265007000.0, "lon": 8.496945, "lat": 57.29305, "speed": 14.5, "course": 53.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 829, CreateTime = 1717076858766, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@36da8e79)
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 211211260.0, "lon": 10.030462, "lat": 54.781198, "speed": 11.5, "course": 310.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 211211260.0, "lon": 10.030462, "lat": 54.781198, "speed": 11.5, "course": 310.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 830, CreateTime = 1717076858766, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6bbdebc5)
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 265513470.0, "lon": 12.68785, "lat": 56.044867, "speed": 0.0, "course": 216.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 265513470.0, "lon": 12.68785, "lat": 56.044867, "speed": 0.0, "course": 216.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 831, CreateTime = 1717076858766, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@9d02b26)
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219010987.0, "lon": 12.652533, "lat": 55.726817, "speed": 7.9, "course": 230.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219010987.0, "lon": 12.652533, "lat": 55.726817, "speed": 7.9, "course": 230.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 832, CreateTime = 1717076858767, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@56b1d76b)
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 220621000.0, "lon": 9.75175, "lat": 55.56001, "speed": 0.0, "course": 39.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 220621000.0, "lon": 9.75175, "lat": 55.56001, "speed": 0.0, "course": 39.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 833, CreateTime = 1717076858767, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@347a3282)
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 231306000.0, "lon": 10.6009, "lat": 57.722183, "speed": 0.0, "course": 42.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 231306000.0, "lon": 10.6009, "lat": 57.722183, "speed": 0.0, "course": 42.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 834, CreateTime = 1717076858767, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@301d140b)
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 220043000.0, "lon": 14.015467, "lat": 54.935967, "speed": 0.5, "course": 270.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 220043000.0, "lon": 14.015467, "lat": 54.935967, "speed": 0.5, "course": 270.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 835, CreateTime = 1717076858767, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@389c9035)
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 233234000.0, "lon": 7.320108, "lat": 56.3927, "speed": 15.4, "course": 213.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 233234000.0, "lon": 7.320108, "lat": 56.3927, "speed": 15.4, "course": 213.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 836, CreateTime = 1717076858767, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@604e02c2)
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 305203000.0, "lon": 14.610582, "lat": 55.380877, "speed": 9.5, "course": 23.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 305203000.0, "lon": 14.610582, "lat": 55.380877, "speed": 9.5, "course": 23.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 837, CreateTime = 1717076858767, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@545c26b)
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 277408000.0, "lon": 15.48425, "lat": 54.97921, "speed": 20.7, "course": 242.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 277408000.0, "lon": 15.48425, "lat": 54.97921, "speed": 20.7, "course": 242.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 838, CreateTime = 1717076858767, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5da02384)
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 219329000.0, "lon": 8.421017, "lat": 55.478227, "speed": 0.0, "course": 338.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 219329000.0, "lon": 8.421017, "lat": 55.478227, "speed": 0.0, "course": 338.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 839, CreateTime = 1717076858767, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1e11d3d)
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 311299000.0, "lon": 11.42364, "lat": 56.330897, "speed": 12.9, "course": 211.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 311299000.0, "lon": 11.42364, "lat": 56.330897, "speed": 12.9, "course": 211.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 840, CreateTime = 1717076858767, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@11a947d1)
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 211910000.0, "lon": 8.246367, "lat": 57.054717, "speed": 23.4, "course": 39.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 211910000.0, "lon": 8.246367, "lat": 57.054717, "speed": 23.4, "course": 39.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 841, CreateTime = 1717076858767, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3a549915)
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 304010515.0, "lon": 10.579578, "lat": 54.569858, "speed": 14.7, "course": 246.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,397 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 304010515.0, "lon": 10.579578, "lat": 54.569858, "speed": 14.7, "course": 246.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 842, CreateTime = 1717076858769, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@663421d8)
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:08", "mmsi": 377411000.0, "lon": 14.376167, "lat": 55.270333, "speed": 11.0, "course": 218.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:08", "mmsi": 377411000.0, "lon": 14.376167, "lat": 55.270333, "speed": 11.0, "course": 218.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 843, CreateTime = 1717076858770, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6fb5c0d6)
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 210008000.0, "lon": 10.943173, "lat": 57.680765, "speed": 17.2, "course": 132.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 210008000.0, "lon": 10.943173, "lat": 57.680765, "speed": 17.2, "course": 132.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 844, CreateTime = 1717076858770, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@34f9953e)
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 259898000.0, "lon": 11.430833, "lat": 56.530167, "speed": 14.6, "course": 49.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 259898000.0, "lon": 11.430833, "lat": 56.530167, "speed": 14.6, "course": 49.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 845, CreateTime = 1717076858770, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2afb2e85)
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 211222780.0, "lon": 12.097245, "lat": 54.176607, "speed": 0.1, "course": 283.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 211222780.0, "lon": 12.097245, "lat": 54.176607, "speed": 0.1, "course": 283.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 846, CreateTime = 1717076858770, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d86f0e3)
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219173000.0, "lon": 13.830545, "lat": 55.424628, "speed": 0.1, "course": 193.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219173000.0, "lon": 13.830545, "lat": 55.424628, "speed": 0.1, "course": 193.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 847, CreateTime = 1717076858770, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2cf43ef5)
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219007609.0, "lon": 10.205052, "lat": 56.134698, "speed": 0.0, "course": 166.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219007609.0, "lon": 10.205052, "lat": 56.134698, "speed": 0.0, "course": 166.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 848, CreateTime = 1717076858770, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@54dc1e30)
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 992191518.0, "lon": 4.6483, "lat": 55.767517, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 992191518.0, "lon": 4.6483, "lat": 55.767517, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 849, CreateTime = 1717076858770, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@27a08d28)
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 211462260.0, "lon": 9.937942, "lat": 54.664318, "speed": 0.0, "course": 30.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 211462260.0, "lon": 9.937942, "lat": 54.664318, "speed": 0.0, "course": 30.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 850, CreateTime = 1717076858770, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7dfb60d7)
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 249939000.0, "lon": 9.179528, "lat": 57.592107, "speed": 12.1, "course": 73.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 249939000.0, "lon": 9.179528, "lat": 57.592107, "speed": 12.1, "course": 73.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 851, CreateTime = 1717076858770, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@70f5fa0b)
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219000622.0, "lon": 8.224662, "lat": 56.689667, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,398 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219000622.0, "lon": 8.224662, "lat": 56.689667, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 852, CreateTime = 1717076858770, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@44ec47bb)
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219000836.0, "lon": 10.412855, "lat": 54.891652, "speed": 0.0, "course": 343.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219000836.0, "lon": 10.412855, "lat": 54.891652, "speed": 0.0, "course": 343.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 853, CreateTime = 1717076858770, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@67064bc3)
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219850000.0, "lon": 9.764833, "lat": 55.358333, "speed": 9.3, "course": 299.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219850000.0, "lon": 9.764833, "lat": 55.358333, "speed": 9.3, "course": 299.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 854, CreateTime = 1717076858770, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@415d622c)
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219000345.0, "lon": 10.8247, "lat": 55.753017, "speed": 16.8, "course": 170.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219000345.0, "lon": 10.8247, "lat": 55.753017, "speed": 16.8, "course": 170.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 855, CreateTime = 1717076858770, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1ea7fdae)
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219011248.0, "lon": 10.355752, "lat": 56.967568, "speed": 1.6, "course": 166.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219011248.0, "lon": 10.355752, "lat": 56.967568, "speed": 1.6, "course": 166.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 856, CreateTime = 1717076858771, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3850b05e)
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219005941.0, "lon": 10.588167, "lat": 57.718633, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219005941.0, "lon": 10.588167, "lat": 57.718633, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 857, CreateTime = 1717076858771, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d5dbcc4)
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 271000601.0, "lon": 11.59855, "lat": 54.482033, "speed": 10.4, "course": 297.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 271000601.0, "lon": 11.59855, "lat": 54.482033, "speed": 10.4, "course": 297.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 858, CreateTime = 1717076858771, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@473bff41)
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 265410000.0, "lon": 11.604978, "lat": 57.607872, "speed": 17.0, "course": 252.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 265410000.0, "lon": 11.604978, "lat": 57.607872, "speed": 17.0, "course": 252.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 859, CreateTime = 1717076858771, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@66503085)
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 477748300.0, "lon": 8.839333, "lat": 57.602667, "speed": 14.9, "course": 61.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,399 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 477748300.0, "lon": 8.839333, "lat": 57.602667, "speed": 14.9, "course": 61.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 860, CreateTime = 1717076858771, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5b3fae51)
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 211222680.0, "lon": 10.135465, "lat": 54.315298, "speed": 0.1, "course": 183.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 211222680.0, "lon": 10.135465, "lat": 54.315298, "speed": 0.1, "course": 183.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 861, CreateTime = 1717076858771, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5b04926e)
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 538002365.0, "lon": 8.6196, "lat": 57.317167, "speed": 11.6, "course": 233.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 538002365.0, "lon": 8.6196, "lat": 57.317167, "speed": 11.6, "course": 233.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 862, CreateTime = 1717076858771, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@435dafb8)
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219002416.0, "lon": 10.216212, "lat": 56.152885, "speed": 0.0, "course": 159.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219002416.0, "lon": 10.216212, "lat": 56.152885, "speed": 0.0, "course": 159.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 863, CreateTime = 1717076858771, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@246e7b4e)
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219001061.0, "lon": 12.680187, "lat": 55.592855, "speed": 0.0, "course": 99.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219001061.0, "lon": 12.680187, "lat": 55.592855, "speed": 0.0, "course": 99.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 864, CreateTime = 1717076858771, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@20514b4)
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219003103.0, "lon": 11.684998, "lat": 57.369353, "speed": 0.2, "course": 158.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219003103.0, "lon": 11.684998, "lat": 57.369353, "speed": 0.2, "course": 158.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 865, CreateTime = 1717076858771, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7ded6178)
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 211149000.0, "lon": 12.792535, "lat": 55.049392, "speed": 12.4, "course": 213.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 211149000.0, "lon": 12.792535, "lat": 55.049392, "speed": 12.4, "course": 213.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 866, CreateTime = 1717076858771, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@53e32112)
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 245180000.0, "lon": 14.543783, "lat": 55.316523, "speed": 11.1, "course": 48.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 245180000.0, "lon": 14.543783, "lat": 55.316523, "speed": 11.1, "course": 48.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 867, CreateTime = 1717076858771, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@400942b)
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 265568080.0, "lon": 12.623913, "lat": 56.427555, "speed": 0.0, "course": 332.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 265568080.0, "lon": 12.623913, "lat": 56.427555, "speed": 0.0, "course": 332.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 868, CreateTime = 1717076858771, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2e8a80ab)
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219787000.0, "lon": 14.691998, "lat": 55.093643, "speed": 0.0, "course": 352.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219787000.0, "lon": 14.691998, "lat": 55.093643, "speed": 0.0, "course": 352.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 869, CreateTime = 1717076858771, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@387ac2a3)
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 992191526.0, "lon": 4.75005, "lat": 55.716382, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 992191526.0, "lon": 4.75005, "lat": 55.716382, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 870, CreateTime = 1717076858772, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@72db9f0f)
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219001682.0, "lon": 9.958555, "lat": 57.592733, "speed": 0.0, "course": 19.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219001682.0, "lon": 9.958555, "lat": 57.592733, "speed": 0.0, "course": 19.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 871, CreateTime = 1717076858773, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@727afcb3)
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 211226860.0, "lon": 7.38564, "lat": 55.260213, "speed": 15.6, "course": 248.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 211226860.0, "lon": 7.38564, "lat": 55.260213, "speed": 15.6, "course": 248.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 872, CreateTime = 1717076858773, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@88fa58f)
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 265586090.0, "lon": 11.9274, "lat": 57.620013, "speed": 0.0, "course": 274.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 265586090.0, "lon": 11.9274, "lat": 57.620013, "speed": 0.0, "course": 274.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 873, CreateTime = 1717076858774, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@660e11e7)
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 352055000.0, "lon": 10.907633, "lat": 57.5336, "speed": 0.1, "course": 46.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 352055000.0, "lon": 10.907633, "lat": 57.5336, "speed": 0.1, "course": 46.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 874, CreateTime = 1717076858774, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4883c9ce)
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 230204000.0, "lon": 12.831475, "lat": 54.71284, "speed": 15.1, "course": 59.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 230204000.0, "lon": 12.831475, "lat": 54.71284, "speed": 15.1, "course": 59.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 875, CreateTime = 1717076858775, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6db93b09)
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219592000.0, "lon": 11.381392, "lat": 57.752603, "speed": 16.9, "course": 342.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,400 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219592000.0, "lon": 11.381392, "lat": 57.752603, "speed": 16.9, "course": 342.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 876, CreateTime = 1717076858775, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@186f58ec)
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219006382.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219006382.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 877, CreateTime = 1717076858775, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@e78e32f)
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 211222290.0, "lon": 13.368548, "lat": 54.910385, "speed": 2.4, "course": 229.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 211222290.0, "lon": 13.368548, "lat": 54.910385, "speed": 2.4, "course": 229.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 878, CreateTime = 1717076858775, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@58e39697)
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 265630560.0, "lon": 12.934838, "lat": 55.410742, "speed": 0.1, "course": 327.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 265630560.0, "lon": 12.934838, "lat": 55.410742, "speed": 0.1, "course": 327.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 879, CreateTime = 1717076858775, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7ca68ff1)
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 245253000.0, "lon": 7.806217, "lat": 55.276548, "speed": 4.1, "course": 327.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 245253000.0, "lon": 7.806217, "lat": 55.276548, "speed": 4.1, "course": 327.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 880, CreateTime = 1717076858775, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1eec10b1)
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 244660757.0, "lon": 8.305212, "lat": 56.550357, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 244660757.0, "lon": 8.305212, "lat": 56.550357, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 881, CreateTime = 1717076858775, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5744f9d8)
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219809000.0, "lon": 8.219318, "lat": 56.70094, "speed": 0.1, "course": 316.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219809000.0, "lon": 8.219318, "lat": 56.70094, "speed": 0.1, "course": 316.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 882, CreateTime = 1717076858775, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@13578a89)
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 220620000.0, "lon": 9.416197, "lat": 57.817188, "speed": 13.7, "course": 267.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 220620000.0, "lon": 9.416197, "lat": 57.817188, "speed": 13.7, "course": 267.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 883, CreateTime = 1717076858776, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5bc65615)
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 265041000.0, "lon": 12.617215, "lat": 56.033083, "speed": 0.0, "course": 261.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 265041000.0, "lon": 12.617215, "lat": 56.033083, "speed": 0.0, "course": 261.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 884, CreateTime = 1717076858777, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2551ac44)
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 266039000.0, "lon": 11.136968, "lat": 56.099173, "speed": 17.6, "course": 207.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 266039000.0, "lon": 11.136968, "lat": 56.099173, "speed": 17.6, "course": 207.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 885, CreateTime = 1717076858777, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@55ab0b0f)
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219010764.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219010764.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 886, CreateTime = 1717076858777, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7a07d0f1)
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 244010708.0, "lon": 12.310818, "lat": 56.125847, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 244010708.0, "lon": 12.310818, "lat": 56.125847, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 887, CreateTime = 1717076858777, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1318575a)
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219013485.0, "lon": 9.149285, "lat": 57.890662, "speed": 2.6, "course": 63.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219013485.0, "lon": 9.149285, "lat": 57.890662, "speed": 2.6, "course": 63.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 888, CreateTime = 1717076858777, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3b03eaf1)
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 230988000.0, "lon": 13.835083, "lat": 55.041017, "speed": 13.3, "course": 247.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 230988000.0, "lon": 13.835083, "lat": 55.041017, "speed": 13.3, "course": 247.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 889, CreateTime = 1717076858777, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@367d6ded)
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 305279000.0, "lon": 12.486002, "lat": 55.600652, "speed": 0.0, "course": 319.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,401 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 305279000.0, "lon": 12.486002, "lat": 55.600652, "speed": 0.0, "course": 319.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 890, CreateTime = 1717076858777, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@72b9a38b)
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 220622000.0, "lon": 11.902453, "lat": 56.54721, "speed": 0.2, "course": 320.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 220622000.0, "lon": 11.902453, "lat": 56.54721, "speed": 0.2, "course": 320.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 891, CreateTime = 1717076858777, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@23ca9801)
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 265150000.0, "lon": 12.300625, "lat": 54.562532, "speed": 16.4, "course": 33.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 265150000.0, "lon": 12.300625, "lat": 54.562532, "speed": 16.4, "course": 33.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 892, CreateTime = 1717076858777, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7baaaeb)
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219008746.0, "lon": 10.302157, "lat": 56.607325, "speed": 0.0, "course": 136.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219008746.0, "lon": 10.302157, "lat": 56.607325, "speed": 0.0, "course": 136.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 893, CreateTime = 1717076858778, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5af5bdf4)
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 220546000.0, "lon": 14.076153, "lat": 55.08154, "speed": 13.6, "course": 219.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 220546000.0, "lon": 14.076153, "lat": 55.08154, "speed": 13.6, "course": 219.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 894, CreateTime = 1717076858778, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@656fe8da)
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 377455000.0, "lon": 12.354267, "lat": 56.1718, "speed": 10.0, "course": 121.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 377455000.0, "lon": 12.354267, "lat": 56.1718, "speed": 10.0, "course": 121.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 895, CreateTime = 1717076858779, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@12127ee6)
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219201000.0, "lon": 9.802573, "lat": 58.051873, "speed": 2.6, "course": 223.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219201000.0, "lon": 9.802573, "lat": 58.051873, "speed": 2.6, "course": 223.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 896, CreateTime = 1717076858779, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@402d63bd)
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219012685.0, "lon": 12.683428, "lat": 54.829953, "speed": 9.2, "course": 54.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219012685.0, "lon": 12.683428, "lat": 54.829953, "speed": 9.2, "course": 54.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 897, CreateTime = 1717076858779, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@37c07c51)
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219000818.0, "lon": 9.889287, "lat": 55.27038, "speed": 0.0, "course": 5.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219000818.0, "lon": 9.889287, "lat": 55.27038, "speed": 0.0, "course": 5.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 898, CreateTime = 1717076858779, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2df36b4b)
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 266262000.0, "lon": 12.631623, "lat": 55.04224, "speed": 17.6, "course": 178.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 266262000.0, "lon": 12.631623, "lat": 55.04224, "speed": 17.6, "course": 178.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 899, CreateTime = 1717076858779, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2c97c55d)
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 636012690.0, "lon": 10.806017, "lat": 55.7887, "speed": 12.2, "course": 177.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 636012690.0, "lon": 10.806017, "lat": 55.7887, "speed": 12.2, "course": 177.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 900, CreateTime = 1717076858780, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@70c6bf9)
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 246276000.0, "lon": 12.191127, "lat": 54.528673, "speed": 9.6, "course": 200.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 246276000.0, "lon": 12.191127, "lat": 54.528673, "speed": 9.6, "course": 200.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 901, CreateTime = 1717076858780, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@331abdbd)
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 257689000.0, "lon": 12.236408, "lat": 54.457098, "speed": 14.8, "course": 28.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,402 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 257689000.0, "lon": 12.236408, "lat": 54.457098, "speed": 14.8, "course": 28.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,403 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 902, CreateTime = 1717076858780, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@50521a6)
2024-05-30 15:47:40 2024-05-30 13:47:40,403 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,403 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219007333.0, "lon": 14.93125, "lat": 54.700317, "speed": 0.5, "course": 305.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,403 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219007333.0, "lon": 14.93125, "lat": 54.700317, "speed": 0.5, "course": 305.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,403 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 903, CreateTime = 1717076858780, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@17aaa176)
2024-05-30 15:47:40 2024-05-30 13:47:40,403 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 265218000.0, "lon": 12.996295, "lat": 55.616082, "speed": 0.0, "course": 318.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 265218000.0, "lon": 12.996295, "lat": 55.616082, "speed": 0.0, "course": 318.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 904, CreateTime = 1717076858780, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@739d43d9)
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219801000.0, "lon": 9.964833, "lat": 57.592883, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219801000.0, "lon": 9.964833, "lat": 57.592883, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 905, CreateTime = 1717076858780, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@158cff42)
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 211165010.0, "lon": 13.15416, "lat": 55.007045, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 211165010.0, "lon": 13.15416, "lat": 55.007045, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 906, CreateTime = 1717076858780, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3928e444)
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 376004900.0, "lon": 12.478233, "lat": 56.888967, "speed": 0.1, "course": 139.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 376004900.0, "lon": 12.478233, "lat": 56.888967, "speed": 0.1, "course": 139.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 907, CreateTime = 1717076858780, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7b4b4306)
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 244806000.0, "lon": 7.284252, "lat": 55.591632, "speed": 4.8, "course": 318.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 244806000.0, "lon": 7.284252, "lat": 55.591632, "speed": 4.8, "course": 318.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 908, CreateTime = 1717076858780, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@62d1443d)
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 319161000.0, "lon": 11.456533, "lat": 56.346267, "speed": 14.4, "course": 28.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 319161000.0, "lon": 11.456533, "lat": 56.346267, "speed": 14.4, "course": 28.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 909, CreateTime = 1717076858780, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@10d5d1ca)
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 305381000.0, "lon": 13.726655, "lat": 55.17238, "speed": 10.6, "course": 96.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 305381000.0, "lon": 13.726655, "lat": 55.17238, "speed": 10.6, "course": 96.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 910, CreateTime = 1717076858781, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6e211d50)
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 244620052.0, "lon": 8.44983, "lat": 55.458747, "speed": 0.1, "course": 187.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 244620052.0, "lon": 8.44983, "lat": 55.458747, "speed": 0.1, "course": 187.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 911, CreateTime = 1717076858781, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4f5320e1)
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 565589000.0, "lon": 10.890467, "lat": 57.7156, "speed": 12.6, "course": 136.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 565589000.0, "lon": 10.890467, "lat": 57.7156, "speed": 12.6, "course": 136.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 912, CreateTime = 1717076858781, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@274b659a)
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 265610900.0, "lon": 12.903567, "lat": 55.756648, "speed": 0.0, "course": 320.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 265610900.0, "lon": 12.903567, "lat": 55.756648, "speed": 0.0, "course": 320.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 913, CreateTime = 1717076858781, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@19aebb38)
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 220256000.0, "lon": 9.963057, "lat": 57.59294, "speed": 0.1, "course": 321.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 220256000.0, "lon": 9.963057, "lat": 57.59294, "speed": 0.1, "course": 321.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 914, CreateTime = 1717076858781, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7f83fec0)
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 219000809.0, "lon": 11.514508, "lat": 54.97197, "speed": 0.0, "course": 165.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 219000809.0, "lon": 11.514508, "lat": 54.97197, "speed": 0.0, "course": 165.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 915, CreateTime = 1717076858781, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@29818df9)
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 257470000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 257470000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 916, CreateTime = 1717076858781, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@559a5ae6)
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 2190064.0, "lon": 11.519003, "lat": 56.716568, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 2190064.0, "lon": 11.519003, "lat": 56.716568, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 917, CreateTime = 1717076858781, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@39015c16)
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 992191528.0, "lon": 4.747432, "lat": 55.71475, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 992191528.0, "lon": 4.747432, "lat": 55.71475, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 918, CreateTime = 1717076858781, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5914c008)
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 992191517.0, "lon": 5.229832, "lat": 55.386017, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 992191517.0, "lon": 5.229832, "lat": 55.386017, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 919, CreateTime = 1717076858781, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7cdf7096)
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 308941000.0, "lon": 10.853432, "lat": 57.990123, "speed": 0.1, "course": 106.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,404 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 308941000.0, "lon": 10.853432, "lat": 57.990123, "speed": 0.1, "course": 106.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 920, CreateTime = 1717076858781, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7b154881)
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:09", "mmsi": 205365000.0, "lon": 11.799872, "lat": 54.42116, "speed": 15.8, "course": 316.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:09", "mmsi": 205365000.0, "lon": 11.799872, "lat": 54.42116, "speed": 15.8, "course": 316.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 921, CreateTime = 1717076858781, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@48474a19)
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219001058.0, "lon": 14.801042, "lat": 55.279127, "speed": 0.2, "course": 313.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219001058.0, "lon": 14.801042, "lat": 55.279127, "speed": 0.2, "course": 313.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 922, CreateTime = 1717076858781, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@372cc799)
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219002159.0, "lon": 10.592778, "lat": 57.718253, "speed": 0.0, "course": 159.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219002159.0, "lon": 10.592778, "lat": 57.718253, "speed": 0.0, "course": 159.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 923, CreateTime = 1717076858781, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@30704a2a)
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 2194005.0, "lon": 4.272, "lat": 56.344267, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 2194005.0, "lon": 4.272, "lat": 56.344267, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 924, CreateTime = 1717076858781, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@61f04de5)
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 220138000.0, "lon": 12.195187, "lat": 55.454255, "speed": 0.0, "course": 339.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 220138000.0, "lon": 12.195187, "lat": 55.454255, "speed": 0.0, "course": 339.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 925, CreateTime = 1717076858782, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1315d440)
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 992191016.0, "lon": 11.046733, "lat": 55.324792, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 992191016.0, "lon": 11.046733, "lat": 55.324792, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 926, CreateTime = 1717076858782, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@42d4d9b4)
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219000407.0, "lon": 10.921417, "lat": 57.296683, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219000407.0, "lon": 10.921417, "lat": 57.296683, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 927, CreateTime = 1717076858782, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@70c7eade)
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 265506580.0, "lon": 11.897807, "lat": 57.692128, "speed": 0.0, "course": 329.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 265506580.0, "lon": 11.897807, "lat": 57.692128, "speed": 0.0, "course": 329.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 928, CreateTime = 1717076858782, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@13bb1e46)
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 245749000.0, "lon": 11.217667, "lat": 57.715333, "speed": 19.2, "course": 290.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 245749000.0, "lon": 11.217667, "lat": 57.715333, "speed": 19.2, "course": 290.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 929, CreateTime = 1717076858782, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2e316fa5)
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219001459.0, "lon": 11.348687, "lat": 54.656807, "speed": 0.1, "course": 327.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219001459.0, "lon": 11.348687, "lat": 54.656807, "speed": 0.1, "course": 327.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 930, CreateTime = 1717076858782, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4acc1aae)
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 220012000.0, "lon": 9.961088, "lat": 57.593908, "speed": 0.1, "course": 317.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 220012000.0, "lon": 9.961088, "lat": 57.593908, "speed": 0.1, "course": 317.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,405 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 931, CreateTime = 1717076858782, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5129833)
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219079000.0, "lon": 7.827008, "lat": 55.488792, "speed": 0.0, "course": 203.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219079000.0, "lon": 7.827008, "lat": 55.488792, "speed": 0.0, "course": 203.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 932, CreateTime = 1717076858782, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4e10fff9)
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 265522220.0, "lon": 11.700578, "lat": 57.70732, "speed": 6.0, "course": 55.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 265522220.0, "lon": 11.700578, "lat": 57.70732, "speed": 6.0, "course": 55.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 933, CreateTime = 1717076858782, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6b79fdd9)
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 304080890.0, "lon": 14.504667, "lat": 55.284667, "speed": 21.6, "course": 37.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 304080890.0, "lon": 14.504667, "lat": 55.284667, "speed": 21.6, "course": 37.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 934, CreateTime = 1717076858782, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@414a8372)
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219000643.0, "lon": 9.7303, "lat": 55.260227, "speed": 0.0, "course": 138.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219000643.0, "lon": 9.7303, "lat": 55.260227, "speed": 0.0, "course": 138.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 935, CreateTime = 1717076858782, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@50085868)
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219001522.0, "lon": 10.585437, "lat": 57.71762, "speed": 0.0, "course": 326.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219001522.0, "lon": 10.585437, "lat": 57.71762, "speed": 0.0, "course": 326.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 936, CreateTime = 1717076858782, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@192e9aa7)
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 265276000.0, "lon": 14.852963, "lat": 54.483963, "speed": 10.6, "course": 303.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 265276000.0, "lon": 14.852963, "lat": 54.483963, "speed": 10.6, "course": 303.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 937, CreateTime = 1717076858782, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3d1d3b6e)
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 2194006.0, "lon": 5.0334, "lat": 55.538917, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 2194006.0, "lon": 5.0334, "lat": 55.538917, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 938, CreateTime = 1717076858782, serialized key size = -1, serialized value size = 109, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@28596eac)
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 212644000.0, "lon": 11.624817, "lat": 57.602933, "speed": 16.3, "course": 97.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 212644000.0, "lon": 11.624817, "lat": 57.602933, "speed": 16.3, "course": 97.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 939, CreateTime = 1717076858783, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3a00a8d7)
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219000181.0, "lon": 10.257507, "lat": 54.942058, "speed": 0.0, "course": 206.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219000181.0, "lon": 10.257507, "lat": 54.942058, "speed": 0.0, "course": 206.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 940, CreateTime = 1717076858783, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5796f692)
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219000827.0, "lon": 8.60105, "lat": 57.12134, "speed": 0.1, "course": 177.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219000827.0, "lon": 8.60105, "lat": 57.12134, "speed": 0.1, "course": 177.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 941, CreateTime = 1717076858783, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3047145)
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219601000.0, "lon": 10.53781, "lat": 55.469842, "speed": 0.0, "course": 310.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219601000.0, "lon": 10.53781, "lat": 55.469842, "speed": 0.0, "course": 310.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 942, CreateTime = 1717076858783, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@604b5387)
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219000592.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219000592.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 943, CreateTime = 1717076858783, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5f320949)
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 265631320.0, "lon": 14.615758, "lat": 55.488392, "speed": 7.9, "course": 185.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 265631320.0, "lon": 14.615758, "lat": 55.488392, "speed": 7.9, "course": 185.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 944, CreateTime = 1717076858783, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3ff0465b)
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 230990000.0, "lon": 11.664932, "lat": 57.673735, "speed": 0.0, "course": 356.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 230990000.0, "lon": 11.664932, "lat": 57.673735, "speed": 0.0, "course": 356.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 945, CreateTime = 1717076858783, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1f5e86b9)
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 2190066.0, "lon": 8.16694, "lat": 56.530083, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,406 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 2190066.0, "lon": 8.16694, "lat": 56.530083, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 946, CreateTime = 1717076858783, serialized key size = -1, serialized value size = 110, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@25b329be)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219000484.0, "lon": 9.755683, "lat": 55.5591, "speed": 0.0, "course": 320.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219000484.0, "lon": 9.755683, "lat": 55.5591, "speed": 0.0, "course": 320.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 947, CreateTime = 1717076858783, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6a040400)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 236561000.0, "lon": 12.997528, "lat": 55.241717, "speed": 11.1, "course": 98.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 236561000.0, "lon": 12.997528, "lat": 55.241717, "speed": 11.1, "course": 98.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 948, CreateTime = 1717076858784, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@57fb5585)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 325423000.0, "lon": 10.619853, "lat": 55.060763, "speed": 0.1, "course": 352.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 325423000.0, "lon": 10.619853, "lat": 55.060763, "speed": 0.1, "course": 352.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 949, CreateTime = 1717076858784, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3cfb7a8d)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 2655146.0, "lon": 12.93794, "lat": 56.790038, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 2655146.0, "lon": 12.93794, "lat": 56.790038, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 950, CreateTime = 1717076858784, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@395a75)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219352000.0, "lon": 10.536175, "lat": 55.471255, "speed": 0.1, "course": 191.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219352000.0, "lon": 10.536175, "lat": 55.471255, "speed": 0.1, "course": 191.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 951, CreateTime = 1717076858784, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4a577a76)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219009267.0, "lon": 11.125878, "lat": 55.332257, "speed": 0.0, "course": 272.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219009267.0, "lon": 11.125878, "lat": 55.332257, "speed": 0.0, "course": 272.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 952, CreateTime = 1717076858784, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@478d59c4)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 211343680.0, "lon": 11.767505, "lat": 54.275642, "speed": 13.1, "course": 59.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 211343680.0, "lon": 11.767505, "lat": 54.275642, "speed": 13.1, "course": 59.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 953, CreateTime = 1717076858784, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@20457caa)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219004838.0, "lon": 11.92872, "lat": 54.571997, "speed": 0.0, "course": 241.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219004838.0, "lon": 11.92872, "lat": 54.571997, "speed": 0.0, "course": 241.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 954, CreateTime = 1717076858784, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6a656025)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 266077000.0, "lon": 11.515007, "lat": 57.76121, "speed": 7.6, "course": 289.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 266077000.0, "lon": 11.515007, "lat": 57.76121, "speed": 7.6, "course": 289.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 955, CreateTime = 1717076858784, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1b1033d5)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 311411000.0, "lon": 13.015605, "lat": 55.180465, "speed": 13.4, "course": 320.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 311411000.0, "lon": 13.015605, "lat": 55.180465, "speed": 13.4, "course": 320.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 956, CreateTime = 1717076858784, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@36fe0a0a)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219014374.0, "lon": 11.101205, "lat": 55.67611, "speed": 0.0, "course": 347.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219014374.0, "lon": 11.101205, "lat": 55.67611, "speed": 0.0, "course": 347.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 957, CreateTime = 1717076858785, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3d559053)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 304010455.0, "lon": 12.805615, "lat": 54.756207, "speed": 7.4, "course": 73.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 304010455.0, "lon": 12.805615, "lat": 54.756207, "speed": 7.4, "course": 73.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 958, CreateTime = 1717076858785, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7cf0ab94)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 277093000.0, "lon": 15.614, "lat": 54.686833, "speed": 16.7, "course": 79.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 277093000.0, "lon": 15.614, "lat": 54.686833, "speed": 16.7, "course": 79.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 959, CreateTime = 1717076858785, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@66e4b144)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 218159000.0, "lon": 10.34531, "lat": 56.97055, "speed": 7.8, "course": 305.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 218159000.0, "lon": 10.34531, "lat": 56.97055, "speed": 7.8, "course": 305.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 960, CreateTime = 1717076858785, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@200c59c8)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 377411000.0, "lon": 14.375833, "lat": 55.270167, "speed": 11.0, "course": 218.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 377411000.0, "lon": 14.375833, "lat": 55.270167, "speed": 11.0, "course": 218.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 961, CreateTime = 1717076858785, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@31ca9292)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 273356200.0, "lon": 10.302957, "lat": 57.7809, "speed": 8.6, "course": 263.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 273356200.0, "lon": 10.302957, "lat": 57.7809, "speed": 8.6, "course": 263.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 962, CreateTime = 1717076858785, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@489f2334)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 244446000.0, "lon": 8.566393, "lat": 55.087777, "speed": 0.0, "course": 184.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 244446000.0, "lon": 8.566393, "lat": 55.087777, "speed": 0.0, "course": 184.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 963, CreateTime = 1717076858785, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@b32d5f2)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 357078000.0, "lon": 5.36735, "lat": 55.256467, "speed": 13.5, "course": 210.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 357078000.0, "lon": 5.36735, "lat": 55.256467, "speed": 13.5, "course": 210.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 964, CreateTime = 1717076858785, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@49321f45)
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 2190071.0, "lon": 8.648272, "lat": 57.110037, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,407 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 2190071.0, "lon": 8.648272, "lat": 57.110037, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 965, CreateTime = 1717076858785, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2c894af3)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 304117000.0, "lon": 11.3855, "lat": 57.565167, "speed": 12.0, "course": 182.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 304117000.0, "lon": 11.3855, "lat": 57.565167, "speed": 12.0, "course": 182.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 966, CreateTime = 1717076858785, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1dbe5ad5)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 212130000.0, "lon": 11.784737, "lat": 56.925183, "speed": 14.4, "course": 341.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 212130000.0, "lon": 11.784737, "lat": 56.925183, "speed": 14.4, "course": 341.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 967, CreateTime = 1717076858785, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3e81d5)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219005662.0, "lon": 12.613788, "lat": 56.0427, "speed": 0.1, "course": 205.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219005662.0, "lon": 12.613788, "lat": 56.0427, "speed": 0.1, "course": 205.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 968, CreateTime = 1717076858785, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@592f7ea0)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 2614800.0, "lon": 14.580335, "lat": 53.981455, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 2614800.0, "lon": 14.580335, "lat": 53.981455, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 969, CreateTime = 1717076858785, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3f1769a4)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 257182000.0, "lon": 11.531582, "lat": 57.358675, "speed": 15.8, "course": 336.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 257182000.0, "lon": 11.531582, "lat": 57.358675, "speed": 15.8, "course": 336.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 970, CreateTime = 1717076858785, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5090f461)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 2655120.0, "lon": 16.45493, "lat": 56.233643, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 2655120.0, "lon": 16.45493, "lat": 56.233643, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 971, CreateTime = 1717076858786, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2454f78f)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 220205000.0, "lon": 12.466705, "lat": 54.95202, "speed": 0.0, "course": 137.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 220205000.0, "lon": 12.466705, "lat": 54.95202, "speed": 0.0, "course": 137.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 972, CreateTime = 1717076858786, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@62c57db)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 2190068.0, "lon": 10.945855, "lat": 56.447273, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 2190068.0, "lon": 10.945855, "lat": 56.447273, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 973, CreateTime = 1717076858786, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2f254f3)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 248980000.0, "lon": 12.095515, "lat": 54.435943, "speed": 17.5, "course": 264.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 248980000.0, "lon": 12.095515, "lat": 54.435943, "speed": 17.5, "course": 264.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 974, CreateTime = 1717076858786, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@55969b30)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 212675000.0, "lon": 11.4328, "lat": 57.457983, "speed": 16.3, "course": 339.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 212675000.0, "lon": 11.4328, "lat": 57.457983, "speed": 16.3, "course": 339.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 975, CreateTime = 1717076858786, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@56fdf682)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219000195.0, "lon": 12.43972, "lat": 55.056557, "speed": 2.1, "course": 136.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219000195.0, "lon": 12.43972, "lat": 55.056557, "speed": 2.1, "course": 136.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 976, CreateTime = 1717076858786, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@328bf109)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 231059000.0, "lon": 10.523423, "lat": 54.853007, "speed": 0.0, "course": 318.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 231059000.0, "lon": 10.523423, "lat": 54.853007, "speed": 0.0, "course": 318.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 977, CreateTime = 1717076858786, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@224e6e67)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 259769000.0, "lon": 13.05775, "lat": 54.819777, "speed": 13.9, "course": 70.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 259769000.0, "lon": 13.05775, "lat": 54.819777, "speed": 13.9, "course": 70.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 978, CreateTime = 1717076858786, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@43e02e05)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 265200000.0, "lon": 11.24065, "lat": 56.159667, "speed": 20.0, "course": 227.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 265200000.0, "lon": 11.24065, "lat": 56.159667, "speed": 20.0, "course": 227.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 979, CreateTime = 1717076858786, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7a90891d)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219005313.0, "lon": 10.214983, "lat": 56.152283, "speed": 0.0, "course": 234.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219005313.0, "lon": 10.214983, "lat": 56.152283, "speed": 0.0, "course": 234.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 980, CreateTime = 1717076858787, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@17fe3cff)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 220620000.0, "lon": 9.416197, "lat": 57.817188, "speed": 13.7, "course": 267.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 220620000.0, "lon": 9.416197, "lat": 57.817188, "speed": 13.7, "course": 267.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 981, CreateTime = 1717076858787, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@46125531)
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 259894000.0, "lon": 15.217843, "lat": 55.639162, "speed": 14.5, "course": 240.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,408 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 259894000.0, "lon": 15.217843, "lat": 55.639162, "speed": 14.5, "course": 240.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 982, CreateTime = 1717076858787, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4c0dbf0)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 236189000.0, "lon": 10.221, "lat": 56.1445, "speed": 0.0, "course": 223.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 236189000.0, "lon": 10.221, "lat": 56.1445, "speed": 0.0, "course": 223.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 983, CreateTime = 1717076858787, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7ae67214)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 211215340.0, "lon": 11.636872, "lat": 54.386723, "speed": 10.4, "course": 131.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 211215340.0, "lon": 11.636872, "lat": 54.386723, "speed": 10.4, "course": 131.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 984, CreateTime = 1717076858787, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1c19a073)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 2655140.0, "lon": 12.708197, "lat": 56.053337, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 2655140.0, "lon": 12.708197, "lat": 56.053337, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 985, CreateTime = 1717076858787, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@48f6d51c)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 211910000.0, "lon": 8.246483, "lat": 57.0548, "speed": 23.5, "course": 39.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 211910000.0, "lon": 8.246483, "lat": 57.0548, "speed": 23.5, "course": 39.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 986, CreateTime = 1717076858787, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4a6b88a9)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219008474.0, "lon": 9.954283, "lat": 57.591617, "speed": 0.0, "course": 359.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219008474.0, "lon": 9.954283, "lat": 57.591617, "speed": 0.0, "course": 359.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 987, CreateTime = 1717076858787, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3542522)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219338000.0, "lon": 8.415328, "lat": 55.475345, "speed": 0.0, "course": 11.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219338000.0, "lon": 8.415328, "lat": 55.475345, "speed": 0.0, "course": 11.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 988, CreateTime = 1717076858787, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@521f0703)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 211190000.0, "lon": 11.279622, "lat": 54.586818, "speed": 14.8, "course": 203.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 211190000.0, "lon": 11.279622, "lat": 54.586818, "speed": 14.8, "course": 203.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 989, CreateTime = 1717076858787, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2c3f6669)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 244996000.0, "lon": 10.736067, "lat": 55.781717, "speed": 12.8, "course": 46.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 244996000.0, "lon": 10.736067, "lat": 55.781717, "speed": 12.8, "course": 46.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 990, CreateTime = 1717076858787, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3a078d87)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 353531000.0, "lon": 7.209733, "lat": 56.084317, "speed": 13.1, "course": 21.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 353531000.0, "lon": 7.209733, "lat": 56.084317, "speed": 13.1, "course": 21.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 991, CreateTime = 1717076858787, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@18d8c2d0)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219948000.0, "lon": 7.899267, "lat": 57.438885, "speed": 2.9, "course": 31.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219948000.0, "lon": 7.899267, "lat": 57.438885, "speed": 2.9, "course": 31.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 992, CreateTime = 1717076858788, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3255e9d7)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 235004750.0, "lon": 10.583512, "lat": 57.71512, "speed": 0.0, "course": 65.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 235004750.0, "lon": 10.583512, "lat": 57.71512, "speed": 0.0, "course": 65.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 993, CreateTime = 1717076858788, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@658ecdda)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 311026000.0, "lon": 6.851132, "lat": 55.541618, "speed": 9.7, "course": 160.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 311026000.0, "lon": 6.851132, "lat": 55.541618, "speed": 9.7, "course": 160.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 994, CreateTime = 1717076858788, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@63e30f59)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219525000.0, "lon": 10.536968, "lat": 57.433462, "speed": 0.0, "course": 127.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219525000.0, "lon": 10.536968, "lat": 57.433462, "speed": 0.0, "course": 127.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 995, CreateTime = 1717076858788, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3d739fb7)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 211629000.0, "lon": 10.513942, "lat": 55.577163, "speed": 9.6, "course": 147.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 211629000.0, "lon": 10.513942, "lat": 55.577163, "speed": 9.6, "course": 147.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 996, CreateTime = 1717076858788, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@20f5c29f)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 211518140.0, "lon": 7.468258, "lat": 55.391337, "speed": 3.3, "course": 88.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 211518140.0, "lon": 7.468258, "lat": 55.391337, "speed": 3.3, "course": 88.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 997, CreateTime = 1717076858788, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@33863b46)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 219000961.0, "lon": 10.833657, "lat": 54.93389, "speed": 0.0, "course": 333.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 219000961.0, "lon": 10.833657, "lat": 54.93389, "speed": 0.0, "course": 333.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 998, CreateTime = 1717076858788, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@48e473a8)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 250002012.0, "lon": 11.898023, "lat": 56.799595, "speed": 14.7, "course": 339.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 250002012.0, "lon": 11.898023, "lat": 56.799595, "speed": 14.7, "course": 339.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 999, CreateTime = 1717076858788, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@694bd324)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Current fetch is finished.
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitting records from fetch for split aisdata-0
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 311007200.0, "lon": 14.134872, "lat": 54.34483, "speed": 15.5, "course": 339.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 311007200.0, "lon": 14.134872, "lat": 54.34483, "speed": 15.5, "course": 339.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1000, CreateTime = 1717076858788, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@672405a8)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 3638.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 3638.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1001, CreateTime = 1717076858791, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@65fa4e01)
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 212636000.0, "lon": 11.968833, "lat": 54.4365, "speed": 14.4, "course": 269.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,409 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 212636000.0, "lon": 11.968833, "lat": 54.4365, "speed": 14.4, "course": 269.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1002, CreateTime = 1717076858792, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@ee80825)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 236213000.0, "lon": 11.873283, "lat": 57.690517, "speed": 0.0, "course": 347.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 236213000.0, "lon": 11.873283, "lat": 57.690517, "speed": 0.0, "course": 347.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1003, CreateTime = 1717076858792, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@390d282f)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 211222710.0, "lon": 10.155975, "lat": 54.370323, "speed": 0.0, "course": 321.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 211222710.0, "lon": 10.155975, "lat": 54.370323, "speed": 0.0, "course": 321.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1004, CreateTime = 1717076858792, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7ec363e3)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 245882000.0, "lon": 10.037583, "lat": 56.68245, "speed": 0.0, "course": 3.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 245882000.0, "lon": 10.037583, "lat": 56.68245, "speed": 0.0, "course": 3.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1005, CreateTime = 1717076858792, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@49feb07c)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 211800000.0, "lon": 11.42475, "lat": 57.220015, "speed": 9.4, "course": 159.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 211800000.0, "lon": 11.42475, "lat": 57.220015, "speed": 9.4, "course": 159.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1006, CreateTime = 1717076858792, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7193046)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 249127000.0, "lon": 7.832337, "lat": 56.931417, "speed": 9.4, "course": 239.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 249127000.0, "lon": 7.832337, "lat": 56.931417, "speed": 9.4, "course": 239.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1007, CreateTime = 1717076858792, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@57052cda)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 2573115.0, "lon": 9.7, "lat": 59.233333, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 2573115.0, "lon": 9.7, "lat": 59.233333, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1008, CreateTime = 1717076858792, serialized key size = -1, serialized value size = 106, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@323c81a2)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 2655185.0, "lon": 14.775318, "lat": 56.22696, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 2655185.0, "lon": 14.775318, "lat": 56.22696, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1009, CreateTime = 1717076858793, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@efdbac9)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:10", "mmsi": 244759000.0, "lon": 8.040485, "lat": 55.093403, "speed": 9.0, "course": 272.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:10", "mmsi": 244759000.0, "lon": 8.040485, "lat": 55.093403, "speed": 9.0, "course": 272.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1010, CreateTime = 1717076858793, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@40a82050)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 211904000.0, "lon": 11.06872, "lat": 56.467697, "speed": 7.5, "course": 168.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 211904000.0, "lon": 11.06872, "lat": 56.467697, "speed": 7.5, "course": 168.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1011, CreateTime = 1717076858793, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3eb5a763)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219004266.0, "lon": 8.222577, "lat": 56.705305, "speed": 0.0, "course": 344.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219004266.0, "lon": 8.222577, "lat": 56.705305, "speed": 0.0, "course": 344.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1012, CreateTime = 1717076858793, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@68d21086)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 211231520.0, "lon": 10.162833, "lat": 54.342167, "speed": 6.6, "course": 179.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 211231520.0, "lon": 10.162833, "lat": 54.342167, "speed": 6.6, "course": 179.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1013, CreateTime = 1717076858793, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@b1ad4a7)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 304010514.0, "lon": 10.83635, "lat": 54.568178, "speed": 11.9, "course": 83.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 304010514.0, "lon": 10.83635, "lat": 54.568178, "speed": 11.9, "course": 83.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1014, CreateTime = 1717076858793, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@a31df34)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 304010928.0, "lon": 10.904767, "lat": 57.703383, "speed": 10.9, "course": 138.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 304010928.0, "lon": 10.904767, "lat": 57.703383, "speed": 10.9, "course": 138.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1015, CreateTime = 1717076858793, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@19acffae)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219009273.0, "lon": 8.598383, "lat": 57.122583, "speed": 1.6, "course": 3.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219009273.0, "lon": 8.598383, "lat": 57.122583, "speed": 1.6, "course": 3.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1016, CreateTime = 1717076858793, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@61829a3d)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219440000.0, "lon": 4.228428, "lat": 56.07843, "speed": 0.1, "course": 280.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219440000.0, "lon": 4.228428, "lat": 56.07843, "speed": 0.1, "course": 280.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1017, CreateTime = 1717076858793, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3ce0d546)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219001362.0, "lon": 10.616185, "lat": 55.061988, "speed": 0.0, "course": 339.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219001362.0, "lon": 10.616185, "lat": 55.061988, "speed": 0.0, "course": 339.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1018, CreateTime = 1717076858793, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@382c6591)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 304822000.0, "lon": 9.436685, "lat": 54.798183, "speed": 0.0, "course": 63.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 304822000.0, "lon": 9.436685, "lat": 54.798183, "speed": 0.0, "course": 63.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1019, CreateTime = 1717076858793, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4683bcb5)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 265874000.0, "lon": 12.247205, "lat": 54.517372, "speed": 12.9, "course": 19.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 265874000.0, "lon": 12.247205, "lat": 54.517372, "speed": 12.9, "course": 19.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1020, CreateTime = 1717076858793, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3325852a)
2024-05-30 15:47:40 2024-05-30 13:47:40,410 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219000373.0, "lon": 10.53715, "lat": 56.077817, "speed": 17.1, "course": 315.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219000373.0, "lon": 10.53715, "lat": 56.077817, "speed": 17.1, "course": 315.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1021, CreateTime = 1717076858793, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@9552ced)
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219004647.0, "lon": 12.093075, "lat": 54.172678, "speed": 0.0, "course": 320.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219004647.0, "lon": 12.093075, "lat": 54.172678, "speed": 0.0, "course": 320.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1022, CreateTime = 1717076858793, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@520ec0bb)
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219000733.0, "lon": 10.259517, "lat": 54.941767, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219000733.0, "lon": 10.259517, "lat": 54.941767, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1023, CreateTime = 1717076858794, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@9b3b85b)
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 319562000.0, "lon": 14.70985, "lat": 55.320317, "speed": 13.1, "course": 229.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 319562000.0, "lon": 14.70985, "lat": 55.320317, "speed": 13.1, "course": 229.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1024, CreateTime = 1717076858795, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@16a07092)
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 273315800.0, "lon": 15.141565, "lat": 54.350972, "speed": 4.8, "course": 239.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 273315800.0, "lon": 15.141565, "lat": 54.350972, "speed": 4.8, "course": 239.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1025, CreateTime = 1717076858795, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@363214ef)
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 636011573.0, "lon": 12.217817, "lat": 54.545467, "speed": 11.5, "course": 198.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 636011573.0, "lon": 12.217817, "lat": 54.545467, "speed": 11.5, "course": 198.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1026, CreateTime = 1717076858795, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@121d018a)
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219003103.0, "lon": 11.684998, "lat": 57.369353, "speed": 0.2, "course": 158.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219003103.0, "lon": 11.684998, "lat": 57.369353, "speed": 0.2, "course": 158.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1027, CreateTime = 1717076858795, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@67812f2)
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 212097000.0, "lon": 10.897935, "lat": 54.909658, "speed": 11.1, "course": 14.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 212097000.0, "lon": 10.897935, "lat": 54.909658, "speed": 11.1, "course": 14.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1028, CreateTime = 1717076858796, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@13c9d64f)
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 233150000.0, "lon": 15.699133, "lat": 55.727817, "speed": 14.4, "course": 62.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 233150000.0, "lon": 15.699133, "lat": 55.727817, "speed": 14.4, "course": 62.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1029, CreateTime = 1717076858796, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@35fa3db5)
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 265410000.0, "lon": 11.604697, "lat": 57.607823, "speed": 17.1, "course": 252.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 265410000.0, "lon": 11.604697, "lat": 57.607823, "speed": 17.1, "course": 252.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1030, CreateTime = 1717076858796, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4f117bd1)
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 230964000.0, "lon": 15.791965, "lat": 55.734478, "speed": 14.0, "course": 62.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 230964000.0, "lon": 15.791965, "lat": 55.734478, "speed": 14.0, "course": 62.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1031, CreateTime = 1717076858796, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@9380f43)
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 2190047.0, "lon": 12.613717, "lat": 55.69725, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 2190047.0, "lon": 12.613717, "lat": 55.69725, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1032, CreateTime = 1717076858796, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@549edb85)
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219001789.0, "lon": 11.082632, "lat": 55.677527, "speed": 0.0, "course": 146.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219001789.0, "lon": 11.082632, "lat": 55.677527, "speed": 0.0, "course": 146.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1033, CreateTime = 1717076858796, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@306d4336)
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 257723000.0, "lon": 7.108693, "lat": 55.51008, "speed": 14.0, "course": 281.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 257723000.0, "lon": 7.108693, "lat": 55.51008, "speed": 14.0, "course": 281.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1034, CreateTime = 1717076858796, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@74e67919)
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 265511440.0, "lon": 11.667133, "lat": 57.62178, "speed": 17.8, "course": 70.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,411 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 265511440.0, "lon": 11.667133, "lat": 57.62178, "speed": 17.8, "course": 70.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1035, CreateTime = 1717076858796, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3d6d22d1)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 265610950.0, "lon": 12.997303, "lat": 55.613713, "speed": 0.0, "course": 129.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 265610950.0, "lon": 12.997303, "lat": 55.613713, "speed": 0.0, "course": 129.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1036, CreateTime = 1717076858796, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1f0d840a)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 211430000.0, "lon": 11.190893, "lat": 54.421613, "speed": 0.0, "course": 176.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 211430000.0, "lon": 11.190893, "lat": 54.421613, "speed": 0.0, "course": 176.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1037, CreateTime = 1717076858797, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4523102e)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 2190065.0, "lon": 8.115162, "lat": 55.56072, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 2190065.0, "lon": 8.115162, "lat": 55.56072, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1038, CreateTime = 1717076858797, serialized key size = -1, serialized value size = 110, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@24a9722)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219000647.0, "lon": 8.424303, "lat": 55.471773, "speed": 0.1, "course": 0.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219000647.0, "lon": 8.424303, "lat": 55.471773, "speed": 0.1, "course": 0.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1039, CreateTime = 1717076858797, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@56e55610)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219005504.0, "lon": 12.589083, "lat": 55.67635, "speed": 0.0, "course": 23.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219005504.0, "lon": 12.589083, "lat": 55.67635, "speed": 0.0, "course": 23.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1040, CreateTime = 1717076858797, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@253ba512)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219008996.0, "lon": 12.611995, "lat": 55.695557, "speed": 0.0, "course": 47.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219008996.0, "lon": 12.611995, "lat": 55.695557, "speed": 0.0, "course": 47.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1041, CreateTime = 1717076858797, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@784473fb)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 2655130.0, "lon": 14.158075, "lat": 55.668102, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 2655130.0, "lon": 14.158075, "lat": 55.668102, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1042, CreateTime = 1717076858797, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2e610856)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 265418000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 265418000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1043, CreateTime = 1717076858797, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@52489e5c)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 245914000.0, "lon": 7.984233, "lat": 55.128183, "speed": 3.1, "course": 129.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 245914000.0, "lon": 7.984233, "lat": 55.128183, "speed": 3.1, "course": 129.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1044, CreateTime = 1717076858797, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2a23a232)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 230007000.0, "lon": 6.394167, "lat": 56.027833, "speed": 19.2, "course": 224.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 230007000.0, "lon": 6.394167, "lat": 56.027833, "speed": 19.2, "course": 224.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1045, CreateTime = 1717076858797, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@71a3c726)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 246043000.0, "lon": 11.910083, "lat": 56.709333, "speed": 14.7, "course": 168.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 246043000.0, "lon": 11.910083, "lat": 56.709333, "speed": 14.7, "course": 168.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1046, CreateTime = 1717076858797, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@572642fc)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 277339000.0, "lon": 15.612968, "lat": 54.976693, "speed": 20.4, "course": 74.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 277339000.0, "lon": 15.612968, "lat": 54.976693, "speed": 20.4, "course": 74.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1047, CreateTime = 1717076858797, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@410a8c3a)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219010252.0, "lon": 10.618402, "lat": 57.712412, "speed": 0.1, "course": 315.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219010252.0, "lon": 10.618402, "lat": 57.712412, "speed": 0.1, "course": 315.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1048, CreateTime = 1717076858799, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@768f941b)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 266203000.0, "lon": 10.663003, "lat": 57.67751, "speed": 0.0, "course": 291.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 266203000.0, "lon": 10.663003, "lat": 57.67751, "speed": 0.0, "course": 291.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1049, CreateTime = 1717076858799, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@19faf71b)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 235034149.0, "lon": 12.1405, "lat": 54.4335, "speed": 14.8, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 235034149.0, "lon": 12.1405, "lat": 54.4335, "speed": 14.8, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1050, CreateTime = 1717076858800, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7cae777a)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 261006470.0, "lon": 14.373462, "lat": 54.020002, "speed": 8.2, "course": 34.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 261006470.0, "lon": 14.373462, "lat": 54.020002, "speed": 8.2, "course": 34.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1051, CreateTime = 1717076858800, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@69505f89)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 265457000.0, "lon": 11.0252, "lat": 56.49275, "speed": 12.6, "course": 7.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 265457000.0, "lon": 11.0252, "lat": 56.49275, "speed": 12.6, "course": 7.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1052, CreateTime = 1717076858800, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@637531f4)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 265527470.0, "lon": 12.546045, "lat": 56.199235, "speed": 0.0, "course": 7.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 265527470.0, "lon": 12.546045, "lat": 56.199235, "speed": 0.0, "course": 7.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1053, CreateTime = 1717076858800, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2d7950ae)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 257983000.0, "lon": 7.449118, "lat": 57.184188, "speed": 14.5, "course": 245.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 257983000.0, "lon": 7.449118, "lat": 57.184188, "speed": 14.5, "course": 245.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1054, CreateTime = 1717076858800, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@22e3e7dc)
2024-05-30 15:47:40 2024-05-30 13:47:40,412 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 215729000.0, "lon": 12.629985, "lat": 54.62705, "speed": 1.0, "course": 57.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 215729000.0, "lon": 12.629985, "lat": 54.62705, "speed": 1.0, "course": 57.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1055, CreateTime = 1717076858800, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@49a4481e)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 211265530.0, "lon": 14.959833, "lat": 55.474333, "speed": 15.0, "course": 59.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 211265530.0, "lon": 14.959833, "lat": 55.474333, "speed": 15.0, "course": 59.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1056, CreateTime = 1717076858800, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3942a4f)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 245461000.0, "lon": 12.938767, "lat": 55.6885, "speed": 0.0, "course": 315.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 245461000.0, "lon": 12.938767, "lat": 55.6885, "speed": 0.0, "course": 315.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1057, CreateTime = 1717076858800, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@648fe6b3)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 211227550.0, "lon": 11.191467, "lat": 54.419717, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 211227550.0, "lon": 11.191467, "lat": 54.419717, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1058, CreateTime = 1717076858801, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@59ef30f9)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 265260000.0, "lon": 10.865683, "lat": 54.74095, "speed": 11.0, "course": 174.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 265260000.0, "lon": 10.865683, "lat": 54.74095, "speed": 11.0, "course": 174.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1059, CreateTime = 1717076858801, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@32607762)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219002827.0, "lon": 10.587308, "lat": 57.71749, "speed": 0.0, "course": 332.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219002827.0, "lon": 10.587308, "lat": 57.71749, "speed": 0.0, "course": 332.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1060, CreateTime = 1717076858801, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1084f533)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 235011250.0, "lon": 12.885, "lat": 54.797833, "speed": 17.4, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 235011250.0, "lon": 12.885, "lat": 54.797833, "speed": 17.4, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1061, CreateTime = 1717076858801, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@b2523ee)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219000543.0, "lon": 10.505278, "lat": 57.492045, "speed": 0.0, "course": 233.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219000543.0, "lon": 10.505278, "lat": 57.492045, "speed": 0.0, "course": 233.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1062, CreateTime = 1717076858801, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2beda28b)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219005502.0, "lon": 10.586548, "lat": 57.717812, "speed": 0.0, "course": 317.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219005502.0, "lon": 10.586548, "lat": 57.717812, "speed": 0.0, "course": 317.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1063, CreateTime = 1717076858801, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1a871bf3)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 2190076.0, "lon": 9.502135, "lat": 55.674682, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 2190076.0, "lon": 9.502135, "lat": 55.674682, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1064, CreateTime = 1717076858801, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2d1d48fd)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 258808000.0, "lon": 12.69685, "lat": 55.63085, "speed": 12.3, "course": 358.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 258808000.0, "lon": 12.69685, "lat": 55.63085, "speed": 12.3, "course": 358.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1065, CreateTime = 1717076858801, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@f8524e3)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 992191520.0, "lon": 4.908132, "lat": 55.530932, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 992191520.0, "lon": 4.908132, "lat": 55.530932, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1066, CreateTime = 1717076858801, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@493a3662)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 273416080.0, "lon": 11.272605, "lat": 57.523782, "speed": 9.1, "course": 296.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 273416080.0, "lon": 11.272605, "lat": 57.523782, "speed": 9.1, "course": 296.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1067, CreateTime = 1717076858801, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6bc0f435)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219461000.0, "lon": 12.042337, "lat": 54.892267, "speed": 0.0, "course": 286.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219461000.0, "lon": 12.042337, "lat": 54.892267, "speed": 0.0, "course": 286.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1068, CreateTime = 1717076858801, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2c5d0310)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 211397660.0, "lon": 11.639893, "lat": 57.104068, "speed": 13.0, "course": 160.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 211397660.0, "lon": 11.639893, "lat": 57.104068, "speed": 13.0, "course": 160.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1069, CreateTime = 1717076858801, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@a598844)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 304010723.0, "lon": 9.506247, "lat": 57.547048, "speed": 10.2, "course": 242.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 304010723.0, "lon": 9.506247, "lat": 57.547048, "speed": 10.2, "course": 242.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1070, CreateTime = 1717076858801, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@12c8264b)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 215140000.0, "lon": 15.208397, "lat": 55.567458, "speed": 12.6, "course": 58.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 215140000.0, "lon": 15.208397, "lat": 55.567458, "speed": 12.6, "course": 58.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1071, CreateTime = 1717076858802, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7ec5197b)
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219294000.0, "lon": 8.598445, "lat": 57.121718, "speed": 0.0, "course": 346.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,413 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219294000.0, "lon": 8.598445, "lat": 57.121718, "speed": 0.0, "course": 346.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1072, CreateTime = 1717076858802, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3ac4d030)
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219689000.0, "lon": 8.2225, "lat": 56.6983, "speed": 0.0, "course": 342.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219689000.0, "lon": 8.2225, "lat": 56.6983, "speed": 0.0, "course": 342.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1073, CreateTime = 1717076858802, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7c196484)
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219005059.0, "lon": 11.92798, "lat": 54.572725, "speed": 0.0, "course": 100.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219005059.0, "lon": 11.92798, "lat": 54.572725, "speed": 0.0, "course": 100.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1074, CreateTime = 1717076858802, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2fb0ff32)
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 377664000.0, "lon": 12.422757, "lat": 55.477638, "speed": 0.0, "course": 207.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 377664000.0, "lon": 12.422757, "lat": 55.477638, "speed": 0.0, "course": 207.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1075, CreateTime = 1717076858802, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@79e8257e)
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219002682.0, "lon": 12.61457, "lat": 56.042895, "speed": 0.0, "course": 319.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219002682.0, "lon": 12.61457, "lat": 56.042895, "speed": 0.0, "course": 319.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1076, CreateTime = 1717076858802, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@65b12f23)
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 257689000.0, "lon": 12.236515, "lat": 54.45722, "speed": 14.8, "course": 27.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 257689000.0, "lon": 12.236515, "lat": 54.45722, "speed": 14.8, "course": 27.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1077, CreateTime = 1717076858802, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@52bb4a55)
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 235035113.0, "lon": 12.61044, "lat": 55.199653, "speed": 14.9, "course": 175.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 235035113.0, "lon": 12.61044, "lat": 55.199653, "speed": 14.9, "course": 175.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1078, CreateTime = 1717076858802, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7ada765f)
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 225388000.0, "lon": 12.09861, "lat": 54.446933, "speed": 10.2, "course": 251.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 225388000.0, "lon": 12.09861, "lat": 54.446933, "speed": 10.2, "course": 251.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1079, CreateTime = 1717076858802, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@42a17faf)
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219001751.0, "lon": 8.598033, "lat": 57.1227, "speed": 0.0, "course": 198.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219001751.0, "lon": 8.598033, "lat": 57.1227, "speed": 0.0, "course": 198.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1080, CreateTime = 1717076858802, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2e0588ef)
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 564698000.0, "lon": 9.546603, "lat": 57.723102, "speed": 11.7, "course": 256.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 564698000.0, "lon": 9.546603, "lat": 57.723102, "speed": 11.7, "course": 256.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1081, CreateTime = 1717076858802, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@26e48698)
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 211188000.0, "lon": 11.24175, "lat": 54.517927, "speed": 14.7, "course": 24.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 211188000.0, "lon": 11.24175, "lat": 54.517927, "speed": 14.7, "course": 24.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1082, CreateTime = 1717076858804, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@fa56495)
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 220253000.0, "lon": 11.345395, "lat": 57.670252, "speed": 20.7, "course": 293.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 220253000.0, "lon": 11.345395, "lat": 57.670252, "speed": 20.7, "course": 293.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1083, CreateTime = 1717076858804, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@46b03ec9)
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219262000.0, "lon": 11.13173, "lat": 55.334237, "speed": 0.0, "course": 99.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219262000.0, "lon": 11.13173, "lat": 55.334237, "speed": 0.0, "course": 99.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1084, CreateTime = 1717076858804, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@44f08400)
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219015103.0, "lon": 13.85075, "lat": 54.923107, "speed": 2.9, "course": 229.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219015103.0, "lon": 13.85075, "lat": 54.923107, "speed": 2.9, "course": 229.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1085, CreateTime = 1717076858804, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@46221a40)
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 211247340.0, "lon": 9.715367, "lat": 54.318483, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,414 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 211247340.0, "lon": 9.715367, "lat": 54.318483, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1086, CreateTime = 1717076858804, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@62875fdd)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 220046000.0, "lon": 9.961408, "lat": 57.593753, "speed": 0.0, "course": 20.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 220046000.0, "lon": 9.961408, "lat": 57.593753, "speed": 0.0, "course": 20.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1087, CreateTime = 1717076858804, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@25066332)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219000431.0, "lon": 11.349992, "lat": 54.653482, "speed": 0.0, "course": 210.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219000431.0, "lon": 11.349992, "lat": 54.653482, "speed": 0.0, "course": 210.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1088, CreateTime = 1717076858804, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@65162316)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219159000.0, "lon": 11.086, "lat": 55.677333, "speed": 0.0, "course": 311.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219159000.0, "lon": 11.086, "lat": 55.677333, "speed": 0.0, "course": 311.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1089, CreateTime = 1717076858804, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@33b0c5ee)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 636091854.0, "lon": 12.309218, "lat": 54.6471, "speed": 16.8, "course": 225.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 636091854.0, "lon": 12.309218, "lat": 54.6471, "speed": 16.8, "course": 225.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1090, CreateTime = 1717076858804, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6b910df2)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219009537.0, "lon": 8.224755, "lat": 56.702655, "speed": 0.0, "course": 334.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219009537.0, "lon": 8.224755, "lat": 56.702655, "speed": 0.0, "course": 334.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1091, CreateTime = 1717076858804, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7d18ec41)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 211216490.0, "lon": 12.167, "lat": 54.291667, "speed": 5.6, "course": 39.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 211216490.0, "lon": 12.167, "lat": 54.291667, "speed": 5.6, "course": 39.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1092, CreateTime = 1717076858805, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@29c26e67)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 246162000.0, "lon": 12.842547, "lat": 56.652068, "speed": 5.1, "course": 80.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 246162000.0, "lon": 12.842547, "lat": 56.652068, "speed": 5.1, "course": 80.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1093, CreateTime = 1717076858805, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1ce84104)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219006382.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219006382.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1094, CreateTime = 1717076858805, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7ff531f6)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 211410690.0, "lon": 11.492013, "lat": 57.168068, "speed": 9.5, "course": 150.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 211410690.0, "lon": 11.492013, "lat": 57.168068, "speed": 9.5, "course": 150.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1095, CreateTime = 1717076858805, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@45b5a0ad)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 376474000.0, "lon": 12.675892, "lat": 55.764925, "speed": 8.8, "course": 180.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 376474000.0, "lon": 12.675892, "lat": 55.764925, "speed": 8.8, "course": 180.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1096, CreateTime = 1717076858805, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7f3e4f2a)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 2190069.0, "lon": 9.824122, "lat": 57.003822, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 2190069.0, "lon": 9.824122, "lat": 57.003822, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1097, CreateTime = 1717076858805, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2100c1a8)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219001555.0, "lon": 12.615175, "lat": 56.042518, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219001555.0, "lon": 12.615175, "lat": 56.042518, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1098, CreateTime = 1717076858805, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@77ac2eff)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 304936000.0, "lon": 12.644828, "lat": 55.899315, "speed": 11.3, "course": 160.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 304936000.0, "lon": 12.644828, "lat": 55.899315, "speed": 11.3, "course": 160.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1099, CreateTime = 1717076858805, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1ff4586f)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 209642000.0, "lon": 10.721212, "lat": 57.4182, "speed": 11.0, "course": 3.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 209642000.0, "lon": 10.721212, "lat": 57.4182, "speed": 11.0, "course": 3.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1100, CreateTime = 1717076858805, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@123e13a4)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219000603.0, "lon": 8.439733, "lat": 55.4608, "speed": 0.0, "course": 210.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219000603.0, "lon": 8.439733, "lat": 55.4608, "speed": 0.0, "course": 210.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1101, CreateTime = 1717076858805, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@35949dca)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 220018000.0, "lon": 11.664167, "lat": 54.4756, "speed": 10.5, "course": 285.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 220018000.0, "lon": 11.664167, "lat": 54.4756, "speed": 10.5, "course": 285.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1102, CreateTime = 1717076858805, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@23598651)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 211369090.0, "lon": 13.154195, "lat": 55.00707, "speed": 0.0, "course": 315.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 211369090.0, "lon": 13.154195, "lat": 55.00707, "speed": 0.0, "course": 315.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1103, CreateTime = 1717076858805, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1e538575)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 236407000.0, "lon": 9.639198, "lat": 57.763912, "speed": 13.1, "course": 74.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 236407000.0, "lon": 9.639198, "lat": 57.763912, "speed": 13.1, "course": 74.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1104, CreateTime = 1717076858805, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7c120628)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 2655135.0, "lon": 13.270358, "lat": 55.478317, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 2655135.0, "lon": 13.270358, "lat": 55.478317, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1105, CreateTime = 1717076858805, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d79bead)
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219945000.0, "lon": 11.314878, "lat": 57.711238, "speed": 17.2, "course": 154.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,415 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219945000.0, "lon": 11.314878, "lat": 57.711238, "speed": 17.2, "course": 154.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1106, CreateTime = 1717076858805, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@27dd65d)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 211230400.0, "lon": 11.263833, "lat": 54.581, "speed": 10.1, "course": 292.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 211230400.0, "lon": 11.263833, "lat": 54.581, "speed": 10.1, "course": 292.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1107, CreateTime = 1717076858806, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7834a)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 304010714.0, "lon": 13.2788, "lat": 54.7096, "speed": 11.8, "course": 265.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 304010714.0, "lon": 13.2788, "lat": 54.7096, "speed": 11.8, "course": 265.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1108, CreateTime = 1717076858806, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6cc8e624)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219043000.0, "lon": 4.211985, "lat": 56.369797, "speed": 0.3, "course": 76.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219043000.0, "lon": 4.211985, "lat": 56.369797, "speed": 0.3, "course": 76.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1109, CreateTime = 1717076858806, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4ce4a1c6)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 219015579.0, "lon": 7.99822, "lat": 55.502902, "speed": 10.8, "course": 290.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 219015579.0, "lon": 7.99822, "lat": 55.502902, "speed": 10.8, "course": 290.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1110, CreateTime = 1717076858806, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@20c75939)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:11", "mmsi": 2190077.0, "lon": 14.879107, "lat": 55.14908, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:11", "mmsi": 2190077.0, "lon": 14.879107, "lat": 55.14908, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1111, CreateTime = 1717076858806, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1ce683b8)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 212172000.0, "lon": 7.04335, "lat": 56.423167, "speed": 15.0, "course": 36.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 212172000.0, "lon": 7.04335, "lat": 56.423167, "speed": 15.0, "course": 36.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1112, CreateTime = 1717076858806, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@37b4afc6)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 220083000.0, "lon": 8.122788, "lat": 56.00477, "speed": 0.0, "course": 303.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 220083000.0, "lon": 8.122788, "lat": 56.00477, "speed": 0.0, "course": 303.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1113, CreateTime = 1717076858806, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5e37d267)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 211327150.0, "lon": 9.579515, "lat": 54.21135, "speed": 7.2, "course": 55.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 211327150.0, "lon": 9.579515, "lat": 54.21135, "speed": 7.2, "course": 55.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1114, CreateTime = 1717076858806, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@44a34609)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 2190067.0, "lon": 9.55263, "lat": 54.96617, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 2190067.0, "lon": 9.55263, "lat": 54.96617, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1115, CreateTime = 1717076858807, serialized key size = -1, serialized value size = 109, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6cf0e666)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 992191016.0, "lon": 11.046735, "lat": 55.324793, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 992191016.0, "lon": 11.046735, "lat": 55.324793, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1116, CreateTime = 1717076858807, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7ea8bea1)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219000547.0, "lon": 10.308207, "lat": 56.990222, "speed": 0.0, "course": 287.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219000547.0, "lon": 10.308207, "lat": 56.990222, "speed": 0.0, "course": 287.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1117, CreateTime = 1717076858807, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1eeceff9)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 273133200.0, "lon": 10.92636, "lat": 54.689568, "speed": 11.9, "course": 300.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 273133200.0, "lon": 10.92636, "lat": 54.689568, "speed": 11.9, "course": 300.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1118, CreateTime = 1717076858807, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@40a17123)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 305376000.0, "lon": 13.94421, "lat": 54.360965, "speed": 12.5, "course": 331.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 305376000.0, "lon": 13.94421, "lat": 54.360965, "speed": 12.5, "course": 331.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1119, CreateTime = 1717076858807, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2b897c87)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 246384000.0, "lon": 12.093, "lat": 54.156017, "speed": 0.1, "course": 180.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 246384000.0, "lon": 12.093, "lat": 54.156017, "speed": 0.1, "course": 180.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1120, CreateTime = 1717076858807, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@106f92e1)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 265191000.0, "lon": 11.496788, "lat": 57.756345, "speed": 11.1, "course": 351.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 265191000.0, "lon": 11.496788, "lat": 57.756345, "speed": 11.1, "course": 351.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1121, CreateTime = 1717076858807, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@69853432)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219006301.0, "lon": 10.586383, "lat": 57.71806, "speed": 0.0, "course": 312.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219006301.0, "lon": 10.586383, "lat": 57.71806, "speed": 0.0, "course": 312.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1122, CreateTime = 1717076858807, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@22666848)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219125000.0, "lon": 8.21977, "lat": 56.693078, "speed": 0.0, "course": 350.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219125000.0, "lon": 8.21977, "lat": 56.693078, "speed": 0.0, "course": 350.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1123, CreateTime = 1717076858809, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@426b45c7)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 311969000.0, "lon": 9.2018, "lat": 57.832867, "speed": 12.0, "course": 33.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 311969000.0, "lon": 9.2018, "lat": 57.832867, "speed": 12.0, "course": 33.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1124, CreateTime = 1717076858809, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2e7f2ff1)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 230217000.0, "lon": 6.975493, "lat": 56.43796, "speed": 14.8, "course": 163.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 230217000.0, "lon": 6.975493, "lat": 56.43796, "speed": 14.8, "course": 163.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1125, CreateTime = 1717076858809, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6e9bbaa8)
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,416 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219000546.0, "lon": 9.423867, "lat": 55.040558, "speed": 0.0, "course": 336.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219000546.0, "lon": 9.423867, "lat": 55.040558, "speed": 0.0, "course": 336.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1126, CreateTime = 1717076858809, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7faebb1b)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 259372000.0, "lon": 12.695835, "lat": 55.613753, "speed": 6.2, "course": 175.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 259372000.0, "lon": 12.695835, "lat": 55.613753, "speed": 6.2, "course": 175.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1127, CreateTime = 1717076858809, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@67f38c54)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219087000.0, "lon": 8.224762, "lat": 56.702982, "speed": 0.0, "course": 13.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219087000.0, "lon": 8.224762, "lat": 56.702982, "speed": 0.0, "course": 13.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1128, CreateTime = 1717076858809, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@30a427fc)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219000463.0, "lon": 10.569932, "lat": 55.516173, "speed": 0.3, "course": 269.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219000463.0, "lon": 10.569932, "lat": 55.516173, "speed": 0.3, "course": 269.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1129, CreateTime = 1717076858809, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@35995ba)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 220000054.0, "lon": 9.175067, "lat": 56.709, "speed": 0.0, "course": 31.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 220000054.0, "lon": 9.175067, "lat": 56.709, "speed": 0.0, "course": 31.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1130, CreateTime = 1717076858809, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@92590a9)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219000762.0, "lon": 10.259028, "lat": 55.911902, "speed": 0.0, "course": 11.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219000762.0, "lon": 10.259028, "lat": 55.911902, "speed": 0.0, "course": 11.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1131, CreateTime = 1717076858809, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@724f3cf5)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 309985000.0, "lon": 9.450635, "lat": 58.135322, "speed": 9.4, "course": 213.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 309985000.0, "lon": 9.450635, "lat": 58.135322, "speed": 9.4, "course": 213.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1132, CreateTime = 1717076858810, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@63c56e87)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219002418.0, "lon": 14.972015, "lat": 55.212363, "speed": 0.0, "course": 200.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219002418.0, "lon": 14.972015, "lat": 55.212363, "speed": 0.0, "course": 200.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1133, CreateTime = 1717076858810, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2c7ed300)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 257496000.0, "lon": 9.2098, "lat": 57.860967, "speed": 14.0, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 257496000.0, "lon": 9.2098, "lat": 57.860967, "speed": 14.0, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1134, CreateTime = 1717076858810, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@97baefe)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 265217000.0, "lon": 12.12877, "lat": 54.156722, "speed": 0.0, "course": 241.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 265217000.0, "lon": 12.12877, "lat": 54.156722, "speed": 0.0, "course": 241.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1135, CreateTime = 1717076858810, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2d883b0)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219001261.0, "lon": 9.633717, "lat": 56.988383, "speed": 0.0, "course": 7.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219001261.0, "lon": 9.633717, "lat": 56.988383, "speed": 0.0, "course": 7.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1136, CreateTime = 1717076858810, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4a21743a)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 375752000.0, "lon": 14.80603, "lat": 55.443758, "speed": 7.9, "course": 260.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 375752000.0, "lon": 14.80603, "lat": 55.443758, "speed": 7.9, "course": 260.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1137, CreateTime = 1717076858810, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@101d58ad)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219006113.0, "lon": 11.128115, "lat": 57.321285, "speed": 0.0, "course": 328.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219006113.0, "lon": 11.128115, "lat": 57.321285, "speed": 0.0, "course": 328.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1138, CreateTime = 1717076858810, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4445080e)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 2190052.0, "lon": 11.196912, "lat": 54.872385, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 2190052.0, "lon": 11.196912, "lat": 54.872385, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1139, CreateTime = 1717076858810, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2c6c635)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219002732.0, "lon": 10.549638, "lat": 57.439335, "speed": 0.0, "course": 162.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219002732.0, "lon": 10.549638, "lat": 57.439335, "speed": 0.0, "course": 162.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1140, CreateTime = 1717076858810, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4387e2f3)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 2655150.0, "lon": 12.05862, "lat": 57.693993, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 2655150.0, "lon": 12.05862, "lat": 57.693993, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1141, CreateTime = 1717076858810, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@39a5121e)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219000345.0, "lon": 10.824833, "lat": 55.752567, "speed": 16.8, "course": 170.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219000345.0, "lon": 10.824833, "lat": 55.752567, "speed": 16.8, "course": 170.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1142, CreateTime = 1717076858810, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@55cc685c)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 231201000.0, "lon": 10.060395, "lat": 57.76537, "speed": 15.7, "course": 12.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 231201000.0, "lon": 10.060395, "lat": 57.76537, "speed": 15.7, "course": 12.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1143, CreateTime = 1717076858810, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@610ffbbe)
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 309272000.0, "lon": 13.889793, "lat": 55.006207, "speed": 12.4, "course": 170.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 309272000.0, "lon": 13.889793, "lat": 55.006207, "speed": 12.4, "course": 170.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,417 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1144, CreateTime = 1717076858810, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1d631d16)
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 210888000.0, "lon": 14.248208, "lat": 53.964367, "speed": 0.0, "course": 0.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 210888000.0, "lon": 14.248208, "lat": 53.964367, "speed": 0.0, "course": 0.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1145, CreateTime = 1717076858811, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@c47d946)
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 245739000.0, "lon": 10.229453, "lat": 54.445688, "speed": 12.1, "course": 207.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 245739000.0, "lon": 10.229453, "lat": 54.445688, "speed": 12.1, "course": 207.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1146, CreateTime = 1717076858811, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3affce1a)
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 211196300.0, "lon": 9.933913, "lat": 54.650873, "speed": 0.0, "course": 356.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 211196300.0, "lon": 9.933913, "lat": 54.650873, "speed": 0.0, "course": 356.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1147, CreateTime = 1717076858811, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@243300f0)
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 211316340.0, "lon": 13.40545, "lat": 54.86595, "speed": 5.4, "course": 359.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 211316340.0, "lon": 13.40545, "lat": 54.86595, "speed": 5.4, "course": 359.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1148, CreateTime = 1717076858811, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@213d32cd)
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 220453000.0, "lon": 9.972873, "lat": 57.593448, "speed": 0.0, "course": 8.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 220453000.0, "lon": 9.972873, "lat": 57.593448, "speed": 0.0, "course": 8.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1149, CreateTime = 1717076858811, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@13025245)
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 265518160.0, "lon": 12.687685, "lat": 56.044737, "speed": 0.0, "course": 174.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 265518160.0, "lon": 12.687685, "lat": 56.044737, "speed": 0.0, "course": 174.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1150, CreateTime = 1717076858811, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@57c9d121)
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219007844.0, "lon": 10.670577, "lat": 54.750895, "speed": 0.0, "course": 348.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219007844.0, "lon": 10.670577, "lat": 54.750895, "speed": 0.0, "course": 348.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1151, CreateTime = 1717076858811, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6bc17fa8)
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219001647.0, "lon": 10.053283, "lat": 55.822222, "speed": 0.0, "course": 337.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219001647.0, "lon": 10.053283, "lat": 55.822222, "speed": 0.0, "course": 337.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1152, CreateTime = 1717076858811, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@23a29347)
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 370614000.0, "lon": 11.533533, "lat": 57.26565, "speed": 14.2, "course": 162.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 370614000.0, "lon": 11.533533, "lat": 57.26565, "speed": 14.2, "course": 162.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1153, CreateTime = 1717076858811, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@22b37d0c)
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 211225390.0, "lon": 11.191225, "lat": 54.419848, "speed": 0.0, "course": 328.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 211225390.0, "lon": 11.191225, "lat": 54.419848, "speed": 0.0, "course": 328.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1154, CreateTime = 1717076858811, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3b6af0a2)
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 265228000.0, "lon": 12.725057, "lat": 54.666107, "speed": 11.6, "course": 66.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 265228000.0, "lon": 12.725057, "lat": 54.666107, "speed": 11.6, "course": 66.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1155, CreateTime = 1717076858811, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5bb6f458)
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 992191507.0, "lon": 5.108882, "lat": 55.4764, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 992191507.0, "lon": 5.108882, "lat": 55.4764, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1156, CreateTime = 1717076858811, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6cb97cc2)
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 992191511.0, "lon": 5.005782, "lat": 55.53035, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 992191511.0, "lon": 5.005782, "lat": 55.53035, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1157, CreateTime = 1717076858811, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@55db2744)
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 244073000.0, "lon": 12.043193, "lat": 54.410755, "speed": 11.8, "course": 89.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 244073000.0, "lon": 12.043193, "lat": 54.410755, "speed": 11.8, "course": 89.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1158, CreateTime = 1717076858811, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@395832bd)
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 305117000.0, "lon": 15.473333, "lat": 55.649167, "speed": 13.7, "course": 65.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 305117000.0, "lon": 15.473333, "lat": 55.649167, "speed": 13.7, "course": 65.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1159, CreateTime = 1717076858812, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@552005fa)
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 265513370.0, "lon": 11.869867, "lat": 57.682433, "speed": 0.0, "course": 341.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,418 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 265513370.0, "lon": 11.869867, "lat": 57.682433, "speed": 0.0, "course": 341.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1160, CreateTime = 1717076858812, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@72582cf0)
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 220247000.0, "lon": 8.417195, "lat": 55.476837, "speed": 0.0, "course": 7.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 220247000.0, "lon": 8.417195, "lat": 55.476837, "speed": 0.0, "course": 7.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1161, CreateTime = 1717076858812, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7eb5d4f8)
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219000062.0, "lon": 12.04125, "lat": 54.892382, "speed": 0.0, "course": 156.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219000062.0, "lon": 12.04125, "lat": 54.892382, "speed": 0.0, "course": 156.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1162, CreateTime = 1717076858812, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@600dc49)
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 261002420.0, "lon": 15.552927, "lat": 54.999748, "speed": 9.5, "course": 356.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 261002420.0, "lon": 15.552927, "lat": 54.999748, "speed": 9.5, "course": 356.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1163, CreateTime = 1717076858812, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@53da16a6)
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219003947.0, "lon": 14.665783, "lat": 54.711108, "speed": 0.6, "course": 309.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219003947.0, "lon": 14.665783, "lat": 54.711108, "speed": 0.6, "course": 309.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1164, CreateTime = 1717076858812, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@60d68f81)
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219000141.0, "lon": 12.427303, "lat": 55.097657, "speed": 0.6, "course": 309.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219000141.0, "lon": 12.427303, "lat": 55.097657, "speed": 0.6, "course": 309.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1165, CreateTime = 1717076858812, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@30948577)
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 244967000.0, "lon": 12.434785, "lat": 54.572395, "speed": 9.8, "course": 59.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 244967000.0, "lon": 12.434785, "lat": 54.572395, "speed": 9.8, "course": 59.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1166, CreateTime = 1717076858812, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@30f6f5b8)
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219000589.0, "lon": 13.856467, "lat": 54.895987, "speed": 9.7, "course": 122.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219000589.0, "lon": 13.856467, "lat": 54.895987, "speed": 9.7, "course": 122.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1167, CreateTime = 1717076858813, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@331aaa26)
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 220341000.0, "lon": 9.962797, "lat": 57.593115, "speed": 0.0, "course": 193.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 220341000.0, "lon": 9.962797, "lat": 57.593115, "speed": 0.0, "course": 193.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1168, CreateTime = 1717076858814, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@67648143)
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 218759000.0, "lon": 11.578877, "lat": 56.121045, "speed": 8.2, "course": 84.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 218759000.0, "lon": 11.578877, "lat": 56.121045, "speed": 8.2, "course": 84.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1169, CreateTime = 1717076858815, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@734f1fe5)
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 245015000.0, "lon": 12.086867, "lat": 54.1194, "speed": 0.0, "course": 324.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 245015000.0, "lon": 12.086867, "lat": 54.1194, "speed": 0.0, "course": 324.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1170, CreateTime = 1717076858815, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@74137f01)
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 245726000.0, "lon": 10.612678, "lat": 56.693325, "speed": 11.2, "course": 37.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 245726000.0, "lon": 10.612678, "lat": 56.693325, "speed": 11.2, "course": 37.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1171, CreateTime = 1717076858815, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@12bea03f)
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 220378000.0, "lon": 12.319167, "lat": 55.433833, "speed": 16.0, "course": 130.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 220378000.0, "lon": 12.319167, "lat": 55.433833, "speed": 16.0, "course": 130.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1172, CreateTime = 1717076858815, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@511345b2)
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219005867.0, "lon": 10.588147, "lat": 57.717865, "speed": 0.0, "course": 309.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219005867.0, "lon": 10.588147, "lat": 57.717865, "speed": 0.0, "course": 309.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1173, CreateTime = 1717076858815, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5aa8c842)
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 211298100.0, "lon": 9.035983, "lat": 54.471183, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 211298100.0, "lon": 9.035983, "lat": 54.471183, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1174, CreateTime = 1717076858815, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@35ac5f61)
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219171000.0, "lon": 8.443975, "lat": 55.464165, "speed": 0.0, "course": 304.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,419 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219171000.0, "lon": 8.443975, "lat": 55.464165, "speed": 0.0, "course": 304.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1175, CreateTime = 1717076858815, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5274aeb3)
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 209273000.0, "lon": 7.756757, "lat": 56.622175, "speed": 11.0, "course": 34.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 209273000.0, "lon": 7.756757, "lat": 56.622175, "speed": 11.0, "course": 34.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=3150, hash=-24057325} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=2}
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=2675, hash=1139712849} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=1}
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=3150, hash=-24057325}, seq 2, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=2675, hash=1139712849}, seq 2, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=3125, hash=340217227} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=5}
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=3225, hash=-1797043381} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=7}
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=3550, hash=713799457} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=6}
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=3550, hash=713799457}, seq 2, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=3125, hash=340217227}, seq 2, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=3550, hash=914969833} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=0}
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=3125, hash=731802636} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,421 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1176, CreateTime = 1717076858815, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@19815f9a)
2024-05-30 15:47:40 2024-05-30 13:47:40,421 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,421 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=3550, hash=914969833}, seq 2, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=3225, hash=-1797043381}, seq 2, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,421 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=3125, hash=731802636}, seq 2, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,420 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=3150, hash=634698663} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=4}
2024-05-30 15:47:40 2024-05-30 13:47:40,422 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=3150, hash=634698663}, seq 2, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,421 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 265629560.0, "lon": 14.286478, "lat": 55.475203, "speed": 0.0, "course": 333.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,422 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 265629560.0, "lon": 14.286478, "lat": 55.475203, "speed": 0.0, "course": 333.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1177, CreateTime = 1717076858816, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5776e30)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 2190074.0, "lon": 10.57464, "lat": 57.738673, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 2190074.0, "lon": 10.57464, "lat": 57.738673, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1178, CreateTime = 1717076858817, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@52f76ea8)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 636014191.0, "lon": 14.11495, "lat": 55.095617, "speed": 14.1, "course": 219.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 636014191.0, "lon": 14.11495, "lat": 55.095617, "speed": 14.1, "course": 219.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1179, CreateTime = 1717076858817, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@25814373)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219014192.0, "lon": 8.222015, "lat": 56.704792, "speed": 0.0, "course": 322.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219014192.0, "lon": 8.222015, "lat": 56.704792, "speed": 0.0, "course": 322.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1180, CreateTime = 1717076858817, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@36efa5d6)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 211211290.0, "lon": 10.035747, "lat": 54.77842, "speed": 11.6, "course": 324.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 211211290.0, "lon": 10.035747, "lat": 54.77842, "speed": 11.6, "course": 324.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1181, CreateTime = 1717076858817, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@8575bd5)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 304201000.0, "lon": 10.262592, "lat": 54.485435, "speed": 10.9, "course": 207.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 304201000.0, "lon": 10.262592, "lat": 54.485435, "speed": 10.9, "course": 207.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1182, CreateTime = 1717076858817, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@61bcf659)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 257438000.0, "lon": 4.749518, "lat": 55.717037, "speed": 0.1, "course": 13.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 257438000.0, "lon": 4.749518, "lat": 55.717037, "speed": 0.1, "course": 13.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1183, CreateTime = 1717076858817, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4e89bbc6)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 259448000.0, "lon": 9.956965, "lat": 57.592565, "speed": 0.0, "course": 116.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 259448000.0, "lon": 9.956965, "lat": 57.592565, "speed": 0.0, "course": 116.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1184, CreateTime = 1717076858817, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@58376d4)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 220541000.0, "lon": 12.309768, "lat": 56.128063, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 220541000.0, "lon": 12.309768, "lat": 56.128063, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1185, CreateTime = 1717076858817, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@37b80c42)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 258606000.0, "lon": 10.727415, "lat": 57.36824, "speed": 14.2, "course": 5.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 258606000.0, "lon": 10.727415, "lat": 57.36824, "speed": 14.2, "course": 5.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1186, CreateTime = 1717076858818, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@31302ad2)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219000185.0, "lon": 10.258298, "lat": 54.942367, "speed": 0.0, "course": 198.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219000185.0, "lon": 10.258298, "lat": 54.942367, "speed": 0.0, "course": 198.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1187, CreateTime = 1717076858819, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@32e4f0b9)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 277339000.0, "lon": 15.613128, "lat": 54.976718, "speed": 20.5, "course": 75.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 277339000.0, "lon": 15.613128, "lat": 54.976718, "speed": 20.5, "course": 75.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1188, CreateTime = 1717076858820, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2ccf05e7)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 257049000.0, "lon": 3.392962, "lat": 56.278233, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 257049000.0, "lon": 3.392962, "lat": 56.278233, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1189, CreateTime = 1717076858821, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5b62d620)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 220334000.0, "lon": 10.587983, "lat": 57.717933, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 220334000.0, "lon": 10.587983, "lat": 57.717933, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1190, CreateTime = 1717076858822, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6bb41124)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 211910000.0, "lon": 8.24675, "lat": 57.054967, "speed": 23.5, "course": 39.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 211910000.0, "lon": 8.24675, "lat": 57.054967, "speed": 23.5, "course": 39.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1191, CreateTime = 1717076858823, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7e4045d3)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219385000.0, "lon": 12.592988, "lat": 55.679297, "speed": 0.1, "course": 280.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219385000.0, "lon": 12.592988, "lat": 55.679297, "speed": 0.1, "course": 280.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1192, CreateTime = 1717076858823, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2a7487c1)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 240198000.0, "lon": 11.134883, "lat": 57.6306, "speed": 14.7, "course": 313.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 240198000.0, "lon": 11.134883, "lat": 57.6306, "speed": 14.7, "course": 313.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1193, CreateTime = 1717076858823, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@676a8779)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219005901.0, "lon": 8.599702, "lat": 57.122575, "speed": 0.1, "course": 72.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219005901.0, "lon": 8.599702, "lat": 57.122575, "speed": 0.1, "course": 72.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1194, CreateTime = 1717076858823, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2c9c9781)
2024-05-30 15:47:40 2024-05-30 13:47:40,423 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 258237000.0, "lon": 10.962002, "lat": 56.67186, "speed": 10.4, "course": 350.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 258237000.0, "lon": 10.962002, "lat": 56.67186, "speed": 10.4, "course": 350.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1195, CreateTime = 1717076858825, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@500e211c)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219923000.0, "lon": 12.274242, "lat": 54.294, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219923000.0, "lon": 12.274242, "lat": 54.294, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1196, CreateTime = 1717076858826, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5ecafe53)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 265463000.0, "lon": 12.264297, "lat": 54.54002, "speed": 11.9, "course": 21.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 265463000.0, "lon": 12.264297, "lat": 54.54002, "speed": 11.9, "course": 21.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1197, CreateTime = 1717076858826, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d28ebbc)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 230984000.0, "lon": 11.48575, "lat": 57.389138, "speed": 18.1, "course": 338.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 230984000.0, "lon": 11.48575, "lat": 57.389138, "speed": 18.1, "course": 338.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1198, CreateTime = 1717076858826, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@25c04907)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 245253000.0, "lon": 7.806165, "lat": 55.276597, "speed": 4.3, "course": 327.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 245253000.0, "lon": 7.806165, "lat": 55.276597, "speed": 4.3, "course": 327.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1199, CreateTime = 1717076858826, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4678a62)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219002767.0, "lon": 11.510508, "lat": 56.716047, "speed": 0.0, "course": 317.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219002767.0, "lon": 11.510508, "lat": 56.716047, "speed": 0.0, "course": 317.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1200, CreateTime = 1717076858826, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@d56c4db)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 265186000.0, "lon": 13.569527, "lat": 54.775045, "speed": 15.2, "course": 156.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 265186000.0, "lon": 13.569527, "lat": 54.775045, "speed": 15.2, "course": 156.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1201, CreateTime = 1717076858826, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2789abc6)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 266225000.0, "lon": 10.549652, "lat": 57.441122, "speed": 0.0, "course": 300.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 266225000.0, "lon": 10.549652, "lat": 57.441122, "speed": 0.0, "course": 300.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1202, CreateTime = 1717076858827, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@265641)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 246262000.0, "lon": 12.7051, "lat": 55.51975, "speed": 12.4, "course": 355.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 246262000.0, "lon": 12.7051, "lat": 55.51975, "speed": 12.4, "course": 355.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1203, CreateTime = 1717076858828, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@38aaf8bd)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 2190048.0, "lon": 12.129532, "lat": 56.079123, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 2190048.0, "lon": 12.129532, "lat": 56.079123, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1204, CreateTime = 1717076858829, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3e1836f)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 257307000.0, "lon": 10.061473, "lat": 57.049807, "speed": 0.0, "course": 216.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 257307000.0, "lon": 10.061473, "lat": 57.049807, "speed": 0.0, "course": 216.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1205, CreateTime = 1717076858830, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@695cdf4e)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219001125.0, "lon": 9.802503, "lat": 57.780832, "speed": 4.5, "course": 329.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219001125.0, "lon": 9.802503, "lat": 57.780832, "speed": 4.5, "course": 329.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1206, CreateTime = 1717076858830, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5bfa087a)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 219014049.0, "lon": 14.881933, "lat": 54.700317, "speed": 0.2, "course": 43.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 219014049.0, "lon": 14.881933, "lat": 54.700317, "speed": 0.2, "course": 43.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1207, CreateTime = 1717076858830, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@347a6ca8)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 265246000.0, "lon": 10.780228, "lat": 57.674322, "speed": 0.1, "course": 45.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 265246000.0, "lon": 10.780228, "lat": 57.674322, "speed": 0.1, "course": 45.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1208, CreateTime = 1717076858831, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3b0f6bb3)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 2655148.0, "lon": 12.390503, "lat": 57.108778, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 2655148.0, "lon": 12.390503, "lat": 57.108778, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1209, CreateTime = 1717076858832, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@34a67533)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 211462260.0, "lon": 9.937942, "lat": 54.664318, "speed": 0.0, "course": 30.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 211462260.0, "lon": 9.937942, "lat": 54.664318, "speed": 0.0, "course": 30.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1210, CreateTime = 1717076858832, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3f140205)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:12", "mmsi": 265548360.0, "lon": 12.785132, "lat": 55.799867, "speed": 11.8, "course": 329.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:12", "mmsi": 265548360.0, "lon": 12.785132, "lat": 55.799867, "speed": 11.8, "course": 329.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1211, CreateTime = 1717076858832, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@58ec2663)
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 220272000.0, "lon": 9.755758, "lat": 55.559403, "speed": 0.0, "course": 311.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 220272000.0, "lon": 9.755758, "lat": 55.559403, "speed": 0.0, "course": 311.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,424 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1212, CreateTime = 1717076858832, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@187e8c3e)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 218083000.0, "lon": 9.43329, "lat": 54.795075, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 218083000.0, "lon": 9.43329, "lat": 54.795075, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1213, CreateTime = 1717076858832, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1ff67def)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219250000.0, "lon": 4.736823, "lat": 55.579583, "speed": 0.5, "course": 186.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219250000.0, "lon": 4.736823, "lat": 55.579583, "speed": 0.5, "course": 186.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1214, CreateTime = 1717076858832, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@ed503e)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219384000.0, "lon": 9.960593, "lat": 57.594508, "speed": 0.0, "course": 340.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219384000.0, "lon": 9.960593, "lat": 57.594508, "speed": 0.0, "course": 340.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1215, CreateTime = 1717076858833, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@390bb17e)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 256587000.0, "lon": 8.931332, "lat": 57.416875, "speed": 14.1, "course": 51.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 256587000.0, "lon": 8.931332, "lat": 57.416875, "speed": 14.1, "course": 51.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1216, CreateTime = 1717076858833, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5578d51d)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219011248.0, "lon": 10.35576, "lat": 56.967543, "speed": 1.5, "course": 167.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219011248.0, "lon": 10.35576, "lat": 56.967543, "speed": 1.5, "course": 167.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1217, CreateTime = 1717076858833, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@79cdc358)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219000613.0, "lon": 11.134575, "lat": 55.333312, "speed": 0.1, "course": 294.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219000613.0, "lon": 11.134575, "lat": 55.333312, "speed": 0.1, "course": 294.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1218, CreateTime = 1717076858833, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@13cb10ff)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 220343000.0, "lon": 10.585657, "lat": 57.717715, "speed": 0.0, "course": 173.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 220343000.0, "lon": 10.585657, "lat": 57.717715, "speed": 0.0, "course": 173.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1219, CreateTime = 1717076858833, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@772fc3b9)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219467000.0, "lon": 13.229683, "lat": 55.264275, "speed": 10.3, "course": 276.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219467000.0, "lon": 13.229683, "lat": 55.264275, "speed": 10.3, "course": 276.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1220, CreateTime = 1717076858833, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@646c307c)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 277382000.0, "lon": 9.448333, "lat": 57.4715, "speed": 10.1, "course": 237.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 277382000.0, "lon": 9.448333, "lat": 57.4715, "speed": 10.1, "course": 237.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1221, CreateTime = 1717076858834, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@732ce8aa)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 244806000.0, "lon": 7.284182, "lat": 55.591675, "speed": 4.7, "course": 318.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 244806000.0, "lon": 7.284182, "lat": 55.591675, "speed": 4.7, "course": 318.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1222, CreateTime = 1717076858834, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@38ab52d8)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 230915000.0, "lon": 7.793983, "lat": 56.477533, "speed": 18.0, "course": 200.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 230915000.0, "lon": 7.793983, "lat": 56.477533, "speed": 18.0, "course": 200.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1223, CreateTime = 1717076858834, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@31106c7f)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 244965000.0, "lon": 7.708047, "lat": 55.25025, "speed": 3.6, "course": 274.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 244965000.0, "lon": 7.708047, "lat": 55.25025, "speed": 3.6, "course": 274.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1224, CreateTime = 1717076858834, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@34fa45f1)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 377801000.0, "lon": 12.470352, "lat": 54.833307, "speed": 9.0, "course": 213.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 377801000.0, "lon": 12.470352, "lat": 54.833307, "speed": 9.0, "course": 213.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1225, CreateTime = 1717076858834, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2007827c)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 253056000.0, "lon": 11.304045, "lat": 54.54514, "speed": 11.5, "course": 110.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 253056000.0, "lon": 11.304045, "lat": 54.54514, "speed": 11.5, "course": 110.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1226, CreateTime = 1717076858835, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@42582936)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219537000.0, "lon": 10.909297, "lat": 55.886092, "speed": 14.3, "course": 40.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219537000.0, "lon": 10.909297, "lat": 55.886092, "speed": 14.3, "course": 40.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1227, CreateTime = 1717076858835, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7019c696)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 246064000.0, "lon": 10.618517, "lat": 57.7124, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 246064000.0, "lon": 10.618517, "lat": 57.7124, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1228, CreateTime = 1717076858835, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@16aad0a9)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219295000.0, "lon": 8.224392, "lat": 56.703433, "speed": 0.0, "course": 141.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219295000.0, "lon": 8.224392, "lat": 56.703433, "speed": 0.0, "course": 141.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1229, CreateTime = 1717076858835, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@aa2a462)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 992191524.0, "lon": 4.799932, "lat": 55.720382, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 992191524.0, "lon": 4.799932, "lat": 55.720382, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1230, CreateTime = 1717076858836, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@9302d99)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 992191510.0, "lon": 4.757032, "lat": 55.578417, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 992191510.0, "lon": 4.757032, "lat": 55.578417, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1231, CreateTime = 1717076858837, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@37a3675f)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 211211250.0, "lon": 10.045858, "lat": 54.768192, "speed": 11.7, "course": 327.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 211211250.0, "lon": 10.045858, "lat": 54.768192, "speed": 11.7, "course": 327.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1232, CreateTime = 1717076858837, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@77ccd69a)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 220464000.0, "lon": 9.904147, "lat": 57.710932, "speed": 20.0, "course": 256.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 220464000.0, "lon": 9.904147, "lat": 57.710932, "speed": 20.0, "course": 256.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1233, CreateTime = 1717076858837, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6852edb5)
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219328000.0, "lon": 14.273642, "lat": 54.900073, "speed": 3.9, "course": 36.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,425 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219328000.0, "lon": 14.273642, "lat": 54.900073, "speed": 3.9, "course": 36.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1234, CreateTime = 1717076858837, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@600659c3)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219267000.0, "lon": 12.991033, "lat": 55.6108, "speed": 0.0, "course": 285.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219267000.0, "lon": 12.991033, "lat": 55.6108, "speed": 0.0, "course": 285.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1235, CreateTime = 1717076858837, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4cb35303)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219001588.0, "lon": 8.46273, "lat": 57.407403, "speed": 9.4, "course": 346.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219001588.0, "lon": 8.46273, "lat": 57.407403, "speed": 9.4, "course": 346.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1236, CreateTime = 1717076858837, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5dda2409)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 2190073.0, "lon": 11.052713, "lat": 57.268858, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 2190073.0, "lon": 11.052713, "lat": 57.268858, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1237, CreateTime = 1717076858837, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@221a5542)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 235073852.0, "lon": 11.351132, "lat": 54.656642, "speed": 0.0, "course": 121.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 235073852.0, "lon": 11.351132, "lat": 54.656642, "speed": 0.0, "course": 121.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1238, CreateTime = 1717076858837, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7080c883)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219005465.0, "lon": 10.67057, "lat": 54.751288, "speed": 0.0, "course": 313.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219005465.0, "lon": 10.67057, "lat": 54.751288, "speed": 0.0, "course": 313.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1239, CreateTime = 1717076858837, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@267db6db)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219009273.0, "lon": 8.598383, "lat": 57.122583, "speed": 1.6, "course": 3.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219009273.0, "lon": 8.598383, "lat": 57.122583, "speed": 1.6, "course": 3.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1240, CreateTime = 1717076858837, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2a0b2471)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219942000.0, "lon": 10.618758, "lat": 55.060252, "speed": 0.0, "course": 300.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219942000.0, "lon": 10.618758, "lat": 55.060252, "speed": 0.0, "course": 300.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1241, CreateTime = 1717076858837, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5acbc437)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219009042.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219009042.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1242, CreateTime = 1717076858837, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2cf9cb3d)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 231730000.0, "lon": 10.588875, "lat": 57.717185, "speed": 0.0, "course": 2.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 231730000.0, "lon": 10.588875, "lat": 57.717185, "speed": 0.0, "course": 2.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1243, CreateTime = 1717076858837, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@67f96b17)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 245529000.0, "lon": 14.249683, "lat": 53.978483, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 245529000.0, "lon": 14.249683, "lat": 53.978483, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1244, CreateTime = 1717076858837, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1422f335)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 265410000.0, "lon": 11.604273, "lat": 57.607752, "speed": 17.2, "course": 252.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 265410000.0, "lon": 11.604273, "lat": 57.607752, "speed": 17.2, "course": 252.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1245, CreateTime = 1717076858838, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@104c67fa)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 211298130.0, "lon": 8.690012, "lat": 54.730377, "speed": 0.0, "course": 105.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 211298130.0, "lon": 8.690012, "lat": 54.730377, "speed": 0.0, "course": 105.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1246, CreateTime = 1717076858838, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@720ef6ed)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219000674.0, "lon": 10.521743, "lat": 54.856665, "speed": 0.0, "course": 163.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219000674.0, "lon": 10.521743, "lat": 54.856665, "speed": 0.0, "course": 163.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1247, CreateTime = 1717076858838, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5e838a68)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 331102000.0, "lon": 10.546783, "lat": 57.441605, "speed": 0.0, "course": 285.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 331102000.0, "lon": 10.546783, "lat": 57.441605, "speed": 0.0, "course": 285.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1248, CreateTime = 1717076858838, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5d3b61d6)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 220345000.0, "lon": 10.024565, "lat": 58.086172, "speed": 2.6, "course": 245.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 220345000.0, "lon": 10.024565, "lat": 58.086172, "speed": 2.6, "course": 245.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1249, CreateTime = 1717076858838, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2ebbae3c)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 211215210.0, "lon": 12.091608, "lat": 54.179755, "speed": 0.0, "course": 296.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 211215210.0, "lon": 12.091608, "lat": 54.179755, "speed": 0.0, "course": 296.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1250, CreateTime = 1717076858838, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2b079c98)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 211824000.0, "lon": 10.985338, "lat": 54.373253, "speed": 0.1, "course": 354.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 211824000.0, "lon": 10.985338, "lat": 54.373253, "speed": 0.1, "course": 354.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1251, CreateTime = 1717076858838, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6995935a)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 245958000.0, "lon": 10.042317, "lat": 57.75844, "speed": 11.3, "course": 59.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 245958000.0, "lon": 10.042317, "lat": 57.75844, "speed": 11.3, "course": 59.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1252, CreateTime = 1717076858838, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6f266a6f)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 265225000.0, "lon": 14.2429, "lat": 53.985218, "speed": 0.2, "course": 45.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 265225000.0, "lon": 14.2429, "lat": 53.985218, "speed": 0.2, "course": 45.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1253, CreateTime = 1717076858838, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1c9fe3f9)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219004903.0, "lon": 11.348017, "lat": 54.656333, "speed": 0.0, "course": 342.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219004903.0, "lon": 11.348017, "lat": 54.656333, "speed": 0.0, "course": 342.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1254, CreateTime = 1717076858838, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@beb5fae)
2024-05-30 15:47:40 2024-05-30 13:47:40,426 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219000892.0, "lon": 11.3596, "lat": 54.915767, "speed": 0.2, "course": 318.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219000892.0, "lon": 11.3596, "lat": 54.915767, "speed": 0.2, "course": 318.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1255, CreateTime = 1717076858838, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4ea102ca)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219000174.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219000174.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1256, CreateTime = 1717076858838, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@12887c63)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219002317.0, "lon": 12.694407, "lat": 55.53753, "speed": 9.9, "course": 357.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219002317.0, "lon": 12.694407, "lat": 55.53753, "speed": 9.9, "course": 357.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1257, CreateTime = 1717076858838, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@71ebc5e0)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 218176000.0, "lon": 7.3663, "lat": 55.544217, "speed": 8.1, "course": 207.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 218176000.0, "lon": 7.3663, "lat": 55.544217, "speed": 8.1, "course": 207.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1258, CreateTime = 1717076858838, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@202cf25c)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 538002019.0, "lon": 11.788222, "lat": 56.41481, "speed": 11.0, "course": 127.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 538002019.0, "lon": 11.788222, "lat": 56.41481, "speed": 11.0, "course": 127.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1259, CreateTime = 1717076858838, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@665d03c1)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 305654000.0, "lon": 9.572613, "lat": 54.20809, "speed": 6.0, "course": 50.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 305654000.0, "lon": 9.572613, "lat": 54.20809, "speed": 6.0, "course": 50.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1260, CreateTime = 1717076858839, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@37e7000d)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219001872.0, "lon": 10.59047, "lat": 57.718583, "speed": 0.0, "course": 325.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219001872.0, "lon": 10.59047, "lat": 57.718583, "speed": 0.0, "course": 325.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1261, CreateTime = 1717076858839, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@180c17d4)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219002731.0, "lon": 11.51136, "lat": 56.715857, "speed": 0.0, "course": 164.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219002731.0, "lon": 11.51136, "lat": 56.715857, "speed": 0.0, "course": 164.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1262, CreateTime = 1717076858839, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5f75a89b)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 230001770.0, "lon": 10.923278, "lat": 56.415052, "speed": 0.0, "course": 4.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 230001770.0, "lon": 10.923278, "lat": 56.415052, "speed": 0.0, "course": 4.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1263, CreateTime = 1717076858839, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@51b8ebbf)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 266331000.0, "lon": 10.785817, "lat": 55.658117, "speed": 18.1, "course": 6.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 266331000.0, "lon": 10.785817, "lat": 55.658117, "speed": 18.1, "course": 6.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1264, CreateTime = 1717076858839, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5ed07eed)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219762000.0, "lon": 7.652883, "lat": 57.543, "speed": 2.1, "course": 75.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219762000.0, "lon": 7.652883, "lat": 57.543, "speed": 2.1, "course": 75.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1265, CreateTime = 1717076858839, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@269a7054)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219904000.0, "lon": 9.665157, "lat": 57.908465, "speed": 0.5, "course": 72.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219904000.0, "lon": 9.665157, "lat": 57.908465, "speed": 0.5, "course": 72.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1266, CreateTime = 1717076858839, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5459256c)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219014124.0, "lon": 9.690283, "lat": 55.675463, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219014124.0, "lon": 9.690283, "lat": 55.675463, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1267, CreateTime = 1717076858839, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@42aad94b)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219072000.0, "lon": 12.59621, "lat": 55.70893, "speed": 0.0, "course": 288.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219072000.0, "lon": 12.59621, "lat": 55.70893, "speed": 0.0, "course": 288.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1268, CreateTime = 1717076858839, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1f50e0e5)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219796000.0, "lon": 15.13562, "lat": 55.059095, "speed": 0.0, "course": 295.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219796000.0, "lon": 15.13562, "lat": 55.059095, "speed": 0.0, "course": 295.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1269, CreateTime = 1717076858839, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6a3d3b8b)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 231695000.0, "lon": 4.434333, "lat": 56.101667, "speed": 12.2, "course": 57.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 231695000.0, "lon": 4.434333, "lat": 56.101667, "speed": 12.2, "course": 57.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1270, CreateTime = 1717076858839, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@77d211e5)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219140000.0, "lon": 8.593228, "lat": 57.119277, "speed": 0.0, "course": 357.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219140000.0, "lon": 8.593228, "lat": 57.119277, "speed": 0.0, "course": 357.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1271, CreateTime = 1717076858839, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@63a6fed5)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 215681000.0, "lon": 12.756018, "lat": 55.271283, "speed": 14.0, "course": 111.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 215681000.0, "lon": 12.756018, "lat": 55.271283, "speed": 14.0, "course": 111.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1272, CreateTime = 1717076858839, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7be96d8c)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219012671.0, "lon": 15.135433, "lat": 55.060233, "speed": 0.0, "course": 256.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219012671.0, "lon": 15.135433, "lat": 55.060233, "speed": 0.0, "course": 256.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1273, CreateTime = 1717076858839, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@780be019)
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 308739000.0, "lon": 12.284667, "lat": 54.542, "speed": 11.4, "course": 13.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,427 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 308739000.0, "lon": 12.284667, "lat": 54.542, "speed": 11.4, "course": 13.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1274, CreateTime = 1717076858840, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1fb18bc4)
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 244323000.0, "lon": 7.641498, "lat": 55.326732, "speed": 3.3, "course": 301.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 244323000.0, "lon": 7.641498, "lat": 55.326732, "speed": 3.3, "course": 301.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1275, CreateTime = 1717076858840, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4bb59eb1)
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219012302.0, "lon": 12.466667, "lat": 54.9525, "speed": 0.0, "course": 2.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219012302.0, "lon": 12.466667, "lat": 54.9525, "speed": 0.0, "course": 2.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1276, CreateTime = 1717076858840, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7b000f46)
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 305601000.0, "lon": 15.704017, "lat": 54.8284, "speed": 15.0, "course": 98.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 305601000.0, "lon": 15.704017, "lat": 54.8284, "speed": 15.0, "course": 98.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1277, CreateTime = 1717076858840, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5c2c3317)
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 265615860.0, "lon": 13.058613, "lat": 55.675678, "speed": 0.0, "course": 330.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 265615860.0, "lon": 13.058613, "lat": 55.675678, "speed": 0.0, "course": 330.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1278, CreateTime = 1717076858840, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4fd06cfd)
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219005513.0, "lon": 8.60116, "lat": 57.121857, "speed": 0.0, "course": 354.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219005513.0, "lon": 8.60116, "lat": 57.121857, "speed": 0.0, "course": 354.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1279, CreateTime = 1717076858840, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@28f723a0)
2024-05-30 15:47:40 2024-05-30 13:47:40,428 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,429 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 265610040.0, "lon": 9.425368, "lat": 57.535335, "speed": 9.2, "course": 239.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,429 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 265610040.0, "lon": 9.425368, "lat": 57.535335, "speed": 9.2, "course": 239.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1280, CreateTime = 1717076858840, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@537673c7)
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219007333.0, "lon": 14.931233, "lat": 54.700317, "speed": 0.6, "course": 310.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219007333.0, "lon": 14.931233, "lat": 54.700317, "speed": 0.6, "course": 310.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1281, CreateTime = 1717076858840, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6e7f4635)
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 220174000.0, "lon": 9.700345, "lat": 57.56008, "speed": 16.2, "course": 60.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 220174000.0, "lon": 9.700345, "lat": 57.56008, "speed": 16.2, "course": 60.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1282, CreateTime = 1717076858840, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@22846883)
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 565617000.0, "lon": 8.142233, "lat": 56.728783, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 565617000.0, "lon": 8.142233, "lat": 56.728783, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1283, CreateTime = 1717076858840, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@337fb550)
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 220223000.0, "lon": 9.319075, "lat": 57.453797, "speed": 17.4, "course": 54.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 220223000.0, "lon": 9.319075, "lat": 57.453797, "speed": 17.4, "course": 54.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1284, CreateTime = 1717076858840, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@537700b3)
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219000017.0, "lon": 9.757952, "lat": 55.561793, "speed": 0.1, "course": 178.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219000017.0, "lon": 9.757952, "lat": 55.561793, "speed": 0.1, "course": 178.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1285, CreateTime = 1717076858840, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@472daa06)
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 211211200.0, "lon": 10.04414, "lat": 54.771718, "speed": 11.8, "course": 328.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 211211200.0, "lon": 10.04414, "lat": 54.771718, "speed": 11.8, "course": 328.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1286, CreateTime = 1717076858840, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@466c1210)
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 207050000.0, "lon": 10.607687, "lat": 57.681653, "speed": 0.2, "course": 47.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 207050000.0, "lon": 10.607687, "lat": 57.681653, "speed": 0.2, "course": 47.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1287, CreateTime = 1717076858840, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@8f7eab8)
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 219108000.0, "lon": 15.100033, "lat": 55.302867, "speed": 9.3, "course": 95.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 219108000.0, "lon": 15.100033, "lat": 55.302867, "speed": 9.3, "course": 95.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1288, CreateTime = 1717076858840, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@636e118d)
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:13", "mmsi": 311814000.0, "lon": 8.505977, "lat": 57.774273, "speed": 14.0, "course": 269.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:13", "mmsi": 311814000.0, "lon": 8.505977, "lat": 57.774273, "speed": 14.0, "course": 269.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1289, CreateTime = 1717076858840, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4939fa7c)
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 265007000.0, "lon": 8.497438, "lat": 57.293257, "speed": 14.5, "course": 52.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 265007000.0, "lon": 8.497438, "lat": 57.293257, "speed": 14.5, "course": 52.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1290, CreateTime = 1717076858841, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6f639dd9)
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 244613000.0, "lon": 12.070725, "lat": 54.48125, "speed": 10.4, "course": 277.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,430 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 244613000.0, "lon": 12.070725, "lat": 54.48125, "speed": 10.4, "course": 277.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1291, CreateTime = 1717076858841, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@58f608a7)
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 992191016.0, "lon": 11.046738, "lat": 55.324793, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 992191016.0, "lon": 11.046738, "lat": 55.324793, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1292, CreateTime = 1717076858841, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4b07884d)
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219000479.0, "lon": 11.962367, "lat": 54.472483, "speed": 15.2, "course": 346.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219000479.0, "lon": 11.962367, "lat": 54.472483, "speed": 15.2, "course": 346.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1293, CreateTime = 1717076858841, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4d6b614b)
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 258514000.0, "lon": 12.600157, "lat": 55.689902, "speed": 0.0, "course": 263.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 258514000.0, "lon": 12.600157, "lat": 55.689902, "speed": 0.0, "course": 263.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1294, CreateTime = 1717076858841, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3e15b06a)
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219000352.0, "lon": 10.224083, "lat": 56.160467, "speed": 0.0, "course": 1.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219000352.0, "lon": 10.224083, "lat": 56.160467, "speed": 0.0, "course": 1.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1295, CreateTime = 1717076858841, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@56ce243f)
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219838000.0, "lon": 10.583858, "lat": 57.715978, "speed": 0.0, "course": 14.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219838000.0, "lon": 10.583858, "lat": 57.715978, "speed": 0.0, "course": 14.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1296, CreateTime = 1717076858841, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@217c9b4b)
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 220356000.0, "lon": 10.663632, "lat": 55.449328, "speed": 0.0, "course": 170.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 220356000.0, "lon": 10.663632, "lat": 55.449328, "speed": 0.0, "course": 170.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1297, CreateTime = 1717076858842, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@370bc716)
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219007457.0, "lon": 8.601093, "lat": 57.121018, "speed": 0.0, "course": 281.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219007457.0, "lon": 8.601093, "lat": 57.121018, "speed": 0.0, "course": 281.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1298, CreateTime = 1717076858842, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@248eb77d)
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 220273000.0, "lon": 10.925035, "lat": 56.409202, "speed": 0.0, "course": 338.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 220273000.0, "lon": 10.925035, "lat": 56.409202, "speed": 0.0, "course": 338.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1299, CreateTime = 1717076858842, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3c6800f)
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 357562000.0, "lon": 8.286683, "lat": 57.255217, "speed": 16.2, "course": 59.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 357562000.0, "lon": 8.286683, "lat": 57.255217, "speed": 16.2, "course": 59.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1300, CreateTime = 1717076858842, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@46a5f5ff)
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219005906.0, "lon": 11.166305, "lat": 56.002213, "speed": 7.5, "course": 233.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219005906.0, "lon": 11.166305, "lat": 56.002213, "speed": 7.5, "course": 233.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1301, CreateTime = 1717076858842, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2fffb94a)
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 265609960.0, "lon": 11.796253, "lat": 57.605617, "speed": 0.0, "course": 331.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 265609960.0, "lon": 11.796253, "lat": 57.605617, "speed": 0.0, "course": 331.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1302, CreateTime = 1717076858842, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7e9bd697)
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 255801540.0, "lon": 11.865667, "lat": 56.740333, "speed": 18.2, "course": 168.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 255801540.0, "lon": 11.865667, "lat": 56.740333, "speed": 18.2, "course": 168.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1303, CreateTime = 1717076858842, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@49eae7b3)
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219001299.0, "lon": 8.421517, "lat": 55.47315, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219001299.0, "lon": 8.421517, "lat": 55.47315, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1304, CreateTime = 1717076858842, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2089f97c)
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219002769.0, "lon": 10.925473, "lat": 56.409285, "speed": 0.0, "course": 319.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219002769.0, "lon": 10.925473, "lat": 56.409285, "speed": 0.0, "course": 319.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1305, CreateTime = 1717076858842, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@726e31ce)
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 265177000.0, "lon": 11.69147, "lat": 57.631308, "speed": 16.9, "course": 24.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 265177000.0, "lon": 11.69147, "lat": 57.631308, "speed": 16.9, "course": 24.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1306, CreateTime = 1717076858842, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@52e17e7a)
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,431 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 377411000.0, "lon": 14.375667, "lat": 55.27, "speed": 11.0, "course": 218.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 377411000.0, "lon": 14.375667, "lat": 55.27, "speed": 11.0, "course": 218.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1307, CreateTime = 1717076858842, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4ca8ccea)
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219014427.0, "lon": 12.087868, "lat": 54.18193, "speed": 0.0, "course": 338.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219014427.0, "lon": 12.087868, "lat": 54.18193, "speed": 0.0, "course": 338.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1308, CreateTime = 1717076858842, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@23059e1a)
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 235398000.0, "lon": 10.584532, "lat": 57.716, "speed": 0.0, "course": 275.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 235398000.0, "lon": 10.584532, "lat": 57.716, "speed": 0.0, "course": 275.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1309, CreateTime = 1717076858842, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@20e62bf5)
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219001149.0, "lon": 12.30889, "lat": 56.127608, "speed": 0.0, "course": 311.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219001149.0, "lon": 12.30889, "lat": 56.127608, "speed": 0.0, "course": 311.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1310, CreateTime = 1717076858842, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@792d833d)
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219001619.0, "lon": 9.543147, "lat": 55.706563, "speed": 0.0, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219001619.0, "lon": 9.543147, "lat": 55.706563, "speed": 0.0, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1311, CreateTime = 1717076858842, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@73e8df6e)
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 245820000.0, "lon": 11.968003, "lat": 54.189752, "speed": 10.3, "course": 79.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 245820000.0, "lon": 11.968003, "lat": 54.189752, "speed": 10.3, "course": 79.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1312, CreateTime = 1717076858842, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7c926a47)
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,432 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 259769000.0, "lon": 13.058168, "lat": 54.819872, "speed": 13.9, "course": 70.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,433 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 259769000.0, "lon": 13.058168, "lat": 54.819872, "speed": 13.9, "course": 70.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,433 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1313, CreateTime = 1717076858843, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6dba4fa3)
2024-05-30 15:47:40 2024-05-30 13:47:40,433 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,433 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 220323000.0, "lon": 10.585283, "lat": 57.717312, "speed": 0.0, "course": 353.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,433 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 220323000.0, "lon": 10.585283, "lat": 57.717312, "speed": 0.0, "course": 353.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1314, CreateTime = 1717076858843, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@789b1d42)
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 220275000.0, "lon": 8.422168, "lat": 55.475463, "speed": 0.0, "course": 325.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 220275000.0, "lon": 8.422168, "lat": 55.475463, "speed": 0.0, "course": 325.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1315, CreateTime = 1717076858843, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4dbdae90)
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 259222000.0, "lon": 11.61861, "lat": 56.51867, "speed": 19.2, "course": 210.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 259222000.0, "lon": 11.61861, "lat": 56.51867, "speed": 19.2, "course": 210.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1316, CreateTime = 1717076858843, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@22123532)
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219014875.0, "lon": 11.508195, "lat": 57.791398, "speed": 11.6, "course": 169.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219014875.0, "lon": 11.508195, "lat": 57.791398, "speed": 11.6, "course": 169.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1317, CreateTime = 1717076858843, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1d6aa184)
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219188000.0, "lon": 8.628267, "lat": 57.535768, "speed": 2.6, "course": 263.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219188000.0, "lon": 8.628267, "lat": 57.535768, "speed": 2.6, "course": 263.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1318, CreateTime = 1717076858843, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3dbbce66)
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 304634000.0, "lon": 10.219833, "lat": 54.4325, "speed": 12.9, "course": 205.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 304634000.0, "lon": 10.219833, "lat": 54.4325, "speed": 12.9, "course": 205.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1319, CreateTime = 1717076858843, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1dd22e6f)
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 259898000.0, "lon": 11.4315, "lat": 56.530333, "speed": 14.5, "course": 50.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 259898000.0, "lon": 11.4315, "lat": 56.530333, "speed": 14.5, "course": 50.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1320, CreateTime = 1717076858843, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2eda2342)
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 211317180.0, "lon": 8.454993, "lat": 57.172063, "speed": 13.2, "course": 221.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 211317180.0, "lon": 8.454993, "lat": 57.172063, "speed": 13.2, "course": 221.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1321, CreateTime = 1717076858843, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6674c19c)
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219000852.0, "lon": 14.687867, "lat": 55.098913, "speed": 0.1, "course": 100.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219000852.0, "lon": 14.687867, "lat": 55.098913, "speed": 0.1, "course": 100.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1322, CreateTime = 1717076858843, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@55febca)
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,434 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 211291160.0, "lon": 8.80775, "lat": 54.497317, "speed": 0.0, "course": 173.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 211291160.0, "lon": 8.80775, "lat": 54.497317, "speed": 0.0, "course": 173.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1323, CreateTime = 1717076858843, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@9f21c58)
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219000605.0, "lon": 8.440415, "lat": 55.460733, "speed": 0.0, "course": 319.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219000605.0, "lon": 8.440415, "lat": 55.460733, "speed": 0.0, "course": 319.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1324, CreateTime = 1717076858844, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@76cdee17)
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 265522600.0, "lon": 11.796227, "lat": 57.605662, "speed": 0.1, "course": 182.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 265522600.0, "lon": 11.796227, "lat": 57.605662, "speed": 0.1, "course": 182.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1325, CreateTime = 1717076858844, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@36f5a973)
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 257689000.0, "lon": 12.236673, "lat": 54.457405, "speed": 14.8, "course": 26.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 257689000.0, "lon": 12.236673, "lat": 54.457405, "speed": 14.8, "course": 26.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1326, CreateTime = 1717076858844, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4c0e05dc)
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 236196000.0, "lon": 12.262183, "lat": 56.19495, "speed": 10.9, "course": 78.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 236196000.0, "lon": 12.262183, "lat": 56.19495, "speed": 10.9, "course": 78.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1327, CreateTime = 1717076858844, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5587c0d9)
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 265514800.0, "lon": 12.99744, "lat": 55.613557, "speed": 0.0, "course": 128.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 265514800.0, "lon": 12.99744, "lat": 55.613557, "speed": 0.0, "course": 128.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1328, CreateTime = 1717076858844, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4ca33128)
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 265504570.0, "lon": 11.871227, "lat": 57.68316, "speed": 0.0, "course": 240.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,435 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 265504570.0, "lon": 11.871227, "lat": 57.68316, "speed": 0.0, "course": 240.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,436 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1329, CreateTime = 1717076858844, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5706b7fe)
2024-05-30 15:47:40 2024-05-30 13:47:40,436 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,436 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219000809.0, "lon": 11.5145, "lat": 54.971973, "speed": 0.0, "course": 190.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,436 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219000809.0, "lon": 11.5145, "lat": 54.971973, "speed": 0.0, "course": 190.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,436 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1330, CreateTime = 1717076858844, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6b1a7827)
2024-05-30 15:47:40 2024-05-30 13:47:40,436 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,436 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219000836.0, "lon": 10.412855, "lat": 54.891653, "speed": 0.0, "course": 59.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,436 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219000836.0, "lon": 10.412855, "lat": 54.891653, "speed": 0.0, "course": 59.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,436 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1331, CreateTime = 1717076858844, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@70fc95)
2024-05-30 15:47:40 2024-05-30 13:47:40,436 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,436 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219868000.0, "lon": 9.958177, "lat": 57.592378, "speed": 0.0, "course": 46.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,436 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219868000.0, "lon": 9.958177, "lat": 57.592378, "speed": 0.0, "course": 46.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,436 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1332, CreateTime = 1717076858844, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@550fb7c2)
2024-05-30 15:47:40 2024-05-30 13:47:40,436 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,436 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 220461000.0, "lon": 10.584858, "lat": 57.716868, "speed": 0.0, "course": 0.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,436 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 220461000.0, "lon": 10.584858, "lat": 57.716868, "speed": 0.0, "course": 0.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1333, CreateTime = 1717076858844, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@37d453da)
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 249622000.0, "lon": 11.662783, "lat": 54.209067, "speed": 10.0, "course": 73.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 249622000.0, "lon": 11.662783, "lat": 54.209067, "speed": 10.0, "course": 73.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1334, CreateTime = 1717076858844, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@fb7de47)
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 636014186.0, "lon": 11.10227, "lat": 56.028032, "speed": 9.4, "course": 24.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 636014186.0, "lon": 11.10227, "lat": 56.028032, "speed": 9.4, "course": 24.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1335, CreateTime = 1717076858848, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@8241f70)
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 257019640.0, "lon": 10.550667, "lat": 57.4425, "speed": 0.0, "course": 148.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 257019640.0, "lon": 10.550667, "lat": 57.4425, "speed": 0.0, "course": 148.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1336, CreateTime = 1717076858848, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@203d0811)
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219012638.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219012638.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1337, CreateTime = 1717076858848, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3562d54f)
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 209392000.0, "lon": 8.570868, "lat": 55.0863, "speed": 0.1, "course": 302.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 209392000.0, "lon": 8.570868, "lat": 55.0863, "speed": 0.1, "course": 302.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1338, CreateTime = 1717076858848, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4966042)
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219438000.0, "lon": 4.910457, "lat": 56.482197, "speed": 0.0, "course": 323.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219438000.0, "lon": 4.910457, "lat": 56.482197, "speed": 0.0, "course": 323.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1339, CreateTime = 1717076858848, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2c61203f)
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 248811000.0, "lon": 10.801115, "lat": 55.73071, "speed": 16.3, "course": 9.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 248811000.0, "lon": 10.801115, "lat": 55.73071, "speed": 16.3, "course": 9.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1340, CreateTime = 1717076858848, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6454d822)
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219263000.0, "lon": 10.537722, "lat": 57.431297, "speed": 0.0, "course": 196.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219263000.0, "lon": 10.537722, "lat": 57.431297, "speed": 0.0, "course": 196.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1341, CreateTime = 1717076858848, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@473fb14a)
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 209696000.0, "lon": 11.374813, "lat": 54.545448, "speed": 15.4, "course": 294.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 209696000.0, "lon": 11.374813, "lat": 54.545448, "speed": 15.4, "course": 294.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1342, CreateTime = 1717076858848, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@701c4d9f)
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,439 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219002358.0, "lon": 11.347953, "lat": 54.656347, "speed": 0.0, "course": 198.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,440 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219002358.0, "lon": 11.347953, "lat": 54.656347, "speed": 0.0, "course": 198.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,440 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1343, CreateTime = 1717076858848, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5559fb7b)
2024-05-30 15:47:40 2024-05-30 13:47:40,440 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,440 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219777000.0, "lon": 10.522413, "lat": 54.851957, "speed": 0.0, "course": 15.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,440 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219777000.0, "lon": 10.522413, "lat": 54.851957, "speed": 0.0, "course": 15.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,440 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1344, CreateTime = 1717076858849, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@170eac3a)
2024-05-30 15:47:40 2024-05-30 13:47:40,440 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,440 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 311995000.0, "lon": 10.266752, "lat": 57.791692, "speed": 19.0, "course": 75.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,440 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 311995000.0, "lon": 10.266752, "lat": 57.791692, "speed": 19.0, "course": 75.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1345, CreateTime = 1717076858849, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2d81ea70)
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219001514.0, "lon": 11.861953, "lat": 54.770128, "speed": 0.0, "course": 327.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219001514.0, "lon": 11.861953, "lat": 54.770128, "speed": 0.0, "course": 327.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1346, CreateTime = 1717076858850, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3f633aea)
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219005954.0, "lon": 10.5867, "lat": 57.718217, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219005954.0, "lon": 10.5867, "lat": 57.718217, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1347, CreateTime = 1717076858850, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@257b9c5e)
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219477000.0, "lon": 15.136455, "lat": 55.063695, "speed": 0.6, "course": 287.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219477000.0, "lon": 15.136455, "lat": 55.063695, "speed": 0.6, "course": 287.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1348, CreateTime = 1717076858850, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@47f69bb7)
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219000872.0, "lon": 10.30461, "lat": 56.990923, "speed": 0.1, "course": 290.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219000872.0, "lon": 10.30461, "lat": 56.990923, "speed": 0.1, "course": 290.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1349, CreateTime = 1717076858851, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@65862b53)
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 240244000.0, "lon": 12.663967, "lat": 55.417933, "speed": 12.6, "course": 197.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 240244000.0, "lon": 12.663967, "lat": 55.417933, "speed": 12.6, "course": 197.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1350, CreateTime = 1717076858852, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4314e963)
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 231812000.0, "lon": 10.6012, "lat": 57.719517, "speed": 0.1, "course": 303.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 231812000.0, "lon": 10.6012, "lat": 57.719517, "speed": 0.1, "course": 303.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1351, CreateTime = 1717076858852, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3af40433)
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 265527020.0, "lon": 12.722263, "lat": 55.903448, "speed": 0.0, "course": 321.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 265527020.0, "lon": 12.722263, "lat": 55.903448, "speed": 0.0, "course": 321.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1352, CreateTime = 1717076858852, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@492c1bf9)
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219009273.0, "lon": 8.598383, "lat": 57.1226, "speed": 1.6, "course": 3.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219009273.0, "lon": 8.598383, "lat": 57.1226, "speed": 1.6, "course": 3.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1353, CreateTime = 1717076858852, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1d247d3c)
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219043000.0, "lon": 4.212002, "lat": 56.369788, "speed": 0.4, "course": 101.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219043000.0, "lon": 4.212002, "lat": 56.369788, "speed": 0.4, "course": 101.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1354, CreateTime = 1717076858852, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@791fc00a)
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 308874000.0, "lon": 12.466178, "lat": 54.705432, "speed": 9.9, "course": 235.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 308874000.0, "lon": 12.466178, "lat": 54.705432, "speed": 9.9, "course": 235.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1355, CreateTime = 1717076858852, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@63d09686)
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 238199000.0, "lon": 10.8875, "lat": 54.637167, "speed": 12.2, "course": 298.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 238199000.0, "lon": 10.8875, "lat": 54.637167, "speed": 12.2, "course": 298.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1356, CreateTime = 1717076858852, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4a0aaad6)
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219014161.0, "lon": 8.12355, "lat": 56.00413, "speed": 0.0, "course": 273.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219014161.0, "lon": 8.12355, "lat": 56.00413, "speed": 0.0, "course": 273.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1357, CreateTime = 1717076858853, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7479e336)
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219226000.0, "lon": 8.126333, "lat": 55.4265, "speed": 14.5, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219226000.0, "lon": 8.126333, "lat": 55.4265, "speed": 14.5, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1358, CreateTime = 1717076858853, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@73616223)
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219000553.0, "lon": 9.88934, "lat": 55.270612, "speed": 0.0, "course": 190.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219000553.0, "lon": 9.88934, "lat": 55.270612, "speed": 0.0, "course": 190.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1359, CreateTime = 1717076858854, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1462ae6f)
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219001359.0, "lon": 10.67102, "lat": 56.148957, "speed": 0.2, "course": 144.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,441 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219001359.0, "lon": 10.67102, "lat": 56.148957, "speed": 0.2, "course": 144.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1360, CreateTime = 1717076858854, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@ba1ea2f)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219014012.0, "lon": 8.422017, "lat": 55.4726, "speed": 0.0, "course": 194.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219014012.0, "lon": 8.422017, "lat": 55.4726, "speed": 0.0, "course": 194.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1361, CreateTime = 1717076858856, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@307ac83e)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 246252000.0, "lon": 12.056653, "lat": 54.46478, "speed": 10.4, "course": 269.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 246252000.0, "lon": 12.056653, "lat": 54.46478, "speed": 10.4, "course": 269.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1362, CreateTime = 1717076858856, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4872c468)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219002881.0, "lon": 8.598895, "lat": 57.121872, "speed": 0.0, "course": 349.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219002881.0, "lon": 8.598895, "lat": 57.121872, "speed": 0.0, "course": 349.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1363, CreateTime = 1717076858856, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@49620adf)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219000188.0, "lon": 10.239088, "lat": 55.094077, "speed": 0.0, "course": 202.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219000188.0, "lon": 10.239088, "lat": 55.094077, "speed": 0.0, "course": 202.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1364, CreateTime = 1717076858856, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4d16614e)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219004263.0, "lon": 10.912168, "lat": 55.710923, "speed": 9.2, "course": 290.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219004263.0, "lon": 10.912168, "lat": 55.710923, "speed": 9.2, "course": 290.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1365, CreateTime = 1717076858856, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2bcb7bea)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 211910000.0, "lon": 8.247133, "lat": 57.055217, "speed": 23.7, "course": 40.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 211910000.0, "lon": 8.247133, "lat": 57.055217, "speed": 23.7, "course": 40.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1366, CreateTime = 1717076858856, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7544ab7f)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 220278000.0, "lon": 9.664255, "lat": 57.901917, "speed": 0.5, "course": 75.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 220278000.0, "lon": 9.664255, "lat": 57.901917, "speed": 0.5, "course": 75.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1367, CreateTime = 1717076858857, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2c2973fa)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 277408000.0, "lon": 15.483253, "lat": 54.978877, "speed": 20.7, "course": 242.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 277408000.0, "lon": 15.483253, "lat": 54.978877, "speed": 20.7, "course": 242.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1368, CreateTime = 1717076858857, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@524b6b20)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 211211290.0, "lon": 10.035627, "lat": 54.778503, "speed": 11.6, "course": 319.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 211211290.0, "lon": 10.035627, "lat": 54.778503, "speed": 11.6, "course": 319.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1369, CreateTime = 1717076858857, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@222f4ea8)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 992191503.0, "lon": 5.107282, "lat": 55.478917, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 992191503.0, "lon": 5.107282, "lat": 55.478917, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1370, CreateTime = 1717076858857, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@72e016c1)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219000191.0, "lon": 10.618252, "lat": 55.061255, "speed": 0.0, "course": 203.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219000191.0, "lon": 10.618252, "lat": 55.061255, "speed": 0.0, "course": 203.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1371, CreateTime = 1717076858857, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@15b10dc4)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219014974.0, "lon": 12.69095, "lat": 56.045267, "speed": 0.0, "course": 273.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219014974.0, "lon": 12.69095, "lat": 56.045267, "speed": 0.0, "course": 273.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1372, CreateTime = 1717076858857, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1c2a6639)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 211284350.0, "lon": 16.505853, "lat": 55.909418, "speed": 14.9, "course": 30.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 211284350.0, "lon": 16.505853, "lat": 55.909418, "speed": 14.9, "course": 30.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1373, CreateTime = 1717076858857, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@44a8311a)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219000845.0, "lon": 8.565945, "lat": 55.088527, "speed": 0.0, "course": 263.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219000845.0, "lon": 8.565945, "lat": 55.088527, "speed": 0.0, "course": 263.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1374, CreateTime = 1717076858857, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@368c6150)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 2190049.0, "lon": 10.918783, "lat": 55.735817, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 2190049.0, "lon": 10.918783, "lat": 55.735817, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1375, CreateTime = 1717076858857, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2b4e8568)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219622000.0, "lon": 10.539443, "lat": 55.470508, "speed": 0.0, "course": 356.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219622000.0, "lon": 10.539443, "lat": 55.470508, "speed": 0.0, "course": 356.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1376, CreateTime = 1717076858857, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@641a2596)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 219011321.0, "lon": 8.965717, "lat": 57.715825, "speed": 0.5, "course": 76.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 219011321.0, "lon": 8.965717, "lat": 57.715825, "speed": 0.5, "course": 76.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1377, CreateTime = 1717076858857, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@61bff8ee)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:14", "mmsi": 210008000.0, "lon": 10.943832, "lat": 57.68044, "speed": 17.2, "course": 132.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:14", "mmsi": 210008000.0, "lon": 10.943832, "lat": 57.68044, "speed": 17.2, "course": 132.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1378, CreateTime = 1717076858857, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@34ec9368)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219850000.0, "lon": 9.7645, "lat": 55.3585, "speed": 9.2, "course": 300.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219850000.0, "lon": 9.7645, "lat": 55.3585, "speed": 9.2, "course": 300.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1379, CreateTime = 1717076858858, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6b562558)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 277334000.0, "lon": 13.974182, "lat": 54.66863, "speed": 13.3, "course": 278.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 277334000.0, "lon": 13.974182, "lat": 54.66863, "speed": 13.3, "course": 278.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1380, CreateTime = 1717076858858, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5e558b31)
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219936000.0, "lon": 9.801677, "lat": 57.740815, "speed": 3.5, "course": 334.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219936000.0, "lon": 9.801677, "lat": 57.740815, "speed": 3.5, "course": 334.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,442 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1381, CreateTime = 1717076858858, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@40b3709d)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 209078000.0, "lon": 11.768, "lat": 56.9225, "speed": 12.8, "course": 159.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 209078000.0, "lon": 11.768, "lat": 56.9225, "speed": 12.8, "course": 159.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1382, CreateTime = 1717076858858, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1014cc30)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 220359000.0, "lon": 9.963175, "lat": 57.59288, "speed": 0.0, "course": 319.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 220359000.0, "lon": 9.963175, "lat": 57.59288, "speed": 0.0, "course": 319.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1383, CreateTime = 1717076858858, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4ab2578f)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 265150000.0, "lon": 12.300995, "lat": 54.562842, "speed": 16.3, "course": 34.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 265150000.0, "lon": 12.300995, "lat": 54.562842, "speed": 16.3, "course": 34.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1384, CreateTime = 1717076858858, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@384c41eb)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 992191508.0, "lon": 4.758667, "lat": 55.579667, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 992191508.0, "lon": 4.758667, "lat": 55.579667, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1385, CreateTime = 1717076858858, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6320e9e7)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 265547270.0, "lon": 11.804403, "lat": 57.611563, "speed": 9.6, "course": 201.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 265547270.0, "lon": 11.804403, "lat": 57.611563, "speed": 9.6, "course": 201.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1386, CreateTime = 1717076858858, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@55e3dcff)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 249605000.0, "lon": 10.854178, "lat": 54.736555, "speed": 13.9, "course": 179.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 249605000.0, "lon": 10.854178, "lat": 54.736555, "speed": 13.9, "course": 179.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1387, CreateTime = 1717076858858, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@db5e7e3)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 265410000.0, "lon": 11.604133, "lat": 57.607727, "speed": 17.1, "course": 251.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 265410000.0, "lon": 11.604133, "lat": 57.607727, "speed": 17.1, "course": 251.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1388, CreateTime = 1717076858858, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@57acaca7)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 215013000.0, "lon": 15.011662, "lat": 55.569808, "speed": 17.1, "course": 238.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 215013000.0, "lon": 15.011662, "lat": 55.569808, "speed": 17.1, "course": 238.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1389, CreateTime = 1717076858858, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@33a70864)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 220356000.0, "lon": 10.663632, "lat": 55.449328, "speed": 0.0, "course": 170.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 220356000.0, "lon": 10.663632, "lat": 55.449328, "speed": 0.0, "course": 170.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1390, CreateTime = 1717076858858, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@78683ecb)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 259579000.0, "lon": 3.3615, "lat": 56.277833, "speed": 1.0, "course": 36.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 259579000.0, "lon": 3.3615, "lat": 56.277833, "speed": 1.0, "course": 36.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1391, CreateTime = 1717076858858, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5ac044da)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 265581970.0, "lon": 10.780103, "lat": 57.674308, "speed": 0.1, "course": 117.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 265581970.0, "lon": 10.780103, "lat": 57.674308, "speed": 0.1, "course": 117.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1392, CreateTime = 1717076858859, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@68bb12b1)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219001232.0, "lon": 11.924897, "lat": 54.573415, "speed": 0.0, "course": 359.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219001232.0, "lon": 11.924897, "lat": 54.573415, "speed": 0.0, "course": 359.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1393, CreateTime = 1717076858859, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@63d4c3ea)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 377262000.0, "lon": 11.406217, "lat": 54.087283, "speed": 9.5, "course": 2.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 377262000.0, "lon": 11.406217, "lat": 54.087283, "speed": 9.5, "course": 2.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1394, CreateTime = 1717076858859, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5a73373d)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 376532000.0, "lon": 10.044333, "lat": 57.057167, "speed": 0.1, "course": 348.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 376532000.0, "lon": 10.044333, "lat": 57.057167, "speed": 0.1, "course": 348.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1395, CreateTime = 1717076858859, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2cd4e3d)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 253062000.0, "lon": 14.339282, "lat": 55.280895, "speed": 12.8, "course": 218.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 253062000.0, "lon": 14.339282, "lat": 55.280895, "speed": 12.8, "course": 218.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1396, CreateTime = 1717076858859, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@32d3fa4f)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 265577470.0, "lon": 11.666837, "lat": 57.699478, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 265577470.0, "lon": 11.666837, "lat": 57.699478, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1397, CreateTime = 1717076858859, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@77dda46c)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219014146.0, "lon": 11.25943, "lat": 54.560233, "speed": 7.0, "course": 116.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219014146.0, "lon": 11.25943, "lat": 54.560233, "speed": 7.0, "course": 116.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1398, CreateTime = 1717076858859, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@34d4af75)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 2655153.0, "lon": 11.821315, "lat": 58.374063, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 2655153.0, "lon": 11.821315, "lat": 58.374063, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1399, CreateTime = 1717076858861, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5c00b374)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219000141.0, "lon": 12.427303, "lat": 55.09766, "speed": 0.3, "course": 352.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219000141.0, "lon": 12.427303, "lat": 55.09766, "speed": 0.3, "course": 352.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1400, CreateTime = 1717076858861, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@71ac3b39)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219007641.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219007641.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1401, CreateTime = 1717076858861, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6b481fa4)
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 244234000.0, "lon": 13.38828, "lat": 54.83365, "speed": 12.3, "course": 66.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 244234000.0, "lon": 13.38828, "lat": 54.83365, "speed": 12.3, "course": 66.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,443 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1402, CreateTime = 1717076858861, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7a76aabf)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 246542000.0, "lon": 10.841588, "lat": 54.542933, "speed": 10.3, "course": 74.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 246542000.0, "lon": 10.841588, "lat": 54.542933, "speed": 10.3, "course": 74.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1403, CreateTime = 1717076858861, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@23b42d96)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 304010515.0, "lon": 10.578817, "lat": 54.569668, "speed": 14.7, "course": 247.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 304010515.0, "lon": 10.578817, "lat": 54.569668, "speed": 14.7, "course": 247.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1404, CreateTime = 1717076858862, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3351af2a)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 245229000.0, "lon": 14.39185, "lat": 55.30455, "speed": 12.5, "course": 220.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 245229000.0, "lon": 14.39185, "lat": 55.30455, "speed": 12.5, "course": 220.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1405, CreateTime = 1717076858862, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@184f33db)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 314208000.0, "lon": 7.8394, "lat": 57.424483, "speed": 12.5, "course": 208.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 314208000.0, "lon": 7.8394, "lat": 57.424483, "speed": 12.5, "course": 208.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1406, CreateTime = 1717076858862, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@57a3413f)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219000429.0, "lon": 11.34501, "lat": 54.650282, "speed": 9.3, "course": 45.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219000429.0, "lon": 11.34501, "lat": 54.650282, "speed": 9.3, "course": 45.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1407, CreateTime = 1717076858862, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@55f91ec0)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219173000.0, "lon": 13.830545, "lat": 55.424628, "speed": 0.1, "course": 193.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219173000.0, "lon": 13.830545, "lat": 55.424628, "speed": 0.1, "course": 193.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1408, CreateTime = 1717076858862, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6befc3aa)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219001262.0, "lon": 11.92985, "lat": 54.57215, "speed": 0.0, "course": 216.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219001262.0, "lon": 11.92985, "lat": 54.57215, "speed": 0.0, "course": 216.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1409, CreateTime = 1717076858863, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@a5ff4e7)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 230315000.0, "lon": 10.944167, "lat": 55.908333, "speed": 15.1, "course": 38.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 230315000.0, "lon": 10.944167, "lat": 55.908333, "speed": 15.1, "course": 38.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1410, CreateTime = 1717076858864, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4738e62a)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 265561990.0, "lon": 13.034538, "lat": 55.624623, "speed": 0.0, "course": 341.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 265561990.0, "lon": 13.034538, "lat": 55.624623, "speed": 0.0, "course": 341.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1411, CreateTime = 1717076858865, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5aaaef13)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 231320000.0, "lon": 10.924367, "lat": 56.410117, "speed": 0.0, "course": 95.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 231320000.0, "lon": 10.924367, "lat": 56.410117, "speed": 0.0, "course": 95.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1412, CreateTime = 1717076858865, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4f4d857f)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219001749.0, "lon": 11.348152, "lat": 54.656488, "speed": 0.0, "course": 105.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219001749.0, "lon": 11.348152, "lat": 54.656488, "speed": 0.0, "course": 105.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1413, CreateTime = 1717076858865, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3a40b8bd)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219000592.0, "lon": 10.922553, "lat": 57.29662, "speed": 0.1, "course": 282.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219000592.0, "lon": 10.922553, "lat": 57.29662, "speed": 0.1, "course": 282.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1414, CreateTime = 1717076858865, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3a491069)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219167000.0, "lon": 5.05345, "lat": 55.398945, "speed": 0.4, "course": 356.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219167000.0, "lon": 5.05345, "lat": 55.398945, "speed": 0.4, "course": 356.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1415, CreateTime = 1717076858866, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3796a244)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 266321000.0, "lon": 11.899112, "lat": 57.69171, "speed": 0.1, "course": 282.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 266321000.0, "lon": 11.899112, "lat": 57.69171, "speed": 0.1, "course": 282.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1416, CreateTime = 1717076858866, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@14d3afb4)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219010982.0, "lon": 8.422612, "lat": 55.475593, "speed": 0.1, "course": 320.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219010982.0, "lon": 8.422612, "lat": 55.475593, "speed": 0.1, "course": 320.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1417, CreateTime = 1717076858866, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2be968c3)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 258407000.0, "lon": 12.68863, "lat": 55.703708, "speed": 10.2, "course": 359.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 258407000.0, "lon": 12.68863, "lat": 55.703708, "speed": 10.2, "course": 359.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1418, CreateTime = 1717076858866, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@59d1ff8f)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 246061000.0, "lon": 12.83498, "lat": 55.859782, "speed": 0.2, "course": 305.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 246061000.0, "lon": 12.83498, "lat": 55.859782, "speed": 0.2, "course": 305.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1419, CreateTime = 1717076858866, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5b57e273)
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 477748300.0, "lon": 8.84, "lat": 57.602833, "speed": 14.9, "course": 60.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,444 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 477748300.0, "lon": 8.84, "lat": 57.602833, "speed": 14.9, "course": 60.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1420, CreateTime = 1717076858866, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@52f058a2)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 319161000.0, "lon": 11.4568, "lat": 56.34655, "speed": 14.4, "course": 28.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 319161000.0, "lon": 11.4568, "lat": 56.34655, "speed": 14.4, "course": 28.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1421, CreateTime = 1717076858866, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@323f9d4f)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219005878.0, "lon": 10.585752, "lat": 57.715887, "speed": 0.1, "course": 334.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219005878.0, "lon": 10.585752, "lat": 57.715887, "speed": 0.1, "course": 334.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1422, CreateTime = 1717076858867, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@64442100)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 2190051.0, "lon": 11.988507, "lat": 55.052172, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 2190051.0, "lon": 11.988507, "lat": 55.052172, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1423, CreateTime = 1717076858867, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@640381)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 256016000.0, "lon": 10.29155, "lat": 56.146333, "speed": 7.7, "course": 302.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 256016000.0, "lon": 10.29155, "lat": 56.146333, "speed": 7.7, "course": 302.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1424, CreateTime = 1717076858867, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@50016e67)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 257494000.0, "lon": 13.298422, "lat": 55.197018, "speed": 6.5, "course": 296.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 257494000.0, "lon": 13.298422, "lat": 55.197018, "speed": 6.5, "course": 296.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1425, CreateTime = 1717076858867, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1e9a44cd)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 304010160.0, "lon": 12.009383, "lat": 55.958967, "speed": 2.3, "course": 38.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 304010160.0, "lon": 12.009383, "lat": 55.958967, "speed": 2.3, "course": 38.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1426, CreateTime = 1717076858867, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5b133a3f)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219000321.0, "lon": 12.34716, "lat": 54.760658, "speed": 8.8, "course": 219.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219000321.0, "lon": 12.34716, "lat": 54.760658, "speed": 8.8, "course": 219.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1427, CreateTime = 1717076858867, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7bcb42d7)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 259269000.0, "lon": 8.596623, "lat": 57.122078, "speed": 0.0, "course": 161.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 259269000.0, "lon": 8.596623, "lat": 57.122078, "speed": 0.0, "course": 161.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1428, CreateTime = 1717076858867, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2062799f)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219024000.0, "lon": 9.773977, "lat": 57.945495, "speed": 0.7, "course": 86.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219024000.0, "lon": 9.773977, "lat": 57.945495, "speed": 0.7, "course": 86.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1429, CreateTime = 1717076858867, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6c92ed72)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 311037700.0, "lon": 11.717197, "lat": 56.994722, "speed": 12.0, "course": 162.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 311037700.0, "lon": 11.717197, "lat": 56.994722, "speed": 12.0, "course": 162.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1430, CreateTime = 1717076858867, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2e92e01d)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 255801950.0, "lon": 12.111483, "lat": 54.15145, "speed": 0.0, "course": 330.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 255801950.0, "lon": 12.111483, "lat": 54.15145, "speed": 0.0, "course": 330.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1431, CreateTime = 1717076858867, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@feed2e2)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 248743000.0, "lon": 11.879573, "lat": 54.373103, "speed": 9.0, "course": 335.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 248743000.0, "lon": 11.879573, "lat": 54.373103, "speed": 9.0, "course": 335.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1432, CreateTime = 1717076858867, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3c73fc01)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 210100000.0, "lon": 4.41624, "lat": 56.197648, "speed": 9.1, "course": 3.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 210100000.0, "lon": 4.41624, "lat": 56.197648, "speed": 9.1, "course": 3.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1433, CreateTime = 1717076858868, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@47717f80)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219000321.0, "lon": 12.34716, "lat": 54.760658, "speed": 8.8, "course": 219.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219000321.0, "lon": 12.34716, "lat": 54.760658, "speed": 8.8, "course": 219.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1434, CreateTime = 1717076858868, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7edafd7b)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 212360000.0, "lon": 15.52475, "lat": 55.753817, "speed": 10.9, "course": 238.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 212360000.0, "lon": 15.52475, "lat": 55.753817, "speed": 10.9, "course": 238.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1435, CreateTime = 1717076858869, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7da5980)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219002761.0, "lon": 15.135648, "lat": 55.06223, "speed": 0.0, "course": 225.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219002761.0, "lon": 15.135648, "lat": 55.06223, "speed": 0.0, "course": 225.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1436, CreateTime = 1717076858869, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@24ea2e8e)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 331209000.0, "lon": 9.88746, "lat": 55.270018, "speed": 0.0, "course": 236.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 331209000.0, "lon": 9.88746, "lat": 55.270018, "speed": 0.0, "course": 236.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1437, CreateTime = 1717076858869, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@682bd8ec)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 233234000.0, "lon": 7.31968, "lat": 56.392323, "speed": 15.4, "course": 212.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 233234000.0, "lon": 7.31968, "lat": 56.392323, "speed": 15.4, "course": 212.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1438, CreateTime = 1717076858870, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4133c1b7)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 215822000.0, "lon": 8.068307, "lat": 55.427423, "speed": 11.7, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 215822000.0, "lon": 8.068307, "lat": 55.427423, "speed": 11.7, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1439, CreateTime = 1717076858870, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@14708648)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 311020200.0, "lon": 6.424138, "lat": 55.545007, "speed": 12.0, "course": 171.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 311020200.0, "lon": 6.424138, "lat": 55.545007, "speed": 12.0, "course": 171.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1440, CreateTime = 1717076858870, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@619b4416)
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 235075191.0, "lon": 13.181433, "lat": 54.790117, "speed": 13.2, "course": 270.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,445 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 235075191.0, "lon": 13.181433, "lat": 54.790117, "speed": 13.2, "course": 270.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1441, CreateTime = 1717076858870, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@57411c71)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 266266000.0, "lon": 6.963097, "lat": 56.020427, "speed": 13.4, "course": 27.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 266266000.0, "lon": 6.963097, "lat": 56.020427, "speed": 13.4, "course": 27.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1442, CreateTime = 1717076858870, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@8a05157)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 311007200.0, "lon": 14.134622, "lat": 54.345235, "speed": 15.5, "course": 339.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 311007200.0, "lon": 14.134622, "lat": 54.345235, "speed": 15.5, "course": 339.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1443, CreateTime = 1717076858870, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1872c4cd)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 266039000.0, "lon": 11.136573, "lat": 56.09874, "speed": 17.5, "course": 206.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 266039000.0, "lon": 11.136573, "lat": 56.09874, "speed": 17.5, "course": 206.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1444, CreateTime = 1717076858870, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@23728821)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219000604.0, "lon": 8.44195, "lat": 55.4616, "speed": 0.0, "course": 225.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219000604.0, "lon": 8.44195, "lat": 55.4616, "speed": 0.0, "course": 225.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1445, CreateTime = 1717076858871, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7c8faaaa)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 2190075.0, "lon": 10.614575, "lat": 55.027093, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 2190075.0, "lon": 10.614575, "lat": 55.027093, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1446, CreateTime = 1717076858871, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@762f7685)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 265579090.0, "lon": 11.660653, "lat": 57.707527, "speed": 0.0, "course": 207.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 265579090.0, "lon": 11.660653, "lat": 57.707527, "speed": 0.0, "course": 207.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1447, CreateTime = 1717076858871, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@78f58021)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219601000.0, "lon": 10.537817, "lat": 55.469835, "speed": 0.0, "course": 309.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219601000.0, "lon": 10.537817, "lat": 55.469835, "speed": 0.0, "course": 309.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1448, CreateTime = 1717076858871, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4ff12c9e)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 246667000.0, "lon": 13.333362, "lat": 55.012083, "speed": 7.1, "course": 258.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 246667000.0, "lon": 13.333362, "lat": 55.012083, "speed": 7.1, "course": 258.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1449, CreateTime = 1717076858871, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4eaa1530)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 211226860.0, "lon": 7.384933, "lat": 55.260058, "speed": 15.6, "course": 249.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 211226860.0, "lon": 7.384933, "lat": 55.260058, "speed": 15.6, "course": 249.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1450, CreateTime = 1717076858871, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@433cd93e)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219007589.0, "lon": 10.785742, "lat": 55.139387, "speed": 0.0, "course": 309.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219007589.0, "lon": 10.785742, "lat": 55.139387, "speed": 0.0, "course": 309.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1451, CreateTime = 1717076858871, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@179cadf0)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 265846000.0, "lon": 10.59827, "lat": 57.717972, "speed": 0.0, "course": 293.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 265846000.0, "lon": 10.59827, "lat": 57.717972, "speed": 0.0, "course": 293.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1452, CreateTime = 1717076858871, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@514fe641)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219002687.0, "lon": 11.928827, "lat": 54.571752, "speed": 0.0, "course": 14.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219002687.0, "lon": 11.928827, "lat": 54.571752, "speed": 0.0, "course": 14.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1453, CreateTime = 1717076858871, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4f527acd)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 265630660.0, "lon": 14.767627, "lat": 55.680998, "speed": 1.3, "course": 85.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 265630660.0, "lon": 14.767627, "lat": 55.680998, "speed": 1.3, "course": 85.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1454, CreateTime = 1717076858871, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6a02af30)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 265610940.0, "lon": 12.687887, "lat": 56.044798, "speed": 0.0, "course": 8.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 265610940.0, "lon": 12.687887, "lat": 56.044798, "speed": 0.0, "course": 8.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1455, CreateTime = 1717076858872, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@18036cad)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219653000.0, "lon": 14.693712, "lat": 55.098538, "speed": 0.0, "course": 74.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219653000.0, "lon": 14.693712, "lat": 55.098538, "speed": 0.0, "course": 74.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1456, CreateTime = 1717076858872, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3650fc02)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219000125.0, "lon": 10.58831, "lat": 57.716912, "speed": 1.7, "course": 88.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219000125.0, "lon": 10.58831, "lat": 57.716912, "speed": 1.7, "course": 88.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1457, CreateTime = 1717076858872, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6a086c17)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 220451000.0, "lon": 14.837127, "lat": 55.248083, "speed": 0.1, "course": 272.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 220451000.0, "lon": 14.837127, "lat": 55.248083, "speed": 0.1, "course": 272.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1458, CreateTime = 1717076858872, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@158c2549)
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219679000.0, "lon": 11.095995, "lat": 55.6746, "speed": 6.9, "course": 269.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219679000.0, "lon": 11.095995, "lat": 55.6746, "speed": 6.9, "course": 269.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,446 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1459, CreateTime = 1717076858872, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@16e94551)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 265073000.0, "lon": 14.870383, "lat": 54.708117, "speed": 6.9, "course": 242.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 265073000.0, "lon": 14.870383, "lat": 54.708117, "speed": 6.9, "course": 242.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1460, CreateTime = 1717076858872, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@27e81b62)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219001673.0, "lon": 9.891767, "lat": 58.077817, "speed": 2.4, "course": 54.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219001673.0, "lon": 9.891767, "lat": 58.077817, "speed": 2.4, "course": 54.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1461, CreateTime = 1717076858872, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@e29b35c)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 265594380.0, "lon": 12.707205, "lat": 55.40724, "speed": 6.4, "course": 8.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 265594380.0, "lon": 12.707205, "lat": 55.40724, "speed": 6.4, "course": 8.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1462, CreateTime = 1717076858872, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7afb79bd)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 265522210.0, "lon": 11.667282, "lat": 57.699177, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 265522210.0, "lon": 11.667282, "lat": 57.699177, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1463, CreateTime = 1717076858872, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2664787e)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 257689000.0, "lon": 12.236725, "lat": 54.457465, "speed": 14.8, "course": 26.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 257689000.0, "lon": 12.236725, "lat": 54.457465, "speed": 14.8, "course": 26.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1464, CreateTime = 1717076858872, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@41b044db)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219106000.0, "lon": 10.507092, "lat": 57.492335, "speed": 0.0, "course": 258.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219106000.0, "lon": 10.507092, "lat": 57.492335, "speed": 0.0, "course": 258.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1465, CreateTime = 1717076858872, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@240bce2)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219023000.0, "lon": 10.911108, "lat": 54.921043, "speed": 10.3, "course": 42.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219023000.0, "lon": 10.911108, "lat": 54.921043, "speed": 10.3, "course": 42.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1466, CreateTime = 1717076858874, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@23d70b86)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 266239000.0, "lon": 12.013342, "lat": 54.367295, "speed": 13.5, "course": 50.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 266239000.0, "lon": 12.013342, "lat": 54.367295, "speed": 13.5, "course": 50.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1467, CreateTime = 1717076858874, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2675200a)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 244806000.0, "lon": 7.284118, "lat": 55.591717, "speed": 4.5, "course": 317.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 244806000.0, "lon": 7.284118, "lat": 55.591717, "speed": 4.5, "course": 317.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1468, CreateTime = 1717076858874, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@65a02e83)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 304669000.0, "lon": 12.080752, "lat": 54.442628, "speed": 9.4, "course": 268.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 304669000.0, "lon": 12.080752, "lat": 54.442628, "speed": 9.4, "course": 268.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1469, CreateTime = 1717076858875, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@62802979)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 992191506.0, "lon": 5.107417, "lat": 55.4773, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 992191506.0, "lon": 5.107417, "lat": 55.4773, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1470, CreateTime = 1717076858875, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@79908594)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 220249000.0, "lon": 8.055945, "lat": 56.315157, "speed": 9.4, "course": 174.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 220249000.0, "lon": 8.055945, "lat": 56.315157, "speed": 9.4, "course": 174.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1471, CreateTime = 1717076858875, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@766a8fdc)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219000501.0, "lon": 10.082083, "lat": 55.104783, "speed": 0.0, "course": 9.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219000501.0, "lon": 10.082083, "lat": 55.104783, "speed": 0.0, "course": 9.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1472, CreateTime = 1717076858875, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@12da73a4)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219009135.0, "lon": 8.599152, "lat": 57.121662, "speed": 0.1, "course": 291.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219009135.0, "lon": 8.599152, "lat": 57.121662, "speed": 0.1, "course": 291.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1473, CreateTime = 1717076858875, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@71f24b67)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219012073.0, "lon": 9.865902, "lat": 55.858018, "speed": 0.0, "course": 336.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219012073.0, "lon": 9.865902, "lat": 55.858018, "speed": 0.0, "course": 336.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1474, CreateTime = 1717076858875, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@cb3dce8)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219678000.0, "lon": 8.445875, "lat": 55.463178, "speed": 0.0, "course": 306.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219678000.0, "lon": 8.445875, "lat": 55.463178, "speed": 0.0, "course": 306.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1475, CreateTime = 1717076858876, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2e05b6cd)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 249434000.0, "lon": 13.241183, "lat": 54.902517, "speed": 13.5, "course": 247.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 249434000.0, "lon": 13.241183, "lat": 54.902517, "speed": 13.5, "course": 247.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1476, CreateTime = 1717076858877, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6f03a7fa)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 211211250.0, "lon": 10.045708, "lat": 54.768328, "speed": 11.7, "course": 327.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 211211250.0, "lon": 10.045708, "lat": 54.768328, "speed": 11.7, "course": 327.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1477, CreateTime = 1717076858877, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@c49700e)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 207083000.0, "lon": 15.34223, "lat": 55.688792, "speed": 12.5, "course": 243.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 207083000.0, "lon": 15.34223, "lat": 55.688792, "speed": 12.5, "course": 243.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1478, CreateTime = 1717076858878, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1e0fa9f3)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 212390000.0, "lon": 13.022175, "lat": 55.620255, "speed": 0.0, "course": 325.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 212390000.0, "lon": 13.022175, "lat": 55.620255, "speed": 0.0, "course": 325.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1479, CreateTime = 1717076858878, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1dbfd721)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 636014480.0, "lon": 11.008867, "lat": 55.965567, "speed": 12.9, "course": 214.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 636014480.0, "lon": 11.008867, "lat": 55.965567, "speed": 12.9, "course": 214.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1480, CreateTime = 1717076858878, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6ff18f1b)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219203000.0, "lon": 8.443833, "lat": 55.464, "speed": 0.0, "course": 322.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219203000.0, "lon": 8.443833, "lat": 55.464, "speed": 0.0, "course": 322.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1481, CreateTime = 1717076858878, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@28ff5beb)
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219592000.0, "lon": 11.38113, "lat": 57.753052, "speed": 16.9, "course": 343.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,447 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219592000.0, "lon": 11.38113, "lat": 57.753052, "speed": 16.9, "course": 343.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1482, CreateTime = 1717076858878, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4b5c2f36)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219321000.0, "lon": 4.8988, "lat": 56.46735, "speed": 0.6, "course": 49.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219321000.0, "lon": 4.8988, "lat": 56.46735, "speed": 0.6, "course": 49.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1483, CreateTime = 1717076858878, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2839efa3)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 220329000.0, "lon": 10.582833, "lat": 57.715267, "speed": 0.1, "course": 334.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 220329000.0, "lon": 10.582833, "lat": 57.715267, "speed": 0.1, "course": 334.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1484, CreateTime = 1717076858879, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4bd324e8)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 2190072.0, "lon": 9.96373, "lat": 57.52368, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 2190072.0, "lon": 9.96373, "lat": 57.52368, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1485, CreateTime = 1717076858879, serialized key size = -1, serialized value size = 109, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@19211e7a)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 218413000.0, "lon": 12.091218, "lat": 54.170987, "speed": 0.0, "course": 287.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 218413000.0, "lon": 12.091218, "lat": 54.170987, "speed": 0.0, "course": 287.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1486, CreateTime = 1717076858880, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@332ea7f7)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 245749000.0, "lon": 11.216667, "lat": 57.7155, "speed": 19.2, "course": 290.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 245749000.0, "lon": 11.216667, "lat": 57.7155, "speed": 19.2, "course": 290.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1487, CreateTime = 1717076858880, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@540d12c6)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:15", "mmsi": 219001849.0, "lon": 10.593845, "lat": 57.719833, "speed": 0.0, "course": 290.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:15", "mmsi": 219001849.0, "lon": 10.593845, "lat": 57.719833, "speed": 0.0, "course": 290.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1488, CreateTime = 1717076858881, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6ab88cb)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 220619000.0, "lon": 10.549023, "lat": 55.864672, "speed": 0.0, "course": 244.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 220619000.0, "lon": 10.549023, "lat": 55.864672, "speed": 0.0, "course": 244.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1489, CreateTime = 1717076858881, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@176894aa)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 265360000.0, "lon": 11.958472, "lat": 57.706422, "speed": 0.0, "course": 358.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 265360000.0, "lon": 11.958472, "lat": 57.706422, "speed": 0.0, "course": 358.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1490, CreateTime = 1717076858881, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@513f98af)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 992191016.0, "lon": 11.04674, "lat": 55.324797, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 992191016.0, "lon": 11.04674, "lat": 55.324797, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1491, CreateTime = 1717076858881, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d982b6c)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 261449000.0, "lon": 13.9909, "lat": 54.8086, "speed": 10.4, "course": 351.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 261449000.0, "lon": 13.9909, "lat": 54.8086, "speed": 10.4, "course": 351.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1492, CreateTime = 1717076858881, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@372f1bc4)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219004128.0, "lon": 10.586217, "lat": 57.717627, "speed": 0.0, "course": 56.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219004128.0, "lon": 10.586217, "lat": 57.717627, "speed": 0.0, "course": 56.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1493, CreateTime = 1717076858881, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@64b1144f)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 266262000.0, "lon": 12.631663, "lat": 55.041672, "speed": 17.6, "course": 177.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 266262000.0, "lon": 12.631663, "lat": 55.041672, "speed": 17.6, "course": 177.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1494, CreateTime = 1717076858882, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@49e60296)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219536000.0, "lon": 7.716502, "lat": 57.230785, "speed": 0.0, "course": 48.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219536000.0, "lon": 7.716502, "lat": 57.230785, "speed": 0.0, "course": 48.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1495, CreateTime = 1717076858884, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6589938d)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219157000.0, "lon": 15.115717, "lat": 55.679967, "speed": 11.4, "course": 58.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219157000.0, "lon": 15.115717, "lat": 55.679967, "speed": 11.4, "course": 58.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1496, CreateTime = 1717076858885, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2a3755c3)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 376481000.0, "lon": 15.521337, "lat": 55.665567, "speed": 7.5, "course": 56.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 376481000.0, "lon": 15.521337, "lat": 55.665567, "speed": 7.5, "course": 56.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1497, CreateTime = 1717076858885, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@46c82fa6)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219011248.0, "lon": 10.355768, "lat": 56.967523, "speed": 1.5, "course": 168.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219011248.0, "lon": 10.355768, "lat": 56.967523, "speed": 1.5, "course": 168.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1498, CreateTime = 1717076858885, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3fc3775b)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 265276000.0, "lon": 14.852545, "lat": 54.484132, "speed": 10.7, "course": 303.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 265276000.0, "lon": 14.852545, "lat": 54.484132, "speed": 10.7, "course": 303.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1499, CreateTime = 1717076858886, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@16ff9ed5)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Current fetch is finished.
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitting records from fetch for split aisdata-0
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 256189000.0, "lon": 10.3891, "lat": 57.794322, "speed": 10.0, "course": 248.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 256189000.0, "lon": 10.3891, "lat": 57.794322, "speed": 10.0, "course": 248.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1500, CreateTime = 1717076858887, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6f64884)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 304080890.0, "lon": 14.505333, "lat": 55.285167, "speed": 21.7, "course": 36.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 304080890.0, "lon": 14.505333, "lat": 55.285167, "speed": 21.7, "course": 36.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1501, CreateTime = 1717076858887, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1c4f2e3)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219002493.0, "lon": 10.447087, "lat": 55.599208, "speed": 0.1, "course": 159.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219002493.0, "lon": 10.447087, "lat": 55.599208, "speed": 0.1, "course": 159.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1502, CreateTime = 1717076858888, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2599242f)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 211106000.0, "lon": 8.601302, "lat": 57.123112, "speed": 0.0, "course": 306.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 211106000.0, "lon": 8.601302, "lat": 57.123112, "speed": 0.0, "course": 306.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1503, CreateTime = 1717076858888, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4f7a1f7f)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 211190000.0, "lon": 11.279288, "lat": 54.586485, "speed": 14.8, "course": 203.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 211190000.0, "lon": 11.279288, "lat": 54.586485, "speed": 14.8, "course": 203.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1504, CreateTime = 1717076858889, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7bfcdc7c)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 220275000.0, "lon": 8.422168, "lat": 55.475463, "speed": 0.0, "course": 325.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 220275000.0, "lon": 8.422168, "lat": 55.475463, "speed": 0.0, "course": 325.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1505, CreateTime = 1717076858889, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5d897a0a)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 265548350.0, "lon": 12.7984, "lat": 55.799532, "speed": 12.3, "course": 331.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 265548350.0, "lon": 12.7984, "lat": 55.799532, "speed": 12.3, "course": 331.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1506, CreateTime = 1717076858889, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@31dd85c8)
2024-05-30 15:47:40 2024-05-30 13:47:40,448 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219002826.0, "lon": 11.928753, "lat": 54.571808, "speed": 0.1, "course": 279.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219002826.0, "lon": 11.928753, "lat": 54.571808, "speed": 0.1, "course": 279.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1507, CreateTime = 1717076858890, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2e43e56b)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 220232000.0, "lon": 8.426817, "lat": 55.473017, "speed": 0.0, "course": 50.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 220232000.0, "lon": 8.426817, "lat": 55.473017, "speed": 0.0, "course": 50.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1508, CreateTime = 1717076858890, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3341c3e3)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 212644000.0, "lon": 11.62565, "lat": 57.60285, "speed": 16.2, "course": 98.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 212644000.0, "lon": 11.62565, "lat": 57.60285, "speed": 16.2, "course": 98.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1509, CreateTime = 1717076858890, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@258eb6ab)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 259769000.0, "lon": 13.058378, "lat": 54.819918, "speed": 13.9, "course": 70.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 259769000.0, "lon": 13.058378, "lat": 54.819918, "speed": 13.9, "course": 70.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1510, CreateTime = 1717076858890, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@78a09417)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 230204000.0, "lon": 12.832098, "lat": 54.713053, "speed": 15.1, "course": 59.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 230204000.0, "lon": 12.832098, "lat": 54.713053, "speed": 15.1, "course": 59.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1511, CreateTime = 1717076858890, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@49f94ed5)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219015063.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219015063.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1512, CreateTime = 1717076858890, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@749ac2d2)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 220315000.0, "lon": 8.123095, "lat": 56.004813, "speed": 0.0, "course": 324.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 220315000.0, "lon": 8.123095, "lat": 56.004813, "speed": 0.0, "course": 324.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1513, CreateTime = 1717076858890, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@24711904)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219013968.0, "lon": 11.35215, "lat": 54.651667, "speed": 0.0, "course": 155.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219013968.0, "lon": 11.35215, "lat": 54.651667, "speed": 0.0, "course": 155.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1514, CreateTime = 1717076858890, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@580d21b1)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 211356520.0, "lon": 12.112288, "lat": 54.146137, "speed": 0.0, "course": 109.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 211356520.0, "lon": 12.112288, "lat": 54.146137, "speed": 0.0, "course": 109.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1515, CreateTime = 1717076858890, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5b015383)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219702000.0, "lon": 10.666973, "lat": 56.155213, "speed": 0.1, "course": 181.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219702000.0, "lon": 10.666973, "lat": 56.155213, "speed": 0.1, "course": 181.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1516, CreateTime = 1717076858890, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@792f8663)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219003452.0, "lon": 12.680213, "lat": 55.593133, "speed": 0.0, "course": 329.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219003452.0, "lon": 12.680213, "lat": 55.593133, "speed": 0.0, "course": 329.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1517, CreateTime = 1717076858890, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@55ba197b)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219011553.0, "lon": 9.753592, "lat": 55.559907, "speed": 0.0, "course": 4.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219011553.0, "lon": 9.753592, "lat": 55.559907, "speed": 0.0, "course": 4.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1518, CreateTime = 1717076858891, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@640baad4)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 265660390.0, "lon": 12.707947, "lat": 55.409312, "speed": 6.3, "course": 8.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 265660390.0, "lon": 12.707947, "lat": 55.409312, "speed": 6.3, "course": 8.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1519, CreateTime = 1717076858891, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@35c7709d)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 218459000.0, "lon": 14.692547, "lat": 55.09341, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 218459000.0, "lon": 14.692547, "lat": 55.09341, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1520, CreateTime = 1717076858891, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@305ef4d8)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219014579.0, "lon": 8.614203, "lat": 56.51717, "speed": 0.0, "course": 298.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219014579.0, "lon": 8.614203, "lat": 56.51717, "speed": 0.0, "course": 298.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1521, CreateTime = 1717076858891, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@352a5269)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 245921000.0, "lon": 11.782613, "lat": 57.278037, "speed": 11.9, "course": 313.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 245921000.0, "lon": 11.782613, "lat": 57.278037, "speed": 11.9, "course": 313.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1522, CreateTime = 1717076858891, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@c4e1312)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219014162.0, "lon": 8.600535, "lat": 57.12244, "speed": 0.0, "course": 162.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219014162.0, "lon": 8.600535, "lat": 57.12244, "speed": 0.0, "course": 162.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1523, CreateTime = 1717076858891, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@203d99e)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 258517000.0, "lon": 9.958977, "lat": 57.593623, "speed": 0.0, "course": 315.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 258517000.0, "lon": 9.958977, "lat": 57.593623, "speed": 0.0, "course": 315.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1524, CreateTime = 1717076858891, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@45bc0532)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219011768.0, "lon": 7.34755, "lat": 55.252757, "speed": 10.2, "course": 251.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219011768.0, "lon": 7.34755, "lat": 55.252757, "speed": 10.2, "course": 251.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1525, CreateTime = 1717076858891, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@22e2bef6)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219007225.0, "lon": 10.308487, "lat": 56.990233, "speed": 0.0, "course": 298.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219007225.0, "lon": 10.308487, "lat": 56.990233, "speed": 0.0, "course": 298.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1526, CreateTime = 1717076858891, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5ec8ef3b)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 258714000.0, "lon": 12.027092, "lat": 54.432458, "speed": 10.6, "course": 271.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 258714000.0, "lon": 12.027092, "lat": 54.432458, "speed": 10.6, "course": 271.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1527, CreateTime = 1717076858891, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@429b1255)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219000896.0, "lon": 14.692273, "lat": 55.094203, "speed": 0.0, "course": 321.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219000896.0, "lon": 14.692273, "lat": 55.094203, "speed": 0.0, "course": 321.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1528, CreateTime = 1717076858891, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@672b1aa1)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219011021.0, "lon": 12.600498, "lat": 54.58742, "speed": 0.6, "course": 63.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219011021.0, "lon": 12.600498, "lat": 54.58742, "speed": 0.6, "course": 63.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1529, CreateTime = 1717076858891, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@50090dbc)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 265411000.0, "lon": 9.782403, "lat": 54.358228, "speed": 7.0, "course": 233.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 265411000.0, "lon": 9.782403, "lat": 54.358228, "speed": 7.0, "course": 233.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1530, CreateTime = 1717076858891, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@492181b1)
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219003966.0, "lon": 10.594145, "lat": 57.719922, "speed": 0.0, "course": 269.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219003966.0, "lon": 10.594145, "lat": 57.719922, "speed": 0.0, "course": 269.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,449 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1531, CreateTime = 1717076858892, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@53b22b7a)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 222222222.0, "lon": 9.89378, "lat": 57.024647, "speed": 0.0, "course": 253.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 222222222.0, "lon": 9.89378, "lat": 57.024647, "speed": 0.0, "course": 253.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1532, CreateTime = 1717076858892, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6c73cdbf)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219003141.0, "lon": 11.79948, "lat": 55.75502, "speed": 0.0, "course": 12.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219003141.0, "lon": 11.79948, "lat": 55.75502, "speed": 0.0, "course": 12.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1533, CreateTime = 1717076858892, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@740f4960)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 220067000.0, "lon": 10.672672, "lat": 54.752347, "speed": 0.0, "course": 240.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 220067000.0, "lon": 10.672672, "lat": 54.752347, "speed": 0.0, "course": 240.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1534, CreateTime = 1717076858892, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@31e66259)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219011922.0, "lon": 13.252437, "lat": 54.764747, "speed": 10.5, "course": 92.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219011922.0, "lon": 13.252437, "lat": 54.764747, "speed": 10.5, "course": 92.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1535, CreateTime = 1717076858892, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@73cd66e4)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219001431.0, "lon": 9.671075, "lat": 54.999263, "speed": 0.0, "course": 229.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219001431.0, "lon": 9.671075, "lat": 54.999263, "speed": 0.0, "course": 229.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1536, CreateTime = 1717076858892, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1214317)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 205365000.0, "lon": 11.79935, "lat": 54.42148, "speed": 15.9, "course": 316.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 205365000.0, "lon": 11.79935, "lat": 54.42148, "speed": 15.9, "course": 316.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1537, CreateTime = 1717076858892, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@f6b5e1a)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 211225380.0, "lon": 11.190168, "lat": 54.421658, "speed": 0.1, "course": 265.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 211225380.0, "lon": 11.190168, "lat": 54.421658, "speed": 0.1, "course": 265.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1538, CreateTime = 1717076858892, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@d1d1104)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 236501000.0, "lon": 14.340187, "lat": 55.15662, "speed": 13.2, "course": 38.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 236501000.0, "lon": 14.340187, "lat": 55.15662, "speed": 13.2, "course": 38.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1539, CreateTime = 1717076858892, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@15ffac05)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219380002.0, "lon": 9.895518, "lat": 57.024903, "speed": 0.0, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219380002.0, "lon": 9.895518, "lat": 57.024903, "speed": 0.0, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1540, CreateTime = 1717076858892, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1e4d6c56)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 265627630.0, "lon": 11.777997, "lat": 57.574382, "speed": 0.0, "course": 272.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 265627630.0, "lon": 11.777997, "lat": 57.574382, "speed": 0.0, "course": 272.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1541, CreateTime = 1717076858892, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4b036a0b)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 277093000.0, "lon": 15.614833, "lat": 54.686833, "speed": 16.7, "course": 79.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 277093000.0, "lon": 15.614833, "lat": 54.686833, "speed": 16.7, "course": 79.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1542, CreateTime = 1717076858892, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2e73c75e)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219099000.0, "lon": 4.54437, "lat": 55.805225, "speed": 1.1, "course": 48.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219099000.0, "lon": 4.54437, "lat": 55.805225, "speed": 1.1, "course": 48.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1543, CreateTime = 1717076858892, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4604c911)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 257182000.0, "lon": 11.531272, "lat": 57.359085, "speed": 15.8, "course": 335.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 257182000.0, "lon": 11.531272, "lat": 57.359085, "speed": 15.8, "course": 335.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1544, CreateTime = 1717076858892, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@33de325b)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 248980000.0, "lon": 12.094672, "lat": 54.435928, "speed": 17.5, "course": 266.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 248980000.0, "lon": 12.094672, "lat": 54.435928, "speed": 17.5, "course": 266.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1545, CreateTime = 1717076858892, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@63dd4519)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219654000.0, "lon": 12.59724, "lat": 55.708812, "speed": 0.0, "course": 289.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219654000.0, "lon": 12.59724, "lat": 55.708812, "speed": 0.0, "course": 289.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1546, CreateTime = 1717076858892, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@53a4270b)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219007333.0, "lon": 14.93125, "lat": 54.700317, "speed": 1.7, "course": 17.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219007333.0, "lon": 14.93125, "lat": 54.700317, "speed": 1.7, "course": 17.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1547, CreateTime = 1717076858893, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3388302f)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 235035113.0, "lon": 12.610547, "lat": 55.199267, "speed": 14.9, "course": 175.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 235035113.0, "lon": 12.610547, "lat": 55.199267, "speed": 14.9, "course": 175.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1548, CreateTime = 1717076858893, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@718680ef)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219244000.0, "lon": 7.499198, "lat": 56.820108, "speed": 0.5, "course": 36.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219244000.0, "lon": 7.499198, "lat": 56.820108, "speed": 0.5, "course": 36.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1549, CreateTime = 1717076858893, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@787ae64b)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219001543.0, "lon": 10.215805, "lat": 56.152645, "speed": 0.0, "course": 333.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219001543.0, "lon": 10.215805, "lat": 56.152645, "speed": 0.0, "course": 333.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1550, CreateTime = 1717076858893, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@a141a30)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 236150000.0, "lon": 11.501548, "lat": 54.519542, "speed": 11.1, "course": 294.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 236150000.0, "lon": 11.501548, "lat": 54.519542, "speed": 11.1, "course": 294.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1551, CreateTime = 1717076858893, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@78ef5a15)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 273327100.0, "lon": 9.492333, "lat": 55.491733, "speed": 0.0, "course": 19.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 273327100.0, "lon": 9.492333, "lat": 55.491733, "speed": 0.0, "course": 19.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1552, CreateTime = 1717076858893, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3dab3c1f)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 211215630.0, "lon": 12.12956, "lat": 54.156082, "speed": 0.0, "course": 148.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 211215630.0, "lon": 12.12956, "lat": 54.156082, "speed": 0.0, "course": 148.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1553, CreateTime = 1717076858893, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@12cccd5f)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219001976.0, "lon": 9.962467, "lat": 57.59325, "speed": 0.0, "course": 266.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219001976.0, "lon": 9.962467, "lat": 57.59325, "speed": 0.0, "course": 266.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1554, CreateTime = 1717076858893, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@38a390ac)
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219799000.0, "lon": 12.309983, "lat": 56.127707, "speed": 0.0, "course": 299.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,450 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219799000.0, "lon": 12.309983, "lat": 56.127707, "speed": 0.0, "course": 299.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1555, CreateTime = 1717076858893, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3a1e4a5f)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 2190062.0, "lon": 8.129343, "lat": 56.00031, "speed": 0.1, "course": 274.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 2190062.0, "lon": 8.129343, "lat": 56.00031, "speed": 0.1, "course": 274.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1556, CreateTime = 1717076858893, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5e31c2c7)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 273324000.0, "lon": 12.99423, "lat": 55.161068, "speed": 7.4, "course": 129.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 273324000.0, "lon": 12.99423, "lat": 55.161068, "speed": 7.4, "course": 129.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1557, CreateTime = 1717076858893, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2ae35a6b)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 213720000.0, "lon": 14.24265, "lat": 55.166383, "speed": 8.0, "course": 93.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 213720000.0, "lon": 14.24265, "lat": 55.166383, "speed": 8.0, "course": 93.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1558, CreateTime = 1717076858893, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@e61896b)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219001343.0, "lon": 11.958083, "lat": 56.228067, "speed": 0.0, "course": 247.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219001343.0, "lon": 11.958083, "lat": 56.228067, "speed": 0.0, "course": 247.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1559, CreateTime = 1717076858893, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@46e5664a)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219000775.0, "lon": 8.220937, "lat": 56.701593, "speed": 0.0, "course": 112.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219000775.0, "lon": 8.220937, "lat": 56.701593, "speed": 0.0, "course": 112.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1560, CreateTime = 1717076858893, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1612b3ab)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 212675000.0, "lon": 11.4324, "lat": 57.45855, "speed": 16.3, "course": 339.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 212675000.0, "lon": 11.4324, "lat": 57.45855, "speed": 16.3, "course": 339.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1561, CreateTime = 1717076858894, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@26129300)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 220339000.0, "lon": 15.135715, "lat": 55.061372, "speed": 0.0, "course": 202.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 220339000.0, "lon": 15.135715, "lat": 55.061372, "speed": 0.0, "course": 202.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1562, CreateTime = 1717076858894, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@24ba7c78)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 220327000.0, "lon": 9.958035, "lat": 57.59413, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 220327000.0, "lon": 9.958035, "lat": 57.59413, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1563, CreateTime = 1717076858894, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@49009993)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 212341000.0, "lon": 7.504795, "lat": 57.426562, "speed": 0.5, "course": 297.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 212341000.0, "lon": 7.504795, "lat": 57.426562, "speed": 0.5, "course": 297.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1564, CreateTime = 1717076858894, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4a8cf4f3)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 265483000.0, "lon": 10.599167, "lat": 57.718167, "speed": 0.0, "course": 118.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 265483000.0, "lon": 10.599167, "lat": 57.718167, "speed": 0.0, "course": 118.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1565, CreateTime = 1717076858894, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7834e431)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 211910000.0, "lon": 8.247267, "lat": 57.0553, "speed": 23.7, "course": 40.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 211910000.0, "lon": 8.247267, "lat": 57.0553, "speed": 23.7, "course": 40.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1566, CreateTime = 1717076858894, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@f9a0ef3)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219001842.0, "lon": 8.222175, "lat": 56.701778, "speed": 0.0, "course": 22.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219001842.0, "lon": 8.222175, "lat": 56.701778, "speed": 0.0, "course": 22.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1567, CreateTime = 1717076858894, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@421bd292)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:16", "mmsi": 219000373.0, "lon": 10.536483, "lat": 56.078183, "speed": 17.1, "course": 315.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:16", "mmsi": 219000373.0, "lon": 10.536483, "lat": 56.078183, "speed": 17.1, "course": 315.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1568, CreateTime = 1717076858894, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6f1d8d4e)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219006387.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219006387.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1569, CreateTime = 1717076858894, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@30d7e9f0)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 259894000.0, "lon": 15.21722, "lat": 55.638967, "speed": 14.5, "course": 241.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 259894000.0, "lon": 15.21722, "lat": 55.638967, "speed": 14.5, "course": 241.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1570, CreateTime = 1717076858894, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6f65948f)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 265513260.0, "lon": 13.144048, "lat": 55.372258, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 265513260.0, "lon": 13.144048, "lat": 55.372258, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1571, CreateTime = 1717076858894, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@73f654b3)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219005932.0, "lon": 15.136647, "lat": 55.057527, "speed": 0.0, "course": 340.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219005932.0, "lon": 15.136647, "lat": 55.057527, "speed": 0.0, "course": 340.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1572, CreateTime = 1717076858894, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7082d07e)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219175000.0, "lon": 10.588313, "lat": 59.24544, "speed": 13.8, "course": 163.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219175000.0, "lon": 10.588313, "lat": 59.24544, "speed": 13.8, "course": 163.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1573, CreateTime = 1717076858894, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7f952ff7)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 212130000.0, "lon": 11.784457, "lat": 56.92559, "speed": 14.3, "course": 340.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 212130000.0, "lon": 11.784457, "lat": 56.92559, "speed": 14.3, "course": 340.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1574, CreateTime = 1717076858894, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3c171d66)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219011196.0, "lon": 11.100302, "lat": 55.675227, "speed": 0.0, "course": 64.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219011196.0, "lon": 11.100302, "lat": 55.675227, "speed": 0.0, "course": 64.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1575, CreateTime = 1717076858894, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7d85959b)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 257723000.0, "lon": 7.108027, "lat": 55.510152, "speed": 13.8, "course": 281.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 257723000.0, "lon": 7.108027, "lat": 55.510152, "speed": 13.8, "course": 281.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1576, CreateTime = 1717076858894, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1be2bb75)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 265200000.0, "lon": 11.239917, "lat": 56.1593, "speed": 20.0, "course": 227.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 265200000.0, "lon": 11.239917, "lat": 56.1593, "speed": 20.0, "course": 227.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1577, CreateTime = 1717076858895, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4d5ec569)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 265507770.0, "lon": 11.793212, "lat": 57.600353, "speed": 0.1, "course": 192.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 265507770.0, "lon": 11.793212, "lat": 57.600353, "speed": 0.1, "course": 192.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1578, CreateTime = 1717076858895, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@49a61d89)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219000873.0, "lon": 10.308233, "lat": 56.990933, "speed": 0.0, "course": 351.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219000873.0, "lon": 10.308233, "lat": 56.990933, "speed": 0.0, "course": 351.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1579, CreateTime = 1717076858895, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@18de706b)
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 257983000.0, "lon": 7.448447, "lat": 57.18402, "speed": 14.5, "course": 245.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,451 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 257983000.0, "lon": 7.448447, "lat": 57.18402, "speed": 14.5, "course": 245.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1580, CreateTime = 1717076858895, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@16e95916)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219001819.0, "lon": 12.982607, "lat": 55.227705, "speed": 10.1, "course": 105.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219001819.0, "lon": 12.982607, "lat": 55.227705, "speed": 10.1, "course": 105.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1581, CreateTime = 1717076858895, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2d27a32f)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 265410000.0, "lon": 11.603855, "lat": 57.607677, "speed": 17.1, "course": 251.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 265410000.0, "lon": 11.603855, "lat": 57.607677, "speed": 17.1, "course": 251.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1582, CreateTime = 1717076858895, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5414a957)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 231306000.0, "lon": 10.6009, "lat": 57.722183, "speed": 0.0, "course": 28.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 231306000.0, "lon": 10.6009, "lat": 57.722183, "speed": 0.0, "course": 28.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1583, CreateTime = 1717076858895, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3fa2c696)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219010987.0, "lon": 12.65215, "lat": 55.726633, "speed": 8.0, "course": 230.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219010987.0, "lon": 12.65215, "lat": 55.726633, "speed": 8.0, "course": 230.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1584, CreateTime = 1717076858895, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@63df099d)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 236451000.0, "lon": 15.169333, "lat": 55.636333, "speed": 12.7, "course": 240.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 236451000.0, "lon": 15.169333, "lat": 55.636333, "speed": 12.7, "course": 240.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1585, CreateTime = 1717076858895, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7371e012)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 273438290.0, "lon": 11.098212, "lat": 57.633692, "speed": 5.4, "course": 284.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 273438290.0, "lon": 11.098212, "lat": 57.633692, "speed": 5.4, "course": 284.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1586, CreateTime = 1717076858895, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@25eb13a)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 220490000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 220490000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1587, CreateTime = 1717076858895, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2be14191)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 999999999.0, "lon": 12.11914, "lat": 54.157457, "speed": 0.0, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 999999999.0, "lon": 12.11914, "lat": 54.157457, "speed": 0.0, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1588, CreateTime = 1717076858895, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@30e92691)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 233199000.0, "lon": 10.993277, "lat": 54.970467, "speed": 11.1, "course": 45.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 233199000.0, "lon": 10.993277, "lat": 54.970467, "speed": 11.1, "course": 45.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1589, CreateTime = 1717076858898, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4ce421ee)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 220550000.0, "lon": 11.7943, "lat": 56.12755, "speed": 8.8, "course": 83.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 220550000.0, "lon": 11.7943, "lat": 56.12755, "speed": 8.8, "course": 83.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1590, CreateTime = 1717076858898, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3b449e29)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 257494000.0, "lon": 13.298422, "lat": 55.197018, "speed": 6.5, "course": 296.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 257494000.0, "lon": 13.298422, "lat": 55.197018, "speed": 6.5, "course": 296.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1591, CreateTime = 1717076858898, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1a08bd19)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 211245200.0, "lon": 12.744148, "lat": 55.012652, "speed": 12.2, "course": 214.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 211245200.0, "lon": 12.744148, "lat": 55.012652, "speed": 12.2, "course": 214.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1592, CreateTime = 1717076858898, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@63acdd67)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 225388000.0, "lon": 12.09861, "lat": 54.446933, "speed": 10.2, "course": 251.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 225388000.0, "lon": 12.09861, "lat": 54.446933, "speed": 10.2, "course": 251.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1593, CreateTime = 1717076858898, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@e2a7bad)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 211411230.0, "lon": 12.689645, "lat": 54.431435, "speed": 0.0, "course": 284.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 211411230.0, "lon": 12.689645, "lat": 54.431435, "speed": 0.0, "course": 284.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1594, CreateTime = 1717076858899, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@11800997)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219000811.0, "lon": 11.482912, "lat": 54.88397, "speed": 0.0, "course": 92.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219000811.0, "lon": 11.482912, "lat": 54.88397, "speed": 0.0, "course": 92.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1595, CreateTime = 1717076858899, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4ebf8ecb)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 211226940.0, "lon": 10.984685, "lat": 54.373398, "speed": 0.0, "course": 143.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 211226940.0, "lon": 10.984685, "lat": 54.373398, "speed": 0.0, "course": 143.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1596, CreateTime = 1717076858899, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4b7d259e)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 235011250.0, "lon": 12.884167, "lat": 54.797833, "speed": 17.4, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 235011250.0, "lon": 12.884167, "lat": 54.797833, "speed": 17.4, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1597, CreateTime = 1717076858899, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1657d84f)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 235070529.0, "lon": 10.92885, "lat": 54.92715, "speed": 7.1, "course": 49.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 235070529.0, "lon": 10.92885, "lat": 54.92715, "speed": 7.1, "course": 49.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1598, CreateTime = 1717076858899, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@70aa7a3)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219000548.0, "lon": 9.3345, "lat": 57.8395, "speed": 6.2, "course": 89.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219000548.0, "lon": 9.3345, "lat": 57.8395, "speed": 6.2, "course": 89.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1599, CreateTime = 1717076858899, serialized key size = -1, serialized value size = 110, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3571a85f)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 371845000.0, "lon": 12.546775, "lat": 54.597372, "speed": 1.5, "course": 59.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 371845000.0, "lon": 12.546775, "lat": 54.597372, "speed": 1.5, "course": 59.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1600, CreateTime = 1717076858899, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@17022aba)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219001362.0, "lon": 10.616185, "lat": 55.061988, "speed": 0.0, "course": 339.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219001362.0, "lon": 10.616185, "lat": 55.061988, "speed": 0.0, "course": 339.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1601, CreateTime = 1717076858900, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3f3f1db5)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219124000.0, "lon": 6.916745, "lat": 56.473245, "speed": 13.3, "course": 214.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219124000.0, "lon": 6.916745, "lat": 56.473245, "speed": 13.3, "course": 214.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1602, CreateTime = 1717076858900, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6dda824e)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219010793.0, "lon": 8.59998, "lat": 57.122903, "speed": 0.0, "course": 146.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219010793.0, "lon": 8.59998, "lat": 57.122903, "speed": 0.0, "course": 146.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1603, CreateTime = 1717076858900, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5551ecfa)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219002783.0, "lon": 8.120043, "lat": 56.371507, "speed": 0.1, "course": 89.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219002783.0, "lon": 8.120043, "lat": 56.371507, "speed": 0.1, "course": 89.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1604, CreateTime = 1717076858900, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@53005b10)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 259486000.0, "lon": 10.540867, "lat": 57.4371, "speed": 0.0, "course": 354.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 259486000.0, "lon": 10.540867, "lat": 57.4371, "speed": 0.0, "course": 354.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1605, CreateTime = 1717076858900, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@14952670)
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 273313900.0, "lon": 12.34983, "lat": 54.6542, "speed": 8.6, "course": 237.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,452 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 273313900.0, "lon": 12.34983, "lat": 54.6542, "speed": 8.6, "course": 237.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1606, CreateTime = 1717076858900, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2de40e5e)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219000751.0, "lon": 14.355065, "lat": 55.557737, "speed": 0.0, "course": 15.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219000751.0, "lon": 14.355065, "lat": 55.557737, "speed": 0.0, "course": 15.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1607, CreateTime = 1717076858900, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@77880124)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 992191509.0, "lon": 4.759832, "lat": 55.580767, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 992191509.0, "lon": 4.759832, "lat": 55.580767, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1608, CreateTime = 1717076858900, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@26810c1e)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 257689000.0, "lon": 12.236827, "lat": 54.457588, "speed": 14.8, "course": 26.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 257689000.0, "lon": 12.236827, "lat": 54.457588, "speed": 14.8, "course": 26.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1609, CreateTime = 1717076858900, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1b1a1818)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 211514540.0, "lon": 10.269497, "lat": 54.496388, "speed": 0.8, "course": 37.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 211514540.0, "lon": 10.269497, "lat": 54.496388, "speed": 0.8, "course": 37.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1610, CreateTime = 1717076858900, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@168163db)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 220253000.0, "lon": 11.344573, "lat": 57.670443, "speed": 20.7, "course": 292.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 220253000.0, "lon": 11.344573, "lat": 57.670443, "speed": 20.7, "course": 292.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1611, CreateTime = 1717076858900, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2137d10e)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 250002012.0, "lon": 11.897808, "lat": 56.799995, "speed": 14.7, "course": 339.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 250002012.0, "lon": 11.897808, "lat": 56.799995, "speed": 14.7, "course": 339.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1612, CreateTime = 1717076858900, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@f78d8ca)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 265501910.0, "lon": 11.913332, "lat": 57.69353, "speed": 0.0, "course": 337.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 265501910.0, "lon": 11.913332, "lat": 57.69353, "speed": 0.0, "course": 337.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1613, CreateTime = 1717076858900, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@44e9dbe5)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 235034149.0, "lon": 12.139833, "lat": 54.4335, "speed": 14.9, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 235034149.0, "lon": 12.139833, "lat": 54.4335, "speed": 14.9, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1614, CreateTime = 1717076858900, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@59ebf718)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219002774.0, "lon": 9.959108, "lat": 57.594272, "speed": 0.0, "course": 261.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219002774.0, "lon": 9.959108, "lat": 57.594272, "speed": 0.0, "course": 261.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1615, CreateTime = 1717076858901, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@464bf28a)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 538090391.0, "lon": 12.248228, "lat": 54.564653, "speed": 13.2, "course": 198.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 538090391.0, "lon": 12.248228, "lat": 54.564653, "speed": 13.2, "course": 198.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1616, CreateTime = 1717076858901, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@f3cdc01)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219000577.0, "lon": 10.528878, "lat": 55.796273, "speed": 0.1, "course": 35.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219000577.0, "lon": 10.528878, "lat": 55.796273, "speed": 0.1, "course": 35.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1617, CreateTime = 1717076858901, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@50018f0)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 220042000.0, "lon": 8.59311, "lat": 57.119637, "speed": 0.0, "course": 259.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 220042000.0, "lon": 8.59311, "lat": 57.119637, "speed": 0.0, "course": 259.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1618, CreateTime = 1717076858901, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3d57c7f)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 212636000.0, "lon": 11.967833, "lat": 54.4365, "speed": 14.2, "course": 270.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 212636000.0, "lon": 11.967833, "lat": 54.4365, "speed": 14.2, "course": 270.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1619, CreateTime = 1717076858901, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1a93112d)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 220193000.0, "lon": 12.595562, "lat": 55.706467, "speed": 0.0, "course": 330.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 220193000.0, "lon": 12.595562, "lat": 55.706467, "speed": 0.0, "course": 330.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1620, CreateTime = 1717076858901, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@73a61aaa)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 636091871.0, "lon": 3.994833, "lat": 56.462333, "speed": 13.1, "course": 179.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 636091871.0, "lon": 3.994833, "lat": 56.462333, "speed": 13.1, "course": 179.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1621, CreateTime = 1717076858901, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@76645bb6)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 304588000.0, "lon": 12.699667, "lat": 55.971833, "speed": 13.4, "course": 336.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 304588000.0, "lon": 12.699667, "lat": 55.971833, "speed": 13.4, "course": 336.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1622, CreateTime = 1717076858901, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5e7af781)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 312412000.0, "lon": 11.098752, "lat": 55.182782, "speed": 8.5, "course": 7.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 312412000.0, "lon": 11.098752, "lat": 55.182782, "speed": 8.5, "course": 7.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1623, CreateTime = 1717076858901, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5ce28f1a)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219945000.0, "lon": 11.315188, "lat": 57.710878, "speed": 17.2, "course": 155.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219945000.0, "lon": 11.315188, "lat": 57.710878, "speed": 17.2, "course": 155.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1624, CreateTime = 1717076858903, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1f52bd66)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219001214.0, "lon": 12.61351, "lat": 56.042672, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219001214.0, "lon": 12.61351, "lat": 56.042672, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1625, CreateTime = 1717076858904, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4b3ffcd1)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 220295000.0, "lon": 10.586477, "lat": 57.717545, "speed": 0.0, "course": 323.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 220295000.0, "lon": 10.586477, "lat": 57.717545, "speed": 0.0, "course": 323.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1626, CreateTime = 1717076858904, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@42f0ccc8)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 246043000.0, "lon": 11.910267, "lat": 56.708867, "speed": 14.7, "course": 168.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 246043000.0, "lon": 11.910267, "lat": 56.708867, "speed": 14.7, "course": 168.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1627, CreateTime = 1717076858905, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@a2201d3)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 314208000.0, "lon": 7.839283, "lat": 57.424317, "speed": 12.4, "course": 203.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 314208000.0, "lon": 7.839283, "lat": 57.424317, "speed": 12.4, "course": 203.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1628, CreateTime = 1717076858906, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@91347c)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 220177000.0, "lon": 4.539333, "lat": 55.468667, "speed": 1.6, "course": 21.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 220177000.0, "lon": 4.539333, "lat": 55.468667, "speed": 1.6, "course": 21.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1629, CreateTime = 1717076858907, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@34fc99cb)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219509000.0, "lon": 10.0269, "lat": 57.795825, "speed": 10.5, "course": 275.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219509000.0, "lon": 10.0269, "lat": 57.795825, "speed": 10.5, "course": 275.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1630, CreateTime = 1717076858907, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@70ae9510)
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 265859000.0, "lon": 10.927608, "lat": 56.409173, "speed": 0.0, "course": 310.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,453 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 265859000.0, "lon": 10.927608, "lat": 56.409173, "speed": 0.0, "course": 310.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1631, CreateTime = 1717076858908, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6a982e4f)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 211405020.0, "lon": 13.907792, "lat": 54.241387, "speed": 0.0, "course": 93.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 211405020.0, "lon": 13.907792, "lat": 54.241387, "speed": 0.0, "course": 93.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1632, CreateTime = 1717076858908, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6323c5b4)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 245253000.0, "lon": 7.806078, "lat": 55.276673, "speed": 3.7, "course": 327.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 245253000.0, "lon": 7.806078, "lat": 55.276673, "speed": 3.7, "course": 327.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1633, CreateTime = 1717076858908, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@33412ada)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 220434000.0, "lon": 11.129417, "lat": 55.331813, "speed": 0.0, "course": 256.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 220434000.0, "lon": 11.129417, "lat": 55.331813, "speed": 0.0, "course": 256.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1634, CreateTime = 1717076858909, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@37432fb7)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 325045000.0, "lon": 14.480833, "lat": 54.644817, "speed": 9.6, "course": 262.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 325045000.0, "lon": 14.480833, "lat": 54.644817, "speed": 9.6, "course": 262.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1635, CreateTime = 1717076858909, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1c028546)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219011248.0, "lon": 10.355772, "lat": 56.96751, "speed": 1.5, "course": 168.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219011248.0, "lon": 10.355772, "lat": 56.96751, "speed": 1.5, "course": 168.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1636, CreateTime = 1717076858909, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@61f1ed17)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 265511440.0, "lon": 11.668142, "lat": 57.621968, "speed": 17.6, "course": 70.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 265511440.0, "lon": 11.668142, "lat": 57.621968, "speed": 17.6, "course": 70.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1637, CreateTime = 1717076858909, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5b5c1c09)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 211188000.0, "lon": 11.242033, "lat": 54.51831, "speed": 14.8, "course": 24.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 211188000.0, "lon": 11.242033, "lat": 54.51831, "speed": 14.8, "course": 24.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1638, CreateTime = 1717076858909, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@75ccbe42)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 258897000.0, "lon": 12.525067, "lat": 56.113132, "speed": 9.8, "course": 130.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 258897000.0, "lon": 12.525067, "lat": 56.113132, "speed": 9.8, "course": 130.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1639, CreateTime = 1717076858909, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7dec3d08)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219003103.0, "lon": 11.684995, "lat": 57.369347, "speed": 0.1, "course": 161.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219003103.0, "lon": 11.684995, "lat": 57.369347, "speed": 0.1, "course": 161.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1640, CreateTime = 1717076858909, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@131beef7)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219005567.0, "lon": 10.302582, "lat": 56.607302, "speed": 0.0, "course": 122.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219005567.0, "lon": 10.302582, "lat": 56.607302, "speed": 0.0, "course": 122.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1641, CreateTime = 1717076858909, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@281c14c9)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219948000.0, "lon": 7.89934, "lat": 57.43895, "speed": 2.8, "course": 34.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219948000.0, "lon": 7.89934, "lat": 57.43895, "speed": 2.8, "course": 34.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1642, CreateTime = 1717076858909, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@38b28126)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 265866000.0, "lon": 12.512965, "lat": 54.826068, "speed": 13.4, "course": 214.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 265866000.0, "lon": 12.512965, "lat": 54.826068, "speed": 13.4, "course": 214.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1643, CreateTime = 1717076858909, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@242aef45)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 236203000.0, "lon": 13.0253, "lat": 55.262262, "speed": 10.3, "course": 273.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 236203000.0, "lon": 13.0253, "lat": 55.262262, "speed": 10.3, "course": 273.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1644, CreateTime = 1717076858909, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@680ad161)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219001549.0, "lon": 10.587085, "lat": 57.718273, "speed": 0.0, "course": 5.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219001549.0, "lon": 10.587085, "lat": 57.718273, "speed": 0.0, "course": 5.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1645, CreateTime = 1717076858910, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@20783af5)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 230217000.0, "lon": 6.975698, "lat": 56.437567, "speed": 14.6, "course": 165.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 230217000.0, "lon": 6.975698, "lat": 56.437567, "speed": 14.6, "course": 165.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1646, CreateTime = 1717076858910, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@cef246d)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 211223400.0, "lon": 12.093808, "lat": 54.154122, "speed": 0.0, "course": 107.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 211223400.0, "lon": 12.093808, "lat": 54.154122, "speed": 0.0, "course": 107.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1647, CreateTime = 1717076858910, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7fcca272)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 266304000.0, "lon": 10.597178, "lat": 57.718667, "speed": 0.0, "course": 207.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 266304000.0, "lon": 10.597178, "lat": 57.718667, "speed": 0.0, "course": 207.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1648, CreateTime = 1717076858910, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4173e533)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219001461.0, "lon": 13.024667, "lat": 55.636967, "speed": 0.0, "course": 357.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219001461.0, "lon": 13.024667, "lat": 55.636967, "speed": 0.0, "course": 357.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1649, CreateTime = 1717076858910, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@20bdc07a)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219013192.0, "lon": 11.016758, "lat": 54.817527, "speed": 0.0, "course": 331.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219013192.0, "lon": 11.016758, "lat": 54.817527, "speed": 0.0, "course": 331.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1650, CreateTime = 1717076858911, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5584544c)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 257462000.0, "lon": 10.027133, "lat": 57.68171, "speed": 12.9, "course": 245.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 257462000.0, "lon": 10.027133, "lat": 57.68171, "speed": 12.9, "course": 245.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1651, CreateTime = 1717076858911, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4fc1b3bc)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 220135000.0, "lon": 9.6243, "lat": 57.910402, "speed": 0.5, "course": 64.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 220135000.0, "lon": 9.6243, "lat": 57.910402, "speed": 0.5, "course": 64.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1652, CreateTime = 1717076858911, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@11c58d0a)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219000345.0, "lon": 10.824983, "lat": 55.7521, "speed": 16.8, "course": 170.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219000345.0, "lon": 10.824983, "lat": 55.7521, "speed": 16.8, "course": 170.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1653, CreateTime = 1717076858911, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5f353158)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 219014165.0, "lon": 10.540688, "lat": 57.437962, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 219014165.0, "lon": 10.540688, "lat": 57.437962, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1654, CreateTime = 1717076858911, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@286438c6)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 265513290.0, "lon": 14.285778, "lat": 55.474882, "speed": 0.0, "course": 7.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 265513290.0, "lon": 14.285778, "lat": 55.474882, "speed": 0.0, "course": 7.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1655, CreateTime = 1717076858912, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6afa2225)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 240198000.0, "lon": 11.134533, "lat": 57.630783, "speed": 14.7, "course": 313.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 240198000.0, "lon": 11.134533, "lat": 57.630783, "speed": 14.7, "course": 313.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1656, CreateTime = 1717076858912, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@57ea5fad)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 211898000.0, "lon": 10.906855, "lat": 54.753553, "speed": 8.2, "course": 350.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 211898000.0, "lon": 10.906855, "lat": 54.753553, "speed": 8.2, "course": 350.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1657, CreateTime = 1717076858912, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@21230bf9)
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 220303000.0, "lon": 10.586967, "lat": 57.717627, "speed": 0.0, "course": 133.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,454 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 220303000.0, "lon": 10.586967, "lat": 57.717627, "speed": 0.0, "course": 133.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1658, CreateTime = 1717076858912, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2808b513)
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 211211810.0, "lon": 10.040502, "lat": 54.774037, "speed": 11.5, "course": 328.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 211211810.0, "lon": 10.040502, "lat": 54.774037, "speed": 11.5, "course": 328.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1659, CreateTime = 1717076858913, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1358513d)
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 477688000.0, "lon": 15.519307, "lat": 55.735258, "speed": 12.2, "course": 242.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 477688000.0, "lon": 15.519307, "lat": 55.735258, "speed": 12.2, "course": 242.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1660, CreateTime = 1717076858913, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@16ca63cc)
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 258069000.0, "lon": 4.234577, "lat": 56.415067, "speed": 11.4, "course": 196.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 258069000.0, "lon": 4.234577, "lat": 56.415067, "speed": 11.4, "course": 196.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1661, CreateTime = 1717076858913, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2f0fde2f)
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 220333000.0, "lon": 10.58637, "lat": 57.717943, "speed": 0.0, "course": 291.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 220333000.0, "lon": 10.58637, "lat": 57.717943, "speed": 0.0, "course": 291.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1662, CreateTime = 1717076858914, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@42c246f0)
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 325045000.0, "lon": 14.480833, "lat": 54.644817, "speed": 9.6, "course": 262.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,455 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 325045000.0, "lon": 14.480833, "lat": 54.644817, "speed": 9.6, "course": 262.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,456 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1663, CreateTime = 1717076858914, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1342362c)
2024-05-30 15:47:40 2024-05-30 13:47:40,456 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,457 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:17", "mmsi": 231048000.0, "lon": 10.573413, "lat": 54.798158, "speed": 0.0, "course": 171.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,457 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:17", "mmsi": 231048000.0, "lon": 10.573413, "lat": 54.798158, "speed": 0.0, "course": 171.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,457 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1664, CreateTime = 1717076858914, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@56d3f38b)
2024-05-30 15:47:40 2024-05-30 13:47:40,457 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,457 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 636091854.0, "lon": 12.308533, "lat": 54.646722, "speed": 16.8, "course": 226.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,457 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 636091854.0, "lon": 12.308533, "lat": 54.646722, "speed": 16.8, "course": 226.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,457 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1665, CreateTime = 1717076858914, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7fcb1d8)
2024-05-30 15:47:40 2024-05-30 13:47:40,457 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,457 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 211263800.0, "lon": 12.08098, "lat": 54.171813, "speed": 0.5, "course": 250.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,457 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 211263800.0, "lon": 12.08098, "lat": 54.171813, "speed": 0.5, "course": 250.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,457 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1666, CreateTime = 1717076858914, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@57d98211)
2024-05-30 15:47:40 2024-05-30 13:47:40,457 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,457 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 257207000.0, "lon": 10.553117, "lat": 56.0227, "speed": 10.4, "course": 36.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,457 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 257207000.0, "lon": 10.553117, "lat": 56.0227, "speed": 10.4, "course": 36.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1667, CreateTime = 1717076858914, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@55a83d90)
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 992191016.0, "lon": 11.046742, "lat": 55.324798, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 992191016.0, "lon": 11.046742, "lat": 55.324798, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1668, CreateTime = 1717076858915, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1caed305)
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219005969.0, "lon": 10.589647, "lat": 57.718375, "speed": 0.0, "course": 339.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219005969.0, "lon": 10.589647, "lat": 57.718375, "speed": 0.0, "course": 339.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1669, CreateTime = 1717076858916, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7e3ed339)
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 230984000.0, "lon": 11.485468, "lat": 57.389535, "speed": 18.2, "course": 338.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 230984000.0, "lon": 11.485468, "lat": 57.389535, "speed": 18.2, "course": 338.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1670, CreateTime = 1717076858916, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@65ec0fe5)
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219004616.0, "lon": 11.124198, "lat": 57.320193, "speed": 0.0, "course": 320.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219004616.0, "lon": 11.124198, "lat": 57.320193, "speed": 0.0, "course": 320.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1671, CreateTime = 1717076858916, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@71bcea75)
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 246238000.0, "lon": 7.744367, "lat": 55.261448, "speed": 3.5, "course": 334.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 246238000.0, "lon": 7.744367, "lat": 55.261448, "speed": 3.5, "course": 334.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1672, CreateTime = 1717076858917, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1be039bc)
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219043000.0, "lon": 4.21201, "lat": 56.369787, "speed": 0.4, "course": 99.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219043000.0, "lon": 4.21201, "lat": 56.369787, "speed": 0.4, "course": 99.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1673, CreateTime = 1717076858918, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@134f96e2)
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 220378000.0, "lon": 12.319833, "lat": 55.4335, "speed": 16.0, "course": 129.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 220378000.0, "lon": 12.319833, "lat": 55.4335, "speed": 16.0, "course": 129.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1674, CreateTime = 1717076858918, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@16593049)
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219005496.0, "lon": 9.956543, "lat": 57.593438, "speed": 0.0, "course": 8.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219005496.0, "lon": 9.956543, "lat": 57.593438, "speed": 0.0, "course": 8.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1675, CreateTime = 1717076858918, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@a09fb5)
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 265285000.0, "lon": 10.849528, "lat": 57.467813, "speed": 16.5, "course": 248.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 265285000.0, "lon": 10.849528, "lat": 57.467813, "speed": 16.5, "course": 248.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1676, CreateTime = 1717076858918, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1a176bc4)
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219743000.0, "lon": 9.668903, "lat": 57.836583, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219743000.0, "lon": 9.668903, "lat": 57.836583, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,458 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1677, CreateTime = 1717076858919, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@750006e2)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 314216000.0, "lon": 12.771317, "lat": 55.784217, "speed": 12.8, "course": 143.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 314216000.0, "lon": 12.771317, "lat": 55.784217, "speed": 12.8, "course": 143.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1678, CreateTime = 1717076858919, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2a04ab73)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 235059487.0, "lon": 11.057818, "lat": 56.008308, "speed": 12.6, "course": 214.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 235059487.0, "lon": 11.057818, "lat": 56.008308, "speed": 12.6, "course": 214.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1679, CreateTime = 1717076858919, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2e5dd4b1)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219000368.0, "lon": 12.616687, "lat": 56.034042, "speed": 0.1, "course": 194.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219000368.0, "lon": 12.616687, "lat": 56.034042, "speed": 0.1, "course": 194.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1680, CreateTime = 1717076858919, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@f35c3f5)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 265630560.0, "lon": 12.93484, "lat": 55.410738, "speed": 0.0, "course": 342.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 265630560.0, "lon": 12.93484, "lat": 55.410738, "speed": 0.0, "course": 342.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1681, CreateTime = 1717076858919, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7a77f3e7)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219000771.0, "lon": 8.35073, "lat": 55.475588, "speed": 10.6, "course": 48.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219000771.0, "lon": 8.35073, "lat": 55.475588, "speed": 10.6, "course": 48.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1682, CreateTime = 1717076858919, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@75a780e9)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219132000.0, "lon": 9.6425, "lat": 57.83175, "speed": 13.4, "course": 275.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219132000.0, "lon": 9.6425, "lat": 57.83175, "speed": 13.4, "course": 275.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1683, CreateTime = 1717076858919, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@351f2ab0)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219007679.0, "lon": 10.588415, "lat": 57.716957, "speed": 0.0, "course": 138.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219007679.0, "lon": 10.588415, "lat": 57.716957, "speed": 0.0, "course": 138.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1684, CreateTime = 1717076858919, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@14146d8d)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 311299000.0, "lon": 11.423142, "lat": 56.330437, "speed": 12.9, "course": 211.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 311299000.0, "lon": 11.423142, "lat": 56.330437, "speed": 12.9, "course": 211.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1685, CreateTime = 1717076858919, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@51b94c23)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 258401000.0, "lon": 4.538047, "lat": 55.763368, "speed": 0.9, "course": 57.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 258401000.0, "lon": 4.538047, "lat": 55.763368, "speed": 0.9, "course": 57.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1686, CreateTime = 1717076858919, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@18502e35)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 992191505.0, "lon": 5.109182, "lat": 55.48035, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 992191505.0, "lon": 5.109182, "lat": 55.48035, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1687, CreateTime = 1717076858919, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@54d6cd25)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 231201000.0, "lon": 10.060582, "lat": 57.765795, "speed": 15.7, "course": 13.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 231201000.0, "lon": 10.060582, "lat": 57.765795, "speed": 15.7, "course": 13.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1688, CreateTime = 1717076858919, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6319aa37)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 265608060.0, "lon": 12.857137, "lat": 56.662657, "speed": 0.0, "course": 308.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 265608060.0, "lon": 12.857137, "lat": 56.662657, "speed": 0.0, "course": 308.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1689, CreateTime = 1717076858919, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@785a2a23)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 306013000.0, "lon": 8.480163, "lat": 57.648617, "speed": 3.9, "course": 24.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 306013000.0, "lon": 8.480163, "lat": 57.648617, "speed": 3.9, "course": 24.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1690, CreateTime = 1717076858919, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@61e2929b)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 211211290.0, "lon": 10.035373, "lat": 54.77866, "speed": 11.5, "course": 316.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 211211290.0, "lon": 10.035373, "lat": 54.77866, "speed": 11.5, "course": 316.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1691, CreateTime = 1717076858919, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@33fc467)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 265858000.0, "lon": 12.884987, "lat": 55.251068, "speed": 10.7, "course": 95.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 265858000.0, "lon": 12.884987, "lat": 55.251068, "speed": 10.7, "course": 95.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1692, CreateTime = 1717076858920, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2dd99e25)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 266039000.0, "lon": 11.136573, "lat": 56.09874, "speed": 17.5, "course": 206.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 266039000.0, "lon": 11.136573, "lat": 56.09874, "speed": 17.5, "course": 206.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1693, CreateTime = 1717076858920, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4fbb28f)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 211265530.0, "lon": 14.9605, "lat": 55.4745, "speed": 15.0, "course": 59.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 211265530.0, "lon": 14.9605, "lat": 55.4745, "speed": 15.0, "course": 59.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1694, CreateTime = 1717076858920, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@71f89ec1)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 211211250.0, "lon": 10.045557, "lat": 54.768465, "speed": 11.7, "course": 327.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 211211250.0, "lon": 10.045557, "lat": 54.768465, "speed": 11.7, "course": 327.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1695, CreateTime = 1717076858920, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@c196065)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 231059000.0, "lon": 10.523423, "lat": 54.853007, "speed": 0.0, "course": 318.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 231059000.0, "lon": 10.523423, "lat": 54.853007, "speed": 0.0, "course": 318.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1696, CreateTime = 1717076858920, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d50ff75)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219014054.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219014054.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1697, CreateTime = 1717076858920, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3466579a)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 212172000.0, "lon": 7.043783, "lat": 56.4235, "speed": 15.0, "course": 35.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 212172000.0, "lon": 7.043783, "lat": 56.4235, "speed": 15.0, "course": 35.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1698, CreateTime = 1717076858920, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@15dc941)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219004896.0, "lon": 10.621103, "lat": 55.058437, "speed": 0.0, "course": 325.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219004896.0, "lon": 10.621103, "lat": 55.058437, "speed": 0.0, "course": 325.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1699, CreateTime = 1717076858920, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@46809b47)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 218413000.0, "lon": 12.091218, "lat": 54.170987, "speed": 0.0, "course": 287.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 218413000.0, "lon": 12.091218, "lat": 54.170987, "speed": 0.0, "course": 287.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1700, CreateTime = 1717076858920, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2cc17fb5)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 265426000.0, "lon": 14.234217, "lat": 55.229067, "speed": 13.0, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 265426000.0, "lon": 14.234217, "lat": 55.229067, "speed": 13.0, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1701, CreateTime = 1717076858920, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2a1d2730)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 258606000.0, "lon": 10.727497, "lat": 57.36863, "speed": 14.2, "course": 6.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 258606000.0, "lon": 10.727497, "lat": 57.36863, "speed": 14.2, "course": 6.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1702, CreateTime = 1717076858920, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@45e5f4f3)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 211222810.0, "lon": 12.097113, "lat": 54.176447, "speed": 0.1, "course": 344.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 211222810.0, "lon": 12.097113, "lat": 54.176447, "speed": 0.1, "course": 344.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1703, CreateTime = 1717076858920, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@77d15ab)
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 377411000.0, "lon": 14.3755, "lat": 55.269832, "speed": 11.0, "course": 218.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,459 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 377411000.0, "lon": 14.3755, "lat": 55.269832, "speed": 11.0, "course": 218.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1704, CreateTime = 1717076858920, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2066fe26)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219010982.0, "lon": 8.422617, "lat": 55.475592, "speed": 0.0, "course": 12.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219010982.0, "lon": 8.422617, "lat": 55.475592, "speed": 0.0, "course": 12.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1705, CreateTime = 1717076858920, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@638179bd)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 249939000.0, "lon": 9.180585, "lat": 57.592273, "speed": 12.2, "course": 73.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 249939000.0, "lon": 9.180585, "lat": 57.592273, "speed": 12.2, "course": 73.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1706, CreateTime = 1717076858922, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@9294b52)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 636014191.0, "lon": 14.114517, "lat": 55.095317, "speed": 14.1, "course": 219.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 636014191.0, "lon": 14.114517, "lat": 55.095317, "speed": 14.1, "course": 219.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1707, CreateTime = 1717076858923, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6616d791)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219001959.0, "lon": 8.423778, "lat": 55.471805, "speed": 0.0, "course": 322.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219001959.0, "lon": 8.423778, "lat": 55.471805, "speed": 0.0, "course": 322.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1708, CreateTime = 1717076858923, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@719692bb)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 220012000.0, "lon": 9.961087, "lat": 57.593903, "speed": 0.0, "course": 270.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 220012000.0, "lon": 9.961087, "lat": 57.593903, "speed": 0.0, "course": 270.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1709, CreateTime = 1717076858923, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@193251a5)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 211222780.0, "lon": 12.09725, "lat": 54.176602, "speed": 0.1, "course": 283.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 211222780.0, "lon": 12.09725, "lat": 54.176602, "speed": 0.1, "course": 283.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1710, CreateTime = 1717076858923, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5a02fa0a)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 265586090.0, "lon": 11.927397, "lat": 57.620015, "speed": 0.0, "course": 276.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 265586090.0, "lon": 11.927397, "lat": 57.620015, "speed": 0.0, "course": 276.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1711, CreateTime = 1717076858923, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@af80484)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 231754000.0, "lon": 7.920345, "lat": 56.709342, "speed": 13.5, "course": 28.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 231754000.0, "lon": 7.920345, "lat": 56.709342, "speed": 13.5, "course": 28.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1712, CreateTime = 1717076858923, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4fbe4c2a)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 538002365.0, "lon": 8.6188, "lat": 57.31685, "speed": 11.6, "course": 233.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 538002365.0, "lon": 8.6188, "lat": 57.31685, "speed": 11.6, "course": 233.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1713, CreateTime = 1717076858923, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@448a8301)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 257273000.0, "lon": 8.205535, "lat": 55.405098, "speed": 10.0, "course": 208.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 257273000.0, "lon": 8.205535, "lat": 55.405098, "speed": 10.0, "course": 208.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1714, CreateTime = 1717076858923, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@915e330)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219001058.0, "lon": 14.801042, "lat": 55.279137, "speed": 0.1, "course": 313.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219001058.0, "lon": 14.801042, "lat": 55.279137, "speed": 0.1, "course": 313.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1715, CreateTime = 1717076858923, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@43030ab2)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 265509710.0, "lon": 11.641258, "lat": 57.744067, "speed": 0.1, "course": 207.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 265509710.0, "lon": 11.641258, "lat": 57.744067, "speed": 0.1, "course": 207.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1716, CreateTime = 1717076858923, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7e61c1e4)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219009273.0, "lon": 8.598383, "lat": 57.122617, "speed": 1.2, "course": 2.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219009273.0, "lon": 8.598383, "lat": 57.122617, "speed": 1.2, "course": 2.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1717, CreateTime = 1717076858923, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6e63c7a2)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 220088000.0, "lon": 9.150382, "lat": 57.882452, "speed": 2.7, "course": 191.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 220088000.0, "lon": 9.150382, "lat": 57.882452, "speed": 2.7, "course": 191.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1718, CreateTime = 1717076858923, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4849a53d)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 311794000.0, "lon": 13.968168, "lat": 54.36555, "speed": 11.9, "course": 154.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 311794000.0, "lon": 13.968168, "lat": 54.36555, "speed": 11.9, "course": 154.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1719, CreateTime = 1717076858924, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1344601c)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 265041000.0, "lon": 12.617218, "lat": 56.033087, "speed": 0.0, "course": 261.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 265041000.0, "lon": 12.617218, "lat": 56.033087, "speed": 0.0, "course": 261.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1720, CreateTime = 1717076858924, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@63daed71)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219000769.0, "lon": 12.61586, "lat": 56.042835, "speed": 0.0, "course": 344.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219000769.0, "lon": 12.61586, "lat": 56.042835, "speed": 0.0, "course": 344.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1721, CreateTime = 1717076858924, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@13f4787f)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219014851.0, "lon": 8.597358, "lat": 57.122698, "speed": 0.0, "course": 237.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219014851.0, "lon": 8.597358, "lat": 57.122698, "speed": 0.0, "course": 237.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1722, CreateTime = 1717076858924, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@16914771)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219010743.0, "lon": 11.793913, "lat": 57.59895, "speed": 0.0, "course": 10.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219010743.0, "lon": 11.793913, "lat": 57.59895, "speed": 0.0, "course": 10.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1723, CreateTime = 1717076858924, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@26e5913f)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219000141.0, "lon": 12.427297, "lat": 55.097663, "speed": 0.4, "course": 306.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219000141.0, "lon": 12.427297, "lat": 55.097663, "speed": 0.4, "course": 306.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1724, CreateTime = 1717076858925, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@126051f7)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219009338.0, "lon": 11.928353, "lat": 54.572412, "speed": 0.1, "course": 167.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219009338.0, "lon": 11.928353, "lat": 54.572412, "speed": 0.1, "course": 167.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1725, CreateTime = 1717076858925, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2267f444)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 219006157.0, "lon": 13.579975, "lat": 55.020403, "speed": 0.0, "course": 294.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 219006157.0, "lon": 13.579975, "lat": 55.020403, "speed": 0.0, "course": 294.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1726, CreateTime = 1717076858926, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3ed185b6)
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 273333020.0, "lon": 11.717483, "lat": 54.204517, "speed": 9.1, "course": 49.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,460 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 273333020.0, "lon": 11.717483, "lat": 54.204517, "speed": 9.1, "course": 49.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1727, CreateTime = 1717076858927, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3437973a)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 257496000.0, "lon": 9.20875, "lat": 57.860983, "speed": 14.0, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 257496000.0, "lon": 9.20875, "lat": 57.860983, "speed": 14.0, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1728, CreateTime = 1717076858928, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@244897a2)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 258805000.0, "lon": 14.29301, "lat": 53.970382, "speed": 0.1, "course": 339.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 258805000.0, "lon": 14.29301, "lat": 53.970382, "speed": 0.1, "course": 339.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1729, CreateTime = 1717076858928, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@391092bb)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 266077000.0, "lon": 11.514452, "lat": 57.761315, "speed": 7.6, "course": 290.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 266077000.0, "lon": 11.514452, "lat": 57.761315, "speed": 7.6, "course": 290.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1730, CreateTime = 1717076858929, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@bde5c1a)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:18", "mmsi": 3638.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:18", "mmsi": 3638.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1731, CreateTime = 1717076858929, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3d8941c)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219850000.0, "lon": 9.764167, "lat": 55.3585, "speed": 9.2, "course": 302.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219850000.0, "lon": 9.764167, "lat": 55.3585, "speed": 9.2, "course": 302.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1732, CreateTime = 1717076858929, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@63cdf642)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 992191515.0, "lon": 4.271982, "lat": 56.3447, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 992191515.0, "lon": 4.271982, "lat": 56.3447, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1733, CreateTime = 1717076858929, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5ef535ca)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219963000.0, "lon": 11.245267, "lat": 57.36665, "speed": 1.7, "course": 13.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219963000.0, "lon": 11.245267, "lat": 57.36665, "speed": 1.7, "course": 13.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1734, CreateTime = 1717076858929, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@27329c82)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 211910000.0, "lon": 8.24765, "lat": 57.05555, "speed": 23.5, "course": 40.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 211910000.0, "lon": 8.24765, "lat": 57.05555, "speed": 23.5, "course": 40.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1735, CreateTime = 1717076858930, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@600d940c)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219005068.0, "lon": 11.160373, "lat": 55.171403, "speed": 0.1, "course": 192.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219005068.0, "lon": 11.160373, "lat": 55.171403, "speed": 0.1, "course": 192.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1736, CreateTime = 1717076858930, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6c7e01a9)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 207088000.0, "lon": 10.801472, "lat": 57.786602, "speed": 10.9, "course": 321.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 207088000.0, "lon": 10.801472, "lat": 57.786602, "speed": 10.9, "course": 321.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1737, CreateTime = 1717076858930, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1b523289)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 266041000.0, "lon": 11.6085, "lat": 54.253167, "speed": 18.4, "course": 60.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 266041000.0, "lon": 11.6085, "lat": 54.253167, "speed": 18.4, "course": 60.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1738, CreateTime = 1717076858931, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@28376bed)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 230915000.0, "lon": 7.7937, "lat": 56.47705, "speed": 17.9, "course": 200.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 230915000.0, "lon": 7.7937, "lat": 56.47705, "speed": 17.9, "course": 200.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1739, CreateTime = 1717076858931, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@24962713)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219000181.0, "lon": 10.257508, "lat": 54.94206, "speed": 0.0, "course": 213.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219000181.0, "lon": 10.257508, "lat": 54.94206, "speed": 0.0, "course": 213.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1740, CreateTime = 1717076858931, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@38790961)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 370614000.0, "lon": 11.5338, "lat": 57.2652, "speed": 14.1, "course": 162.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 370614000.0, "lon": 11.5338, "lat": 57.2652, "speed": 14.1, "course": 162.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1741, CreateTime = 1717076858932, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3235b29d)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 304117000.0, "lon": 11.385333, "lat": 57.564667, "speed": 12.0, "course": 182.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 304117000.0, "lon": 11.385333, "lat": 57.564667, "speed": 12.0, "course": 182.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1742, CreateTime = 1717076858932, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@214ecf35)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 992191521.0, "lon": 4.179298, "lat": 56.1784, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 992191521.0, "lon": 4.179298, "lat": 56.1784, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1743, CreateTime = 1717076858932, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@34f5cab0)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219007572.0, "lon": 9.897355, "lat": 57.05738, "speed": 0.0, "course": 307.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219007572.0, "lon": 9.897355, "lat": 57.05738, "speed": 0.0, "course": 307.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1744, CreateTime = 1717076858932, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4437ef4e)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219002467.0, "lon": 8.42721, "lat": 55.479075, "speed": 0.1, "course": 349.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219002467.0, "lon": 8.42721, "lat": 55.479075, "speed": 0.1, "course": 349.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1745, CreateTime = 1717076858932, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5b891c0f)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219809000.0, "lon": 8.21932, "lat": 56.70094, "speed": 0.0, "course": 13.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219809000.0, "lon": 8.21932, "lat": 56.70094, "speed": 0.0, "course": 13.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1746, CreateTime = 1717076858932, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@c69472c)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219959000.0, "lon": 8.446518, "lat": 57.519195, "speed": 2.6, "course": 254.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219959000.0, "lon": 8.446518, "lat": 57.519195, "speed": 2.6, "course": 254.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1747, CreateTime = 1717076858932, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@16d3bc5b)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 309359000.0, "lon": 10.229, "lat": 56.9835, "speed": 8.0, "course": 276.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 309359000.0, "lon": 10.229, "lat": 56.9835, "speed": 8.0, "course": 276.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1748, CreateTime = 1717076858933, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d657c50)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219007596.0, "lon": 12.467395, "lat": 54.952775, "speed": 0.0, "course": 86.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219007596.0, "lon": 12.467395, "lat": 54.952775, "speed": 0.0, "course": 86.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1749, CreateTime = 1717076858933, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7e1f7c97)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 265186000.0, "lon": 13.569872, "lat": 54.774597, "speed": 15.2, "course": 156.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 265186000.0, "lon": 13.569872, "lat": 54.774597, "speed": 15.2, "course": 156.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1750, CreateTime = 1717076858933, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3889045f)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 311814000.0, "lon": 8.505255, "lat": 57.774263, "speed": 14.0, "course": 269.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 311814000.0, "lon": 8.505255, "lat": 57.774263, "speed": 14.0, "course": 269.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1751, CreateTime = 1717076858933, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@33b34671)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 244721000.0, "lon": 7.843965, "lat": 55.201895, "speed": 3.0, "course": 334.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 244721000.0, "lon": 7.843965, "lat": 55.201895, "speed": 3.0, "course": 334.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1752, CreateTime = 1717076858933, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@75722bab)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219921000.0, "lon": 15.135282, "lat": 55.064072, "speed": 0.0, "course": 318.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219921000.0, "lon": 15.135282, "lat": 55.064072, "speed": 0.0, "course": 318.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1753, CreateTime = 1717076858933, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@700c0a56)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219014054.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219014054.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1754, CreateTime = 1717076858933, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5753f4)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 238199000.0, "lon": 10.8875, "lat": 54.637167, "speed": 12.2, "course": 298.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 238199000.0, "lon": 10.8875, "lat": 54.637167, "speed": 12.2, "course": 298.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1755, CreateTime = 1717076858933, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@29fe0d41)
2024-05-30 15:47:40 2024-05-30 13:47:40,461 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 256587000.0, "lon": 8.931895, "lat": 57.417122, "speed": 14.1, "course": 51.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 256587000.0, "lon": 8.931895, "lat": 57.417122, "speed": 14.1, "course": 51.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1756, CreateTime = 1717076858933, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4db544a6)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219000737.0, "lon": 11.352373, "lat": 54.65325, "speed": 0.1, "course": 13.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219000737.0, "lon": 11.352373, "lat": 54.65325, "speed": 0.1, "course": 13.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1757, CreateTime = 1717076858933, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5dfbb9fc)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 220546000.0, "lon": 14.075462, "lat": 55.081047, "speed": 13.6, "course": 219.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 220546000.0, "lon": 14.075462, "lat": 55.081047, "speed": 13.6, "course": 219.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1758, CreateTime = 1717076858933, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@67099944)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219787000.0, "lon": 14.692, "lat": 55.093642, "speed": 0.0, "course": 334.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219787000.0, "lon": 14.692, "lat": 55.093642, "speed": 0.0, "course": 334.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1759, CreateTime = 1717076858933, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3ec414e1)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 265410000.0, "lon": 11.603438, "lat": 57.607598, "speed": 17.1, "course": 251.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 265410000.0, "lon": 11.603438, "lat": 57.607598, "speed": 17.1, "course": 251.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1760, CreateTime = 1717076858933, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5933e7eb)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 265874000.0, "lon": 12.247525, "lat": 54.517877, "speed": 12.9, "course": 20.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 265874000.0, "lon": 12.247525, "lat": 54.517877, "speed": 12.9, "course": 20.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1761, CreateTime = 1717076858933, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@59079168)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219000195.0, "lon": 12.43983, "lat": 55.056488, "speed": 2.2, "course": 137.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219000195.0, "lon": 12.43983, "lat": 55.056488, "speed": 2.2, "course": 137.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1762, CreateTime = 1717076858934, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@726ff0b5)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 244806000.0, "lon": 7.284057, "lat": 55.59176, "speed": 4.4, "course": 320.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 244806000.0, "lon": 7.284057, "lat": 55.59176, "speed": 4.4, "course": 320.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1763, CreateTime = 1717076858934, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6c928105)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 220620000.0, "lon": 9.415018, "lat": 57.817155, "speed": 13.7, "course": 267.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 220620000.0, "lon": 9.415018, "lat": 57.817155, "speed": 13.7, "course": 267.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1764, CreateTime = 1717076858934, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2ad82fc3)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 257689000.0, "lon": 12.236927, "lat": 54.457712, "speed": 14.8, "course": 25.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 257689000.0, "lon": 12.236927, "lat": 54.457712, "speed": 14.8, "course": 25.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1765, CreateTime = 1717076858934, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4fb16721)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 308941000.0, "lon": 10.853428, "lat": 57.990128, "speed": 0.1, "course": 106.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 308941000.0, "lon": 10.853428, "lat": 57.990128, "speed": 0.1, "course": 106.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1766, CreateTime = 1717076858935, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4256dc3a)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 211377940.0, "lon": 12.08723, "lat": 54.181803, "speed": 0.0, "course": 359.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 211377940.0, "lon": 12.08723, "lat": 54.181803, "speed": 0.0, "course": 359.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1767, CreateTime = 1717076858935, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3ab4e7dc)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 220464000.0, "lon": 9.903148, "lat": 57.710782, "speed": 20.1, "course": 255.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 220464000.0, "lon": 9.903148, "lat": 57.710782, "speed": 20.1, "course": 255.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1768, CreateTime = 1717076858935, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5179717e)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 211211260.0, "lon": 10.029682, "lat": 54.781577, "speed": 11.7, "course": 309.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 211211260.0, "lon": 10.029682, "lat": 54.781577, "speed": 11.7, "course": 309.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1769, CreateTime = 1717076858935, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@15359c1f)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 220174000.0, "lon": 9.70107, "lat": 57.560287, "speed": 16.3, "course": 60.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 220174000.0, "lon": 9.70107, "lat": 57.560287, "speed": 16.3, "course": 60.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1770, CreateTime = 1717076858935, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6176358f)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 992192025.0, "lon": 10.59365, "lat": 57.41465, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 992192025.0, "lon": 10.59365, "lat": 57.41465, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1771, CreateTime = 1717076858935, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7c61b47a)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 311995000.0, "lon": 10.267545, "lat": 57.791793, "speed": 19.0, "course": 76.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 311995000.0, "lon": 10.267545, "lat": 57.791793, "speed": 19.0, "course": 76.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1772, CreateTime = 1717076858935, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6609d809)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 231059000.0, "lon": 10.52344, "lat": 54.853018, "speed": 0.0, "course": 332.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 231059000.0, "lon": 10.52344, "lat": 54.853018, "speed": 0.0, "course": 332.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1773, CreateTime = 1717076858935, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5fe565b3)
2024-05-30 15:47:40 2024-05-30 13:47:40,462 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 211211200.0, "lon": 10.043845, "lat": 54.771998, "speed": 11.9, "course": 328.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 211211200.0, "lon": 10.043845, "lat": 54.771998, "speed": 11.9, "course": 328.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1774, CreateTime = 1717076858935, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@feff98d)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 211343680.0, "lon": 11.768305, "lat": 54.275923, "speed": 13.1, "course": 59.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 211343680.0, "lon": 11.768305, "lat": 54.275923, "speed": 13.1, "course": 59.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1775, CreateTime = 1717076858935, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7edc4e6e)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 246276000.0, "lon": 12.190862, "lat": 54.528262, "speed": 9.6, "course": 200.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 246276000.0, "lon": 12.190862, "lat": 54.528262, "speed": 9.6, "course": 200.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1776, CreateTime = 1717076858935, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@563d182c)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 230988000.0, "lon": 13.8341, "lat": 55.040783, "speed": 13.3, "course": 247.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 230988000.0, "lon": 13.8341, "lat": 55.040783, "speed": 13.3, "course": 247.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1777, CreateTime = 1717076858935, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@228127a5)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 220256000.0, "lon": 9.963058, "lat": 57.59294, "speed": 0.0, "course": 27.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 220256000.0, "lon": 9.963058, "lat": 57.59294, "speed": 0.0, "course": 27.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1778, CreateTime = 1717076858935, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@525291e9)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219005941.0, "lon": 10.588167, "lat": 57.718633, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219005941.0, "lon": 10.588167, "lat": 57.718633, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1779, CreateTime = 1717076858935, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4e611af3)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 304010455.0, "lon": 12.806132, "lat": 54.756302, "speed": 7.4, "course": 72.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 304010455.0, "lon": 12.806132, "lat": 54.756302, "speed": 7.4, "course": 72.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1780, CreateTime = 1717076858935, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7023976b)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 220621000.0, "lon": 9.75175, "lat": 55.56002, "speed": 0.0, "course": 39.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 220621000.0, "lon": 9.75175, "lat": 55.56002, "speed": 0.0, "course": 39.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1781, CreateTime = 1717076858935, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5bb43ac5)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219005662.0, "lon": 12.613787, "lat": 56.042703, "speed": 0.0, "course": 216.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219005662.0, "lon": 12.613787, "lat": 56.042703, "speed": 0.0, "course": 216.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1782, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1d2f2583)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219079000.0, "lon": 7.827017, "lat": 55.488787, "speed": 0.0, "course": 203.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219079000.0, "lon": 7.827017, "lat": 55.488787, "speed": 0.0, "course": 203.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1783, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5bdf0257)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 257478000.0, "lon": 12.885815, "lat": 55.614567, "speed": 10.5, "course": 40.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 257478000.0, "lon": 12.885815, "lat": 55.614567, "speed": 10.5, "course": 40.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1784, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@37ab4e88)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219000961.0, "lon": 10.833658, "lat": 54.933888, "speed": 0.0, "course": 349.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219000961.0, "lon": 10.833658, "lat": 54.933888, "speed": 0.0, "course": 349.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1785, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4db338aa)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219002757.0, "lon": 12.548635, "lat": 55.886307, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219002757.0, "lon": 12.548635, "lat": 55.886307, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1786, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@29540fa2)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 319562000.0, "lon": 14.709083, "lat": 55.31995, "speed": 13.1, "course": 229.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 319562000.0, "lon": 14.709083, "lat": 55.31995, "speed": 13.1, "course": 229.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1787, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@aba6d65)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 244660757.0, "lon": 8.305212, "lat": 56.550357, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 244660757.0, "lon": 8.305212, "lat": 56.550357, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1788, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6708adb4)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 636012690.0, "lon": 10.806033, "lat": 55.78815, "speed": 12.2, "course": 177.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 636012690.0, "lon": 10.806033, "lat": 55.78815, "speed": 12.2, "course": 177.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1789, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@33aaaf97)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219000827.0, "lon": 8.601057, "lat": 57.121337, "speed": 0.0, "course": 161.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219000827.0, "lon": 8.601057, "lat": 57.121337, "speed": 0.0, "course": 161.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1790, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3a8a9f5f)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 220622000.0, "lon": 11.902442, "lat": 56.547223, "speed": 0.2, "course": 317.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 220622000.0, "lon": 11.902442, "lat": 56.547223, "speed": 0.2, "course": 317.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1791, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@63020c2e)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 211462260.0, "lon": 9.937933, "lat": 54.664333, "speed": 0.0, "course": 31.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 211462260.0, "lon": 9.937933, "lat": 54.664333, "speed": 0.0, "course": 31.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1792, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@41c568f7)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 265522220.0, "lon": 11.700988, "lat": 57.707477, "speed": 5.7, "course": 54.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 265522220.0, "lon": 11.700988, "lat": 57.707477, "speed": 5.7, "course": 54.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1793, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2775b14f)
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 266331000.0, "lon": 10.785918, "lat": 55.658615, "speed": 18.1, "course": 6.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,463 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 266331000.0, "lon": 10.785918, "lat": 55.658615, "speed": 18.1, "course": 6.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1794, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@496bb299)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219004266.0, "lon": 8.222577, "lat": 56.705308, "speed": 0.0, "course": 357.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219004266.0, "lon": 8.222577, "lat": 56.705308, "speed": 0.0, "course": 357.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1795, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3a7bb4e6)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 219329000.0, "lon": 8.421013, "lat": 55.478235, "speed": 0.0, "course": 338.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 219329000.0, "lon": 8.421013, "lat": 55.478235, "speed": 0.0, "course": 338.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1796, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5013f18e)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 211707000.0, "lon": 11.86105, "lat": 57.68835, "speed": 0.0, "course": 20.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 211707000.0, "lon": 11.86105, "lat": 57.68835, "speed": 0.0, "course": 20.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1797, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5ae6cd0a)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 377455000.0, "lon": 12.354967, "lat": 56.17155, "speed": 9.9, "course": 121.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 377455000.0, "lon": 12.354967, "lat": 56.17155, "speed": 9.9, "course": 121.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1798, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4e8d43b5)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 357562000.0, "lon": 8.287417, "lat": 57.25545, "speed": 16.3, "course": 59.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 357562000.0, "lon": 8.287417, "lat": 57.25545, "speed": 16.3, "course": 59.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1799, CreateTime = 1717076858936, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@29360206)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 992191502.0, "lon": 5.116167, "lat": 55.480667, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 992191502.0, "lon": 5.116167, "lat": 55.480667, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1800, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6666092f)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 357078000.0, "lon": 5.3668, "lat": 55.255933, "speed": 13.5, "course": 210.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 357078000.0, "lon": 5.3668, "lat": 55.255933, "speed": 13.5, "course": 210.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1801, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@a841674)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 244316000.0, "lon": 16.9321, "lat": 55.39555, "speed": 8.7, "course": 115.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 244316000.0, "lon": 16.9321, "lat": 55.39555, "speed": 8.7, "course": 115.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1802, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2eb06c7a)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 244446000.0, "lon": 8.566435, "lat": 55.087783, "speed": 0.0, "course": 130.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 244446000.0, "lon": 8.566435, "lat": 55.087783, "speed": 0.0, "course": 130.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1803, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@378f6d98)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 233150000.0, "lon": 15.7003, "lat": 55.728167, "speed": 14.4, "course": 62.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 233150000.0, "lon": 15.7003, "lat": 55.728167, "speed": 14.4, "course": 62.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1804, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@61f62537)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 235004750.0, "lon": 10.583513, "lat": 57.715125, "speed": 0.0, "course": 29.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 235004750.0, "lon": 10.583513, "lat": 57.715125, "speed": 0.0, "course": 29.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1805, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4bebb8cb)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 265547260.0, "lon": 11.807543, "lat": 57.6555, "speed": 13.4, "course": 55.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 265547260.0, "lon": 11.807543, "lat": 57.6555, "speed": 13.4, "course": 55.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1806, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6615ce70)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 305286000.0, "lon": 11.885085, "lat": 54.997545, "speed": 0.1, "course": 256.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 305286000.0, "lon": 11.885085, "lat": 54.997545, "speed": 0.1, "course": 256.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1807, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2a3a9c87)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:19", "mmsi": 220046000.0, "lon": 9.96141, "lat": 57.59375, "speed": 0.0, "course": 20.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:19", "mmsi": 220046000.0, "lon": 9.96141, "lat": 57.59375, "speed": 0.0, "course": 20.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1808, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7ab5db6a)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219226000.0, "lon": 8.125667, "lat": 55.4265, "speed": 14.5, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219226000.0, "lon": 8.125667, "lat": 55.4265, "speed": 14.5, "course": 271.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1809, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6c0e1917)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 2190064.0, "lon": 11.519008, "lat": 56.716573, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 2190064.0, "lon": 11.519008, "lat": 56.716573, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1810, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@24202ca8)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 220223000.0, "lon": 9.319785, "lat": 57.454068, "speed": 17.5, "course": 54.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 220223000.0, "lon": 9.319785, "lat": 57.454068, "speed": 17.5, "course": 54.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1811, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5a00420f)
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 325423000.0, "lon": 10.619847, "lat": 55.060765, "speed": 0.1, "course": 47.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,464 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 325423000.0, "lon": 10.619847, "lat": 55.060765, "speed": 0.1, "course": 47.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1812, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@ebaacae)
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219000643.0, "lon": 9.730303, "lat": 55.260218, "speed": 0.0, "course": 162.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219000643.0, "lon": 9.730303, "lat": 55.260218, "speed": 0.0, "course": 162.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1813, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@12e0dacf)
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 992191016.0, "lon": 11.04674, "lat": 55.324798, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 992191016.0, "lon": 11.04674, "lat": 55.324798, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1814, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3700f157)
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219002416.0, "lon": 10.216208, "lat": 56.152885, "speed": 0.0, "course": 246.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219002416.0, "lon": 10.216208, "lat": 56.152885, "speed": 0.0, "course": 246.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1815, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6f48cd82)
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219000733.0, "lon": 10.2595, "lat": 54.941767, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219000733.0, "lon": 10.2595, "lat": 54.941767, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1816, CreateTime = 1717076858937, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@34ccd319)
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 215681000.0, "lon": 12.756662, "lat": 55.27114, "speed": 14.0, "course": 111.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 215681000.0, "lon": 12.756662, "lat": 55.27114, "speed": 14.0, "course": 111.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1817, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@20ee51ed)
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 2194005.0, "lon": 4.272, "lat": 56.344267, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 2194005.0, "lon": 4.272, "lat": 56.344267, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1818, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@10d486ee)
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219440000.0, "lon": 4.228432, "lat": 56.078437, "speed": 0.0, "course": 278.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219440000.0, "lon": 4.228432, "lat": 56.078437, "speed": 0.0, "course": 278.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1819, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@39597dab)
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219537000.0, "lon": 10.90984, "lat": 55.886402, "speed": 14.3, "course": 40.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219537000.0, "lon": 10.90984, "lat": 55.886402, "speed": 14.3, "course": 40.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1820, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6bdf2582)
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219005504.0, "lon": 12.589083, "lat": 55.67635, "speed": 0.0, "course": 23.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219005504.0, "lon": 12.589083, "lat": 55.67635, "speed": 0.0, "course": 23.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1821, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@396c702d)
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 2194006.0, "lon": 5.0334, "lat": 55.538917, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 2194006.0, "lon": 5.0334, "lat": 55.538917, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1822, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 109, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@d3b7218)
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,465 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219294000.0, "lon": 8.598445, "lat": 57.121717, "speed": 0.0, "course": 311.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219294000.0, "lon": 8.598445, "lat": 57.121717, "speed": 0.0, "course": 311.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1823, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7ffde231)
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 636091254.0, "lon": 9.370167, "lat": 58.024033, "speed": 16.9, "course": 44.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 636091254.0, "lon": 9.370167, "lat": 58.024033, "speed": 16.9, "course": 44.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1824, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6d9c2b79)
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219004838.0, "lon": 11.92872, "lat": 54.571997, "speed": 0.0, "course": 304.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219004838.0, "lon": 11.92872, "lat": 54.571997, "speed": 0.0, "course": 304.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1825, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@37abc3ff)
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 245461000.0, "lon": 12.938767, "lat": 55.6885, "speed": 0.0, "course": 315.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 245461000.0, "lon": 12.938767, "lat": 55.6885, "speed": 0.0, "course": 315.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1826, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@61d6dca0)
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 236189000.0, "lon": 10.221, "lat": 56.1445, "speed": 0.0, "course": 223.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 236189000.0, "lon": 10.221, "lat": 56.1445, "speed": 0.0, "course": 223.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1827, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@71aa46c1)
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219000407.0, "lon": 10.921433, "lat": 57.296683, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219000407.0, "lon": 10.921433, "lat": 57.296683, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1828, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7d616c6e)
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 215013000.0, "lon": 15.011062, "lat": 55.569605, "speed": 17.1, "course": 239.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 215013000.0, "lon": 15.011062, "lat": 55.569605, "speed": 17.1, "course": 239.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1829, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@14bcec06)
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 305203000.0, "lon": 14.610925, "lat": 55.381323, "speed": 9.5, "course": 24.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 305203000.0, "lon": 14.610925, "lat": 55.381323, "speed": 9.5, "course": 24.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1830, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@43d801ed)
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219008746.0, "lon": 10.302135, "lat": 56.60734, "speed": 0.1, "course": 136.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219008746.0, "lon": 10.302135, "lat": 56.60734, "speed": 0.1, "course": 136.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1831, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6067db19)
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219001682.0, "lon": 9.958532, "lat": 57.59274, "speed": 0.0, "course": 19.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219001682.0, "lon": 9.958532, "lat": 57.59274, "speed": 0.0, "course": 19.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1832, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1613c967)
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219001459.0, "lon": 11.348678, "lat": 54.656808, "speed": 0.0, "course": 359.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219001459.0, "lon": 11.348678, "lat": 54.656808, "speed": 0.0, "course": 359.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,466 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1833, CreateTime = 1717076858938, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@653ccb7f)
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 2655146.0, "lon": 12.93794, "lat": 56.790035, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 2655146.0, "lon": 12.93794, "lat": 56.790035, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1834, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6668695c)
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219000647.0, "lon": 8.424325, "lat": 55.471758, "speed": 0.1, "course": 138.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219000647.0, "lon": 8.424325, "lat": 55.471758, "speed": 0.1, "course": 138.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1835, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3889c99b)
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 2190066.0, "lon": 8.166937, "lat": 56.530087, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 2190066.0, "lon": 8.166937, "lat": 56.530087, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1836, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3059671c)
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 265513470.0, "lon": 12.687867, "lat": 56.04485, "speed": 0.0, "course": 216.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 265513470.0, "lon": 12.687867, "lat": 56.04485, "speed": 0.0, "course": 216.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1837, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@333d255b)
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219338000.0, "lon": 8.415328, "lat": 55.475345, "speed": 0.0, "course": 11.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219338000.0, "lon": 8.415328, "lat": 55.475345, "speed": 0.0, "course": 11.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1838, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@163a98e9)
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 255801540.0, "lon": 11.866, "lat": 56.739833, "speed": 18.2, "course": 168.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 255801540.0, "lon": 11.866, "lat": 56.739833, "speed": 18.2, "course": 168.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1839, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@60895ea4)
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219007333.0, "lon": 14.93125, "lat": 54.700333, "speed": 0.8, "course": 45.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219007333.0, "lon": 14.93125, "lat": 54.700333, "speed": 0.8, "course": 45.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1840, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1b93a42e)
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 265585140.0, "lon": 11.618843, "lat": 57.772153, "speed": 0.0, "course": 329.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 265585140.0, "lon": 11.618843, "lat": 57.772153, "speed": 0.0, "course": 329.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1841, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@41de5dfa)
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219010252.0, "lon": 10.6184, "lat": 57.712412, "speed": 0.0, "course": 327.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219010252.0, "lon": 10.6184, "lat": 57.712412, "speed": 0.0, "course": 327.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1842, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@36168f8)
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 265177000.0, "lon": 11.69189, "lat": 57.631808, "speed": 17.0, "course": 23.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 265177000.0, "lon": 11.69189, "lat": 57.631808, "speed": 17.0, "course": 23.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1843, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@29b77a4e)
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 265527470.0, "lon": 12.546047, "lat": 56.199235, "speed": 0.0, "course": 7.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 265527470.0, "lon": 12.546047, "lat": 56.199235, "speed": 0.0, "course": 7.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1844, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2f031982)
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 311411000.0, "lon": 13.014928, "lat": 55.180945, "speed": 13.3, "course": 320.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 311411000.0, "lon": 13.014928, "lat": 55.180945, "speed": 13.3, "course": 320.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1845, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1c01a015)
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 277408000.0, "lon": 15.482418, "lat": 54.97871, "speed": 20.7, "course": 242.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,467 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 277408000.0, "lon": 15.482418, "lat": 54.97871, "speed": 20.7, "course": 242.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1846, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@14af2dc5)
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219001362.0, "lon": 10.616188, "lat": 55.061983, "speed": 0.0, "course": 19.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219001362.0, "lon": 10.616188, "lat": 55.061983, "speed": 0.0, "course": 19.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1847, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6585014)
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 211222290.0, "lon": 13.36838, "lat": 54.910308, "speed": 2.4, "course": 232.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 211222290.0, "lon": 13.36838, "lat": 54.910308, "speed": 2.4, "course": 232.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1848, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@31a09654)
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219043000.0, "lon": 4.212028, "lat": 56.369788, "speed": 0.4, "course": 92.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219043000.0, "lon": 4.212028, "lat": 56.369788, "speed": 0.4, "course": 92.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1849, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@20b0997d)
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219002317.0, "lon": 12.694382, "lat": 55.537855, "speed": 10.1, "course": 357.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219002317.0, "lon": 12.694382, "lat": 55.537855, "speed": 10.1, "course": 357.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1850, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4d9c59ab)
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219000479.0, "lon": 11.962183, "lat": 54.4729, "speed": 15.4, "course": 345.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219000479.0, "lon": 11.962183, "lat": 54.4729, "speed": 15.4, "course": 345.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1851, CreateTime = 1717076858939, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@98068fc)
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 2190071.0, "lon": 8.648272, "lat": 57.110042, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 2190071.0, "lon": 8.648272, "lat": 57.110042, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1852, CreateTime = 1717076858940, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3ca74dae)
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219801000.0, "lon": 9.964817, "lat": 57.592883, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219801000.0, "lon": 9.964817, "lat": 57.592883, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1853, CreateTime = 1717076858940, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@18784036)
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 271000601.0, "lon": 11.59775, "lat": 54.482267, "speed": 10.4, "course": 297.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 271000601.0, "lon": 11.59775, "lat": 54.482267, "speed": 10.4, "course": 297.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1854, CreateTime = 1717076858940, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@37060393)
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 265444000.0, "lon": 13.039145, "lat": 55.241065, "speed": 10.4, "course": 92.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 265444000.0, "lon": 13.039145, "lat": 55.241065, "speed": 10.4, "course": 92.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1855, CreateTime = 1717076858940, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3dcb5a07)
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 265506580.0, "lon": 11.897805, "lat": 57.692127, "speed": 0.0, "course": 330.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 265506580.0, "lon": 11.897805, "lat": 57.692127, "speed": 0.0, "course": 330.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1856, CreateTime = 1717076858940, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3b07ba2d)
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 211222700.0, "lon": 10.147628, "lat": 54.360133, "speed": 0.0, "course": 57.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 211222700.0, "lon": 10.147628, "lat": 54.360133, "speed": 0.0, "course": 57.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1857, CreateTime = 1717076858940, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6124248b)
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219002159.0, "lon": 10.592777, "lat": 57.718257, "speed": 0.0, "course": 123.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219002159.0, "lon": 10.592777, "lat": 57.718257, "speed": 0.0, "course": 123.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,468 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1858, CreateTime = 1717076858940, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@66b9b9a7)
2024-05-30 15:47:40 2024-05-30 13:47:40,469 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,469 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 265218000.0, "lon": 12.9963, "lat": 55.616077, "speed": 0.0, "course": 318.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,469 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 265218000.0, "lon": 12.9963, "lat": 55.616077, "speed": 0.0, "course": 318.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,469 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1859, CreateTime = 1717076858940, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@145cc15)
2024-05-30 15:47:40 2024-05-30 13:47:40,469 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,469 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 230315000.0, "lon": 10.9445, "lat": 55.908667, "speed": 15.1, "course": 38.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,469 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 230315000.0, "lon": 10.9445, "lat": 55.908667, "speed": 15.1, "course": 38.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,469 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1860, CreateTime = 1717076858941, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@715d8c2)
2024-05-30 15:47:40 2024-05-30 13:47:40,469 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,469 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219352000.0, "lon": 10.536173, "lat": 55.471258, "speed": 0.1, "course": 192.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,469 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219352000.0, "lon": 10.536173, "lat": 55.471258, "speed": 0.1, "course": 192.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1861, CreateTime = 1717076858941, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@47d5a4d7)
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 265610900.0, "lon": 12.90357, "lat": 55.75665, "speed": 0.0, "course": 322.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 265610900.0, "lon": 12.90357, "lat": 55.75665, "speed": 0.0, "course": 322.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1862, CreateTime = 1717076858941, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6c0a490b)
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 2190068.0, "lon": 10.945843, "lat": 56.44728, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 2190068.0, "lon": 10.945843, "lat": 56.44728, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1863, CreateTime = 1717076858941, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@438005fb)
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 255803370.0, "lon": 9.030823, "lat": 57.497663, "speed": 10.3, "course": 241.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 255803370.0, "lon": 9.030823, "lat": 57.497663, "speed": 10.3, "course": 241.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1864, CreateTime = 1717076858941, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6afa0681)
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 2614800.0, "lon": 14.580335, "lat": 53.981455, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 2614800.0, "lon": 14.580335, "lat": 53.981455, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1865, CreateTime = 1717076858941, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@63e415)
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219004263.0, "lon": 10.91175, "lat": 55.711012, "speed": 9.1, "course": 290.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219004263.0, "lon": 10.91175, "lat": 55.711012, "speed": 9.1, "course": 290.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1866, CreateTime = 1717076858941, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3e1fb703)
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 259222000.0, "lon": 11.618105, "lat": 56.518212, "speed": 19.2, "course": 210.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 259222000.0, "lon": 11.618105, "lat": 56.518212, "speed": 19.2, "course": 210.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1867, CreateTime = 1717076858941, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7d73c2e6)
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 305279000.0, "lon": 12.486002, "lat": 55.60066, "speed": 0.0, "course": 319.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 305279000.0, "lon": 12.486002, "lat": 55.60066, "speed": 0.0, "course": 319.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1868, CreateTime = 1717076858941, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@47071dc7)
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,470 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 2655120.0, "lon": 16.454932, "lat": 56.233643, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,471 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 2655120.0, "lon": 16.454932, "lat": 56.233643, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,471 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1869, CreateTime = 1717076858941, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@585b1a7e)
2024-05-30 15:47:40 2024-05-30 13:47:40,471 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,471 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 353531000.0, "lon": 7.210067, "lat": 56.084783, "speed": 13.2, "course": 21.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,471 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 353531000.0, "lon": 7.210067, "lat": 56.084783, "speed": 13.2, "course": 21.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,471 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1870, CreateTime = 1717076858941, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1b3f19d9)
2024-05-30 15:47:40 2024-05-30 13:47:40,471 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,471 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219001522.0, "lon": 10.585437, "lat": 57.71762, "speed": 0.0, "course": 344.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,472 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219001522.0, "lon": 10.585437, "lat": 57.71762, "speed": 0.0, "course": 344.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,472 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1871, CreateTime = 1717076858941, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@78389caa)
2024-05-30 15:47:40 2024-05-30 13:47:40,472 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,472 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 265007000.0, "lon": 8.498137, "lat": 57.293545, "speed": 14.8, "course": 52.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,472 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 265007000.0, "lon": 8.498137, "lat": 57.293545, "speed": 14.8, "course": 52.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,472 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1872, CreateTime = 1717076858941, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7ae4f4f)
2024-05-30 15:47:40 2024-05-30 13:47:40,472 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,472 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 992191501.0, "lon": 5.133082, "lat": 55.469067, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,472 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 992191501.0, "lon": 5.133082, "lat": 55.469067, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,472 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1873, CreateTime = 1717076858945, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7a63d2e)
2024-05-30 15:47:40 2024-05-30 13:47:40,472 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,472 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 266112000.0, "lon": 15.484198, "lat": 55.11014, "speed": 6.2, "course": 124.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,472 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 266112000.0, "lon": 15.484198, "lat": 55.11014, "speed": 6.2, "course": 124.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,472 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1874, CreateTime = 1717076858945, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@64341dd2)
2024-05-30 15:47:40 2024-05-30 13:47:40,473 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,473 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219001061.0, "lon": 12.680182, "lat": 55.592852, "speed": 0.0, "course": 44.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,473 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219001061.0, "lon": 12.680182, "lat": 55.592852, "speed": 0.0, "course": 44.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,473 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1875, CreateTime = 1717076858946, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@58d50032)
2024-05-30 15:47:40 2024-05-30 13:47:40,473 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,473 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 2655140.0, "lon": 12.70819, "lat": 56.05334, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,473 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 2655140.0, "lon": 12.70819, "lat": 56.05334, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,473 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1876, CreateTime = 1717076858946, serialized key size = -1, serialized value size = 110, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2df4e850)
2024-05-30 15:47:40 2024-05-30 13:47:40,473 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,473 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219005502.0, "lon": 10.586547, "lat": 57.717822, "speed": 0.0, "course": 317.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,473 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219005502.0, "lon": 10.586547, "lat": 57.717822, "speed": 0.0, "course": 317.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1877, CreateTime = 1717076858946, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1b8dff8d)
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 215140000.0, "lon": 15.209182, "lat": 55.567728, "speed": 12.6, "course": 58.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 215140000.0, "lon": 15.209182, "lat": 55.567728, "speed": 12.6, "course": 58.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1878, CreateTime = 1717076858946, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5f93bba3)
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 211378550.0, "lon": 13.646917, "lat": 54.513383, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 211378550.0, "lon": 13.646917, "lat": 54.513383, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1879, CreateTime = 1717076858946, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2fb7f4f3)
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 233234000.0, "lon": 7.319292, "lat": 56.391995, "speed": 15.4, "course": 213.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 233234000.0, "lon": 7.319292, "lat": 56.391995, "speed": 15.4, "course": 213.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1880, CreateTime = 1717076858946, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@250b3f3d)
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 319161000.0, "lon": 11.45715, "lat": 56.3469, "speed": 14.4, "course": 28.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 319161000.0, "lon": 11.45715, "lat": 56.3469, "speed": 14.4, "course": 28.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1881, CreateTime = 1717076858946, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@518ecd86)
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 261006470.0, "lon": 14.373798, "lat": 54.020283, "speed": 8.2, "course": 35.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 261006470.0, "lon": 14.373798, "lat": 54.020283, "speed": 8.2, "course": 35.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1882, CreateTime = 1717076858946, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@13022ab7)
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 248811000.0, "lon": 10.801278, "lat": 55.731228, "speed": 16.3, "course": 9.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 248811000.0, "lon": 10.801278, "lat": 55.731228, "speed": 16.3, "course": 9.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1883, CreateTime = 1717076858946, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3024448)
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,474 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219009267.0, "lon": 11.125885, "lat": 55.332257, "speed": 0.0, "course": 272.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219009267.0, "lon": 11.125885, "lat": 55.332257, "speed": 0.0, "course": 272.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1884, CreateTime = 1717076858946, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7f0c71c2)
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 210008000.0, "lon": 10.944485, "lat": 57.680115, "speed": 17.2, "course": 132.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 210008000.0, "lon": 10.944485, "lat": 57.680115, "speed": 17.2, "course": 132.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1885, CreateTime = 1717076858946, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@58c96158)
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 259898000.0, "lon": 11.432, "lat": 56.530667, "speed": 14.4, "course": 50.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 259898000.0, "lon": 11.432, "lat": 56.530667, "speed": 14.4, "course": 50.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1886, CreateTime = 1717076858946, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5a1caf64)
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 273416080.0, "lon": 11.271972, "lat": 57.523947, "speed": 9.1, "course": 296.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 273416080.0, "lon": 11.271972, "lat": 57.523947, "speed": 9.1, "course": 296.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1887, CreateTime = 1717076858947, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4bad906b)
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219012685.0, "lon": 12.684093, "lat": 54.83022, "speed": 9.1, "course": 54.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219012685.0, "lon": 12.684093, "lat": 54.83022, "speed": 9.1, "course": 54.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1888, CreateTime = 1717076858947, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@57337abd)
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 305381000.0, "lon": 13.727595, "lat": 55.172315, "speed": 10.7, "course": 96.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 305381000.0, "lon": 13.727595, "lat": 55.172315, "speed": 10.7, "course": 96.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1889, CreateTime = 1717076858948, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@44e312a2)
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 219002415.0, "lon": 8.22216, "lat": 56.704695, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 219002415.0, "lon": 8.22216, "lat": 56.704695, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1890, CreateTime = 1717076858948, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7bbbf2d5)
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 352055000.0, "lon": 10.907617, "lat": 57.5336, "speed": 0.1, "course": 46.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 352055000.0, "lon": 10.907617, "lat": 57.5336, "speed": 0.1, "course": 46.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1891, CreateTime = 1717076858948, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5cb21b01)
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 211904000.0, "lon": 11.068845, "lat": 56.467392, "speed": 7.5, "course": 169.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 211904000.0, "lon": 11.068845, "lat": 56.467392, "speed": 7.5, "course": 169.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1892, CreateTime = 1717076858948, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@109864b8)
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 304010928.0, "lon": 10.9054, "lat": 57.703017, "speed": 10.9, "course": 138.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 304010928.0, "lon": 10.9054, "lat": 57.703017, "speed": 10.9, "course": 138.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1893, CreateTime = 1717076858948, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4cb2020b)
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 244010708.0, "lon": 12.310825, "lat": 56.125847, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 244010708.0, "lon": 12.310825, "lat": 56.125847, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1894, CreateTime = 1717076858948, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@683b6c12)
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 211230400.0, "lon": 11.263167, "lat": 54.581167, "speed": 10.1, "course": 293.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 211230400.0, "lon": 11.263167, "lat": 54.581167, "speed": 10.1, "course": 293.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1895, CreateTime = 1717076858948, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@249d1807)
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 218159000.0, "lon": 10.34476, "lat": 56.97076, "speed": 7.9, "course": 305.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 218159000.0, "lon": 10.34476, "lat": 56.97076, "speed": 7.9, "course": 305.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1896, CreateTime = 1717076858948, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@77731588)
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,475 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 565589000.0, "lon": 10.8914, "lat": 57.7151, "speed": 12.6, "course": 135.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 565589000.0, "lon": 10.8914, "lat": 57.7151, "speed": 12.6, "course": 135.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1897, CreateTime = 1717076858949, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2b8df337)
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 211222710.0, "lon": 10.155978, "lat": 54.370317, "speed": 0.0, "course": 321.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 211222710.0, "lon": 10.155978, "lat": 54.370317, "speed": 0.0, "course": 321.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1898, CreateTime = 1717076858949, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@186541a8)
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 211910000.0, "lon": 8.247783, "lat": 57.055633, "speed": 23.4, "course": 39.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 211910000.0, "lon": 8.247783, "lat": 57.055633, "speed": 23.4, "course": 39.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1899, CreateTime = 1717076858950, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@54743f83)
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 2573115.0, "lon": 9.7, "lat": 59.233333, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 2573115.0, "lon": 9.7, "lat": 59.233333, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1900, CreateTime = 1717076858951, serialized key size = -1, serialized value size = 106, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3bc4bfd0)
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 2655185.0, "lon": 14.775318, "lat": 56.22696, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 2655185.0, "lon": 14.775318, "lat": 56.22696, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1901, CreateTime = 1717076858951, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7f14e7d4)
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:20", "mmsi": 244620052.0, "lon": 8.44983, "lat": 55.458765, "speed": 0.1, "course": 7.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:20", "mmsi": 244620052.0, "lon": 8.44983, "lat": 55.458765, "speed": 0.1, "course": 7.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1902, CreateTime = 1717076858951, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4d4e919f)
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219000818.0, "lon": 9.889278, "lat": 55.270375, "speed": 0.0, "course": 6.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219000818.0, "lon": 9.889278, "lat": 55.270375, "speed": 0.0, "course": 6.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1903, CreateTime = 1717076858951, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@38332792)
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219009704.0, "lon": 12.385638, "lat": 55.611592, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219009704.0, "lon": 12.385638, "lat": 55.611592, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1904, CreateTime = 1717076858951, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2617257b)
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 265328000.0, "lon": 11.791677, "lat": 57.599572, "speed": 0.0, "course": 346.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 265328000.0, "lon": 11.791677, "lat": 57.599572, "speed": 0.0, "course": 346.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1905, CreateTime = 1717076858951, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7e654c2a)
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219005059.0, "lon": 11.92798, "lat": 54.572725, "speed": 0.0, "course": 191.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219005059.0, "lon": 11.92798, "lat": 54.572725, "speed": 0.0, "course": 191.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1906, CreateTime = 1717076858951, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@471ee810)
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219008474.0, "lon": 9.954283, "lat": 57.591617, "speed": 0.0, "course": 359.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219008474.0, "lon": 9.954283, "lat": 57.591617, "speed": 0.0, "course": 359.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1907, CreateTime = 1717076858952, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@66b048d6)
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 245914000.0, "lon": 7.984433, "lat": 55.128083, "speed": 3.2, "course": 130.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 245914000.0, "lon": 7.984433, "lat": 55.128083, "speed": 3.2, "course": 130.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1908, CreateTime = 1717076858952, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@79138586)
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 244996000.0, "lon": 10.736833, "lat": 55.782117, "speed": 12.8, "course": 46.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 244996000.0, "lon": 10.736833, "lat": 55.782117, "speed": 12.8, "course": 46.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1909, CreateTime = 1717076858952, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2d438292)
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 245882000.0, "lon": 10.037583, "lat": 56.68245, "speed": 0.0, "course": 4.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 245882000.0, "lon": 10.037583, "lat": 56.68245, "speed": 0.0, "course": 4.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1910, CreateTime = 1717076858952, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1d2da142)
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 304010723.0, "lon": 9.505463, "lat": 57.546832, "speed": 10.2, "course": 243.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,476 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 304010723.0, "lon": 9.505463, "lat": 57.546832, "speed": 10.2, "course": 243.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1911, CreateTime = 1717076858952, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@793fbcc9)
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 225388000.0, "lon": 12.097955, "lat": 54.446788, "speed": 10.2, "course": 250.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 225388000.0, "lon": 12.097955, "lat": 54.446788, "speed": 10.2, "course": 250.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1912, CreateTime = 1717076858952, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1c6539dd)
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219001013.0, "lon": 11.082957, "lat": 55.677395, "speed": 0.0, "course": 5.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219001013.0, "lon": 11.082957, "lat": 55.677395, "speed": 0.0, "course": 5.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1913, CreateTime = 1717076858952, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2d837fd1)
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219001063.0, "lon": 11.844732, "lat": 55.965523, "speed": 0.0, "course": 327.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219001063.0, "lon": 11.844732, "lat": 55.965523, "speed": 0.0, "course": 327.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1914, CreateTime = 1717076858952, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5d54fc92)
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219946000.0, "lon": 7.045105, "lat": 56.175295, "speed": 0.1, "course": 209.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219946000.0, "lon": 7.045105, "lat": 56.175295, "speed": 0.1, "course": 209.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1915, CreateTime = 1717076858952, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5909da05)
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 215729000.0, "lon": 12.630052, "lat": 54.627075, "speed": 1.0, "course": 56.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 215729000.0, "lon": 12.630052, "lat": 54.627075, "speed": 1.0, "course": 56.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1916, CreateTime = 1717076858952, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6c97bb28)
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 211629000.0, "lon": 10.514322, "lat": 55.576828, "speed": 9.6, "course": 147.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 211629000.0, "lon": 10.514322, "lat": 55.576828, "speed": 9.6, "course": 147.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1917, CreateTime = 1717076858952, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5a5c2c9c)
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 245180000.0, "lon": 14.544583, "lat": 55.316937, "speed": 11.1, "course": 48.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 245180000.0, "lon": 14.544583, "lat": 55.316937, "speed": 11.1, "course": 48.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1918, CreateTime = 1717076858952, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2016fb29)
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219001684.0, "lon": 12.615938, "lat": 56.036615, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219001684.0, "lon": 12.615938, "lat": 56.036615, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1919, CreateTime = 1717076858952, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3758c4dc)
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 265410000.0, "lon": 11.6033, "lat": 57.607573, "speed": 17.0, "course": 250.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,477 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 265410000.0, "lon": 11.6033, "lat": 57.607573, "speed": 17.0, "course": 250.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1920, CreateTime = 1717076858953, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@664777e4)
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 2190047.0, "lon": 12.613717, "lat": 55.69725, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 2190047.0, "lon": 12.613717, "lat": 55.69725, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1921, CreateTime = 1717076858954, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5dc48f7c)
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219262000.0, "lon": 11.131735, "lat": 55.33424, "speed": 0.0, "course": 99.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219262000.0, "lon": 11.131735, "lat": 55.33424, "speed": 0.0, "course": 99.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1922, CreateTime = 1717076858954, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4a1ce85e)
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 304010515.0, "lon": 10.57822, "lat": 54.569525, "speed": 14.7, "course": 247.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 304010515.0, "lon": 10.57822, "lat": 54.569525, "speed": 14.7, "course": 247.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1923, CreateTime = 1717076858954, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3b93abe5)
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219001261.0, "lon": 9.633717, "lat": 56.988383, "speed": 0.0, "course": 7.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219001261.0, "lon": 9.633717, "lat": 56.988383, "speed": 0.0, "course": 7.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1924, CreateTime = 1717076858954, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@66360324)
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 304822000.0, "lon": 9.436688, "lat": 54.798183, "speed": 0.1, "course": 6.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,478 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 304822000.0, "lon": 9.436688, "lat": 54.798183, "speed": 0.1, "course": 6.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1925, CreateTime = 1717076858954, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1f70dff1)
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 220205000.0, "lon": 12.466692, "lat": 54.952028, "speed": 0.0, "course": 283.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 220205000.0, "lon": 12.466692, "lat": 54.952028, "speed": 0.0, "course": 283.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1926, CreateTime = 1717076858954, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@32038a59)
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 211800000.0, "lon": 11.425045, "lat": 57.219608, "speed": 9.4, "course": 158.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 211800000.0, "lon": 11.425045, "lat": 57.219608, "speed": 9.4, "course": 158.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1927, CreateTime = 1717076858954, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1469d37f)
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219000484.0, "lon": 9.755667, "lat": 55.5591, "speed": 0.0, "course": 206.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219000484.0, "lon": 9.755667, "lat": 55.5591, "speed": 0.0, "course": 206.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1928, CreateTime = 1717076858954, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4290ddf5)
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 2190065.0, "lon": 8.115157, "lat": 55.560725, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 2190065.0, "lon": 8.115157, "lat": 55.560725, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1929, CreateTime = 1717076858954, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5b061d01)
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219002767.0, "lon": 11.510508, "lat": 56.716045, "speed": 0.0, "course": 339.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219002767.0, "lon": 11.510508, "lat": 56.716045, "speed": 0.0, "course": 339.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1930, CreateTime = 1717076858954, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@75f9157a)
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 211231520.0, "lon": 10.162833, "lat": 54.341833, "speed": 6.5, "course": 180.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 211231520.0, "lon": 10.162833, "lat": 54.341833, "speed": 6.5, "course": 180.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1931, CreateTime = 1717076858955, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2f51c291)
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219001789.0, "lon": 11.082637, "lat": 55.677523, "speed": 0.0, "course": 151.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219001789.0, "lon": 11.082637, "lat": 55.677523, "speed": 0.0, "course": 151.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1932, CreateTime = 1717076858955, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6b6acdfb)
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 209696000.0, "lon": 11.373918, "lat": 54.545687, "speed": 15.4, "course": 295.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 209696000.0, "lon": 11.373918, "lat": 54.545687, "speed": 15.4, "course": 295.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1933, CreateTime = 1717076858955, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6f3b82)
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 265228000.0, "lon": 12.725732, "lat": 54.666285, "speed": 11.6, "course": 65.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 265228000.0, "lon": 12.725732, "lat": 54.666285, "speed": 11.6, "course": 65.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1934, CreateTime = 1717076858955, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3d80bc30)
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 266160000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 266160000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1935, CreateTime = 1717076858955, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1c64b45b)
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 2655130.0, "lon": 14.15808, "lat": 55.6681, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 2655130.0, "lon": 14.15808, "lat": 55.6681, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1936, CreateTime = 1717076858955, serialized key size = -1, serialized value size = 109, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@215cb739)
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 211211290.0, "lon": 10.035173, "lat": 54.778773, "speed": 11.6, "course": 314.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 211211290.0, "lon": 10.035173, "lat": 54.778773, "speed": 11.6, "course": 314.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1937, CreateTime = 1717076858955, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@58163bbb)
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 220000054.0, "lon": 9.175067, "lat": 56.709, "speed": 0.0, "course": 31.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 220000054.0, "lon": 9.175067, "lat": 56.709, "speed": 0.0, "course": 31.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1938, CreateTime = 1717076858956, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@604f6db5)
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 266148000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,479 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 266148000.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1939, CreateTime = 1717076858956, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5930cb8b)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 304010514.0, "lon": 10.83729, "lat": 54.568235, "speed": 11.9, "course": 83.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 304010514.0, "lon": 10.83729, "lat": 54.568235, "speed": 11.9, "course": 83.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1940, CreateTime = 1717076858956, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1d914aeb)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 235007859.0, "lon": 10.618642, "lat": 57.441578, "speed": 0.0, "course": 4.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 235007859.0, "lon": 10.618642, "lat": 57.441578, "speed": 0.0, "course": 4.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1941, CreateTime = 1717076858956, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@74b37101)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 258808000.0, "lon": 12.696833, "lat": 55.631417, "speed": 12.3, "course": 359.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 258808000.0, "lon": 12.696833, "lat": 55.631417, "speed": 12.3, "course": 359.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1942, CreateTime = 1717076858956, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6f8a98e7)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 212097000.0, "lon": 10.898197, "lat": 54.910208, "speed": 11.1, "course": 15.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 212097000.0, "lon": 10.898197, "lat": 54.910208, "speed": 11.1, "course": 15.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1943, CreateTime = 1717076858956, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@30b96a0e)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219000872.0, "lon": 10.30461, "lat": 56.990923, "speed": 0.1, "course": 290.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219000872.0, "lon": 10.30461, "lat": 56.990923, "speed": 0.1, "course": 290.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1944, CreateTime = 1717076858956, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2768b8e0)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219002827.0, "lon": 10.58731, "lat": 57.717492, "speed": 0.0, "course": 331.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219002827.0, "lon": 10.58731, "lat": 57.717492, "speed": 0.0, "course": 331.8}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1945, CreateTime = 1717076858956, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@48bcfe75)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219006113.0, "lon": 11.128117, "lat": 57.321285, "speed": 0.0, "course": 318.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219006113.0, "lon": 11.128117, "lat": 57.321285, "speed": 0.0, "course": 318.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1946, CreateTime = 1717076858956, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@73ca0a25)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 249127000.0, "lon": 7.831652, "lat": 56.931198, "speed": 9.4, "course": 239.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 249127000.0, "lon": 7.831652, "lat": 56.931198, "speed": 9.4, "course": 239.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1947, CreateTime = 1717076858956, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@8d8e748)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219001236.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219001236.0, "lon": 181.0, "lat": 91.0, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1948, CreateTime = 1717076858956, serialized key size = -1, serialized value size = 105, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6a15f10b)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219171000.0, "lon": 8.443983, "lat": 55.464175, "speed": 0.0, "course": 303.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219171000.0, "lon": 8.443983, "lat": 55.464175, "speed": 0.0, "course": 303.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1949, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4575e56a)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 311969000.0, "lon": 9.202483, "lat": 57.833417, "speed": 12.0, "course": 33.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 311969000.0, "lon": 9.202483, "lat": 57.833417, "speed": 12.0, "course": 33.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1950, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@664d54c3)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 220453000.0, "lon": 9.972882, "lat": 57.593453, "speed": 0.0, "course": 7.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 220453000.0, "lon": 9.972882, "lat": 57.593453, "speed": 0.0, "course": 7.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1951, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@29600de5)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 370614000.0, "lon": 11.5338, "lat": 57.2652, "speed": 14.1, "course": 162.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 370614000.0, "lon": 11.5338, "lat": 57.2652, "speed": 14.1, "course": 162.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1952, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6c383c6b)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 266039000.0, "lon": 11.136182, "lat": 56.098308, "speed": 17.6, "course": 207.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 266039000.0, "lon": 11.136182, "lat": 56.098308, "speed": 17.6, "course": 207.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1953, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@68cca33)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219689000.0, "lon": 8.2225, "lat": 56.6983, "speed": 0.0, "course": 18.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219689000.0, "lon": 8.2225, "lat": 56.6983, "speed": 0.0, "course": 18.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1954, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 110, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@aeb6d6d)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219005504.0, "lon": 12.589083, "lat": 55.67635, "speed": 0.0, "course": 23.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219005504.0, "lon": 12.589083, "lat": 55.67635, "speed": 0.0, "course": 23.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1955, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@23cd56f0)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219230000.0, "lon": 12.691137, "lat": 56.043238, "speed": 0.0, "course": 275.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219230000.0, "lon": 12.691137, "lat": 56.043238, "speed": 0.0, "course": 275.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1956, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@e3bfd86)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 992191512.0, "lon": 5.030867, "lat": 55.538017, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 992191512.0, "lon": 5.030867, "lat": 55.538017, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1957, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6e866320)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 314208000.0, "lon": 7.839067, "lat": 57.424133, "speed": 12.3, "course": 210.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 314208000.0, "lon": 7.839067, "lat": 57.424133, "speed": 12.3, "course": 210.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1958, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3fd7fb98)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219525000.0, "lon": 10.536965, "lat": 57.433455, "speed": 0.0, "course": 127.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219525000.0, "lon": 10.536965, "lat": 57.433455, "speed": 0.0, "course": 127.7}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1959, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@76645044)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219592000.0, "lon": 11.380877, "lat": 57.753498, "speed": 16.9, "course": 343.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219592000.0, "lon": 11.380877, "lat": 57.753498, "speed": 16.9, "course": 343.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1960, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@27e254c3)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 266203000.0, "lon": 10.662998, "lat": 57.677512, "speed": 0.0, "course": 292.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 266203000.0, "lon": 10.662998, "lat": 57.677512, "speed": 0.0, "course": 292.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1961, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7aa0bc7c)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 377801000.0, "lon": 12.46999, "lat": 54.832998, "speed": 9.0, "course": 214.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 377801000.0, "lon": 12.46999, "lat": 54.832998, "speed": 9.0, "course": 214.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1962, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7a2b838b)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 259448000.0, "lon": 9.956973, "lat": 57.59256, "speed": 0.0, "course": 327.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 259448000.0, "lon": 9.956973, "lat": 57.59256, "speed": 0.0, "course": 327.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1963, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2e190afa)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 2190076.0, "lon": 9.50212, "lat": 55.674668, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 2190076.0, "lon": 9.50212, "lat": 55.674668, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1964, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 110, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1be807b6)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 305376000.0, "lon": 13.943753, "lat": 54.361478, "speed": 12.5, "course": 332.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 305376000.0, "lon": 13.943753, "lat": 54.361478, "speed": 12.5, "course": 332.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1965, CreateTime = 1717076858957, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@64d40beb)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219295000.0, "lon": 8.22439, "lat": 56.703433, "speed": 0.0, "course": 170.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219295000.0, "lon": 8.22439, "lat": 56.703433, "speed": 0.0, "course": 170.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1966, CreateTime = 1717076858958, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4245fb21)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 236561000.0, "lon": 12.998502, "lat": 55.241627, "speed": 11.1, "course": 98.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 236561000.0, "lon": 12.998502, "lat": 55.241627, "speed": 11.1, "course": 98.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1967, CreateTime = 1717076858958, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@24ed6749)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 265150000.0, "lon": 12.301512, "lat": 54.563283, "speed": 16.3, "course": 34.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 265150000.0, "lon": 12.301512, "lat": 54.563283, "speed": 16.3, "course": 34.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1968, CreateTime = 1717076858958, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7fe311d5)
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219007844.0, "lon": 10.670568, "lat": 54.750897, "speed": 0.0, "course": 319.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,480 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219007844.0, "lon": 10.670568, "lat": 54.750897, "speed": 0.0, "course": 319.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1969, CreateTime = 1717076858958, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@3b2cc691)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 209642000.0, "lon": 10.721268, "lat": 57.418717, "speed": 11.0, "course": 3.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 209642000.0, "lon": 10.721268, "lat": 57.418717, "speed": 11.0, "course": 3.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1970, CreateTime = 1717076858958, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@56ddae26)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219000431.0, "lon": 11.34999, "lat": 54.653482, "speed": 0.0, "course": 210.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219000431.0, "lon": 11.34999, "lat": 54.653482, "speed": 0.0, "course": 210.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1971, CreateTime = 1717076858959, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@19c55c9b)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 265426000.0, "lon": 14.234217, "lat": 55.229067, "speed": 13.0, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 265426000.0, "lon": 14.234217, "lat": 55.229067, "speed": 13.0, "course": 272.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1972, CreateTime = 1717076858959, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7ecf9bcf)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 211247340.0, "lon": 9.715367, "lat": 54.318483, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 211247340.0, "lon": 9.715367, "lat": 54.318483, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1973, CreateTime = 1717076858959, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@238ad2c9)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 211227550.0, "lon": 11.19145, "lat": 54.419717, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 211227550.0, "lon": 11.19145, "lat": 54.419717, "speed": 0.0, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1974, CreateTime = 1717076858959, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@189df400)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 236407000.0, "lon": 9.64029, "lat": 57.764077, "speed": 13.0, "course": 74.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 236407000.0, "lon": 9.64029, "lat": 57.764077, "speed": 13.0, "course": 74.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1975, CreateTime = 1717076858959, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2b0f520c)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 477748300.0, "lon": 8.840833, "lat": 57.603, "speed": 14.9, "course": 60.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 477748300.0, "lon": 8.840833, "lat": 57.603, "speed": 14.9, "course": 60.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1976, CreateTime = 1717076858959, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@299cb541)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 376474000.0, "lon": 12.675892, "lat": 55.764562, "speed": 8.8, "course": 180.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 376474000.0, "lon": 12.675892, "lat": 55.764562, "speed": 8.8, "course": 180.1}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1977, CreateTime = 1717076858959, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5c753621)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 2190069.0, "lon": 9.82412, "lat": 57.00382, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 2190069.0, "lon": 9.82412, "lat": 57.00382, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1978, CreateTime = 1717076858959, serialized key size = -1, serialized value size = 109, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2bbfe45b)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219002732.0, "lon": 10.549643, "lat": 57.439323, "speed": 0.0, "course": 198.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219002732.0, "lon": 10.549643, "lat": 57.439323, "speed": 0.0, "course": 198.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1979, CreateTime = 1717076858959, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@7af14c12)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 304936000.0, "lon": 12.644992, "lat": 55.898815, "speed": 11.3, "course": 160.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 304936000.0, "lon": 12.644992, "lat": 55.898815, "speed": 11.3, "course": 160.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1980, CreateTime = 1717076858960, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@360bd8b0)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219000603.0, "lon": 8.439767, "lat": 55.460783, "speed": 0.0, "course": 148.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219000603.0, "lon": 8.439767, "lat": 55.460783, "speed": 0.0, "course": 148.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1981, CreateTime = 1717076858960, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@43ba246e)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 273356200.0, "lon": 10.302145, "lat": 57.780857, "speed": 8.6, "course": 263.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 273356200.0, "lon": 10.302145, "lat": 57.780857, "speed": 8.6, "course": 263.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1982, CreateTime = 1717076858960, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@17f38d7e)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 211410690.0, "lon": 11.492412, "lat": 57.167685, "speed": 9.5, "course": 150.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 211410690.0, "lon": 11.492412, "lat": 57.167685, "speed": 9.5, "course": 150.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1983, CreateTime = 1717076858960, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6712d24e)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 211215340.0, "lon": 11.637557, "lat": 54.386373, "speed": 10.4, "course": 130.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 211215340.0, "lon": 11.637557, "lat": 54.386373, "speed": 10.4, "course": 130.9}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1984, CreateTime = 1717076858960, serialized key size = -1, serialized value size = 117, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@fb45844)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219002682.0, "lon": 12.614577, "lat": 56.042897, "speed": 0.0, "course": 321.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219002682.0, "lon": 12.614577, "lat": 56.042897, "speed": 0.0, "course": 321.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1985, CreateTime = 1717076858960, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1dbf8488)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219000546.0, "lon": 9.423867, "lat": 55.040555, "speed": 0.0, "course": 310.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219000546.0, "lon": 9.423867, "lat": 55.040555, "speed": 0.0, "course": 310.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1986, CreateTime = 1717076858960, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@162c623c)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 211518140.0, "lon": 7.468565, "lat": 55.391348, "speed": 3.4, "course": 86.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 211518140.0, "lon": 7.468565, "lat": 55.391348, "speed": 3.4, "course": 86.6}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1987, CreateTime = 1717076858960, serialized key size = -1, serialized value size = 114, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@67dd4215)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219796000.0, "lon": 15.135625, "lat": 55.059093, "speed": 0.0, "course": 354.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219796000.0, "lon": 15.135625, "lat": 55.059093, "speed": 0.0, "course": 354.3}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1988, CreateTime = 1717076858960, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4a8640d2)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 277093000.0, "lon": 15.6155, "lat": 54.687, "speed": 16.7, "course": 79.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 277093000.0, "lon": 15.6155, "lat": 54.687, "speed": 16.7, "course": 79.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1989, CreateTime = 1717076858960, serialized key size = -1, serialized value size = 111, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2bfc16ce)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 2655135.0, "lon": 13.270358, "lat": 55.478318, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 2655135.0, "lon": 13.270358, "lat": 55.478318, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1990, CreateTime = 1717076858960, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@5eb4bc0f)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219005465.0, "lon": 10.67057, "lat": 54.751288, "speed": 0.0, "course": 325.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219005465.0, "lon": 10.67057, "lat": 54.751288, "speed": 0.0, "course": 325.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1991, CreateTime = 1717076858960, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@53f48026)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 2190077.0, "lon": 14.879098, "lat": 55.149078, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 2190077.0, "lon": 14.879098, "lat": 55.149078, "speed": NaN, "course": NaN}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1992, CreateTime = 1717076858960, serialized key size = -1, serialized value size = 112, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2b0cda5a)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219138000.0, "lon": 8.218667, "lat": 56.696533, "speed": 0.1, "course": 6.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219138000.0, "lon": 8.218667, "lat": 56.696533, "speed": 0.1, "course": 6.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1993, CreateTime = 1717076858960, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@600df393)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 636011573.0, "lon": 12.2175, "lat": 54.544917, "speed": 11.5, "course": 198.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 636011573.0, "lon": 12.2175, "lat": 54.544917, "speed": 11.5, "course": 198.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1994, CreateTime = 1717076858960, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@1b226f59)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 211824000.0, "lon": 10.985342, "lat": 54.373252, "speed": 0.1, "course": 354.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 211824000.0, "lon": 10.985342, "lat": 54.373252, "speed": 0.1, "course": 354.5}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1995, CreateTime = 1717076858960, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@6c2029ab)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 219009273.0, "lon": 8.598383, "lat": 57.122633, "speed": 0.8, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 219009273.0, "lon": 8.598383, "lat": 57.122633, "speed": 0.8, "course": 0.0}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1996, CreateTime = 1717076858961, serialized key size = -1, serialized value size = 113, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@21b3e07f)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 211226860.0, "lon": 7.384235, "lat": 55.259897, "speed": 15.6, "course": 248.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 211226860.0, "lon": 7.384235, "lat": 55.259897, "speed": 15.6, "course": 248.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1997, CreateTime = 1717076858961, serialized key size = -1, serialized value size = 116, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@2e2d0eb1)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:21", "mmsi": 266225000.0, "lon": 10.549645, "lat": 57.44112, "speed": 0.0, "course": 300.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:21", "mmsi": 266225000.0, "lon": 10.549645, "lat": 57.44112, "speed": 0.0, "course": 300.4}
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1998, CreateTime = 1717076858961, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@267de48a)
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,481 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Received message from Kafka: {"t": "01/03/2011 00:00:22", "mmsi": 218759000.0, "lon": 11.579485, "lat": 56.121068, "speed": 8.2, "course": 85.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,482 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] INFO  aisdata.Main  - Deserializing message: {"t": "01/03/2011 00:00:22", "mmsi": 218759000.0, "lon": 11.579485, "lat": 56.121068, "speed": 8.2, "course": 85.2}
2024-05-30 15:47:40 2024-05-30 13:47:40,482 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Emitted record: ConsumerRecord(topic = aisdata, partition = 0, leaderEpoch = 0, offset = 1999, CreateTime = 1717076858961, serialized key size = -1, serialized value size = 115, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = [B@4bfdec9f)
2024-05-30 15:47:40 2024-05-30 13:47:40,482 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: MORE_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,482 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Current fetch is finished.
2024-05-30 15:47:40 2024-05-30 13:47:40,482 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:47:40 2024-05-30 13:47:40,482 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: NOTHING_AVAILABLE
2024-05-30 15:47:40 2024-05-30 13:47:40,520 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=2563, hash=-124538828} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=2}
2024-05-30 15:47:40 2024-05-30 13:47:40,521 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=2138, hash=1598315584} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=1}
2024-05-30 15:47:40 2024-05-30 13:47:40,521 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=2563, hash=13152893} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=6}
2024-05-30 15:47:40 2024-05-30 13:47:40,521 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=2788, hash=-2003048823} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=0}
2024-05-30 15:47:40 2024-05-30 13:47:40,521 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=2238, hash=393128357} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=7}
2024-05-30 15:47:40 2024-05-30 13:47:40,521 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=3088, hash=-53890920} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,521 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (3/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_2_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=2563, hash=-124538828}, seq 3, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,521 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=2738, hash=2006633154} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=4}
2024-05-30 15:47:40 2024-05-30 13:47:40,522 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (8/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_7_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=2238, hash=393128357}, seq 3, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,522 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (1/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_0_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=2788, hash=-2003048823}, seq 3, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,522 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (5/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_4_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=2738, hash=2006633154}, seq 3, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,522 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (2/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_1_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=2138, hash=1598315584}, seq 3, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,523 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_e3dfc0d7e9ecd8a43f85f0b68ebf3b80_3_0)] PipelinedSubpartition#pollBuffer Buffer{cnt=3, size=2588, hash=1028706089} @ ResultSubpartitionInfo{partitionIdx=0, subPartitionIdx=5}
2024-05-30 15:47:40 2024-05-30 13:47:40,523 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (7/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_6_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=2563, hash=13152893}, seq 3, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,523 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (6/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_5_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=2588, hash=1028706089}, seq 3, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,524 [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0] TRACE org.apache.flink.runtime.io.network.logger.NetworkActionsLogger  - [TumblingEventTimeWindows -> Map -> Sink: Print to Std. Out (4/8)#0 (b8f610225c2c775ea87fe3766e0e537c_87aa6a78642c52c526689f50e970e2b8_3_0)] LocalInputChannel#getNextBuffer Buffer{cnt=3, size=3088, hash=-53890920}, seq 3, ChannelStatePersister(lastSeenBarrier=-1 (COMPLETED)} @ InputChannelInfo{gateIdx=0, inputChannelIdx=3}
2024-05-30 15:47:40 2024-05-30 13:47:40,883 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=5): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:40 2024-05-30 13:47:40,883 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:40 2024-05-30 13:47:40,883 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:40 2024-05-30 13:47:40,884 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=2) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:40 2024-05-30 13:47:40,884 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:40 2024-05-30 13:47:40,884 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9482
2024-05-30 15:47:40 2024-05-30 13:47:40,884 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=6) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=2, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:40 2024-05-30 13:47:40,884 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:40 2024-05-30 13:47:40,884 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9481
2024-05-30 15:47:41 2024-05-30 13:47:41,389 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=6): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:41 2024-05-30 13:47:41,390 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:41 2024-05-30 13:47:41,390 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:41 2024-05-30 13:47:41,390 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=3) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:41 2024-05-30 13:47:41,390 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:41 2024-05-30 13:47:41,391 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 8975
2024-05-30 15:47:41 2024-05-30 13:47:41,391 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=7) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=3, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:41 2024-05-30 13:47:41,391 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:41 2024-05-30 13:47:41,391 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 8974
2024-05-30 15:47:41 2024-05-30 13:47:41,898 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=7): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:41 2024-05-30 13:47:41,898 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:41 2024-05-30 13:47:41,900 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:41 2024-05-30 13:47:41,900 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=4) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:41 2024-05-30 13:47:41,900 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:41 2024-05-30 13:47:41,900 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 8467
2024-05-30 15:47:41 2024-05-30 13:47:41,900 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=8) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=4, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:41 2024-05-30 13:47:41,901 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:41 2024-05-30 13:47:41,901 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 8464
2024-05-30 15:47:42 2024-05-30 13:47:42,411 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=8): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:42 2024-05-30 13:47:42,412 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:42 2024-05-30 13:47:42,413 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:42 2024-05-30 13:47:42,413 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=5) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:42 2024-05-30 13:47:42,413 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:42 2024-05-30 13:47:42,414 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 7953
2024-05-30 15:47:42 2024-05-30 13:47:42,414 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=9) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=5, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:42 2024-05-30 13:47:42,415 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:42 2024-05-30 13:47:42,415 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 7951
2024-05-30 15:47:42 2024-05-30 13:47:42,922 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=9): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:42 2024-05-30 13:47:42,922 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:42 2024-05-30 13:47:42,922 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:42 2024-05-30 13:47:42,922 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=6) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:42 2024-05-30 13:47:42,922 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:42 2024-05-30 13:47:42,922 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 7443
2024-05-30 15:47:42 2024-05-30 13:47:42,922 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=10) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=6, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:42 2024-05-30 13:47:42,923 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:42 2024-05-30 13:47:42,923 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 7442
2024-05-30 15:47:43 2024-05-30 13:47:43,430 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=10): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:43 2024-05-30 13:47:43,430 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:43 2024-05-30 13:47:43,431 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:43 2024-05-30 13:47:43,431 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=7) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:43 2024-05-30 13:47:43,431 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:43 2024-05-30 13:47:43,431 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 6935
2024-05-30 15:47:43 2024-05-30 13:47:43,431 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=11) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=7, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:43 2024-05-30 13:47:43,431 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:43 2024-05-30 13:47:43,431 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 6934
2024-05-30 15:47:43 2024-05-30 13:47:43,934 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=11): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:43 2024-05-30 13:47:43,934 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:43 2024-05-30 13:47:43,934 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:43 2024-05-30 13:47:43,934 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=8) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:43 2024-05-30 13:47:43,934 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:43 2024-05-30 13:47:43,934 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 6431
2024-05-30 15:47:43 2024-05-30 13:47:43,934 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=12) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=8, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:43 2024-05-30 13:47:43,934 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:43 2024-05-30 13:47:43,934 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 6431
2024-05-30 15:47:44 2024-05-30 13:47:44,439 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=12): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:44 2024-05-30 13:47:44,439 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:44 2024-05-30 13:47:44,439 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:44 2024-05-30 13:47:44,439 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=9) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:44 2024-05-30 13:47:44,439 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:44 2024-05-30 13:47:44,439 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 5926
2024-05-30 15:47:44 2024-05-30 13:47:44,439 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=13) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=9, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:44 2024-05-30 13:47:44,440 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:44 2024-05-30 13:47:44,440 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 5925
2024-05-30 15:47:44 2024-05-30 13:47:44,944 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=13): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:44 2024-05-30 13:47:44,944 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:44 2024-05-30 13:47:44,945 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:44 2024-05-30 13:47:44,945 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=10) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:44 2024-05-30 13:47:44,945 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:44 2024-05-30 13:47:44,945 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 5421
2024-05-30 15:47:44 2024-05-30 13:47:44,945 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=14) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=10, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:44 2024-05-30 13:47:44,945 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:44 2024-05-30 13:47:44,945 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 5420
2024-05-30 15:47:45 2024-05-30 13:47:45,447 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=14): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:45 2024-05-30 13:47:45,447 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:45 2024-05-30 13:47:45,448 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:45 2024-05-30 13:47:45,448 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=11) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:45 2024-05-30 13:47:45,448 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:45 2024-05-30 13:47:45,448 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 4918
2024-05-30 15:47:45 2024-05-30 13:47:45,448 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=15) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=11, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:45 2024-05-30 13:47:45,448 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:45 2024-05-30 13:47:45,448 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 4917
2024-05-30 15:47:45 2024-05-30 13:47:45,950 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=15): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:45 2024-05-30 13:47:45,950 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:45 2024-05-30 13:47:45,950 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:45 2024-05-30 13:47:45,950 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=12) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:45 2024-05-30 13:47:45,950 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:45 2024-05-30 13:47:45,950 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 4415
2024-05-30 15:47:45 2024-05-30 13:47:45,950 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=16) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=12, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:45 2024-05-30 13:47:45,950 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:45 2024-05-30 13:47:45,950 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 4415
2024-05-30 15:47:46 2024-05-30 13:47:46,455 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=16): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:46 2024-05-30 13:47:46,455 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:46 2024-05-30 13:47:46,456 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:46 2024-05-30 13:47:46,456 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=13) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:46 2024-05-30 13:47:46,456 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:46 2024-05-30 13:47:46,456 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 3910
2024-05-30 15:47:46 2024-05-30 13:47:46,456 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=17) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=13, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:46 2024-05-30 13:47:46,457 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:46 2024-05-30 13:47:46,457 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 3908
2024-05-30 15:47:46 2024-05-30 13:47:46,962 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=17): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:46 2024-05-30 13:47:46,963 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:46 2024-05-30 13:47:46,963 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:46 2024-05-30 13:47:46,963 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=14) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:46 2024-05-30 13:47:46,963 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:46 2024-05-30 13:47:46,963 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 3403
2024-05-30 15:47:46 2024-05-30 13:47:46,963 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=18) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=14, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:46 2024-05-30 13:47:46,964 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:46 2024-05-30 13:47:46,964 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 3401
2024-05-30 15:47:47 2024-05-30 13:47:47,469 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=18): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:47 2024-05-30 13:47:47,470 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:47 2024-05-30 13:47:47,470 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:47 2024-05-30 13:47:47,470 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=15) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:47 2024-05-30 13:47:47,470 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:47 2024-05-30 13:47:47,470 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 2896
2024-05-30 15:47:47 2024-05-30 13:47:47,470 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=19) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=15, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:47 2024-05-30 13:47:47,471 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:47 2024-05-30 13:47:47,471 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 2895
2024-05-30 15:47:47 2024-05-30 13:47:47,973 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=19): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:47 2024-05-30 13:47:47,973 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:47 2024-05-30 13:47:47,974 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:47 2024-05-30 13:47:47,974 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=16) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:47 2024-05-30 13:47:47,974 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:47 2024-05-30 13:47:47,974 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 2392
2024-05-30 15:47:47 2024-05-30 13:47:47,974 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=20) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=16, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:47 2024-05-30 13:47:47,974 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:47 2024-05-30 13:47:47,974 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 2391
2024-05-30 15:47:48 2024-05-30 13:47:48,476 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=20): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:48 2024-05-30 13:47:48,476 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:48 2024-05-30 13:47:48,476 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:48 2024-05-30 13:47:48,476 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=17) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:48 2024-05-30 13:47:48,476 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:48 2024-05-30 13:47:48,476 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 1889
2024-05-30 15:47:48 2024-05-30 13:47:48,477 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=21) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=17, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:48 2024-05-30 13:47:48,477 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:48 2024-05-30 13:47:48,477 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 1888
2024-05-30 15:47:48 2024-05-30 13:47:48,980 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=21): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:48 2024-05-30 13:47:48,980 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:48 2024-05-30 13:47:48,981 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:48 2024-05-30 13:47:48,981 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=18) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:48 2024-05-30 13:47:48,981 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:48 2024-05-30 13:47:48,981 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 1385
2024-05-30 15:47:48 2024-05-30 13:47:48,981 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=22) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=18, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:48 2024-05-30 13:47:48,982 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:48 2024-05-30 13:47:48,982 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 1384
2024-05-30 15:47:49 2024-05-30 13:47:49,408 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Trigger heartbeat request.
2024-05-30 15:47:49 2024-05-30 13:47:49,408 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received heartbeat request from 7d46956d08c4d3e636e723818e0985fb.
2024-05-30 15:47:49 2024-05-30 13:47:49,409 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Trigger heartbeat request.
2024-05-30 15:47:49 2024-05-30 13:47:49,411 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Received heartbeat from ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff.
2024-05-30 15:47:49 2024-05-30 13:47:49,411 [flink-akka.actor.default-dispatcher-12] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Received heartbeat request from 7d46956d08c4d3e636e723818e0985fb.
2024-05-30 15:47:49 2024-05-30 13:47:49,412 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Received slot report from instance 7f90e2a01ddd0421ecb568d96eaba705: SlotReport{
2024-05-30 15:47:49     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_0, allocationID=8d65a0633b594e1023055f8eb5d4271d, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:47:49     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_1, allocationID=1682416b57c3204f1e47034ed712058a, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:47:49     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_2, allocationID=b8b5242c6762175095a12034622f0abe, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:47:49     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_3, allocationID=6a1740c95dc7f606c4106bac93511e32, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:47:49     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_4, allocationID=00eeda8d0616dc2caf6cec5a00ec1267, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:47:49     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_5, allocationID=77ba640e4dccc1995b4af4cd8b888262, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:47:49     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_6, allocationID=6ec3018dfd7ad2d8dcaa869612169256, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:47:49     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_7, allocationID=0a6a4da3bdbd82f89f0b6179ebdf87a3, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}}.
2024-05-30 15:47:49 2024-05-30 13:47:49,412 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.io.network.partition.ResourceManagerPartitionTrackerImpl  - Processing cluster partition report from task executor ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff: PartitionReport{entries=[]}.
2024-05-30 15:47:49 2024-05-30 13:47:49,414 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Received heartbeat from 85185983243c48e6bbb6f78065441b1e.
2024-05-30 15:47:49 2024-05-30 13:47:49,485 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=22): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:49 2024-05-30 13:47:49,486 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:49 2024-05-30 13:47:49,486 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:49 2024-05-30 13:47:49,486 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=19) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:49 2024-05-30 13:47:49,486 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:49 2024-05-30 13:47:49,486 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 879
2024-05-30 15:47:49 2024-05-30 13:47:49,486 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=23) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=19, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:49 2024-05-30 13:47:49,487 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:49 2024-05-30 13:47:49,487 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 878
2024-05-30 15:47:49 2024-05-30 13:47:49,553 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Trigger heartbeat request.
2024-05-30 15:47:49 2024-05-30 13:47:49,554 [flink-akka.actor.default-dispatcher-12] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received heartbeat request from 85185983243c48e6bbb6f78065441b1e.
2024-05-30 15:47:49 2024-05-30 13:47:49,563 [flink-akka.actor.default-dispatcher-9] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Received heartbeat from ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff.
2024-05-30 15:47:49 2024-05-30 13:47:49,992 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=23): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:49 2024-05-30 13:47:49,993 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:49 2024-05-30 13:47:49,993 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:49 2024-05-30 13:47:49,993 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=20) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:49 2024-05-30 13:47:49,993 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:49 2024-05-30 13:47:49,993 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 373
2024-05-30 15:47:49 2024-05-30 13:47:49,993 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=24) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=20, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:49 2024-05-30 13:47:49,993 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:49 2024-05-30 13:47:49,993 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 372
2024-05-30 15:47:50 2024-05-30 13:47:50,369 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Finished running task FetchTask
2024-05-30 15:47:50 2024-05-30 13:47:50,369 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:47:50 2024-05-30 13:47:50,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Current fetch is finished.
2024-05-30 15:47:50 2024-05-30 13:47:50,370 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: NOTHING_AVAILABLE
2024-05-30 15:47:50 2024-05-30 13:47:50,369 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Cleaned wakeup flag.
2024-05-30 15:47:50 2024-05-30 13:47:50,370 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Prepare to run FetchTask
2024-05-30 15:47:50 2024-05-30 13:47:50,371 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:50 2024-05-30 13:47:50,371 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 10000
2024-05-30 15:47:50 2024-05-30 13:47:50,497 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=24): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:50 2024-05-30 13:47:50,497 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:50 2024-05-30 13:47:50,497 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:50 2024-05-30 13:47:50,497 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=21) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:50 2024-05-30 13:47:50,497 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:50 2024-05-30 13:47:50,497 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9873
2024-05-30 15:47:50 2024-05-30 13:47:50,498 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=25) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=21, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:50 2024-05-30 13:47:50,498 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:50 2024-05-30 13:47:50,498 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9872
2024-05-30 15:47:51 2024-05-30 13:47:51,001 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=25): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:51 2024-05-30 13:47:51,001 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:51 2024-05-30 13:47:51,001 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:51 2024-05-30 13:47:51,001 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=22) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:51 2024-05-30 13:47:51,001 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:51 2024-05-30 13:47:51,001 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9369
2024-05-30 15:47:51 2024-05-30 13:47:51,001 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=26) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=22, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:51 2024-05-30 13:47:51,002 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:51 2024-05-30 13:47:51,002 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9368
2024-05-30 15:47:51 2024-05-30 13:47:51,510 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=26): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:51 2024-05-30 13:47:51,510 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:51 2024-05-30 13:47:51,510 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:51 2024-05-30 13:47:51,510 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=23) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:51 2024-05-30 13:47:51,510 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:51 2024-05-30 13:47:51,510 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 8860
2024-05-30 15:47:51 2024-05-30 13:47:51,510 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=27) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=23, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:51 2024-05-30 13:47:51,511 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:51 2024-05-30 13:47:51,511 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 8859
2024-05-30 15:47:52 2024-05-30 13:47:52,016 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=27): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:52 2024-05-30 13:47:52,016 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:52 2024-05-30 13:47:52,016 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:52 2024-05-30 13:47:52,016 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=24) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:52 2024-05-30 13:47:52,016 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:52 2024-05-30 13:47:52,016 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 8354
2024-05-30 15:47:52 2024-05-30 13:47:52,017 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=28) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=24, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:52 2024-05-30 13:47:52,017 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:52 2024-05-30 13:47:52,017 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 8353
2024-05-30 15:47:52 2024-05-30 13:47:52,520 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=28): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:52 2024-05-30 13:47:52,521 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:52 2024-05-30 13:47:52,521 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:52 2024-05-30 13:47:52,521 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=25) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:52 2024-05-30 13:47:52,521 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:52 2024-05-30 13:47:52,521 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 7849
2024-05-30 15:47:52 2024-05-30 13:47:52,521 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=29) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=25, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:52 2024-05-30 13:47:52,521 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:52 2024-05-30 13:47:52,521 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 7849
2024-05-30 15:47:53 2024-05-30 13:47:53,025 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=29): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:53 2024-05-30 13:47:53,025 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:53 2024-05-30 13:47:53,026 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:53 2024-05-30 13:47:53,026 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=26) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:53 2024-05-30 13:47:53,026 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:53 2024-05-30 13:47:53,026 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 7345
2024-05-30 15:47:53 2024-05-30 13:47:53,026 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=30) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=26, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:53 2024-05-30 13:47:53,026 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:53 2024-05-30 13:47:53,026 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 7344
2024-05-30 15:47:53 2024-05-30 13:47:53,530 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=30): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:53 2024-05-30 13:47:53,531 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:53 2024-05-30 13:47:53,531 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:53 2024-05-30 13:47:53,531 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=27) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:53 2024-05-30 13:47:53,531 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:53 2024-05-30 13:47:53,531 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 6839
2024-05-30 15:47:53 2024-05-30 13:47:53,531 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=31) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=27, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:53 2024-05-30 13:47:53,532 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:53 2024-05-30 13:47:53,532 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 6838
2024-05-30 15:47:54 2024-05-30 13:47:54,037 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=31): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:54 2024-05-30 13:47:54,038 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:54 2024-05-30 13:47:54,038 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:54 2024-05-30 13:47:54,038 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=28) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:54 2024-05-30 13:47:54,038 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:54 2024-05-30 13:47:54,038 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 6332
2024-05-30 15:47:54 2024-05-30 13:47:54,038 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=32) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=28, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:54 2024-05-30 13:47:54,038 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:54 2024-05-30 13:47:54,038 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 6332
2024-05-30 15:47:54 2024-05-30 13:47:54,541 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=32): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:54 2024-05-30 13:47:54,542 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:54 2024-05-30 13:47:54,542 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:54 2024-05-30 13:47:54,542 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=29) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:54 2024-05-30 13:47:54,542 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:54 2024-05-30 13:47:54,542 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 5828
2024-05-30 15:47:54 2024-05-30 13:47:54,542 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=33) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=29, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:54 2024-05-30 13:47:54,543 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:54 2024-05-30 13:47:54,543 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 5827
2024-05-30 15:47:55 2024-05-30 13:47:55,047 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=33): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:55 2024-05-30 13:47:55,047 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:55 2024-05-30 13:47:55,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:55 2024-05-30 13:47:55,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=30) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:55 2024-05-30 13:47:55,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:55 2024-05-30 13:47:55,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 5323
2024-05-30 15:47:55 2024-05-30 13:47:55,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=34) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=30, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:55 2024-05-30 13:47:55,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:55 2024-05-30 13:47:55,048 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 5322
2024-05-30 15:47:55 2024-05-30 13:47:55,553 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=34): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:55 2024-05-30 13:47:55,553 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:55 2024-05-30 13:47:55,554 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:55 2024-05-30 13:47:55,554 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=31) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:55 2024-05-30 13:47:55,554 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:55 2024-05-30 13:47:55,554 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 4817
2024-05-30 15:47:55 2024-05-30 13:47:55,554 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=35) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=31, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:55 2024-05-30 13:47:55,554 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:55 2024-05-30 13:47:55,554 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 4816
2024-05-30 15:47:56 2024-05-30 13:47:56,061 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=35): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:56 2024-05-30 13:47:56,061 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:56 2024-05-30 13:47:56,062 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:56 2024-05-30 13:47:56,062 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=32) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:56 2024-05-30 13:47:56,062 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:56 2024-05-30 13:47:56,062 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 4309
2024-05-30 15:47:56 2024-05-30 13:47:56,062 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=36) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=32, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:56 2024-05-30 13:47:56,062 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:56 2024-05-30 13:47:56,062 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 4308
2024-05-30 15:47:56 2024-05-30 13:47:56,566 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=36): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:56 2024-05-30 13:47:56,566 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:56 2024-05-30 13:47:56,566 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:56 2024-05-30 13:47:56,566 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=33) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:56 2024-05-30 13:47:56,566 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:56 2024-05-30 13:47:56,566 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 3804
2024-05-30 15:47:56 2024-05-30 13:47:56,567 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=37) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=33, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:56 2024-05-30 13:47:56,567 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:56 2024-05-30 13:47:56,567 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 3803
2024-05-30 15:47:57 2024-05-30 13:47:57,071 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=37): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:57 2024-05-30 13:47:57,071 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:57 2024-05-30 13:47:57,072 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:57 2024-05-30 13:47:57,072 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=34) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:57 2024-05-30 13:47:57,072 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:57 2024-05-30 13:47:57,072 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 3299
2024-05-30 15:47:57 2024-05-30 13:47:57,072 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=38) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=34, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:57 2024-05-30 13:47:57,073 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:57 2024-05-30 13:47:57,073 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 3297
2024-05-30 15:47:57 2024-05-30 13:47:57,580 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=38): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:57 2024-05-30 13:47:57,580 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:57 2024-05-30 13:47:57,580 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:57 2024-05-30 13:47:57,580 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=35) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:57 2024-05-30 13:47:57,580 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:57 2024-05-30 13:47:57,580 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 2790
2024-05-30 15:47:57 2024-05-30 13:47:57,580 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=39) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=35, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:57 2024-05-30 13:47:57,581 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:57 2024-05-30 13:47:57,581 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 2790
2024-05-30 15:47:58 2024-05-30 13:47:58,087 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=39): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:58 2024-05-30 13:47:58,087 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:58 2024-05-30 13:47:58,087 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:58 2024-05-30 13:47:58,088 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=36) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:58 2024-05-30 13:47:58,088 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:58 2024-05-30 13:47:58,088 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 2283
2024-05-30 15:47:58 2024-05-30 13:47:58,088 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=40) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=36, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:58 2024-05-30 13:47:58,088 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:58 2024-05-30 13:47:58,088 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 2282
2024-05-30 15:47:58 2024-05-30 13:47:58,595 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=40): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:58 2024-05-30 13:47:58,596 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:58 2024-05-30 13:47:58,596 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:58 2024-05-30 13:47:58,596 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=37) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:58 2024-05-30 13:47:58,596 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:58 2024-05-30 13:47:58,596 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 1774
2024-05-30 15:47:58 2024-05-30 13:47:58,596 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=41) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=37, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:58 2024-05-30 13:47:58,597 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:58 2024-05-30 13:47:58,597 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 1773
2024-05-30 15:47:59 2024-05-30 13:47:59,103 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=41): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:59 2024-05-30 13:47:59,103 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:59 2024-05-30 13:47:59,103 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:59 2024-05-30 13:47:59,103 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=38) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:59 2024-05-30 13:47:59,103 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:59 2024-05-30 13:47:59,103 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 1267
2024-05-30 15:47:59 2024-05-30 13:47:59,103 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=42) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=38, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:59 2024-05-30 13:47:59,103 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:59 2024-05-30 13:47:59,103 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 1267
2024-05-30 15:47:59 2024-05-30 13:47:59,410 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Trigger heartbeat request.
2024-05-30 15:47:59 2024-05-30 13:47:59,411 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received heartbeat request from 7d46956d08c4d3e636e723818e0985fb.
2024-05-30 15:47:59 2024-05-30 13:47:59,412 [flink-akka.actor.default-dispatcher-13] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Received heartbeat from ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff.
2024-05-30 15:47:59 2024-05-30 13:47:59,415 [flink-akka.actor.default-dispatcher-13] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Received slot report from instance 7f90e2a01ddd0421ecb568d96eaba705: SlotReport{
2024-05-30 15:47:59     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_0, allocationID=8d65a0633b594e1023055f8eb5d4271d, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:47:59     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_1, allocationID=1682416b57c3204f1e47034ed712058a, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:47:59     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_2, allocationID=b8b5242c6762175095a12034622f0abe, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:47:59     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_3, allocationID=6a1740c95dc7f606c4106bac93511e32, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:47:59     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_4, allocationID=00eeda8d0616dc2caf6cec5a00ec1267, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:47:59     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_5, allocationID=77ba640e4dccc1995b4af4cd8b888262, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:47:59     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_6, allocationID=6ec3018dfd7ad2d8dcaa869612169256, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:47:59     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_7, allocationID=0a6a4da3bdbd82f89f0b6179ebdf87a3, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}}.
2024-05-30 15:47:59 2024-05-30 13:47:59,415 [flink-akka.actor.default-dispatcher-13] DEBUG org.apache.flink.runtime.io.network.partition.ResourceManagerPartitionTrackerImpl  - Processing cluster partition report from task executor ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff: PartitionReport{entries=[]}.
2024-05-30 15:47:59 2024-05-30 13:47:59,416 [flink-akka.actor.default-dispatcher-13] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Trigger heartbeat request.
2024-05-30 15:47:59 2024-05-30 13:47:59,416 [flink-akka.actor.default-dispatcher-13] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Received heartbeat request from 7d46956d08c4d3e636e723818e0985fb.
2024-05-30 15:47:59 2024-05-30 13:47:59,416 [flink-akka.actor.default-dispatcher-15] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Received heartbeat from 85185983243c48e6bbb6f78065441b1e.
2024-05-30 15:47:59 2024-05-30 13:47:59,555 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Trigger heartbeat request.
2024-05-30 15:47:59 2024-05-30 13:47:59,555 [flink-akka.actor.default-dispatcher-15] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received heartbeat request from 85185983243c48e6bbb6f78065441b1e.
2024-05-30 15:47:59 2024-05-30 13:47:59,559 [flink-akka.actor.default-dispatcher-7] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Received heartbeat from ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff.
2024-05-30 15:47:59 2024-05-30 13:47:59,607 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=42): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:47:59 2024-05-30 13:47:59,607 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:47:59 2024-05-30 13:47:59,607 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:59 2024-05-30 13:47:59,607 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=39) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:47:59 2024-05-30 13:47:59,607 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:47:59 2024-05-30 13:47:59,607 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 763
2024-05-30 15:47:59 2024-05-30 13:47:59,607 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=43) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=39, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:47:59 2024-05-30 13:47:59,608 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:47:59 2024-05-30 13:47:59,608 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 762
2024-05-30 15:48:00 2024-05-30 13:48:00,109 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=43): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:00 2024-05-30 13:48:00,109 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:00 2024-05-30 13:48:00,109 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:00 2024-05-30 13:48:00,109 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=40) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:00 2024-05-30 13:48:00,109 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:00 2024-05-30 13:48:00,109 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 261
2024-05-30 15:48:00 2024-05-30 13:48:00,109 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=44) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=40, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:00 2024-05-30 13:48:00,110 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:00 2024-05-30 13:48:00,110 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 260
2024-05-30 15:48:00 2024-05-30 13:48:00,371 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Finished running task FetchTask
2024-05-30 15:48:00 2024-05-30 13:48:00,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:48:00 2024-05-30 13:48:00,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Current fetch is finished.
2024-05-30 15:48:00 2024-05-30 13:48:00,371 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Cleaned wakeup flag.
2024-05-30 15:48:00 2024-05-30 13:48:00,371 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Prepare to run FetchTask
2024-05-30 15:48:00 2024-05-30 13:48:00,371 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: NOTHING_AVAILABLE
2024-05-30 15:48:00 2024-05-30 13:48:00,371 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:00 2024-05-30 13:48:00,371 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 10000
2024-05-30 15:48:00 2024-05-30 13:48:00,616 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=44): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:00 2024-05-30 13:48:00,616 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:00 2024-05-30 13:48:00,617 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:00 2024-05-30 13:48:00,617 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=41) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:00 2024-05-30 13:48:00,617 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:00 2024-05-30 13:48:00,617 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9755
2024-05-30 15:48:00 2024-05-30 13:48:00,617 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=45) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=41, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:00 2024-05-30 13:48:00,618 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:00 2024-05-30 13:48:00,618 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9753
2024-05-30 15:48:01 2024-05-30 13:48:01,119 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=45): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:01 2024-05-30 13:48:01,119 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:01 2024-05-30 13:48:01,119 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:01 2024-05-30 13:48:01,120 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=42) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:01 2024-05-30 13:48:01,120 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:01 2024-05-30 13:48:01,120 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9252
2024-05-30 15:48:01 2024-05-30 13:48:01,120 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=46) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=42, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:01 2024-05-30 13:48:01,120 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:01 2024-05-30 13:48:01,120 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9251
2024-05-30 15:48:01 2024-05-30 13:48:01,623 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=46): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:01 2024-05-30 13:48:01,624 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:01 2024-05-30 13:48:01,625 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:01 2024-05-30 13:48:01,625 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=43) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:01 2024-05-30 13:48:01,625 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:01 2024-05-30 13:48:01,625 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 8748
2024-05-30 15:48:01 2024-05-30 13:48:01,625 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=47) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=43, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:01 2024-05-30 13:48:01,626 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:01 2024-05-30 13:48:01,626 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 8745
2024-05-30 15:48:02 2024-05-30 13:48:02,129 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=47): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:02 2024-05-30 13:48:02,130 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:02 2024-05-30 13:48:02,130 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:02 2024-05-30 13:48:02,130 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=44) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:02 2024-05-30 13:48:02,130 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:02 2024-05-30 13:48:02,130 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 8241
2024-05-30 15:48:02 2024-05-30 13:48:02,130 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=48) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=44, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:02 2024-05-30 13:48:02,131 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:02 2024-05-30 13:48:02,131 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 8240
2024-05-30 15:48:02 2024-05-30 13:48:02,637 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=48): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:02 2024-05-30 13:48:02,637 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:02 2024-05-30 13:48:02,637 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:02 2024-05-30 13:48:02,637 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=45) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:02 2024-05-30 13:48:02,637 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:02 2024-05-30 13:48:02,638 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 7734
2024-05-30 15:48:02 2024-05-30 13:48:02,638 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=49) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=45, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:02 2024-05-30 13:48:02,638 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:02 2024-05-30 13:48:02,638 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 7733
2024-05-30 15:48:03 2024-05-30 13:48:03,144 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=49): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:03 2024-05-30 13:48:03,144 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:03 2024-05-30 13:48:03,145 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:03 2024-05-30 13:48:03,145 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=46) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:03 2024-05-30 13:48:03,145 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:03 2024-05-30 13:48:03,145 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 7227
2024-05-30 15:48:03 2024-05-30 13:48:03,145 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=50) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=46, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:03 2024-05-30 13:48:03,146 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:03 2024-05-30 13:48:03,146 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 7226
2024-05-30 15:48:03 2024-05-30 13:48:03,654 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=50): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:03 2024-05-30 13:48:03,655 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:03 2024-05-30 13:48:03,655 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:03 2024-05-30 13:48:03,655 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=47) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:03 2024-05-30 13:48:03,655 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:03 2024-05-30 13:48:03,655 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 6717
2024-05-30 15:48:03 2024-05-30 13:48:03,655 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=51) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=47, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:03 2024-05-30 13:48:03,656 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:03 2024-05-30 13:48:03,656 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 6715
2024-05-30 15:48:04 2024-05-30 13:48:04,162 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=51): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:04 2024-05-30 13:48:04,162 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:04 2024-05-30 13:48:04,162 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:04 2024-05-30 13:48:04,162 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=48) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:04 2024-05-30 13:48:04,162 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:04 2024-05-30 13:48:04,162 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 6209
2024-05-30 15:48:04 2024-05-30 13:48:04,162 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=52) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=48, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:04 2024-05-30 13:48:04,163 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:04 2024-05-30 13:48:04,163 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 6208
2024-05-30 15:48:04 2024-05-30 13:48:04,668 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=52): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:04 2024-05-30 13:48:04,668 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:04 2024-05-30 13:48:04,669 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:04 2024-05-30 13:48:04,669 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=49) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:04 2024-05-30 13:48:04,669 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:04 2024-05-30 13:48:04,669 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 5703
2024-05-30 15:48:04 2024-05-30 13:48:04,669 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=53) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=49, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:04 2024-05-30 13:48:04,669 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:04 2024-05-30 13:48:04,669 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 5702
2024-05-30 15:48:05 2024-05-30 13:48:05,175 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=53): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:05 2024-05-30 13:48:05,175 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:05 2024-05-30 13:48:05,175 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:05 2024-05-30 13:48:05,175 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=50) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:05 2024-05-30 13:48:05,175 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:05 2024-05-30 13:48:05,175 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 5196
2024-05-30 15:48:05 2024-05-30 13:48:05,176 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=54) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=50, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:05 2024-05-30 13:48:05,176 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:05 2024-05-30 13:48:05,176 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 5195
2024-05-30 15:48:05 2024-05-30 13:48:05,680 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=54): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:05 2024-05-30 13:48:05,680 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:05 2024-05-30 13:48:05,680 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:05 2024-05-30 13:48:05,680 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=51) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:05 2024-05-30 13:48:05,681 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:05 2024-05-30 13:48:05,681 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 4691
2024-05-30 15:48:05 2024-05-30 13:48:05,681 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=55) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=51, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:05 2024-05-30 13:48:05,681 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:05 2024-05-30 13:48:05,681 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 4690
2024-05-30 15:48:06 2024-05-30 13:48:06,186 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=55): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:06 2024-05-30 13:48:06,186 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:06 2024-05-30 13:48:06,187 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:06 2024-05-30 13:48:06,187 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=52) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:06 2024-05-30 13:48:06,187 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:06 2024-05-30 13:48:06,187 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 4185
2024-05-30 15:48:06 2024-05-30 13:48:06,187 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=56) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=52, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:06 2024-05-30 13:48:06,187 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:06 2024-05-30 13:48:06,187 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 4184
2024-05-30 15:48:06 2024-05-30 13:48:06,694 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=56): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:06 2024-05-30 13:48:06,694 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:06 2024-05-30 13:48:06,694 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:06 2024-05-30 13:48:06,694 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=53) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:06 2024-05-30 13:48:06,694 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:06 2024-05-30 13:48:06,695 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 3677
2024-05-30 15:48:06 2024-05-30 13:48:06,695 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=57) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=53, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:06 2024-05-30 13:48:06,695 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:06 2024-05-30 13:48:06,695 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 3676
2024-05-30 15:48:07 2024-05-30 13:48:07,198 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=57): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:07 2024-05-30 13:48:07,198 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:07 2024-05-30 13:48:07,199 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:07 2024-05-30 13:48:07,199 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=54) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:07 2024-05-30 13:48:07,199 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:07 2024-05-30 13:48:07,199 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 3173
2024-05-30 15:48:07 2024-05-30 13:48:07,199 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=58) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=54, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:07 2024-05-30 13:48:07,199 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:07 2024-05-30 13:48:07,199 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 3172
2024-05-30 15:48:07 2024-05-30 13:48:07,704 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=58): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:07 2024-05-30 13:48:07,704 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:07 2024-05-30 13:48:07,705 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:07 2024-05-30 13:48:07,705 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=55) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:07 2024-05-30 13:48:07,705 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:07 2024-05-30 13:48:07,705 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 2667
2024-05-30 15:48:07 2024-05-30 13:48:07,705 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=59) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=55, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:07 2024-05-30 13:48:07,705 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:07 2024-05-30 13:48:07,705 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 2666
2024-05-30 15:48:08 2024-05-30 13:48:08,212 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=59): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:08 2024-05-30 13:48:08,212 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:08 2024-05-30 13:48:08,213 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:08 2024-05-30 13:48:08,213 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=56) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:08 2024-05-30 13:48:08,213 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:08 2024-05-30 13:48:08,213 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 2159
2024-05-30 15:48:08 2024-05-30 13:48:08,213 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=60) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=56, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:08 2024-05-30 13:48:08,214 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:08 2024-05-30 13:48:08,214 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 2158
2024-05-30 15:48:08 2024-05-30 13:48:08,719 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=60): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:08 2024-05-30 13:48:08,719 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:08 2024-05-30 13:48:08,720 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:08 2024-05-30 13:48:08,720 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=57) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:08 2024-05-30 13:48:08,720 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:08 2024-05-30 13:48:08,720 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 1652
2024-05-30 15:48:08 2024-05-30 13:48:08,720 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=61) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=57, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:08 2024-05-30 13:48:08,720 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:08 2024-05-30 13:48:08,720 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 1651
2024-05-30 15:48:09 2024-05-30 13:48:09,226 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=61): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:09 2024-05-30 13:48:09,226 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:09 2024-05-30 13:48:09,226 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:09 2024-05-30 13:48:09,227 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=58) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:09 2024-05-30 13:48:09,227 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:09 2024-05-30 13:48:09,227 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 1145
2024-05-30 15:48:09 2024-05-30 13:48:09,227 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=62) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=58, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:09 2024-05-30 13:48:09,227 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:09 2024-05-30 13:48:09,227 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 1144
2024-05-30 15:48:09 2024-05-30 13:48:09,413 [flink-akka.actor.default-dispatcher-13] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Trigger heartbeat request.
2024-05-30 15:48:09 2024-05-30 13:48:09,415 [flink-akka.actor.default-dispatcher-13] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received heartbeat request from 7d46956d08c4d3e636e723818e0985fb.
2024-05-30 15:48:09 2024-05-30 13:48:09,416 [flink-akka.actor.default-dispatcher-14] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Received heartbeat from ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff.
2024-05-30 15:48:09 2024-05-30 13:48:09,417 [flink-akka.actor.default-dispatcher-14] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Received slot report from instance 7f90e2a01ddd0421ecb568d96eaba705: SlotReport{
2024-05-30 15:48:09     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_0, allocationID=8d65a0633b594e1023055f8eb5d4271d, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:48:09     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_1, allocationID=1682416b57c3204f1e47034ed712058a, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:48:09     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_2, allocationID=b8b5242c6762175095a12034622f0abe, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:48:09     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_3, allocationID=6a1740c95dc7f606c4106bac93511e32, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:48:09     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_4, allocationID=00eeda8d0616dc2caf6cec5a00ec1267, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:48:09     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_5, allocationID=77ba640e4dccc1995b4af4cd8b888262, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:48:09     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_6, allocationID=6ec3018dfd7ad2d8dcaa869612169256, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:48:09     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_7, allocationID=0a6a4da3bdbd82f89f0b6179ebdf87a3, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}}.
2024-05-30 15:48:09 2024-05-30 13:48:09,417 [flink-akka.actor.default-dispatcher-14] DEBUG org.apache.flink.runtime.io.network.partition.ResourceManagerPartitionTrackerImpl  - Processing cluster partition report from task executor ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff: PartitionReport{entries=[]}.
2024-05-30 15:48:09 2024-05-30 13:48:09,418 [flink-akka.actor.default-dispatcher-14] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Trigger heartbeat request.
2024-05-30 15:48:09 2024-05-30 13:48:09,418 [flink-akka.actor.default-dispatcher-14] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Received heartbeat request from 7d46956d08c4d3e636e723818e0985fb.
2024-05-30 15:48:09 2024-05-30 13:48:09,418 [flink-akka.actor.default-dispatcher-13] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Received heartbeat from 85185983243c48e6bbb6f78065441b1e.
2024-05-30 15:48:09 2024-05-30 13:48:09,557 [flink-akka.actor.default-dispatcher-17] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Trigger heartbeat request.
2024-05-30 15:48:09 2024-05-30 13:48:09,560 [flink-akka.actor.default-dispatcher-17] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received heartbeat request from 85185983243c48e6bbb6f78065441b1e.
2024-05-30 15:48:09 2024-05-30 13:48:09,561 [flink-akka.actor.default-dispatcher-14] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Received heartbeat from ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff.
2024-05-30 15:48:09 2024-05-30 13:48:09,733 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=62): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:09 2024-05-30 13:48:09,734 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:09 2024-05-30 13:48:09,734 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:09 2024-05-30 13:48:09,734 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=59) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:09 2024-05-30 13:48:09,734 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:09 2024-05-30 13:48:09,734 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 638
2024-05-30 15:48:09 2024-05-30 13:48:09,734 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=63) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=59, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:09 2024-05-30 13:48:09,735 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:09 2024-05-30 13:48:09,735 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 636
2024-05-30 15:48:10 2024-05-30 13:48:10,240 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=63): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:10 2024-05-30 13:48:10,240 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:10 2024-05-30 13:48:10,240 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:10 2024-05-30 13:48:10,240 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=60) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:10 2024-05-30 13:48:10,240 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:10 2024-05-30 13:48:10,240 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 131
2024-05-30 15:48:10 2024-05-30 13:48:10,241 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=64) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=60, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:10 2024-05-30 13:48:10,241 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:10 2024-05-30 13:48:10,241 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 130
2024-05-30 15:48:10 2024-05-30 13:48:10,372 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Finished running task FetchTask
2024-05-30 15:48:10 2024-05-30 13:48:10,372 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Cleaned wakeup flag.
2024-05-30 15:48:10 2024-05-30 13:48:10,372 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Prepare to run FetchTask
2024-05-30 15:48:10 2024-05-30 13:48:10,372 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:48:10 2024-05-30 13:48:10,374 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Current fetch is finished.
2024-05-30 15:48:10 2024-05-30 13:48:10,375 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: NOTHING_AVAILABLE
2024-05-30 15:48:10 2024-05-30 13:48:10,372 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:10 2024-05-30 13:48:10,375 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 10000
2024-05-30 15:48:10 2024-05-30 13:48:10,743 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=64): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:10 2024-05-30 13:48:10,743 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:10 2024-05-30 13:48:10,743 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:10 2024-05-30 13:48:10,743 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=61) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:10 2024-05-30 13:48:10,743 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:10 2024-05-30 13:48:10,743 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9629
2024-05-30 15:48:10 2024-05-30 13:48:10,743 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=65) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=61, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:10 2024-05-30 13:48:10,743 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:10 2024-05-30 13:48:10,743 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9629
2024-05-30 15:48:11 2024-05-30 13:48:11,246 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=65): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:11 2024-05-30 13:48:11,246 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:11 2024-05-30 13:48:11,246 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:11 2024-05-30 13:48:11,246 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=62) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:11 2024-05-30 13:48:11,246 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:11 2024-05-30 13:48:11,246 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9126
2024-05-30 15:48:11 2024-05-30 13:48:11,246 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=66) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=62, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:11 2024-05-30 13:48:11,247 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:11 2024-05-30 13:48:11,247 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9125
2024-05-30 15:48:11 2024-05-30 13:48:11,750 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=66): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:11 2024-05-30 13:48:11,750 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:11 2024-05-30 13:48:11,751 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:11 2024-05-30 13:48:11,751 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=63) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:11 2024-05-30 13:48:11,751 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:11 2024-05-30 13:48:11,751 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 8622
2024-05-30 15:48:11 2024-05-30 13:48:11,752 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=67) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=63, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:11 2024-05-30 13:48:11,752 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:11 2024-05-30 13:48:11,752 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 8620
2024-05-30 15:48:12 2024-05-30 13:48:12,258 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=67): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:12 2024-05-30 13:48:12,258 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:12 2024-05-30 13:48:12,259 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:12 2024-05-30 13:48:12,259 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=64) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:12 2024-05-30 13:48:12,259 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:12 2024-05-30 13:48:12,259 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 8114
2024-05-30 15:48:12 2024-05-30 13:48:12,259 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=68) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=64, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:12 2024-05-30 13:48:12,260 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:12 2024-05-30 13:48:12,260 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 8113
2024-05-30 15:48:12 2024-05-30 13:48:12,765 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=68): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:12 2024-05-30 13:48:12,765 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:12 2024-05-30 13:48:12,765 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:12 2024-05-30 13:48:12,765 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=65) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:12 2024-05-30 13:48:12,765 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:12 2024-05-30 13:48:12,765 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 7607
2024-05-30 15:48:12 2024-05-30 13:48:12,766 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=69) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=65, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:12 2024-05-30 13:48:12,766 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:12 2024-05-30 13:48:12,766 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 7606
2024-05-30 15:48:13 2024-05-30 13:48:13,271 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=69): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:13 2024-05-30 13:48:13,271 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:13 2024-05-30 13:48:13,272 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:13 2024-05-30 13:48:13,272 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=66) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:13 2024-05-30 13:48:13,272 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:13 2024-05-30 13:48:13,272 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 7101
2024-05-30 15:48:13 2024-05-30 13:48:13,272 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=70) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=66, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:13 2024-05-30 13:48:13,273 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:13 2024-05-30 13:48:13,273 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 7100
2024-05-30 15:48:13 2024-05-30 13:48:13,775 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=70): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:13 2024-05-30 13:48:13,776 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:13 2024-05-30 13:48:13,776 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:13 2024-05-30 13:48:13,776 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=67) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:13 2024-05-30 13:48:13,776 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:13 2024-05-30 13:48:13,776 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 6597
2024-05-30 15:48:13 2024-05-30 13:48:13,776 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=71) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=67, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:13 2024-05-30 13:48:13,777 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:13 2024-05-30 13:48:13,777 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 6596
2024-05-30 15:48:14 2024-05-30 13:48:14,282 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=71): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:14 2024-05-30 13:48:14,282 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:14 2024-05-30 13:48:14,283 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:14 2024-05-30 13:48:14,283 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=68) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:14 2024-05-30 13:48:14,283 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:14 2024-05-30 13:48:14,283 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 6090
2024-05-30 15:48:14 2024-05-30 13:48:14,283 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=72) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=68, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:14 2024-05-30 13:48:14,283 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:14 2024-05-30 13:48:14,283 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 6089
2024-05-30 15:48:14 2024-05-30 13:48:14,788 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=72): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:14 2024-05-30 13:48:14,788 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:14 2024-05-30 13:48:14,788 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:14 2024-05-30 13:48:14,788 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=69) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:14 2024-05-30 13:48:14,788 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:14 2024-05-30 13:48:14,788 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 5584
2024-05-30 15:48:14 2024-05-30 13:48:14,788 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=73) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=69, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:14 2024-05-30 13:48:14,789 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:14 2024-05-30 13:48:14,789 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 5584
2024-05-30 15:48:15 2024-05-30 13:48:15,293 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=73): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:15 2024-05-30 13:48:15,293 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:15 2024-05-30 13:48:15,294 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:15 2024-05-30 13:48:15,294 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=70) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:15 2024-05-30 13:48:15,294 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:15 2024-05-30 13:48:15,294 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 5079
2024-05-30 15:48:15 2024-05-30 13:48:15,294 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=74) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=70, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:15 2024-05-30 13:48:15,295 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:15 2024-05-30 13:48:15,295 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 5078
2024-05-30 15:48:15 2024-05-30 13:48:15,798 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=74): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:15 2024-05-30 13:48:15,798 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:15 2024-05-30 13:48:15,799 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:15 2024-05-30 13:48:15,799 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=71) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:15 2024-05-30 13:48:15,799 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:15 2024-05-30 13:48:15,799 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 4574
2024-05-30 15:48:15 2024-05-30 13:48:15,799 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=75) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=71, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:15 2024-05-30 13:48:15,799 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:15 2024-05-30 13:48:15,799 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 4573
2024-05-30 15:48:16 2024-05-30 13:48:16,304 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=75): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:16 2024-05-30 13:48:16,305 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:16 2024-05-30 13:48:16,305 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:16 2024-05-30 13:48:16,305 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=72) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:16 2024-05-30 13:48:16,305 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:16 2024-05-30 13:48:16,305 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 4067
2024-05-30 15:48:16 2024-05-30 13:48:16,305 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=76) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=72, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:16 2024-05-30 13:48:16,306 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:16 2024-05-30 13:48:16,306 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 4066
2024-05-30 15:48:16 2024-05-30 13:48:16,810 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=76): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:16 2024-05-30 13:48:16,810 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:16 2024-05-30 13:48:16,811 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:16 2024-05-30 13:48:16,811 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=73) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:16 2024-05-30 13:48:16,811 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:16 2024-05-30 13:48:16,811 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 3562
2024-05-30 15:48:16 2024-05-30 13:48:16,811 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=77) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=73, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:16 2024-05-30 13:48:16,811 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:16 2024-05-30 13:48:16,811 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 3561
2024-05-30 15:48:17 2024-05-30 13:48:17,314 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=77): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:17 2024-05-30 13:48:17,315 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:17 2024-05-30 13:48:17,315 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:17 2024-05-30 13:48:17,315 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=74) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:17 2024-05-30 13:48:17,315 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:17 2024-05-30 13:48:17,315 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 3057
2024-05-30 15:48:17 2024-05-30 13:48:17,315 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=78) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=74, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:17 2024-05-30 13:48:17,316 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:17 2024-05-30 13:48:17,316 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 3057
2024-05-30 15:48:17 2024-05-30 13:48:17,819 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=78): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:17 2024-05-30 13:48:17,819 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:17 2024-05-30 13:48:17,820 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:17 2024-05-30 13:48:17,820 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=75) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:17 2024-05-30 13:48:17,820 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:17 2024-05-30 13:48:17,820 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 2553
2024-05-30 15:48:17 2024-05-30 13:48:17,820 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=79) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=75, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:17 2024-05-30 13:48:17,821 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:17 2024-05-30 13:48:17,821 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 2552
2024-05-30 15:48:18 2024-05-30 13:48:18,330 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=79): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:18 2024-05-30 13:48:18,330 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:18 2024-05-30 13:48:18,331 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:18 2024-05-30 13:48:18,331 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=76) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:18 2024-05-30 13:48:18,331 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:18 2024-05-30 13:48:18,331 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 2042
2024-05-30 15:48:18 2024-05-30 13:48:18,331 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=80) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=76, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:18 2024-05-30 13:48:18,332 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:18 2024-05-30 13:48:18,332 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 2040
2024-05-30 15:48:18 2024-05-30 13:48:18,836 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=80): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:18 2024-05-30 13:48:18,836 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:18 2024-05-30 13:48:18,837 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:18 2024-05-30 13:48:18,837 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=77) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:18 2024-05-30 13:48:18,837 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:18 2024-05-30 13:48:18,837 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 1536
2024-05-30 15:48:18 2024-05-30 13:48:18,837 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=81) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=77, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:18 2024-05-30 13:48:18,838 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:18 2024-05-30 13:48:18,838 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 1534
2024-05-30 15:48:19 2024-05-30 13:48:19,343 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=81): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:19 2024-05-30 13:48:19,343 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:19 2024-05-30 13:48:19,344 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:19 2024-05-30 13:48:19,344 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=78) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:19 2024-05-30 13:48:19,344 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:19 2024-05-30 13:48:19,344 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 1029
2024-05-30 15:48:19 2024-05-30 13:48:19,344 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=82) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=78, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:19 2024-05-30 13:48:19,345 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:19 2024-05-30 13:48:19,345 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 1027
2024-05-30 15:48:19 2024-05-30 13:48:19,417 [flink-akka.actor.default-dispatcher-13] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Trigger heartbeat request.
2024-05-30 15:48:19 2024-05-30 13:48:19,418 [flink-akka.actor.default-dispatcher-16] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received heartbeat request from 7d46956d08c4d3e636e723818e0985fb.
2024-05-30 15:48:19 2024-05-30 13:48:19,419 [flink-akka.actor.default-dispatcher-13] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Trigger heartbeat request.
2024-05-30 15:48:19 2024-05-30 13:48:19,420 [flink-akka.actor.default-dispatcher-18] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Received heartbeat request from 7d46956d08c4d3e636e723818e0985fb.
2024-05-30 15:48:19 2024-05-30 13:48:19,421 [flink-akka.actor.default-dispatcher-13] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Received heartbeat from ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff.
2024-05-30 15:48:19 2024-05-30 13:48:19,421 [flink-akka.actor.default-dispatcher-13] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager  - Received slot report from instance 7f90e2a01ddd0421ecb568d96eaba705: SlotReport{
2024-05-30 15:48:19     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_0, allocationID=8d65a0633b594e1023055f8eb5d4271d, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:48:19     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_1, allocationID=1682416b57c3204f1e47034ed712058a, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:48:19     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_2, allocationID=b8b5242c6762175095a12034622f0abe, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:48:19     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_3, allocationID=6a1740c95dc7f606c4106bac93511e32, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:48:19     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_4, allocationID=00eeda8d0616dc2caf6cec5a00ec1267, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:48:19     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_5, allocationID=77ba640e4dccc1995b4af4cd8b888262, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:48:19     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_6, allocationID=6ec3018dfd7ad2d8dcaa869612169256, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}
2024-05-30 15:48:19     SlotStatus{slotID=ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff_7, allocationID=0a6a4da3bdbd82f89f0b6179ebdf87a3, jobID=b2acee74555094750d6ee11d259188ed, resourceProfile=ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}}}.
2024-05-30 15:48:19 2024-05-30 13:48:19,421 [flink-akka.actor.default-dispatcher-13] DEBUG org.apache.flink.runtime.io.network.partition.ResourceManagerPartitionTrackerImpl  - Processing cluster partition report from task executor ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff: PartitionReport{entries=[]}.
2024-05-30 15:48:19 2024-05-30 13:48:19,421 [flink-akka.actor.default-dispatcher-13] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager  - Received heartbeat from 85185983243c48e6bbb6f78065441b1e.
2024-05-30 15:48:19 2024-05-30 13:48:19,560 [flink-akka.actor.default-dispatcher-18] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Trigger heartbeat request.
2024-05-30 15:48:19 2024-05-30 13:48:19,561 [flink-akka.actor.default-dispatcher-19] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor  - Received heartbeat request from 85185983243c48e6bbb6f78065441b1e.
2024-05-30 15:48:19 2024-05-30 13:48:19,564 [flink-akka.actor.default-dispatcher-18] DEBUG org.apache.flink.runtime.jobmaster.JobMaster  - Received heartbeat from ebbe13d6-9ee6-4e67-aeff-4f1a290dd9ff.
2024-05-30 15:48:19 2024-05-30 13:48:19,851 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=82): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:19 2024-05-30 13:48:19,852 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:19 2024-05-30 13:48:19,853 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:19 2024-05-30 13:48:19,853 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=79) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:19 2024-05-30 13:48:19,853 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:19 2024-05-30 13:48:19,853 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 521
2024-05-30 15:48:19 2024-05-30 13:48:19,853 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=83) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=79, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:19 2024-05-30 13:48:19,854 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:19 2024-05-30 13:48:19,854 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 518
2024-05-30 15:48:20 2024-05-30 13:48:20,358 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=83): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:20 2024-05-30 13:48:20,358 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:20 2024-05-30 13:48:20,358 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:20 2024-05-30 13:48:20,359 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=80) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:20 2024-05-30 13:48:20,359 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:20 2024-05-30 13:48:20,359 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 14
2024-05-30 15:48:20 2024-05-30 13:48:20,359 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=84) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=80, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:20 2024-05-30 13:48:20,359 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:20 2024-05-30 13:48:20,359 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 13
2024-05-30 15:48:20 2024-05-30 13:48:20,376 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Finished running task FetchTask
2024-05-30 15:48:20 2024-05-30 13:48:20,376 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Cleaned wakeup flag.
2024-05-30 15:48:20 2024-05-30 13:48:20,376 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher  - Prepare to run FetchTask
2024-05-30 15:48:20 2024-05-30 13:48:20,376 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Getting next source data batch from queue
2024-05-30 15:48:20 2024-05-30 13:48:20,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Current fetch is finished.
2024-05-30 15:48:20 2024-05-30 13:48:20,377 [Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.flink.connector.base.source.reader.SourceReaderBase  - Source reader status: NOTHING_AVAILABLE
2024-05-30 15:48:20 2024-05-30 13:48:20,377 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:20 2024-05-30 13:48:20,377 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 10000
2024-05-30 15:48:20 2024-05-30 13:48:20,864 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=84): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:20 2024-05-30 13:48:20,864 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:20 2024-05-30 13:48:20,865 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:20 2024-05-30 13:48:20,865 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=81) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:20 2024-05-30 13:48:20,865 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:20 2024-05-30 13:48:20,865 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9512
2024-05-30 15:48:20 2024-05-30 13:48:20,865 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=85) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=81, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:20 2024-05-30 13:48:20,866 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:20 2024-05-30 13:48:20,866 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9511
2024-05-30 15:48:21 2024-05-30 13:48:21,373 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Received FETCH response from node 1 for request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=85): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1036515551, responses=[])
2024-05-30 15:48:21 2024-05-30 13:48:21,373 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Node 1 sent an incremental fetch response with throttleTimeMs = 0 for session 1036515551 with response=(), implied=(aisdata-0)
2024-05-30 15:48:21 2024-05-30 13:48:21,373 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Added READ_UNCOMMITTED fetch request for partition aisdata-0 at position FetchPosition{offset=2000, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}} to node kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:21 2024-05-30 13:48:21,373 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Built incremental fetch (sessionId=1036515551, epoch=82) for node 1. Added (), altered (), removed (), replaced () out of (aisdata-0)
2024-05-30 15:48:21 2024-05-30 13:48:21,373 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(aisdata-0), canUseTopicIds=True) to broker kafka:9092 (id: 1 rack: null)
2024-05-30 15:48:21 2024-05-30 13:48:21,374 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9003
2024-05-30 15:48:21 2024-05-30 13:48:21,374 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=13, clientId=flink_consumer-3, correlationId=86) and timeout 30000 to node 1: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1036515551, sessionEpoch=82, topics=[], forgottenTopicsData=[], rackId='')
2024-05-30 15:48:21 2024-05-30 13:48:21,374 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Skipping fetch for partition aisdata-0 because previous request to kafka:9092 (id: 1 rack: null) has not been processed
2024-05-30 15:48:21 2024-05-30 13:48:21,374 [Source Data Fetcher for Source: Kafka Source -> (Map, Map -> Timestamps/Watermarks -> Map) (4/8)#0] TRACE org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=flink_consumer-3, groupId=flink_consumer] Polling for fetches with timeout 9002